content,newcol
"new view hypercube genus introduction hypercubes two cell embeddings graph genus embeddings hypercubes parallel genus embeddings instruction ringel discovered formula minimum genus torus dimensional hypercube graph embedded give new proof formula building surface union certain face hypercube skeleton odd dimension entire skeleton decomposes copy surface, intersection two copy hypercube graph graph drawn surface without crossed edge kuratowski theorem theorem implies complete bipartite graph figure cannot drawn sphere plane without crossed edge min one try draw sphere, always fail however, drawn torus, shown figure genus graph denoted least integer drawn closed, connected, orientable surface genus without edge crossing sphere genus surface hole genus thus figure also show together drawing torus genus respectively indeed, ringel proved thus drawing figure optimal genus formula established well known family graph instance, difficult proof simple formula instrumental settling heawood map coloring conjecture chapter dimensional hypercube graph ringel beineke harary used recursive argument exploiting hypercube product structure deduce proof lead generalization like contrast, short, visual proof directly construct genus surface square face cube show odd skeleton cube union copy genus surface, common faces, intersecting pairwise section define hypercubes, skeleta, cell embeddings graph surfaces, state euler formula genus proof equation section section give bonus factorization skeleton genus surface let denote unit interval let denote boundary use notation useful regard interval active inactive manner described dimensional hypercube, cube polytope thus intersection half space see introduction polytopes vertex element identify binary string length example, etc edge connected component product one active factor inactive factor thus edges, line segment joining two vertex differ exactly one coordinate namely active coordinate face square connected component two factor rest thus faces, boundary face consists four edge likewise face formed choosing three position face cube whose boundary six face general, cube face formed choosing active factor face cube brevity call faces, faces, face vertices, edges, faces, respectively, stated face called facet two opposite facet two component sole th factor reader verify two nonopposite facet intersect face collectively facet form boundary skeleton union faces, skeleton union square face skeleton hypercube graph, denoted vertex digit binary strings, edge connects two vertex differ exactly one position figure show hypercube graph dimension bipartite, is, vertex partitioned two set say, black white edge join black vertex white vertex black vertex binary string odd number s, white vertex even number s, figure figure illustrates another nice feature hypercubes edge colored color edge whose endpoint differ th coordinate get color note vertex incident exactly one edge color surface mathematical object look locally like plane, differ radically plane globally earth surface example look locally like plane least flat land globally plane all, sphere exactly, surface compact connected topological space point neighborhood homeomorphic open disk see introductory text chapter development informal remark make orientable surface sphere, torus, holed torus, and, general, surface hole nonorientable surface one cut bius band of, focus number hole orientable surface called genus denote unique surface genus arbitrary orientable surface, genus denoted sphere genus thus denoted figure show example noted earlier, genus graph smallest integer drawn without crossed edge drawing regarded continuous injection called embedding embedding surface genus called genus embedding figure show genus embeddings embedding divide regions, connected component cell embedding one region homeomorphic open disk region cell embedding called face every genus embedding cell embedding theorem example, embedding figure three face two square one octagon embedding eight faces, square euler formula theorem implies cell embedding connected graph closed orientable surface vertices, edges, faces, checking embedding figure get figure get face cell embedding connected graph vertex edge face gon, edge exactly two faces, get graph bipartite, triangles, equation yield lemma corollary vertices, edges, bipartite, ready theorem genus hypercube graph color edge color edge joining vertex differ th coordinate given color face whose edge colored bicolored pair assemble collection face one bicolors one bicolors, face particular bicolor, edge belongs exactly two face color two face bicolors addition modulo thus face arranged cyclicly around vertex, manner described figure follows face form surface skeleton embedded surface square regions, connected connected assume moment surface orientable genus formula thus embedded surface genus lowest genus possible lemma say yes finish proof must verify orientable indeed something prove here, skeleton contains bius strip figure left must verify none exist this, note face local orientation given right hand rule either one black vertex place right hand black vertex finger pointing edge color edge color thumb point direction square, finger indicate counterclockwise orientation square white vertices, thumb point figure show orientation preserved move square adjacent square follows orientable let carry construction proof first, color edge solid, dashed, dotted, figure construction, form surface including solid dashed faces, dashed dotted faces, dotted solid face fact face get six face shown upper left figure form surface cube, topologically equivalent sphere next, consider edge colored figure construction dictate form surface including solid dashed faces, dashed dotted faces, dotted dash dotted faces, dash dotted solid face sixteen face see bottom left figure resulting surface torus surface include solid dotted dashed dash dotted face clearly see perimeter edge belong included face walking hole torus, one walk four solid dotted face see perimeter four dashed dash dotted faces, inside torus representation figure long history according robbin perspective view standard originated schlegel let apply construction get genus embedding assign specific color edge avoid visual clutter image say five edge color thus include cube face bicolored obtain embedding shown figure embedding include cube face bicolored thus embedding exactly half face cube one walk model see edge half face without intersection half face cube form surface isometric one see section missing face clearly visible perimeter edge face belong embedding one nice feature embeddings aid greatly visualization hypercubes one can, example, easily pick ten facet see fit together highlight this, offer exercise related model figure exercise locate face square model exercise identify ten facet facet cube exercise cube face one cube find least one, locate two cube facet share exercise arbitrary vertex, find five cube facet share vertex approach cube embedding extrinsic describe recursive procedure hook together two lower genus surface family connecting tube contrast, intrinsic method interesting consequence entire skeleton decomposed copy genus surface recall cycle graph hamiltonian cycle contains vertex graph complete graph graph vertex set edge joining pair distinct vertex ordering give rise hamiltonian cycle whose edge arithmetic modulo arguing proof theorem hamiltonian cycle union face bicolored addition mod surface genus embedding fact, permutation induces permutation standard unit vector carry isometrically onto sending vertex vertices, edge edges, face face another hamiltonian cycle share edge, call family surface parallel family every face square belongs exactly one collection hamiltonian cycle hamiltonian decomposition edge belongs exactly one cycle long known odd hamiltonian decomposition hamiltonian cycle problem recreational mathematics, asking whether one could find seating arrangement around round table gave pair people unique side side appearance see get nice consequence hypercube odd hamiltonian decomposition give rise parallel family genus embeddings is, skeleton decomposed face disjoint isometric copy genus embeddings let take hamiltonian decomposition genus embeddings intersect pairwise proof theorem faces, copy contain face completing article, found da also obtained theorem theorem using general version approach, avoiding issue nonorientability induction dimension da credit idea using skeleton coxeter construction certain skew polyhedron indeed, two coxeter skew polyhedron coincide genus surface though coxeter refer graph genus fact, idea generalized direction decomposition edge disjoint cycles, possible odd theorem euler yield parallel family surface skeleton see parallel family given theorem surface pairwise isometric polytopal perspective applied graph genus question nonorientable genus cube seems many nice",mathematics
"extremal problem martingale transforms, introduction simplest foliation example linear quadratic function horizontal herringbone investigation vector field equation fissure example polynomial third degree instruction paper, begin series study extremal problem estimating distribution martingale transforms bounded martingale bellman function corresponding problem pointwise minimal diagonally concave function horizontal strip, satisfying certain given boundary condition describe basic structure arise constructing function present solution case asymmetric boundary condition sufficiently small width strip article, start series paper going describe algorithm constructing bellman function extremal problem described inspired successful description algorithm constructing bellman function sufficiently wide class integral extremal problem bmo realized also recent generalization result general class functions, including among others muckenhoupt classes, see original extremal problem infinite dimensional functional space reduced problem constructing pointwise minimal locally concave function corresponding two dimensional domain parabolic strip case bmo given boundary condition, see minimal locally concave function turn linear along direction interior point domain thus, two dimensional domain foliated linear segment two dimensional subdomains, call structure foliation foliation constructed, possible reconstruct bellman function obtain sharp estimate original extremal problem similar approach used obtain sharp estimate various question martingale theory general random process go back called burkholder method many example usage method literature review topic found studying estimate martingale transformations, instead locally concave function called diagonally concave function arise concave along line segment form const recently, discovered certain class extremal problem martingale transforms closely related corresponding extremal problem bmo burkholder method reduces problem estimating distribution martingale transform bounded martingale finding minimal diagonally concave function horizontal strip, satisfying certain symmetric boundary condition upper lower boundary strip turn structure function sense coincides structure minimal locally concave function parabolic strip corresponding boundary data detail found discovering connection, desire consider broader class problem horizontal strip arose naturally, arbitrary, necessarily symmetric, boundary value specified boundary strip solving problem, guided two consideration first, generalization seemed natural dictated logic development theory is, interested understanding construct bellman function specific problem understand algorithm allows constructing necessary function wide class problem since guided internal task method development, looking specific application although many example series papers, example applying theory external problem second, since considerable interest various estimate martingale transforms see lose hope theory may find application future external problem however, ask reader seek application proposed text let proceed formal statement problem let standard probability space, dense filtration trivial algebra let two martingale space generated integrable function let martingale difference due triviality say martingale martingale transformation martingale exists sequence function measurable respect follows, restrict case almost everywhere given consider following two dimensional domain pair function generating martingale called admissible point almost everywhere set admissible pair denoted adm let two measurable function set define function formula main goal study construct bellman function given solving problem, provide description joint distribution function martingale transformation recent work problem solved case symmetric boundary condition description given condition function defined two dimensional domain called diagonally concave concave direction const following theorem go back burkholder proof found, example, chapter book function diagonally concave strip satisfies boundary condition moreover, pointwise minimal among function satisfying property function defined subdomain called bellman candidate candidate bellman function following condition satisfied diagonally concave satisfies boundary condition point one following condition hold exists straight line segment going one direction const connects point function linear function linear direction const neighborhood recent paper novikov proved remarkable theorem allows one verify given diagonally concave function pointwise minimal among function boundary value present simplified version, theorem let diagonally concave function say extremal direction endpoint segment endpoint lie parallel function linear, differentiable direction let function diagonally concave upper semi continuous discrete set discontinuity let assume interior point one following condition hold linear extremal direction linear extremal direction extremal direction linear direction neighborhood pointwise minimal among diagonally concave function boundary value future, construct diagonally concave function satisfy assumption theorem thus obtain minimal function according theorem function bellman function original extremal problem simplicity, assume boundary function smooth, although presented constructions, smoothness sufficient use theorem also assume function satisfy estimate since looking minimal possible diagonally concave function, concavity must degenerate point least one direction either along line segment const along line segment const call line segment extremal first case, call right extremal segments, second case, left extremal segment section, consider simplest case subregion foliated one type extremal segment either right one left one subregion foliated right extremal segment denoted similarly, subregion foliated left extremal segment denoted case right left extremal segment symmetric suppose linear along right extremal segment foliate mean boundary point connected extremal segment along linear words, equivalently, construction, linear therefore concave along direction const need check concavity along direction const fixed point define check function concave compute derivative value function derivative evaluated value derivative evaluated fix extremal segment passing point is, line concavity point extremal segment orthogonal direction implies inequality hold expression linear non negative non negative thus, obtain condition proved following statement function defined bellman candidate region condition satisfied symmetric case left extremal segments, bellman candidate given formula instead condition obtain following inequality formulate symmetric statement characterizing bellman candidate case function defined bellman candidate region condition satisfied approach inequality condition take limiting form limiting form condition approach opposite inequality lead following statement let sufficiently small exists function defined bellman candidate sufficiently small exists function defined bellman candidate since function sufficiently smooth, condition implies condition hold sufficiently small given also neighborhood size therefore, statement follows proposition case conclusion follows proposition let function uniformly bounded entire real line uniformly separated zero, sufficiently small function simple right foliation case simple left foliation case conclusion follows directly rewrite condition using taylor formula case similar let function identically equal constant expression left side coincide bellman function given simple foliation similarly, expression left side coincide bellman function given simple foliation bellman function linear let suppose define condition satisfied condition satisfied thus, two region simple foliations, remaining triangle vertex triangle, bellman function linear diagonal direction foliation symmetric one described respect axis need swap so, left consider case relation hold foliation similarly, relation hold, foliation particular, function linear along diagonal direction consider foliation arise neighborhood point two family extremal segment distinct direction meet point lying curve, call foliation herringbone, considering curve spine herringbone extremal segment expanding point spine rib rib go spine boundary, call herringbone vertical see fig go opposite boundary strip, call horizontal vertical herringbone extend upwards downwards horizontal herringbone extend left right right left, depending direction extending, call left right, respectively see fig horizontal herringbone whose spine connects two opposite boundary strip called fissure fissure one four direction right fissure start bottom boundary, call southeast se fissure start top boundary, call northeast ne fissure left fissure start bottom boundary, call southwest sw fissure start top boundary, call northwest nw fissure see fig note cases, name fissure indicates extends section consider different fissure boundary subdomains left right foliation study local behavior horizontal herringbone consider case left herringbone extends left right right one, everything symmetric assume spine left herringbone graph function interval, say foliation defined follows point e, point spine, two rib start one go point upper boundary, go point lower boundary, see left part fig parameter considered function variable point lying domain foliated rib rib going lower boundary foliate domain extremal segment spine herringbone call lower rib function implicitly defined identity similarly, extremal segment going spine upper boundary called upper rib identity holds, condition necessary foliation assume strict inequality except possibly finite number point spine know value spine denote def calculate value rib using linearity writing formula let agree following simplification notation future, omit argument functions, assuming derivative always calculated value derivative calculated value derivative calculated special case argument satisfy rule, explicitly written let write formula bellman candidate left herringbone function must completely determined boundary condition first step, derive important relationship function bellman candidate smooth corresponding foliation left herringbone described above, case right herringbone, consider case left herringbone symmetric case considered absolutely similarly however, formally obtained symmetry this, need change direction axis, e, change sign first derivative consider plane containing following three point segment belong graph function linear corresponding direction since diagonally concave smooth, plane tangent graph point therefore, vector tangent graph along spine herringbone parallel plane hence, coincides let show equation necessary also sufficient condition function smooth proving this, simplify calculation introduce three auxiliary function variable rewrite follows take following form meaning coefficient evident formula sign slope corresponding extremal line condition function defined smooth start auxiliary differentiation formula useful later first, relation lead identity differentiating let calculate derivative respect using equivalent form took account introduce two notation rewritten similarly, obtain differentiate respect see continuous side spine, limit side point spine equal e, continuous since function smooth, enough continuity gradient alternatively, also easy directly verify continuity using differentiate respect therefore, continuous side spine, limit side point spine equal function defined bellman candidate condition concave direction const functions, concavity equivalent inequality check inequality separately part herringbone, thanks smoothness, implies desired concavity entire herringbone let defined using function satisfying condition concave direction const defined boundary value follows first, differentiate respect differentiate expression respect thus, prove diagonal concavity need calculate compare obtained expression first, consider case differentiating respect obtain expression linear extremal line e, fixed non positive value non positive thus, obtain following necessary condition consider lower half herringbone, similarly, obtain necessary condition follow note condition necessary also sufficient diagonally concave comparing obtain necessary condition equivalent equality defines spine non zero given condition satisfied, obtain remaining condition transform formula implies left horizontal herringbone intersect axis point cannot calculate directly however, point isolated, pa limit find term boundary value slope spine point value derivative evaluated formula work happen e, multiple root case considered one subsequent paper symmetrically, right horizontal herringbone intersect axis point see spine horizontal herringbone intersects axis coincides segment, condition show possible function differ constant corresponding interval small bellman function inside interval resemble one built symmetric strip, e, everywhere see however, ready consider case therefore postpone investigation two equation two unknown function consider definition term function defined differential equation derive substituting defines spine left horizontal herringbone foliation diagonally concave function boundary value satisfies following differential equation differentiate get using obtain written substituting formula collecting term obtain coincides conclude section listing change formula left horizontal herringbone need made obtain corresponding formula right herringbone mentioned beginning proof proposition need change direction axis, thus formally reverse sign first derivative distinguish right left herringbones, use index example, function defining spine right left herringbones, value corresponding spines, end section, consider right herringbone, object marked index usually omit index subtle change made argument derivative argument function function satisfies relation instead therefore, instead obtain definition remains same, well definition change sign derivative take form formula given proposition see make change definition changing sign derivative instead write then, instead get formula remains same, need change sign instead condition obtain condition diagonal concavity lead relation giving definition different sign front instead obtain instead expression remains must change sign condition diagonal concavity situation, natural introduce function definition, condition diagonal concavity remains unchanged finally, analogue following equation far, used notation function variable introduce function defined entire plane except axis function defined case right left herringbone function respectively, expressed term follows state condition necessary sufficient diagonal concavity herringbone also region condition concavity rewritten condition concavity section, explore behavior integral curve vector field differential equation describing left herringbone shift first coordinate instead write remains second coordinate thus, left herringbone, argument instead argument instead convenient consideration evolution integral curve parameter increase node move grows corresponding point intersection left herringbone central line strip e, left herringbone move right following, consider parametrization investigated integral curve system write shorter formulas, omit argument derivatives, assuming function sign always argument thus, instead write start description stationary point system, e, point right hand side equation zero first, consider stationary point lying central line form determined equation interval central line stationary point integral curve vector field left herringbone intersect central line strip point solution symmetrically, point intersection right herringbone central line form describe behavior integral curve neighborhood stationary point, calculate jacobian matrix system let root stationary point furthermore, assume equation finite number simple root therefore, jacobian matrix identity operator scalar multiplier mean stationary point always dicritical node, local behavior integral curve shown figure mentioned earlier, assume following condition consider two curve neighborhood defined equation mean mean smooth, equation unique smooth solution neighborhood follows implicit function theorem fact derivative left hand side respect equal curve intersect node later, see small intersection curve boundary intersection curve boundary give two stationary point vector field curve neighborhood described equation curve neighborhood described equation sign function right curve coincides sign expression left, sign opposite fixed consider function interval small enough, function opposite sign endpoint interval therefore, inside interval, exists root uniqueness root guaranteed implicit function theorem sign function right curve coincides sign derivative left, sign opposite prove representation expand function second order term then, constant term give coefficient give proof second part proposition completely similar instead consider let calculate slope curve similarly, slope curve given thus, make following conclusion small slope curve positive le upper half strip greater lower half small slope curve negative sufficiently small, exists unique root equation e, moreover, similarly, exists unique root equation e, moreover, following simple statement play important role investigating behavior integral curve vector field slope integral curve field point strictly increasing strictly decrease obtain following expression slope integral curve differentiating expression respect give formula directly implies desired result investigate vector field around stationary point since satisfies formula take form small value parameter eigenvalue matrix right hand side e, saddle point eigenvectors meaning two integral curve passing stationary point slope behavior integral curve around stationary point shown fig need detailed approximation eigenvector corresponding eigenvalue approach easy compute corresponding eigenvector equal thus slope corresponding integral curve important compare slope curve slope curve use calculate slope curve thus, relative position two curve near determined sign consider stationary point since satisfies formula take form therefore, small matrix eigenvalue also saddle point eigenvectors meaning two integral curve passing stationary point slope behavior integral curve near stationary point shown fig combining information, understand behavior integral curve vector field near three stationary point small value overall picture shown fig end section, list change need made consider vector field equation integral curve may spine right herringbone case, symmetric picture sufficiently small following three stationary point unique solution equation interval unique solution equation interval furthermore, defined ready construct foliation call fissure first, let consider left fissure recall horizontal herringbone extend left right one boundary fissure must intersect middle line strip, meaning must value previous section, know point must stationary point, also seen directly right herringbone, condition thus, precisely point around could construct either right left simple foliation small see section section, sufficiently small build fissure near point solves equation sw fissure shown fig term sw fissure mean fissure come southwest words, horizontal herringbone extending left right bottom boundary top denote region foliated fissure sw here, first coordinate endpoint segment intersection foliated region middle line foliation may appear possible boundary value therefore, impose following additional condition simple root equation meaning foliation appear additional condition satisfied complicated considered later goal prove following statement let let root equation described corollary sufficiently small exists sw fissure spine function defined interval solves equation formula function given defines bellman candidate sw foliated fissure exists standard bellman candidate see together described candidate sw form smooth bellman candidate union three region sign second third derivative determine direction corresponding fissure thus, reflection respect line give se fissure let let root equation described corollary sufficiently small exists se fissure spine function defined interval solves equation formula function given defines bellman candidate se foliated fissure exists standard bellman candidate see together described candidate se form smooth bellman candidate union three region reflection respect line swap lead following statement let let root equation described corollary sufficiently small exists nw fissure spine function defined interval solves equation formula function given defines bellman candidate nw foliated fissure exists standard bellman candidate see together described candidate nw form smooth bellman candidate union three region let let root equation described corollary sufficiently small exists ne fissure spine function defined interval solves equation formula function given defines bellman candidate ne foliated fissure exists standard bellman candidate see together described candidate ne form smooth bellman candidate union three region consider case sw fissure neighborhood this, need solve equation seek solution interval boundary condition satisfying convexity condition investigating vector field preceding section, claimed exists exactly one integral curve field connecting node saddle point upper boundary prove statement describe detailed property curve recall, field horizontally shifted compared field generated equation mentioned integral curve give upper half herringbone point obtain lower half herringbone, must take unique integral curve starting node, directed towards lower boundary, together upper half form smooth curve natural parametrization see one bold curve figure need verify convexity condition satisfied ensure slope herringbone spine exceed e, construct desired foliation see figure corresponding function diagonally concave let denote integral curve field originating positive slope know curve exists unique moreover, slope described imposed condition derivative function ensure see slope curve e, le slope curve noted proposition region lie right curve upper half strip left curve lower half strip see figure consider open subdomain upper half strip bounded curve middle line vertical line explained, curve originating saddle point neighborhood point lie curve enters need prove cross boundary node note due assumption inequality satisfied neighborhood thus sufficiently small hold well inequality implies hence also satisfied then, see mean integral curve vector field graph function first coordinate slope integral curve field equal point intersection curve except, possibly, stationary point slope curve upper half strip strictly le see thus integral curve upper half strip intersect curve top bottom moving right left therefore, integral curve cannot exit boundary upper half strip furthermore, two integral curve vector field intersect stationary points, e, middle line intersect node thus, proved connects two stationary point saddle point node see figure fix temporarily consider slope curve equal see slope curve see meaning latter curve steeper neighborhood point therefore, sufficiently close lie consequently, curve also lie neighborhood point now, suppose intersects point since lie first point intersection, slope point intersection must le slope impossible within according proposition due continuity curve respect conclude lie left thus, curve intersect node shown integral curve thus slope strictly le upper half strip, need verify node fact, need check integral curve unit slope node purpose, calculate integral curve second order compare curve e, let integral curve interested defined equation then, obtain recall given smooth integral curve implies comparing obtained equation investigated integral curve equation curve e, see integral curve go left curve e, domain therefore cannot coincide conclude slope strictly le continue lower half strip, choose integral curve starting left slope thus, obtain smooth curve entire strip slope curve lower half strip strictly greater see remark reasoning similar given upper half strip show curve lower half strip intersection curve lie domain proved point curve second condition automatically satisfied sufficiently small now, prove small exists point intersection curve lower boundary strip denote first coordinate point check fix consider curve domain fix curve intersects line consider reason upper half strip, curve intersect curve larger located curve smaller therefore, exists point point intersection curve since slope strictly first coordinate point consequently, thus, constructed sw fissure domain sw point root equation construct required domain sufficient satisfy condition due need check first condition positive since expression definition see derivative strictly positive small conclude hold sufficiently small unfortunately, cannot say anything similar since slope curve inside strip lie strictly inequality always true sufficient construct simple left foliation domain left fissure this, need check condition satisfied left neighborhood again, due suffices check first condition, e, expand expression since expression strictly positive sufficiently small section, partially consider case boundary function third degree polynomial consider possible polynomial since described foliation arise third degree polynomial however, considered foliation allow describe case sufficiently small possible foliation considered forthcoming paper start case case considered section symmetry respect axis allows consider case otherwise, replace using symmetry respect axis, assume otherwise, swap first, consider simplest case constant, and, therefore, foliation symmetric case horizontal herringbone, spine axis see since assumed left herringbone case course, symmetric right herringbone thus, assume assumption, construct simple foliation small indeed, direct calculation, condition transforms condition take form small condition satisfied precisely, satisfied thus, right simple foliation condition satisfied left simple foliation construct infinite left herringbone, spine line consider case opposite case obtained swapping fact, explicitly solve equation since take following simple form solution equation represented family two special solution know herringbone impossible see remark herringbone spine given generate diagonally concave functions, minimal diagonally concave function generated spine check this, compute function see simple case, direct calculation give herringbone spine admissible diagonally concave function, integral line must lie region e, strip consider extremal line field generated equation easy plotting graph function value constant see fig obtain integral line passing given point, must shift graph appropriately along axis see sought extremal line foliate strip two horizontal asymptote get moreover, exponentially decay infinity show exp then, using conclude increase exponentially whereas herringbone increase polynomial mean herringbone give minimal diagonally concave function indeed, corresponding function minimal diagonally concave function according theorem concluding consideration case note obtain bellman function taking left herringbone right herringbone appear let turn case situation, expression one root construct fissure assumption sw fissure, assumption proposition satisfied addition proposition want check foliation take place e, foliation entire strip follows check this, need verify three fact construct sw fissure region sw construct simple right foliation region e, condition satisfied construct simple left foliation region e, condition satisfied purpose, need examine vector field closely convenient consider field strip also entire plane considered vector field four stationary point three already known fourth point second intersection two parabola given equation respectively see fig direct calculation show coordinate understand behavior integral curve around points, need compute jacobian matrix point see see always node point saddle since see behavior field two stationary point important goal simplest part task construct simple right foliation direct calculations, see turn note second inequality follows first one condition hold strictly increasing respect consider integral curve field start end lower boundary, corresponds spine sw herringbone reasoning repeat argument proof proposition there, used fact small enough here, consider arbitrary use specific expression boundary function find slope integral curve need compute eigenvectors matrix represent matrix characteristic polynomial matrix form thus eigenvalue eigenvectors given choose one two integral curve passing point which, shift right give spine desired sw herringbone specifically, must take eigenvector slope greater le mean take give slope eigenvector equal compare slope slope curve curve parabola see fig given equation slope slope strictly le expression thus, upper half strip, desired integral curve pa curve or, equivalently, right parabola e, domain since curve right parabola integral curve visualization picture presented fig comparison fig add several new line change notation parabola see denoted meaning integral curve field intersects line slope equal hold boundary except singular point also labeled parabola intersects integral curve slope equal therefore denoted slope upper boundary strip except singular point set point integral curve pa horizontally denoted consists two line latter line pa three stationary point cubic parabola pa four stationary point set point integral curve pa vertically except singular point finally, add integral curve fissure starting point together parabola pa parabola next stationary point reasoning explaining two curve cannot intersect earlier slope integral curve point strictly le contained proof proposition need show integral curve lower half strip pa domain this, need check end fissure left stationary point e, indeed, geometrically clear zero slope, integral curve must turn slope equal go vertically intersects slope equal intersects parabola intersects line this, course, happens strip explains guarantee fissure generates diagonally concave function but, see shortly, also ensures possibility constructing simple left foliation subsequent, need check condition situation, take form since slope main curve strictly le inequality first condition follows second condition precisely inequality verified concluding consideration case note sw fissure bounded e, always indeed, description set show line asymptote integral curve therefore, spine herringbone must intersect lower boundary strip finite point finally, let say word case due symmetry, consider case before, need investigate root polynomial discriminant quadratic polynomial negative, const applying proposition conclude simple right foliation small case however, grows, foliation appear considered yet, postpone complete study case also ready consider foliation arises discriminant quadratic polynomial zero, is, multiple root equation therefore, remaining part section, assume discriminant positive, e, equation two root denote root assuming assumption mean therefore, three possible situation see illustration possibility fig nw fissure near proposition sw fissure near proposition ne fissure near proposition sw fissure near proposition ne fissure near proposition se fissure near proposition note case impossible, assumption aim prove small always following foliation number close instead depending sign precisely, take need verify fulfillment condition construct condition interval construct leave verification reader, several hint precisely defined, determine point corresponding quadratic polynomial change sign second condition always weaker small automatically satisfied boundary defined strict, instead checking sign corresponding quadratic polynomial points, check purpose, sufficient know following relation hold slope spine lie strictly",mathematics
"interacting stochastic process sparse random graph introduction classical mean field result interacting stochastic process interacting process sparse graph hydrodynamic limit marginal dynamic tree open question instruction reporting error background question interest interacting diffusion mean field limit nonlinear diffusion process interacting jump process mean field limit limitation mean field approximation local convergence sparse graph sequence hydrodynamic limit markov random field property outline derivation local equation diffusion line local equation diffusion unimodular galton watson tree marginal dynamic pure jump process generalization approximation long time behavior invariant measure local equation refined convergence result analytic characterization interacting particle system game experimental large ensemble stochastically evolving interacting particle describe phenomenon diverse field including statistical physics, neuroscience, biology, engineering systems, infinitesimal evolution particle depends state history state history neighboring particle respect underlying, possibly random, interaction graph high dimensional process typically complex amenable exact analysis, dynamic quite well understood interaction graph complete graph case, classical theorem show limit number particle go infinity, dynamic empirical measure law typical particle coincide characterized term much tractable dynamical system reduced dimension called mean field limit contrast, recently much known corresponding convergence result complementary case interaction graph sparse ie, uniformly bounded average degree article provides brief survey classical work describes recent progress sparse regime relies combination technique random graph theory, markov random fields, stochastic analysis article concludes discussing ramification application posing several open problem keywords interacting particle systems, markov random fields, mean field limits, nonlinear processes, sparse random graphs, local convergence, erd nyi graphs, galton watson trees, unimodularity msc subject classification primary secondary recurring theme probability theory emergence deterministic predictable behavior aggregation many random element classical result strong law large number established kolmogorov state given sequence random variable independent identically distributed iid finite mean equivalently, distributed according product probability measure probability measure borel set satisfies probability one, similar spirit, glivenko cantelli theorem, also established provides information asymptotic behavior empirical measure iid random variable specifically, show probability one, represents dirac delta measure denotes law distribution random variable convergence called kolmogorov distance, particular implies weak convergence, is, every bounded, continuous function similar result also hold random variable independent, exhibit form weak dependence instance, consider triangular array dependent random variable common mean, finite variances, exhibit asymptotic correlation decay sense exist positive real number sup cov represents covariance follows chebyshev inequality normalized partial sum satisfies hand, many interesting case one want analyze large collection strongly dependent random element analysis often facilitated graphical model representations, capture conditional independence property random element via graph specific class graphical model important present discussion markov random field mrf precise definition given section theory mrfs associated gibbs measure go back late pioneering work dobrushin lanford ruelle motivated model statistical physic involving static interacting random element case key question efficient computation analytical characterization marginal distribution high dimensional ensemble random element article focus dynamic large ensemble stochastic process whose interaction governed underlying graph represents finite countably infinite vertex set subset unordered pair distinct vertex represent undirected edge graph graph always assumed simple ie, pair comprised two distinct vertex locally finite, is, size neighborhood finite notation often also used indicate given graph initial condition interested collection stochastic process indexed vertex satisfies whose interaction structure governed graph specifically, infinitesimal evolution time depends state history state history neighboring particle time note includes case markovian, infinitesimal evolution depends current state particles, well non markovian evolutions, infinitesimal evolution particle depend history history particle neighbrhood conciseness, restrict discussion two type dynamic interacting diffusions, described section interacting jump processes, described section given markovian non markovian interacting process large finite graph, quantity interest include following macroscopic behavior system captured global empirical measure process, defined note random probability measure state space encodes fraction particle taking value different measurable subset state space microscopic behavior, particular marginal dynamic typical particle mean dynamic vertex referred root, assumed chosen uniformly random finite vertex set important question ascertain dynamic depends graph topology due complexity high dimensionality dynamics, quantity typically amenable exact analysis efficient computation goal instead identify tractable approximation reduced dimension rigorously justified limit theorems, number particle go infinity desirable goal obtain autonomous characterization limiting marginal dynamic typical particle evolution empirical measure, refer full particle system dynamic section review well understood case clique complete graph vertices, pair distinct vertex connected edge see figure suitable initial condition convergence result context interacting diffusion model go back half century seminal work mckean fall rubric mean field limit briefly described section broad conditions, limits, law exist coincide, described certain nonlinear stochastic process recent work also considered interacting process certain dense random graph sequence generic example random graph called erd nyi graph graph vertex pair vertex edge probability independently edge see figure realization respectively motivated study synchronization phenomena, work considers suitably scaled pairwise interacting diffusion dense erd nyi graph sequence divergent average degree show law converges mean field limit complete graph case key idea regime, particle weakly interacting become asymptotically independent, thus empirical measure behaves iid case described section main focus article complementary setting interacting stochastic process sequence sparse possibly random graphs, average degree vertex uniformly bounded typical example erd nyi graph sequence extensive analysis various interacting stochastic process deterministic sparse graphs, originating work spitzer followed significant analysis several markovian model including contact process, exclusion process, voter model first studied dimensional lattice see monograph regular tree eg, recent work also considered process sparse random interaction graph see, eg, incomplete list none latter work appear address main question listed autonomous characterization marginal dynamic typical particle fact, interacting diffusion sequence sparse erd nyi graph obtaining characterization remained important open question eg, see sparse regime challenging particle strong interactions, neighboring particle remain correlated limit topology graph strong influence section describe recent progress particular provides resolution open question article concludes section generalization open question work mean field model various aspect interacting particle system extensive impossible representative short article instead, hope provide enough pointer reader get flavor classical result set context recent result monograph covering various aspect interacting particle system include given simple, locally finite, undirected graph use cl denote closure note cl always finite, denotes cardinality set describe dynamic locally interacting diffusion interacting jump process rather provide general setting, make simplifying assumption whenever convenient illustrate key issue given initial condition every consider collection diffusive particles, indexed node graph evolve according following coupled system stochastic differential equation sdes iid standard brownian motion independent vertex isolated, represents local empirical measure neighborhood time drift coefficient sufficiently regular ensure sde unique weak solution isolated, precise definition important set equal arbitrary quantity special case interest linear dependence measure term, say, form interaction potential symmetric last two variable case, system reduces following system pairwise interacting diffusion model phenomenon different fields, including statistical physic neuroscience trajectory particle lie space continuous real valued function endow topology uniform convergence compact set consider sde complete graph, assume without loss generality vertex set present sufficient condition drift one establish standard mean field result given polish space wasserstein metric defined follows infimum coupling namely probability measure first second marginals respectively let space probability measure equipped wasserstein metric suppose bounded every map lipschitz continuous, uniformly respect compact subset note assumption satisfied drift form interaction potential lipschitz continuous bounded, uniformly respect compact subset suppose assumption holds, exists initial condition satisfy unique strong solution sde moreover, unique solution sde global empirical measure defined satisfies furthermore, law converges weakly product is, bounded continuous function interaction, theorem would simply functional strong law large number result however, even particle weakly interacting symmetry interaction ensures influence particle drift another particle vanishes limit property finite subset random variable asymptotically independent referred chaoticity, well known equivalent convergence deterministic law proposition now, implies initial condition chaotic thus theorem asserts dynamic chaoticity also hold positive time phenomenon referred propagation chaos turn, lead autonomous description limiting marginal process markov process whose infinitesimal evolution time also depends law time result, forward kolmogorov equation master equation partial differential equation pde describing evolution marginal law nonlinear consequently, process referred nonlinear markov process drift form suitable condition shown law absolutely continuous respect lebesgue measure density satisfies granular medium equation thus, pde technique useful studying nonlinear markov process see, eg, many different approach establishing mean field limits, including pde analysis, fixed point arguments, martingale technique stochastic coupling construction first, one need establishing well posedness nonlinear sde analytical approach problem entail proving uniqueness nonlinear pde describing evolution marginal law another, probabilistic, approach first consider mapping take continuous measure flow measure flow unique solution sde replaced observing flow must fixed point mapping, well posedness equivalent uniqueness fixed point mapping latter established showing mapping contraction exploiting lipschitz continuity drift given well posedness, coupling approach proving convergence proceeds first defining dimensional process whose every coordinate independent copy nonlinear process one couple process original process driven brownian motion using formula, lipschitz condition drift standard estimates, one show distance empirical measure vanishes since strong law large number ensures empirical measure latter converges law equal concludes proof alternative approach proving convergence first use generator markov process identify martingale involving empirical measure process next show sequence relatively compact tight characterize subsequential limit satisfies known nonlinear martingale problem, finally establish well posedness latter one consider general dynamic drift diffusion coefficient function current state empirical measure process, well non markovian version depend history process also interested interacting pure jump processes, describe model statistical physics, engineering, epidemiology dynamic opinion formation concreteness, consider voter model aim capture opinion dynamics, particle take value state space represents two possible opinion allowed transition jump direction particle lie set rate particle change opinion equal fraction neighbor opposite opinion note dependence rate neighboring state symmetric generally, state system jump rate particle could complicated symmetric functional neighboring state also depend time addition state symmetric dependence neighboring state succinctly captured saying rate functional unnormalized empirical measure neighboring state note lie space locally finite nonnegative integer valued measure general setup, consider finite state space subset possible jump directions, collection jump rate function given simple finite graph initial condition valued process representing configuration associated ip evolves according following system jump sdes iid poisson random measure intensity measure leb leb represents lebesgue measure random unnormalized empirical measure corresponding state particle neighborhood time sde capture simple evolution time particle node make transition state rate depends current time, state node prior current time, symmetrically state neighboring node prior current time, encoded use unnormalized measure instead empirical measure allows one capture broader class model jump rate depend number neighboring node particular state fraction case model like contact process note trajectory particle lie dl space right continuous valued function finite left limit solution jump sde markov jump process law also characterized via associated infinitesimal generator function vector th coordinate elsewhere however, jump sde representation convenient generalization non markovian process see furthermore, jump sde formulation also better suited describing form limiting marginal dynamic sparse graphs, described section mean field result analogous theorem also hold jump setting following regularity assumption jump rate function jump rate function take form otherwise, function lipschitz continuous, uniformly compact subset assumption reflects fact mean field setting, dependence jump rate neighboring particle must sufficiently regular function usual normalized empirical measure following result established theorem see also suppose assumption hold initial condition chaotic, is, converges total variation metric deterministic limit converges weakly unique solution following nonlinear jump sde poisson process intensity leb independent furthermore, law converges weakly evolution law mean field diffusion limit characterized nonlinear pde, evolution law nonlinear jump process characterized unique solution forward equation, nonlinear integrodifferential equation theorem meant provide flavor mean field result survey mean field limit current focus, worth mentioning diffusive jump process settings, one obtain mean field limit weaker assumption much general dynamic diffusion coefficient also function current state empirical measure process, well non markovian version drift coefficient jump rate depend history process see, eg, propagation chaos result interacting non markovian jump diffusion large deviation analysis non markovian weakly interacting diffusion mean field limit theorem established theorem indicate law nonlinear markov process respectively, used approximate quantity interest interacting diffusion jump process finite graph particular, consider voter model described section jump rate take explicit form case, one would expect dynamic reates could provide approximation probability agreement two neighboring particle voter model sufficiently large complete graph however, lack better alternative, mean field approximation used even dynamic graph approximation may reasonably well dense graph vertex high degree inaccurate sparse graph figure plot evolution probability state root agrees precisely two neighbor voter model rooted regular tree generations, given time zero, particle independently opinion probability vertical bar figure provide confidence interval simulation mean field approximation assumes neighboring vertex independent, thus performs poorly ad hoc refinement mean field approximation take account correlation also remain inaccurate setting strongly motivates development convergence theory empirical distribution marginal dynamic sparse graph sequence could lead principled approximation turn interacting process sparse graph sequence initial condition assume finite vertex chosen uniformly random vertex unlike case complete graph even dense graph sequence degree vertex remains bounded neighboring vertex become asymptotically independent thus, number neighbor becomes important clear one cannot expect limit sending number vertex infinity, without imposing additional consistency requirement graph sequence lead following question graph sequence would one expect limit sequences, converge deterministic limit converges deterministic limit, limit always coincide limit law autonomous reduced dimension description limit marginal whenever limit exists light first question above, review natural notion convergence sparse graph called local convergence section notion used study asymptotic property static model gibbs measure discrete valued marked random graph given graph two vertex path length sequence every graph said connected exists finite path two vertex graph distance two vertex minimum length path rooted graph graph special vertex referred root useful notion convergent sequence connected rooted sparse graph local convergence, introduced benjamini schramm reference local convergence include first introduce terminology required define local convergence isomorphism one rooted graph another bijection vertex set edge edge two rooted graph said isomorphic exists isomorphism let denote set isomorphism class connected rooted graph also need consider convergence graph carry mark representing initial condition trajectory state dynamic vertex mind, given polish space define marked rooted graph tuple rooted graph vector marks, indexed vertex say two marked rooted graph isomorphic exists isomorphism rooted graph rooted graph map mark mark ie, let denote set isomorphism class marked rooted graph define topology local convergence space let denote induced subgraph rooted containing vertex graph distance root distance defined supremum isomorphic, interpret now, let denote metric induces polish topology metrize similarly defining distance two marked graph supremum exists isomorphism respective topologies, polish space see lemma appendix polish space let denote space bounded continuous function always assume space equipped borel algebra one talk weak convergence convergence distribution random graph random marked graph random element specifically, sequence random valued random element said converge distribution local weak sense valued limit every bounded continuous function likewise, convergence distribution local weak sense isomorphism class random marked graph equivalent weak convergence space figure illustrates two generic example locally convergent graph sequence let cycle, connected graph vertex every vertex degree along root chosen uniformly random vertex converges weakly infinite line graph rooted fixed vertex see figure le trivial example illustrated figure given sequence erd nyi graph converges distribution local weak sense galton watson gw tree offspring distribution given poisson distribution latter example unimodular galton watson ugw tree, defined follows given probability distribution finite nonzero first moment, is, satisfies random tree ugw root whose neighborhood size distributed according neighbor vertex referred offspring root form first generation tree recursively, vertex nth generation tree independent random number offspring equivalently, neighbor away root distribution th generation tree comprised offspring vertex th generation easy verify poisson distribution, hence, galton watson tree poisson offspring distribution fact ugw poisson distribution another special case regular tree, given ugw ugw tree sense canonical object since arise local weak limit many sparse random graph sequence including erd nyi graphs, configuration model preferential attachment graph see section discussion example extend notion convergence graph necessarily connected, given unrooted graph vertex define isomorphism class connected component contains root furthermore, finite, let denote random vertex chosen uniformly set case denotes connected component random vertex sequence finite random graph said converge distribution local weak sense sequence finite random graph said converge probability local weak sense every analogously, given marked unroooted, necessarily connected graph denotes connected component containing root corresponding mark notion convergence distribution probability local weak sense marked graph defined exactly analogous fashion definition place respectively unmarked marked graphs, convergence probability clearly implies convergence distribution use notation graph isomorphism class often omit root notation simply refer rather given sequence random graph converges either distribution probability local weak sense limit graph iid mark polish space distribution irrespective easy show marked graph sequence also converges local weak sense unmarked counterpart iid distribution fact, shown proposition convergence marked graph sequence hold larger class possibly dependent mark distributed according gibbs measure graph respect fixed pairwise interaction functional address raised beginning section first result state sequence graph marked initial condition converges either probability distribution local weak sense limit graph, graph marked trajectory solve corresponding sde also converge limit graph sense result also characterizes limit global empirical measure suitable condition suppose assumption holds, sequence necessarily connected, finite random marked graph converges distribution local weak sense valued limit also, let solution sde initial data let unique weak solution sde limit graph converges distribution local weak sense valued element particular, converges weakly moreover, converges probability local weak sense also converges probability local weak sense additionally, converges weakly law result follows theorem establish result general, possibly non markovian diffusive dynamic version first assertion theorem also established slightly different class interacting diffusion theorem seen establishing continuity local weak topology dynamic respect initial data, comprising graph marked initial condition also provides condition empirical measure shown deterministic limit equivalently, hydrodynamic limit additionally coincides limit law root particle, thus answering affirmative beginning section discussed earlier, complete graph analogous phenomenon hold due asymptotic independence trajectory two particle contrast, sparse regime, neighboring particle remain dependent limit instead, proof relies showing trajectory finite neighborhood two independent vertices, chosen uniformly random graph become asymptotically independent limit latter property relies certain correlation decay property dynamic spirit see lemma detail however, emphasized sparse regime deterministic hydrodynamic limit result hold initial data converges stronger sense convergence probability local weak sense indeed, shown theorem limiting empirical measure stochastic initial data converges distribution local weak sense particular, fix suppose graph obtained taking connected component vertex chosen uniformly random erd nyi graph setting root chosen vertex also, let initial condition iid common distribution let denote restriction initial condition converge distribution local weak sense iid distribution ugw poi however, whereas converges weakly law dynamic root vertex converges weakly following random limit given limit truly stochastic because, well known elementary theory branching process always positive probability ugw tree finite positive probability infinite furthermore, also exist example show even limiting empirical measure deterministic, need coincide law root particle limit example, occur graph homogeneous root chosen uniformly random vertex graph see, eg, section discussion show existence nature hydrodynamic limit far subtle sparse regime case complete dense graphs, even diffusive dynamic setting jump processes, additional subtlety arise whereas diffusion setting, assumption ensures drift particle node experience effect perturbation state neighboring particle, analogous assumption would stringent cover jump model interest sparse graph latter case, effect neighboring particle jump intensity vertex either remains constant voter model, grows degree vertex many models, including contact process see precisely accommodate dependence jump intensity expressed function unnormalized sum dirac mass neighboring state introduced rather normalized empirical measure hydrodynamic limit sparse graphs, suffice impose following mild assumption rate every suppose exist constant nondecreasing every sup note jump sde describing dynamics, third argument equal unnormalized empirical measure state neighbor vertex, defined thus, irepresents degree vertex assumption allows uniform bound jump rate vertex grow degree vertex state analog theorem jump diffusion recall definition ugw tree given remark suppose assumption holds, sequence necessarily connected, finite random rooted marked graph converges probability local weak sense limit ugw tree finite, strictly positive first second moment let solution jump sde initial data let unique strong solution sde limit graph converges probability local weak sense valued element furthermore, converges weakly law theorem follows general result established theorem corollary diffusion case, proof theorem involves establishing continuity property dynamic respect graph initial condition well correlation decay property however, proof property considerably involved diffusion case due weaker condition imposed jump intensity assumption one, jump setting even well posedness particle system infinite random graph unbounded degree automatic shown appendix exist example simple jump particle system uniformly bounded jump rate function multiple solution certain graph exponential growth quote liggett given intuitive description behavior particles, often clear whether exists process corresponds description therefore important find condition infinite particle system exist finite graphs, finitely number jump bounded interval, process remains constant jump thus, one simply order jump define process recursively problem infinite graph setting one cannot always identify first jump liggett used analytical construction invoking theory semi group establish general existence theorem law markovian particle system infinite graph quite general necessarily finite range interaction context nearest neighbor interaction lattices, alternative, probabilistic approach used establish well posedness markovian interacting particle system harris however, approach seem apply graph finite maximal degree hand, graph particular interest like ugw poisson tree discussed see remark unbounded degree assumption well posedness possibly non markovian interacting jump process established theorem large class possibly random graph satisfy certain finite dissociability property almost surely, property shown hold ugw tree corollary proof theorem follows combining well posedness result continuity property dynamic respect initial data correlation decay property established proposition theorem respectively hydrodynamic limit result reduces characterization limit law understanding marginal law root dynamic infinite limit graph given local weak limit many random graph tree see remark focus understanding marginal dynamic random tree evolution root driven local neighborhood empirical measure unnormalized counterpart complete sufficiently dense graph case, limit number particle go infinity, local empirical measure coincides global empirical measure thus, case hydrodynamic limit yield autonomous characterization limit marginal dynamic contrast, graph sequence sparse, neighboring vertex remain strongly correlated, local neighborhood empirical measure remains stochastic thus hydrodynamic limit result section adequate provide autonomous characterization marginal dynamic instead, adopt different perspective, better suited analysis large collection dependent random element mentioned section first step try identify conditional independence structure random variable end, identify certain markov random field mrf property trajectory section describe exploit property, along filtering result stochastic analysis symmetry property graph, identify autonomously defined local equation satisfied marginal dynamic cl root neighborhood first diffusion line section diffusion ugw tree section finally jump process section unlike mean field case, consideration marginal root neighborhood rather root appears necessary order obtain autonomous characterization also necessary order capture correlation neighboring vertices, vanish sparse regime discussion local equation given section worth noting since graph consider locally finite, neighorhood root almost surely finite thus, local equation describes evolution almost surely finite number interacting particle combined convergence result theorem finite dimensional interacting process serf approximation marginals possibly non markovian interacting process arbitrarily large number particles, thus constitutes significant dimension reduction first introduce definition mrf fix measurable space possibly infinite, locally finite graph random element said first order mrf abbreviated mrf respect every finite set conditionally independent given denote hand, said first order global mrf hold possibly infinite furthermore said first order semi global mrf abbreviated sgmrf hold finite furthermore, said second order mrf mrf respectively, second order sgmrf sgmrf respect mrf respectively, sgmrf respect square graph contains well vertex pair distance two apart cases, say exhibit certain mrf property whenever valued random element law satisfies mrf property sgmrf property, introduced viewed generalization tree indexed markov chain chapter general graphs, clearly strictly stronger mrf property collection path either let represent trajectory interval respectively, subset let certain mrf property preserved evolution interacting processes, sense made precise following theorem let deterministic graph uniformly bounded degree almost sure realization ugw tree suppose valued element form mrf sgmrf respect assumption hold unique solution diffusive sde valued trajectory also form mrf respectively, sgmrf respect hand, suppose assumption holds, valued random element form mrf sgmrf respect unique solution jump sde also form mrf respectively, mrf cases, assertion also hold replaced discussion section provides insight second order, general first order, mrf property preserved dynamic preservation mrf property diffusion graph bounded degree follows theorem proof proceeds first establishing result finite graph appealing girsanov theorem gibbs markov theorem theorem also often referred hammersley clifford theorem suitably approximating infinite system sequence finite system proof preservation mrf sgmrf property jump process theorem follows rather different approach exploit certain duality marginals interacting system nonexplosive point process directly establish infinite dimensional girsanov theorem, obviating need approximation argument approach also allows general initial condition incorporate infinite histories, required characterize solution local equation described section flow suitable path space result diffusion generalized similar fashion using approach developed prior work question largely focused interacting diffusions, specifically characterizing gibbs measure path space order construct weak solution infinite dimensional sdes deuschel initiated perspective diffusion drift gradient type although explicitly stated, mrf property implicit proof existence weak solution, relies estimate dobrushin contraction coefficient crucially require additional smoothness boundedness property drift cattiaux, roelly, zessin relaxed boundedness condition allow markovian, malliavin differential drifts, using variational characterization integration part formula subsequent work used cluster expansion method applies system obtained small perturbation non interacting system dereudre roelly established gibbsian property path interacting one dimensional diffusion possibly history dependent drift sublinear growth using specific entropy, crucially requires shift invariant initial condition another direction, several work considered mrf gibbsian nature marginals rather paths, diffusion jump process context preservation property hold general sufficiently small time horizon interaction strength furthermore, none work seems considered sgmrf property, crucial derivation local equation, elaborated section describe sgmrf property theorem used obtain autonomous characterization marginal dynamic root neighborhood regular tree simplicity, identify identify root additionally, rather consider general form focus special case pairwise interacting diffusion without time dependence drift dropped superscript denoting graph dependence notational conciseness also assume shift invariant sgmrf given setup, goal understand marginal dynamic root neighborhood characterization marginal via local equation entail four key ingredients, elaborate upon mimicking theorem rewrite dynamic marginal interest follows let denote filtered space support adapted process root node, observe time drift depends however, time drift depends likewise drift node depends since lie closure root, system equation autonomous since drift time depends random element beyond nevertheless, together show known process, mean drift progressively measurable consequence continuity fact adapted continuous process therefore, one appeal mimicking theorem process filtering theory see appendix allows one express solution sde whose drift time functional past time rather arbitrary adapted process mimicking theorem allows one conclude extending probability space necessary exist independent brownian motion extended probability space satisfies progressively measurable version conditional expectation recall clearly, conditioning alter drift coefficient root particle, remains original system however, altered conditioning see mrf property used simplify expression ii markov random field structure compute drift provide self contained description law dynamic one need able express conditional law given past term joint law preferably, term law get nonanticipative description dynamic end, invoke property theorem trajectory time form sgmrf second order markov chain use property, let consider corresponding first order property namely ask whether fact expect every one may attempt bolster hypothesis reasoning conditioned become decoupled satisfy following sde independent brownian motion however, careful inspection would reveal reasoning fallacious evolution thus random element directly depends state turn dependent brownian motion thus, conditioning cause driving brownian motion become correlated thus, conditioning, independent follow sde driven independent brownian motion however, show conditioning driving noise process remain decoupled ie, independent although conditioning alter distribution longer brownian motion even martingale returning simplification expression drift given note since relation implies independent conditioned drift rewritten reasoning, analogous expression hold iii symmetry consideration despite simplification last section, second term right hand side still involves thus written purely term law however, rewritten form exploiting shift variance particle system since true initial condition dynamic precisely, fact distribution allows conclude along analogous expression equation show independent dimensional brownian motions, modulo additional technical measurability integrability conditions, identifies form local equation satisfied marginal dynamic line see definition complete definition observe even though original system describes linear markov process, marginal characterized local equation system nonlinear, describes nonlinear non markovian process since drift functional depends history time law however, structure ensures coupled system longer depends value process thus autonomously defined iv uniqueness solution local equation argument show law marginal solves local equation system complete autonomous characterization marginal remains show law marginal unique solution local equation system rather, complete specification stated definition method described section prove well posedness nonlinear markov process characterize limit marginal law node complete graph case run difficulty due path dependence and, importantly, nonlinearity occurring dependence conditional laws, le regular nevertheless, possible prove well posedness using approaches, entailing relative entropy estimate symmetry properties, via correspondence infinite particle system detail found section local equation root neighborhood regular tree derived manner similar case invoking mimicking theorem theorem exploiting additional rotational transational symmetry arising automorphism group place translational reflection symmetry however, full expression local equation omitted special case ugw tree discussed next section, whose analysis subtle let probability distribution satisfying let ugw tree remark again, would like describe marginal dynamic particle process root node random neighborhood elucidated last section, main ingredient derivation local equation line mimicking theorem, conditional independence property, symmetry consideration and, finally, well posedness local equation mimicking theorem applied without change also however, mrf property theorem applies deterministic graph thus sufficient instead, one need annealed version, is, one also take account random structure tree one show event root isolated child root, conditioned trajectory trajectory particle subtree rooted independent trajectory cl root neighborhood, and, moreover, conditional law given depend see proposition case would follow theorem homogeneity dynamics, general case, one also account randomness root neighborhood furthermore, symmetry property considerably subtle appropriate notion unimodularity unimodularity viewed analog infinite graph property finite graph root uniformly distributed graph",mathematics
"complete space like self expanders minkovski space introduction preliminary proof main theorem instruction purpose study complete space like self expanders minkovski space use maximum principle omori yau type, obtain rigidity theorem dimensional complete space like self expanders minkovski space complete space like self expanders dimension give classification assumption constant squared norm second fundamental form dimensional smooth immersed hypersurface called self expanders mean curvature flow mean curvature vector satisfies equation denote position vector inward unit normal field, respectively denote standard inner product equation equivalent self expanders self similar solution mean curvature flow, is, family hypersurfaces satisfying equation mean curvature flow self expanders important model behavior mean curvature flow coming conical singularity also model long time behavior flow starting entire graph many classification result self expanders ishimura halldorsson classified self expander curve halldorsson state complete self expander curve immersed convex, properly embedded asymptotic boundary cone vertex origin cheng zhou studied property complete properly immersed self expanders recently, ancari cheng studied immersed self expander hypersurfaces whose mean curvature linear growth control obtained rigidity property hyperplanes self expanders euclidean space result self expanders done cf paper, use maximum principle omori yau type, obtain classification complete space like self expanders minkowski space let complete space like self expander constant squared norm second fundamental form inf hyperbolic space hyperbolic cylinder component second fundamental form, completely classify complete self expanders constant squared norm second fundamental form minkovski space study follows let dimensional complete space like self expander squared norm second fundamental form constant, one space like affine plane origin, hyperbolic cylinder hyperbolic space component second fundamental form, fact, using proof method theorem also give classification complete self expanders euclidean space condition constant squared norm second fundamental form, classification result plane origin, indicates conclusion ancari cheng still hold without assumption scalar curvature let dimensional space like hypersurface dimensional minkovski space choose local orthonormal frame field dual coframe field that, restricted tangent paper, shall make use following convention range indices, structure equation levi civita connection hypersurface restricting form get taking exterior derivative obtain called second fundamental form mean curvature respectively let squared norm second fundamental form gauss equation given defining covariant derivative obtain codazzi equation taking exterior differentiation defining following ricci identity taking exterior differentiation get let tangent vector field denote bakry emery ricci tensor lie derivative along vector field define differential operator denote laplacian gradient operator, respectively following maximum principle omori yau type concerning operator used paper, proved chen qiu let complete riemannian manifold, vector field bakry emery ricci tensor bounded below, bounded above, exists sequence next suppose self expander, is, simple calculation, following basic formula paper, shall always take formula using ricci identities, get following lemma let dimensional complete space like self expander let dimensional complete space like self expander constant, order use maximum principle omori yau type, need following lemma let dimensional complete space like self expander squared norm second fundamental form constant, bakry emery ricci tensor bounded below, unit vector choose local tangent orthonormal frame field definition self expander, direct computation give yield proof lemma finished arbitrary fixed point always choose local frame field equality inequality hold taking exterior derivative know besides, ricci identity obtain is, cheng peng obtain rigidity theorem complete self shrinkers without assumption polynomial volume growth motivated work, obtain following result self expanders theorem let complete space like self expander constant squared norm second fundamental form inf hyperbolic space hyperbolic cylinder since inf without loss generality, assume inf constant lemma infer bakry emery ricci curvature bounded maximum principle omori yau type concerning operator function exists sequence obvious namely, second fundamental form parallel constant follows infer indicates number distinct principal curvature two one principal curvature, is, totally umbilic, hyperbolic space two distinct constant principal curvatures, congruence theorem abe, koike yamaguchi hyperbolic cylinder order prove main theorem paper, need following theorem let complete space like self expander non zero constant squared norm second fundamental form, inf use proof contradiction suppose inf exists sequence constant, know bounded sequences, one assume follows use obtain yield since non zero constant, draw imply follows follows conclude combining infer implies contradiction also obtain contradiction fact, declare otherwise, know infer contradiction assuming first equation draw consequently following relationship derived simple calculation follows impossible assuming using similar method also obtain contradiction proof theorem thus finished proof theorem know space like affine plane obvious either theorem theorem acknowledgement first author partially supported china postdoctoral science foundation grant second author partly supported grant nsfc, gdups guangdong natural science foundation grant",mathematics
"quick probability oriented introduction operator splitting method scope paper first example matrix lie product formula semigroups chernoff product formula abstract cauchy problem trotter kato formula general formulation splitting scheme multiplicative additive splitting method naive probabilistic example error splitting scheme source remark relation acps practice rate convergence remark error representation deterministic case boundary conditions, inhomogeneous acps phenomenon order reduction general exponential splitting method baker campbell hausdorff formula taylor expansion, kunita expansion exponential method sdes general result spdes sdes example diffeomorphic flow sdes, brownian web non homeomorphic home nv document mine splitting overview vovchanskyi splitting overview biberbib ateverybibitem clearfieldlanguage ateverybibitem clearfieldnote survey devoted operator splitting method abstract formulation application probability survey focused multiplicative methods, bch formula used discus exponential splitting method short informal introduction additive splitting presented introduce framework available deterministic probabilistic result concentrate constructing wide picture field operator splitting methods, providing rigorous description setting abstract cauchy problem informal discussion parallel advance limitation common difficulty listed, well example work provide solution hint new result provided bibliography contains illustrative deterministic example selection probability related work paper extended reworked version short course given author uzbekistan ukrainian reading stochastic process tashkent kyiv, prepared special issue theory stochastic process devoted publishing lecture note aforementioned workshop operator splitting method family well known method decomposing dynamical system providing representation governing mechanism sum simpler component force using representation provide approximation real trajectory dynamical system though idea splitting often associated celebrated abstract trotter kato formula, case approximation constructed using composition subsystem driven exactly one component aforementioned representation, go far beyond includes weighted linear combination subsystems, composition mixed backward forward euler scheme encountered optimization theory disguise specifically, idea follows time interval divided sufficiently small steps, every step solution operator original system replaced approximation constructed splitting procedure, solution combined recursively starting time due general nature idea, operator splitting essentially used anywhere ode pdes natural decomposition arise, decomposition dictated presence co existing physical, chemical biological mechanisms, often acting different space time scales, property available numerical method consider general advection diffusion reaction equation represents diffusion, field possibly superficial velocity source sink may chemical origin, velocity field reflects physical property reservoir etc one may prefer drastically different numerical method integrating subsystem obtaining splitting rh sum differential operator second order treating subsystem separately instance, physically justified first order equation developed theory often explicitly relies conservation law eg hundsver numerical diffusion part typically treated via finite element eg zientayzhu finite assume consider ode try simulate using explicit forward euler method step size necessary condition operator matrix norm, implies order since limited practice, may possible forward euler method stable however, decomposition equation solved explicitly toy model example stiff non stiff part original equation isolated stiffness eg haiwan solving, lam numerical, hundsver numerical deterministic setting mil numerical stochastic setting context operator splitting method understood vague general sense system stiff successful application certain numerical method usually explicit one used field standard integrator requires impractically small time step thus infeasible costly hard implement idea current example combine well previous example since competing mechanism different origin chemical mechanical may act different scales, typical source stiffness directly increase stiffness ratio eg blaca concise development example consider stiff ode constant coefficient eigenvalue distinct, real negative term get negligible comparison grows explicit euler method step size display asymptotic behavior moreover, condition violated, approximation diverge thus stability explicit euler method depends parameter subsystem whose contribution dynamic whole system minor best typical feature stiff system separation problematic direction rest system beneficial case let consider let one dimensional gaussian density variance combining operator interval give two dimensional wiener process thus operator splitting scheme exact trivial case example alternating direction method whose name quite self explanatory result, operator splitting procedure often developed equation problem general formulation instance, navier stokes equation, zakai equation filtration theory, advection diffusion reaction equations, composite optimization problem example non pde setting wide availability method result application physic mechanic fluids, gas solid classical, quantum celestial mechanic electromagnetism symplectic integration etc chemistry, biology, geology, ecology, weather forecasting, finances, general machine learning problem including image processing, large scale optimization etc numerous field time, operator splitting method encountered purely theoretical study proper example given later text scope survey purely pedagogical suggest brief quick introduction operator splitting methods, presenting basic form accessible newcomer background probability still discussing limitation technical issue method provide wider picture least mention direction whole theory go beyond trotter kato formula give example result developed use operator splitting method field probability show randomness lead new insight new technique probabilistic orientation simply mean prefer probabilistic examples, assume standard level knowledge probability, concentrate multiplicative exponential splitting include short survey general theory multiplicative splitting spdes same, also lead asymmetry text discussion baker campbell hausdorff formula rather lengthy material expected covered textbook probability reader assumed familiar spdes variational method part devoted spdes explain setting emphasized enough information around person interested topic, including high quality introductory level text textbook even trying compete classical texts, merely concentrate gathering least form bibliographic reference important basic facts, hint probabilistic result expanded lecture note aforementioned course giving total newcomer basic understanding map navigate level exposition thus le basic shallow even though result cited often deep extremely technical obtain given scope goal survey, would irreparably pretentious, futile plainly impossible proceed otherwise thus refer original source proofs, detail precise formulation result discussed paper known obviously, sheer amount publication devoted theoretical applied study operator splitting method immediately render impossible task providing exhaustive even representative bibliography unless attention restricted limited partial case specific problem task highly nontrivial even result, choice illustrative example extend random, apologize advance whose contribution represented accept critique gaps, claiming ill intent also give link survey collection reference instead citing source directly occasion still, hope bibliography independent value real attempt give historical note track result initial source made reader interested general broad picture may proposed consult following selection work entry point pazy semigroups, goldstein semigroups, enna one parameter, da one parameter, itoka evolution, cher product, ethkur markov trotter kato formula, perturbation theory semigroups formulation term abstract evolution equations, glowoshyin splitting, faha splitting survey, general theory, history, connection optimization problems, pdes variational inequalities, examples, hundsver numerical treatment advection diffusion reaction equations, example discussion numerics, reedsai methods, si functional, johnla feynman, lohibetz feynmankac, hall quantum, reedsi method zeid applied physical exposition application feynman path integral feynman kac formula, holkarlkenlie splitting operator splitting method rough solutions, glowoshyin splitting, gloleta augmented, glo finite, ya method, ryuyin large scale, baucom convex, mar methods, mar splitting, mar splitting surveys, innumerable references, applications, using operator splitting numerical method solving pdes variational nonlinear inequalities, convex optimization problem including sparse large scale problem fixed point algorithms, problem monotone operator etc, hailu geometric, blaca concise, mclachquis splitting, sanzcal numerical application geometric integration ode source contain vast bibliography additional reference given later text follows aforementioned source used starting point start recalling famous lie product formula matrix let set matrix function solution given arbitrary matrix norm original source theorem seems untrackable cofriedkake eigenvalue one possible proof lie product formula based following telescopic identity id let identity implies local error finish proof arithmetic identity thus hold unbounded operators, despite triviality, standard well known tool estimating global error term local error encountered numerous occasion across whole selection work referenced present paper see, idea proof theorem extends abstract setting directly suitable form uniform boundedness stability hold max otherwise, new method proposed implies method least second order matrix commute, is, however, matrix commute, corresponding exponential hence method exact fact statement theorem alternative proof theorem usually use property matrix logarithm additionally cannot easily extended general abstract setting give simplest example operator splitting technique given consider ode then, theorem theorem also find application theory matrix lie group corresponding homeomorphisms hall lie matrix trace inequality petz survey etc next theorem originally proposed one two dimensional difference scheme also proved direct calculation arbitrary matrix norm common agreement strang gi marchuk independently proposed use idea theorem derive one popular operator splitting method obviously, theorem used solve ode example simple installment strang splitting scheme achieves second order accuracy almost increase number necessary calculation since three subsequent step equal local error strang splitting hundsver numerical venture forth, need recall standard material semigroups abstract cauchy problem acp trotter kato theorem chernoff product formula pazy semigroups, goldstein semigroups, enna one parameter, da one parameter, itoka evolution, cher product, ethkur markov omit detail technicality integral bochner integral let banach space family bounded linear operator one parameter strongly continuous semigroup, semigroup, id mapping strongly continuous denote domain linear operator linear operator generator semigroup generator closed densely defined pair defines semigroup uniquely semigroup exists st called contraction semigroup though customary write semigroup generated follow convention unless stated otherwise bounded linear operator eg family semigroup generator feller valued process automatically defines contraction semigroup space continuous function vanish infinity ethkur markov, bottschiwang levy particular, feller one dimensional diffusion interval generator precise description incorporates boundary condition thus behavior process boundary corresponds killing note possible general give full description feller process often sufficient consider core instead, is, set closure equal ethkur markov however, heat semigroup semigroup thus one carefully choose space semigroup act wiener process analogously defines semigroup generator bokryro fokker however, possibility extend feller semigroup onto linked property adjoint operator thus property fokker plank kolmogorov equation discussion condition see eg stroock partial, ca generators, bottschiwang levy enna one parameter, section vi assume densely defined closed linear operator non empty resolvent set banach space consider autonomous inhomogeneous abstract cauchy problem given classical solution valued function st continuous continuously differentiable term norm hold homogeneous acp well posed unique classical solution depends uniformly continuously initial data following result give well known relation acps semigroups homogeneous acp well posed generates semigroup generates semigroup function take value function unique classical solution type solution particular, mild solution often used function fail satisfy regularity assumption stated non autonomous acp called evolution problem classical solution defined similarly autonomous case simple analog theorem exists see pazy semigroups, goldstein semigroups theory nani well posedness, schnau wellposedness batcsofarni operator, remark survey reference moreover, requires compatibility domain question time dependent, standard condition equation solved however, well posedness non autonomous homogeneous acp implies existence evolution family bounded operator also called propagator st id mapping strongly continuous fixed solution given via mild solution analog given via general, non autonomous inhomogeneous acps, unavoidable applications, may behave unexpected way one careful draw conclusion property corresponding propagator nani well posedness notice, consider homogeneous acps following theorem version celebrated trotter kato theorem whose general form provides basis numerous approximation scheme theory semigroups, including yosida approximation one consult goto convergence, gokoto general, itoka evolution survey general approximation theory semigroups, result rate convergence operator norm, reference number reference concerning chernoff trotter kato product formula given later pfei approximation, pfei probabilistic, pfei some, pfei general use probabilistic method develop unified exposition many approximation formula see also bentpau optimal roughly speaking, trotter kato theorem connect convergence semigroups, resolvent generator let semigroups banach space generator st fixed following assertion exists densely defined operator st strongly core range id dense exists bounded linear operator dense range st id strongly semigroups converge strongly uniformly bounded set semigroup generator st id hold probabilistic formulation theorem feller process found kallenberg trotter kato theorem behind result approximation feller process markov chains, particular kallenberg counterexample trotter kato theorem, particular probabilistic origin, found bob limitation variational nonlinear version trotter kato theorem, itoka evolution generalization norm operator topology, zag notes, cazag operator next theorem called chernoff product formula another fundamental tool approximation theory semigroups let family bounded linear operator st id let limit exist id dense subspace closure generates semigroup sequence positive integer positive sequence satisfying convergence uniform bounded interval formula provides approximation semigroup term family exposition method obtaining approximation given survey method reference application stochastic process including manifold domain dirichlet robin boundary condition found method, chernoff, chernoff killed, mamoresmo chernoff, butgrosmo lagrangian, nitt approximations, sha chernoffs, ne chernoffarx, smoweizwi chernoffs, mamoresmo chernoff, ob representation, smototru hamiltonian, feynman, butschismo hamiltonian, butgrosmo lagrangian, chernoff, smoweizwi brownian reference given later text trotter kato theorem context approximation theory relevant, following additional reference illustrate possibility strengthen conclusion chernoff product formula zag notes, zag comments, za note chernoff formula, cazag operator, galre rate, galre upper arx, prud speedarx establish convergence operator norm obtain estimate rate convergence self adjoint operator quasi sectorial contraction semigroups etc pau operator norm, zag comments, zag notes, cazag operator obtain estimate using probabilistic argument convergence arbitrary slow may hold stronger topology theorem yield exponential formula bounded operator theorem used deduce series representation taken definition exponential method cf lejay girsanov assume real valued function lipschitz continuous bounded, inf consider sde standard wiener process euler maruyama approximation side, one show family defined via satisfies condition theorem implying sufficiently smooth compactly supported see also smoweizwi chernoffs, mamoresmo chernoff, smoweizwi brownian application chernoff product formula pathwise approximation random process note result recover first order weak euler maruyama scheme butgrosmo lagrangian let one dimensional gaussian density mean variance rewritten representation original semigroup limit iterated integral wrt finite dimensional projection pseudo measure phase space wiener measure called feynman formula smototru hamiltonian present alternative approach feynman kac formula see method, chernoff killed, smoweizwi chernoffs, mamoresmo chernoff, ob representation, smototru hamiltonian, feynman, butschismo hamiltonian, butgrosmo lagrangian, chernoff, smoweizwi brownian result feynman formula method setting passing limit give particular case girsanov theorem eg lipshi statistic behavior solution pde differentiability thus behavior corresponding semigroup subtle moment applications, particularly probabilistic interpretation used typical example function min moment feller process hit boundary domain discontinuous though usually result, weak variational formulation term gelfand triple pawin first weak distributional formulation lerarey probabilistic, trizab pfaffian suggested alternative see also feepop stochastic, wang viscosity one particular example versatility chernoff product formula used prove central limit theorem goldstein semigroups state one core result theory abstract operator splitting, trotter kato formula let semigroups banach space generator respectively, st define id dense closure generates semigroup uniformly compact interval theorem formulated finite number semigroups eg pazy semigroups result belongs trotter kato yul daletskii also obtained similar product formula time see dafo measure reference choice topology matter convergence may hold stronger topology neidsteza remark stability assumption cannot dropped kuhnwa lie assume complex valued function shr dinger operator describes motion spinless quantum particle action real valued potential follows wave function solution probability density time position particle interpreted acp hilbert space operator essentially self adjoint is, self adjoint extension rather mild assumption semigroup generated unitary semigroup, particular since semigroups respectively, trotter kato theorem implies polygonal approximation feynman integral history trajectory space continuous trajectory starting reedsai methods, reedsi method goldstein semigroups, johnla feynman action integral expression purely formal trotter kato formula standard way give representation rigorous meaning reedsai methods, si functional, johnla feynman, lohibetz feynmankac, hall quantum, reedsi method customary textbook quantum mechanic derive feynman kac formula shr dinger operator corollary trotter kato formula understand idea formally recall solution following autonomous homogeneous pde assumption used follows given via standard wiener process hand, solution combining semigroup heat semigroup accordance trotter kato theorem yield approximation solution similarly noted precise formulation physical probabilistic version feynman kac formula may dictated different point focus physicist often concerned result laplacian singular irregular different sen potential eg belonging kato class remark applies primarily textbook lejay girsanov cf example possible derive girsanov theorem using trotter kato formula assumption regularity drift following original source, explain intuition behind let heat semigroup semigroup alternatively given small thus shown wiener process since trotter kato formula self adjoint operator reedsai methods, hall quantum usually written self adjoint operator self adjoint extension bounded additionally also importance version physic follows stone theorem hilbert spaces, every unitary group generator form self adjoint every symmetric semigroup generator form bounded self adjoint exactly situation quantum mechanic trotter kato formula admits special proof independent trotter kato theorem case particular, densely defined self adjoint proof rather direct reference extension see lohibetz feynmankac, johnla feynman, si functional particular however, rate convergence found recently additional assumption see eg example related reference formulate formal non autonomous version trotter kato formula, consider operator corresponding non autonomous acps well posed propagator respectively additionally, assume depend one expects note condition domain constant rather limiting one excludes time dependent boundary condition general bc usually incorporated description domain enna one parameter also batcsofarni operator trotter kato formula used derive approximation non autonomous acp autonomous acps constant coefficient cf example that, assume propagator well posed non autonomous acp define semigroups equation strongly uniformly compact set example may small even sum defined via quadratic form johnla feynman, chapter hall quantum, chapter fact, one use trotter kato formula define generalized sum two operator incompatible domain goldstein semigroups, remark original formulation trotter kato theorem pdes requires boundary condition time independent general, adding non autonomous boundary initial condition lead significant technical issue moment, almost attention given question rate convergence even though extremely important question application another feature formulation theorem usage strong topology know either question may stronger result due reference given chernoff product formula rate convergence arbitrary slow convergence stronger topology may hold understand reason behind fact thus emphasize limitation standard version trotter kato formula need short discussion proof theorem since theorem direct corollary theorem subsequent reasoning well known note original proof theorem fall apart soon operator involved unbounded eg contain differentiation condition set id dense implies nontrivial way densely defined closed exists indeed generator semigroup condition seen enna one parameter extension hille yosida theorem fact, formulation trotter kato formula require generator semigroup applies chernoff product formula eg da one parameter practical terms, mean one careful domain trying replicate original proof rest proof theorem consists two separate claim first one relies following observation linear bounded operator satisfying poisson random variable mean therefore bounded operator one prove assumption thus left prove second part proof since trotter kato theorem implies possibility either bound expression replace strong convergence convergence operator norm general proof trotter kato theorem produce result internally result, standard chernoff product formula trotter kato formula formulated term strong convergence bound may possible refine strengthen convergence trotter kato theorem special class generator eg self adjoint maximal accretive one one combine improved estimate particular, obtained using property poisson distribution consistency estimate trotter kato theorem yield conclusion convergence operator norm provide estimate speed cazag operator, zag notes, pau operator norm, zag comments, za note chernoff formula see also pazy semigroups, chapter lemma may compared goto convergence, gokoto general estimate speed convergence often include original element see also itoka evolution, itoka trotter result type reference concerning bound rate convergence added later decomposition proof condition theorem illustration one overarching principle numerical analysis stability consistency imply convergence fundamental result known lax richtmyer theorem lax equivalence theorem context finite difference approximation pdes consistent finite difference scheme well posed linear initial value problem convergent stable principle extends setting situation soon approximation scheme arises see itoka evolution discussion setting evolution equation glowoshyin splitting, chapter discussion case trotter kato formula condition give stability scheme convergence generator behavior family consistency condition case etc however, one forget that, contrary case lax richtmyer theorem, principle stability consistency imply convergence longer rigorous statement also reflect full nature proof since proof deal range domain unbounded operator obtain generator semigroup side, principle remains extremely powerful tool often encountered situation various bound developed discussion consistency term resolvent see itoka trotter discussion possible trade consistency stability, itoka trotter, huitoka aspect version inhomogeneous acps, huitoka aspect composition generator contraction semigroups automatically stable alternatively, method expected stable operator involved commute bjor operator common duality theory multiplicative splitting method also obvious aforementioned scheme classical proof possible way establish stronger version trotter kato formula topic revisited later let solution operator acp initial value let solution operator recurrent approximation scheme uniform time mesh converge original solution setting id is, global error sum propagated local truncation error propagated initial error partial case decomposition revisiting formulate following typical meta theorem generator contraction semigroups respectively, obviously, tricky part obtain estimate often achieved ad hoc method faou analysis consider pde bounded derivative satisfies let heat semigroup possible, using formula property wiener process, show local error satisfies wiener process, used derive consistency bound combined energy stability estimate original semigroup example implies trotter kato formula first order accurate note rate convergence obtained using probabilistic technique faou analysis also establishes estimate linear case result version trotter kato formula case one step approximation strang splitting generalization trotter kato, bounds, developments, extension type semigroups reference see, besides source listed above, ro error, cazag operator, neidzag error estimate, neizag fractional, ichita error, ichita error, johnla feynman, ichi recent, caneidza accretive, faouosschratz analysis, neidza convergence, za trotter, hanos dimension, hanos dimension, neidza fractional, ichineidza trotter, ichitataza note, ichita norm, fa product, bjor operator, vui generalization, neidsteza operator, vuiwresza general, vuiwresza trotter, neidza trotter, neidsteza remarks, caneidza comments, neidsteza trotter, vuiwres product, csoehrfas operator chernoff product formula trotter kato formula particular, non autonomous case studied dafo measures, ichita error, neidza convergence, hanos dimension, batcsofarni operator, enna one parameter, fa product, vui generalization, vuiwresza general, vuiwresza trotter, neidsteza trotter, vuiwres product particular, vuiwresza general, vuiwresza trotter, vuiwres product study time dependent domain version non autonomous trotter kato formula alternative setting established te stabilite, dafo measures, eisenhan variational, itoka evolution, batcsofarni operator particular, te stabilite, eisenhan variational use framework gelfand triple rigged hilbert space result nonlinear trotter kato formulae, see reference reedsai methods, supplement viii splitting level semigroups mean splitting time numerical scheme also include spatial discretization practice result combining time splitting spatial discretization particular, version chernoff formula see itoka evolution, batcsoni operator splittings, bacsofarni operator spatial see also remark revisiting example feller processes, one see action corresponding semigroup defined well behaved necessarily function outside class though function may appear application see doerteich semigroup one extension splitting scheme larger class function preservation rate convergence spdes previous section contain rigorous description trotter kato formula semigroups henceforward care idea illustration longer aim give precise formulation step domain general operator splitting method numerical theoretical scheme approximate original solution without priori expectation convergence unified exposition abstract initial value problem ivp assumption corresponding operator eg multivalued discontinuous used mostly follow exposition glowoshyin splitting, hundsver numerical consider autonomous ivp possibly nonlinear assume section write similar term lh ivp later text resume writing rh assume fixed let fixed time step integer set form partition following scheme general version trotter kato formula called lie trotter splitting scheme particular, general version theorem general setting, define follows general, one expects lie trotter splitting first order accurate however, conclusion guaranteed adjustment non autonomous case standard though may nontrivial mathematically treated rigorously eg time considered additional variable new operator introduced explicit approach example used use second option scheme consider assume next scheme called strang splitting scheme asymmetrical way treated matrices, theorem introduce abstract formulation, consider defined via one expect second order general case but, earlier, guaranteed repeat universal remark absence universal rate given splitting scheme future strang splitting quite popular due second order, also require doubling number computation compared lie splitting already seen finite dimensional case indeed, propagator semigroup get lie trotter strang splitting scheme multiplicative splitting scheme formal semigroups combined via composition exclusively following peaceman rachford douglas rachford operator splitting scheme called additive formulate underlying idea, consider ode solution approximated using explicit forward euler method using implicit backward euler method formally respectively cf idea peaceman rachford splitting follows divide half, run forward euler scheme backward euler scheme run algorithm half interval, switching role setting autonomous linear version douglas rachford splitting similar idea autonomous linear version douglas rachford splitting extended case glowoshyin splitting last additive scheme write explicitly development peaceman rachford splitting called fractional scheme additive splitting scheme expected first order accurate general second order accurate operator nice operator computationally problematic eg multivalued peaceman rachford douglas rachford splittings modified exclude second subproblem instance, solving first equation get peaceman rachford splitting common additive operator splitting scheme tseng splitting eg suchogimouk parallel, alge iteration davis yin splitting eg arato direct, chenchangliu three operator general, additive operator splitting scheme considered known convergent provided operator involved monotone let recall basic fact last assumption optimization theory baucom convex, zeid nonlinear briefly explain terminology often encountered context operator splitting method optimization let banach space possibly nonlinear multivalued operator called monotone operator monotonicity one cornerstone optimization theory general convex optimization particular browder minty theorem state additionally hemicontinuous coercive is, mapping continuous equation solution moreover, subdifferential proper closed convex function necessarily maximally monotone operator so, roughly speaking, one solve instead original optimization problem is, one find function zero set define proximal operator operator prox coincides resolvent id additionally, prox id lipschitz operator admit decomposition called firmly non expansive, fixed point proximal iteration guaranteed converge relation present variational inequality convex function one find numerous application operator splitting method context theory monotone proximal operator particular, context fixed point iteration result often formulated either term fixed point proximal operator term resolvent zero set monotone operator technically, however, zero set sampled running fixed point iteration algorithm, method based lagrange multiplier commonly used formulation moreover, popular effective alternating direction method lagrange multiplier addm actually reformulated peaceman rachford douglas rachford splittings additive operator splitting scheme baucom convex called forward backward splitting derived follows want find note alternatively show fixed point id id one may expect sufficiently small fixed point iteration converge monotone also cocoercive operator cocoercive firmly non expansive cocoercive operator often appear proper gradient note corresponding ivp splitting scheme usually spatially discretized additionally practice high dimensional system possibly nonlinear differential equations, one selects method solve system separately outer splitting scheme instance, starting second order parabolic pde replacing spacial derivative corresponding difference quotient obtain spatial high dimensional ode possibly non uniform grid space basis function finite element scheme used matrix depends grid size grid explicitly space time discretizations used, high dimensional possibly nonlinear equation time space discretizations treated differently larger scale additive method usually built discretization time multiplicative splitting schemes, contrast, usually dictate subproblems solved choosing concrete method lead variation initial scheme instance, considering non autonomous lie trotter splitting choosing step backward euler method obtain marchuk yanenko splitting define autonomous case alternative version trotter kato theorem outer inner optimization share time step alternatively, one use runge kutta type method step smaller time step splitting scheme etc multiplicative method feature fixed one step internal optimization step marchuk yanenko splitting called alternatively locally one dimensional method lod generalized sense hundsver numerical peaceman rachford douglas rachford splittings known alternating direction implicit method adi multiplicative splitting method subclass exponential operator splitting method also called simply higher order splitting method method formally represented linear combination formal semigroups form number necessarily non negative even real method often used construct higher order scheme however, term exponential splitting sometimes simply mean standard lie trotter splitting autonomous strang splitting exponential splitting scheme matrices, scheme second order accurate hundsver numerical using one define formally forth order requires solving pde backward time special constructive operator splitting scheme build simpler one usually multiplicative often called hybrid, weighted, additive alternative meaning iterative briefly treated context exponential splitting method later text operator splitting method encountered probabilistic setting mostly multiplicative modern classification operator splitting method presented glowoshyin splitting however, multiplicative additive method historically different origin different society contributor specific operator splitting scheme particular version general scheme eg st rmet verlet integration method may developed rediscovered narrow ad hoc method particular problem, nomenclature rather diverse necessarily posse integrity researcher interested historical accuracy would desire following short interlude collect alternative name start lie trotter splitting standard historically justified alternative name fractional step method method fractional step also include similar scheme possibility revolve around sur name lie, te trotter kato different combinations, one common lie splitting glowoshyin splitting analyst often speak trotter kato formula probabilists may use splitting physicist may speak suzuki trotter expansion decomposition sequential splitting another alternative strang splitting called marchuk strang splitting autonomous peaceman rachford marchuk yanenko splittings written term revolvents thus sequential splitting resolvent splitting eg considered separately another example ryu splitting eg arcamtam strengthened, matam resolvent additive, sequential, weighted iterative splitting scheme may mean different thing different author refer section example particular version algorithm include st rmet verlet leapfrog method see section time evolving block decimation ursol parallel, hahamccu hybrid split hamiltonian method casanzshaw split, shanlanjohnneal split split step fourier alezashei split step, tasmithwolf analysis mapping method wi origin, mal mapping gradient projection cuishanb analysis, finowright gradient split bregman method golbreosher geometric, oberoshertatsai numerical primal dual splitting botcsethend recent, conkiconthi proximal rosenbrock approximate matrix factorization botver new, beckgonpewei comparison aforementioned tseng, davis lin, ryu splittings others intermediate value approximation real solution additive splitting method true multiplicative scheme additive splitting method seen particular instance implicit explicit mixed method imex note matrix contains case second derivative thus introduces stiffness system even present originally particular, implicit method advised solving ode section consider basic idea behind actual implementation splitting scheme parabolic pde, usage mc since additional layer spacial discretization almost always present, total error operator splitting scheme composed theoretical error splitting procedure itself, error space time discretization procedure used obtain finite dimensional formulation subproblems, ordinary calculational error chosen method corresponding program implementation used solve finite dimensional problem error additive, obviously, though one try obtain additive bound occasion, stability final scheme may vary greatly different choice internal sub routine discretization may involve choosing mesh, basis expansions, interpolation point space time grid, choosing specific formula first second higher derivative boundary, variable grid steps, finite difference finite volume general, using volume mass preservation formulation etc alternatively, probabilistic interpretation available, one may apply mc methods, upper bound error becomes, roughly speaking, statistical discrepancy due insufficient number simulation estimated eg using berry esseen, bikelis concentration inequality grata stochastic error actual simulation procedure corresponding random process let consider basic naive example explain situation consider ordinary pde inhomogeneous term lie trotter splitting scheme separate ode semigroup markov process assume square root lipschitz continuous bounded, independent wiener processes, function satisfies suitable growth condition process semigroup well defined suppose time step splitting scheme exact expression one step two possible lie trotter splittings let family numerical approximation flow whose nature may arbitrary sense let number mc simulation step splitting scheme let simulation time step one step splitting procedure mc solve respectively error numerical scheme come number source semigroup recover original flow unless ode solved explicitly, number simulation finite, simulation perfect random number generator produce pseudorandom number actually, value simulated using smaller time step limit small get, higher order simulation scheme require either calculating iterated stochastic integral reliably providing family random variable moment given order etc, splitting however, mc unavailable specific pde even applicable, method rarely first choice pdes practice note one cannot really simulate discretized whole straightforwardly instance, standard finite difference scheme properly modified unbounded domain eg introducing artificial boundary transforming original pde one bounded domain hand, real world engineering pdes usually stated bounded domain automatically though mc significantly le sensitive problem unbounded domains, presence boundary cause problem one think using classical euler maruyama scheme simulate one dimensional sde whose solution always stay positive impossible keep approximation positive since use symmetrical random increments, one consider corrected suitable implicit scheme etc remedy consider bounded domain bc boundary assumed piecewise lipschitz, customary apply feynman kac formula get analog defined one could try consider decomposition cf section family degenerate first order pdes define instead since bc function only, alternative setting however, reference section show naive approach bc proper one transforms time hit even though consider dirichlet bc, clear decomposition cannot arbitrary even accommodate eg set may unreachable bc make sense process cannot reflected neumann bc cannot imposed etc recalling classification boundary point diffusion exists dimension higher equal see particular difficulty probabilistic origin assume also given family possibly non uniform grid tessellation whose size converge following ode finite dimensional spatially discretized version term appears due boundary correction calculating derivative explicitly depends discretized version ic change step splitting scheme let denote finite dimensional approximation grid time step one use standard scheme time step solving ode get solved remarked already, matrix depends contains second power grid size thus need implicit sufficiently stable method whose step size get smaller thus limit choice grid practice introduces error value depends domain property etc scheme run every step splitting procedure however, let choose simplicity forward euler method time step instead linear matrix valued equation also need family numerical approximation flow whose nature may arbitrary appropriate sense approximation also finite dimensional live grid may defined arbitrary also make sense therefore combine operator need introduce interpolation procedure well defined simplest example linear interpolation uniform grid get instead left write corresponding version mc defined thus get additional source error decomposition bc corresponding correction solving ode part corresponding pdes interpolation point grid space discretization, property grids, choice difference quotient etc internal time discretization associated internal error continue discussion bc affect splitting later practice, grid is, fixed choosing proper mean choosing sufficiently numerically efficient spatial discretization however, different subproblems diffusion ode case may use different spatial discretizations different grid instance, assume dimension splitting applied second order operator decomposed itse",mathematics
"homeomorphism type floyd boundary infinite ended group introduction preliminary construction floyd boundary amalgamated free product hnn extension homeomorphism type floyd boundary free product homeomorphism type floyd boundary amalgamated free product hnn extension main theorem component floyd boundary infinite ended group instruction reporting error coarse geometric notion floyd completion group tree cayley graph corresponding amalgamated free product tree cayley graph corresponding hnn extension boundary stabilizer two topology equivalence topology hnn extension case amalgam case hnn extension case proof theorem proof theorem proof theorem experimental suppose finitely generated infinite group graph group decomposition edge group finite paper establishes topology floyd boundary uniquely determined topology floyd boundary vertex group one first compactification group introduced floyd flo known floyd boundary general, floyd boundary depends scaling function known floyd function compactification exhibit strong connection theory hyperbolic relatively hyperbolic group given hyperbolic group exists floyd function floyd boundary respect homeomorphic gromov boundary see gro similarly, finitely generated group hyperbolic relative collection subgroups, gerasimov ger show exists floyd function continuous equivariant map floyd boundary respect bowditch boundary floyd boundary also connection convergence action see kar martin wi polhkatkowski proved topology gromov boundary free product hyperbolic group uniquely determined topology gromov bounary free factor paper, drop hypothesis free factor hyperbolic prove similar result floyd boundary throughout paper, group assumed finitely generated following main result paper theorem theorem suppose two infinite group suppose graph group decomposition respectively edge group finite then, following vertex group elementary infinitely many end floyd boundary homeomorphic cantor set suppose least one vertex group either non elementary let denote set homeomorphism type floyd boundary non elementary vertex group respectively floyd boundary homeomorphic floyd boundary non elementary group one virtually cyclic one interesting consequence theorem that, floyd function, floyd boundary virtually free group homeomorphic cantor set see corollary need following result prove previous theorem, tell homeomorphism type floyd boundary free product theorem theorem let two free product least one free factor either non elementary let denote set homeomorphism type floyd boundary non elementary free factor respectively floyd boundary homeomorphic floyd boundary remark theorem, free factor elementary either floyd boundary contains point homeomorphic cantor set see corollary next, look connected component floyd boundary infinite ended group obtain partial converse theorem theorem theorem suppose two finitely generated infinite ended group suppose graph group decomposition respectively edge group finite, non elementary vertex group ended also, assume least one vertex group non elementary then, following let denote set homeomorphism type floyd boundary non elementary vertex group respectively floyd boundary homeomorphic floyd boundary organization paper section recall basic fact floyd boundary exlain cayley graph amalgamted free product hnn extension section contains construction floyd boundary amalgamated free product hnn extension finite group section discus homeomorphism type floyd boundary free product then, section discus homeomorphism type floyd boundary amalgamated free product hnn extension there, deduce number interesting corollary section give proof theorem finally, section finish paper discussing connected component floyd boundary graph group finite edge group let metric space let geodesic joining isometric embedding two point joined geodesic called geodesic metric space geodesic joining denoted throughout paper, graph assumed connected shall denote quantity inf suppose two metric space given bi lipschitz map one map said bi lipschitz bi lipschitz notion floyd boundary group introduced floyd flo let group generated finite set, say, let cayley graph respect assigning edge unit length, see naturally complete geodesic metric space denote metric let function satisfying following two condition exists call floyd function simplify construction floyd boundary, floyd function f, de ne example floyd function define new metric scaling length edge let denote identity element edge connecting vertex define new edge length path given consecutive edge floyd length defined define easy see metric called floyd metric cauchy completion metric space called floyd completion subspace called floyd boundary denoted definition depend choice finite generating set see flo lemma thus, suppress dependence generating set denote completion note finite diameter summable compact since group act isometry action extends action homeomorphism see kar detail similarly, one define floyd boundary locally finite graph sequence said shortest sequence if, shortest sequence cauchy sequence since given exists shortest, hence lemma suppose two finitely generated groups, finite group let amalgamated free product monomorphisms choose finite generating set let cayley graph respect generating set denote associated word metric start subsection defining bass serre tree ser corresponding let unit interval vertex define tree called bass serre tree divided transitive closure relation defined follows tree come natural action vertex denote stabilizer let cayley graph respect respectively let subgraphs vertex respectively since subgraphs subgraphs diameter define graph union identified thus, obtain subgraph union identified denote subgraph finally, define graph equivalence relation induced note cayley graph respect define map sending contain subgraph sends well since distance apart coarsely well defined notation write edge if, either vertex cayley graph isometric either denote preimage nothing similarly, denote preimage vertex denote preimage denote subgraphs point, using notation assume shortest possible coset representative similarly, assume cosets let finitely generated group finite subgroup group let hnn extension let isomorphism then, presentation let finite generating set contains let cayley graph respect stable letter denote word metric firstly, give description bass serre tree, say, vertex set say, set left cosets set edge say, set left cosets vertex connected edge let cayley graph respect consider graph induced following equivalence relation denote equivalence class subgraph spanned vertex connected component isometric word metric now, cayley graph defined using graph follows vertex connected bass serre tree similarly, join vertex denote subgraph spanned vertex discussion, say subgraphs connected subgraph hence, define natural projection map, case well defined amalgamated free product case let subsection next subsection devoted construction floyd boundary hyperbolic trivial, martin wi polhkatkowski gave construction gromov boundary closely follow construction let floyd function notation retain notation used subsection denote scaled cayley graph respect generating set floyd metric sake ease, denote metric subspace respectively similarly, denote metric subspace define metric completion let floyd boundary respectively let set divided equivalence relation induced equivalence class element denoted set come natural action left also come natural projection onto set vertex preimage vertex denoted identified lemma let denotes gromov boundary then, set, denote boundary also, set, define compactification set come natural action natural map coarsely well defined preimage vertex identified, set, metric completion two way put topology here, give description topologies, prove two equivalent topology using neighborhood system point set basis open neighborhood basis open neighborhood define basis open neighborhood point fix vertex let suppose vertex let open neighborhood define set first edge geodesic geodesic ray vertex set neighborhood basis collection set run neighborhood basis let let subtree consisting element first edge suppose vertex distance let denotes gromov boundary let define take collection basis open neighborhood skip straightforward verification collection set satisfy axiom basis open neighborhood metric recall floyd metric notation metric subspace indicated first paragraph section defining metric record following observation follows kar natural translation map bi lipschitz hence induces homeomorphism similarly, homeomorphic let fix vertex let sequence vertex lie geodesic ray joining suppose connected edge choose straightforward show cauchy sequence choice cauchy equivalent call sequence cauchy representative definition metric define metric following manner suppose vertex let cauchy sequence representing then, lim limit exists cauchy, independent chosen sequence suppose let cauchy sequence representing respectively then, lim since cauchy, limit exists, independent chosen sequence let three distinct point let cauchy representative respectively, discussion show following definition depend chosen sequence lim lim cauchy sequence representing lim definition metric directly conclude vertex restriction completion metric metric space definition, follows pseudo metric remains check positivity thus, following three case remaining consider case suppose then, remark suppose let first last edge geodesic suppose joined similarly, suppose joined then, following inequality suppose cauchy sequence representing respectively then, putting equation applying limit sides, get remark fact compact subset hence, conclude case suppose let let cauchy representative let first edge geodesic ray suppose joined then, case get let cauchy representative putting last equation taking limit sides, get case suppose respective cauchy representative let geodesic respectively exists unique vertex let first edge suppose joined joined then, sufficiently large geodesic joining pa implies hence, conclude now, ready prove following floyd boundary isometric recall every two possible proof, choose value closest let natural inclusion map, isometric embedding hence extends isometric embedding denotes cauchy completion show fact isometry note nothing cauchy completion let shortest sequence then, lemma cauchy sequence also, distance non decreasing hence, following two case case exists sufficiently large n, distance since shortest sequence exists vertex large hence, converges point case distance go since shortest, exists geodesic ray, say, let point represented then, subsequence becomes cauchy representative hence, converges let exists shortest sequence two cases, know exists hence, continuity implies hence, conclude since, construction, dense turn implies hence, isometry give desired result let topology defined neighborhood basis let topology induced metric subsection, show finer let let represents coset reduced representative let radius ball show exists neighborhood choose let note compact subset define evident open neighborhood let element let first edge either geodesic geodesic ray assume joined since every path joining pa since representative necessarily reduced contained get thus, using inequality get using triangle inequality, get hence, conclude now, let let open ball radius choose unique sequence along unique geodesic converges let edge reduced representative coset associated vertex cauchy representative thus, converges choose easy see every path pa hence, using inequality triangle inequality, get hence finer let vertex let neighborhood neighborhood since open exists ball radius contained let radius ball then, follows definition neighborhood let let neighborhood choose let ball radius then, again, easy see subsection, retain notation subsection let floyd function denote scaled cayley graph respect generating set floyd metric sake ease, denote metric subspace similarly, denote metric subspace define metric completion boundary stabilizer let set divided equivalence relation induced equivalence class element denoted set come natural action left also come natural projection onto set vertex result similar lemma hold implies homeomorphic hence, every vertex identified let denotes gromov boundary then, set, define boundary also, set, define compactification set come natural action natural map case well defined preimage vertex identified, set, metric completion subsection similarly define topology metric following step employed previous subsections, one easily show topology topology induced metric homeomorphic well metric isometric hence, subspace topology induced homeomorphic main goal section prove following theorem section, assume group infinite unless mentioned otherwise suppose two free product infinite group let two floyd function homeomorphism easy application induction give following suppose two free product infinite group let two floyd function then, notation let fixed homeomorphism floyd boundary denote homeomorphism induced let bass serre tree respectively finally, denote cayley graph respectively construction cayley graph free product section taking trivial suppose two finitely generated groups, two floyd function respectively let cayley graph respectively floyd metric then, compact metrizable space one metric subspace metric respectively following lemma analog lemma context floyd boundary let homeomorphism bijection homeomorphism define map take exists compact easy application triangle inequality show dense order element sequence define choose required iterate following two step alternatively step suppose smallest number yet defined since dense choose image map then, define step suppose smallest number chosen image since dense hence dense choose yet defined then, define performing two step alternatively, see bijection since compact metrizable, prove homeomorphism, sufficient prove continuous consider sequence converges then, lim thus lim implies lim using triangle inequality, therefore converges hence, continuity converges definition follows lim thus, converges hence, continuous immediately following exists bijection following hold let let open neighborhood exists neighborhood let bijection lemma thus, homeomorphism prove required bijection since open neighborhood viewing subspace open neighborhood since compact exists open neighborhood clear using argument lemma get following topological result corollary, use coming section let compact metric space countable dense subspace every element isolated respectively denote assume exists homeomorphism exists bijection map homeomorphism using corollary prove following topological lemma, turn useful later following lemma, closure subset metric space shall denoted let compact metric space countable dense subset containing isolated point define then, exist metric subspace exist bijections induce homeomorphisms identity map let metric space isometric embedding let let let quotient map note set, now, bh lemma define metric follows inf metric compatible topology defined quotient map clear definition restriction either isometric embedding also, countable dense subset contains isolated point now, define note restriction isometry onto nothing identity map since compact, applying corollary get bijection induces homeomorphim let then, take restriction composition restricted hence lemma previous lemma generalized many property lemma using notation used lemma assume many property mentioned lemma let neighborhood straightforward check exists neighborhood isomorphism corresponding homeomorphisms let bijections lemma let edge stabilized respectively recall non trivial element expressed uniquely, reduced form, allowing also define map map edge edge easy check isomorphism now, ready prove homeomorphic sufficient prove homeomorphic note that, set representative form similarly, set representative form choose unique smallest possible case choose unique representative element called reduced represenatives finally, define map following manner let let reduced representative define let represent infinite word subword consisting first letter corresponds th edge geodesic via correspondence define infinite word right give geodesic ray starting note restriction map induced isomorphism map homeomorphism definition follows bijection show homeomorphism, sufficient prove continuous two case considered case let let vertex let open neighborhood corollary open neighborhood then, definition neighborhood follows case let integer consider subtree defined respect let subtree respect base vertex again, definition neighborhoods, follows completes proof theorem end section proving following interesting case let floyd function let infinite group finite group homeomorphic assume lemma and, exists bijection extends homeomorphism sake distinction, let let extends homeomorphisms denote scaled cayley graph bass serre tree respectively let set vertex represents cosets vertex set discussion section know sufficient produce homeomorphism since finite group, empty implies every representing coset empty progressing along line proof theorem define homeomorphism domain codomain subspace topology induced let represents unique reduced form discussed section let denotes natural number define map follows map induces required homeomorphism discussed proof theorem every element exists unique reduced representative define map following manner remark corollary deduce continuous every straightforward check also continuous every point hence, conclude continuous since compact bijection, also homeomorphism hence, conclude proof far, proved homeomorphism type floyd boundary free product infinite group depends homeomorphism type floyd boundary free factor now, proceed prove similar result group admitting decomposition amalgamted free product hnn extension finite group fix floyd function section main result subsection following suppose infinite group then, following also infinite finite homeomorphic cantor set non trivial finite group infinitely many end denote scaled cayley graph bass serre tree respectively let edge joining respectively let subset contain exactly one coset representative coset respectively also assume identity contained edge unique reduced form allowing case infinite, empty easy check countable, dense subset respectively applying corollary get bijections extend homeomorphisms id id define reduced form element map graph isomorphism inducing homeomorphism define map follows following discussion proof theorem every element choose reduced representative reduced form define define assume let map take since remark show continuous every point vertex represents coset applying similar argument give conclusion continuous every point since homeomorphism, easy see also continuous every point since continuous bijection compact, homeomorphism case finite group empty let index show use map defined last case let bijection let edge joining bass serre tree define take edge reduced form note isomorphism hence induces homeomorphism now, used define homeomorphism last case finally, proposition get completes proof case let denote bass serre tree cayley graph respectively section know since, finite groups, empty, implies empty hence, since degree vertex bounded fixed natural number, homeomorphic cantor set theorem ended virtually cyclic hence see kar proposition immediately following corollary whose proof easy application induction let tree vertex let graph group edge group finite suppose fundamental group vertex group then, following infinite infinite and, finite then, reindexing required suppose exists infinite finite then, finite infinite ended homeomorphic canter set subsection devoted prove following theorem let finite subgroup then, following infinite group finite either equal homeomorphic cantor set sake distinction, let isomorphic copy let generating set denote bass serre tree cayley graph respect generating set respectively discussion subsection sufficient produce homeomorphism let set left coset representative respectively, every coset exists unique reduced representative coset form possible proof, denote identity map id lemma disjoint subset bijections id homeomorphisms since dense exist bijections id homeomorphisms see corollary define map similarly, define map isometric copy construction, conclude id id homeomorphisms firstly, define graph isomorphism follows induces homeomorphism define map follows let define define using remark show continuous since compact bijection, conclude homeomorphism since finite, empty hence, however, regular homeomorphic cantor set theorem finite case, virtually cyclic hence let free product elementary group least one free factor infinite then, floyd boundary homeomorphic cantor set two case consider case reindexing, required, assume infinite finite then, corollary since virtually cyclic, thus, theorem let non trivial finite group then, proposition since isomorphic floyd boundary homeomorphic now, theorem homeomorphic cantor set case reindexing, necessary, suppose exists infinite finite then, corollary infinite virtually cyclic induction, easy prove homeomorphic cantor set end subsection proving following remove dependence floyd boundary free product virtually cyclic group let free product infinite group that, virtually cyclic then, homeomorphic prove induction let then, since isomorphic homeomorphic theorem suppose now, theorem homeomorphic theorem corollary follows case combining corollary corollary following let non elementary elementary group then, following floyd boundary homeomorphic let two floyd function fixed next section here, main goal prove following suppose two finitely generated infinite group suppose graph group decomposition respectively edge group finite then, following vertex group elementary infinitely many end homeomorphic cantor set suppose least one vertex group either non elementary let denote set homeomorphism type floyd boundary non elementary vertex group respect respectively homeomorphic prove theorem, use following result let two free product least one free factor either non elementary let denote set homeomorphism type floyd boundary non elementary free factor respect respectively floyd boundary homeomorphic floyd boundary getting proof theorem prove following result turn useful proving theorem suppose free product infinite group homeomorphic homeomorphic immediately following corollary suppose free product infinite group applying theorem see homeomorphic theorem suppose free product infinite group suppose homeomorphic then, homeomorphic prove induction theorem follows suppose then, theorem homeomorphic using theorem proposition immediately following corollary let infinite group finite let free product group infinite group finite group prove induction proposition let assume now, proposition see inductive hypothesis, hence, theorem finally, corollary let theorem let bass serre tree suppose let bass serre tree subsection, first all, prove isomorphism using isomorphism, define map prove fact homeomorphism isomorphism let cayley graph respect finite generating set then, compact metrizable space restricted metric, compact, dense contains isolated point then, lemma exist exist bijections induce homeomorphisms respectively since homeomorphic lemma exists bijection induces homeomorphism let identity map element written identity respective group shall call standard form let edge edge respectively note edge translate similarly, edge either translate translate define map following manner case let edge standard form two subcases subcase suppose then, define otherwise otherwise case, define subcase suppose then, define where, otherwise otherwise case, define case let edge standard form two subcases subcase suppose then, define where, otherwise otherwise case, define subcase suppose then, define otherwise otherwise case, define construction follows isomorphism homeomorphism let scaled cayley graph respectively let compact metrizable space constructed section proposition follows homeomorphic homeomorphic let identity homeomorphisms, let homeomorphism homeomorphism since isomorphism, induces homeomorphism define map following manner suppose let vertex discussed proof theorem exists unique reduced representative define suppose then, define remark corollary continuity every point follows definition neighborhoods, straightforward check continuity every point since compact bijection, conclude homeomorphism hence, complete proof theorem let natural number reindexing groups, required, elementary group now, following two case occur case suppose then, corollary since reindexing necessary, then, theorem done then, corollary corollary exists again, done theorem case suppose corollary get using corollary corollary see easy application corollary induction give since following process above, exist finally, corollary let undeline graph let maximal tree respectively then, restriction tree group finite edge group whose fundamental group are, say, infinite then, theorem homeomorphic cantor set corollary corollary suppose finite since repeated hnn extension infinitely many ends, least one edge outside give hnn extension, say, infinite group then, repeated application theorem see again, theorem homeomorphic cantor set now, theorem corollary give homeomorphic corollary hence, floyd boundary homeomorphic cantor set similarly, analysis, one show homeomorphic cantor set let vertex group respectively two case consider case reindexing required assume non elementary and, elementary then, corollary since reindexing required assume non elementary and, elementary thus, now, theorem corollary give similarly, hence, theorem case reindexing required assume exists non elementary elementary similarly, assume exists non elementary elementary thus, combining corollary corollary now, theorem give since theorem give complete proof theorem well known gromov boundary hyperbolic group connected ended section, first all, prove analog fact context floyd boundary let ended group floyd function denote scaled cayley graph respect finite generating set floyd metric denotes metric cayley graph assume metric completion metric connected define map sake contradiction, assume non empty, disjoint open subset let denote closure definition follows sequence converging point also converges thus, see check let let sequence suppose exists infinite subsequence contained turn implies give contradiction disjoint hence, eventually contained applying similar argument lead following conclusion since non empty, exists assume sequence respectively, every denote closed metric ball radius since ended, exist subsequence path joining contained let edge since compact, exists subsequence converges since easy see implies give contradiction hence, desired result now, record following fact whose proof proof proposition let group split graph group edge group finite infinite ended suppose non elementary vertex group ended then, connected component either homeomorphic floyd boundary non elementary vertex group singleton set now, ready prove following give partial converse theorem suppose two finitely generated infinite ended group suppose graph group decomposition respectively edge group",mathematics
"introduction setting theory theoretical data driven information level numerical experiment result proof bias conditional monte carlo discrete distribution instruction reporting error heavy tailed case light tailed case empirical truncation level heavy tailed case light tailed case validating theory impact tail truncation impact tail heaviness data driven estimation quantifying tail uncertainty using bootstrap detection tail heaviness summary experimental takeaway experimental propagation input tail uncertainty rare event estimation propagation input tail uncertainty rare event estimation light versus heavy tail dichotomy zl columbiaedu consider estimation small probability risk quantity associated rare catastrophic event model based literature, much focus devoted efficient monte carlo computation analytical approximation assuming model accurately specified paper, study distinct direction propagation model uncertainty impact reliability rare event estimate specifically, consider basic setup exceedance iid sum, investigate lack tail information input summand affect output probability argue heavy tailed problem much vulnerable input uncertainty light tailed problems, reasoned large deviation behavior numerical evidence also investigate approach quantify model error problem using combination bootstrap extreme value theory, showing positive outcome also uncovering statistical challenge uncertainty propagation, model uncertainty, rare event estimation, large deviation estimating small probability risk quantity associated rare catastrophic event ubiquitous risk analysis management example include prediction large asset loss finance cash flow imbalance insurance system overload service operation breakdown communication system model based approaches, namely model built capture internal dynamic system, much focus literature devoted efficient monte carlo computation analytical approximation, assuming model accurately specified eg, however, virtually cases, target rare event quantity computed model affected input misspecifications, inaccuracy calibrating model propagated output make target estimate erroneous even meaningless study impact input misspecifications gathered growing attention recent years, generally known problem model uncertainty input uncertainty main focus develop methodology quantify error output estimation decision attributed model misspecifications, measured term bound variance see, eg, stochastic simulation literature, finance, economics, control operation management application extremal estimation, problem intimately related extreme value theory, one attempt extrapolate tail beyond scope data statistically justified fashion, along uncertainty quantification recently, framework called distributionally robust optimization studied construct bound extremal measure additional robustness property beyond statistical asymptotics approach utilizes postulation acknowledgement true distribution within neighborhood baseline model marginal information extremal coefficient moment shape assumption tail monotonicity convexity simulation based rare event analysis, studied method efficiently compute sensitivity rare event probability respect model parameters, proposed averaging distribution fit input model enhance tail performance contrast past literature focused technique quantify impact model uncertainty, paper aim understand significance impact relation level input information propagation mechanic rare event problem specifically, consider basic problem large exceedance probability iid sum, input model refers probability distribution governing summand here, suppose input data informs summand distribution first question would simply using empirical distribution input model fit, would rare event probability reasonably close truth assuming computational monte carlo error negligible address question viewpoint main uncertainty input model undermines accuracy rare event estimation lack knowledge tail central, non tail part input distribution typically fit parametric nonparametric techniques, adequate data perform fit question simply empirical distribution contrast, tail portion often ill informed due inadequate data, yet high impact aggregated tail behavior thus, address question first focus truncating tail input model affect rare event estimate main contention heavy tailed problem suffers much larger impact input model truncation light tailed counterpart truncation level represents amount tail knowledge obtained data, maximum data remaining data discard fixed number largest data point consequence, using empirical distribution even moderate data size, asked question fails estimate heavy tailed rare event quantity reliably hand, effect missing tail light tailed estimation relatively milder hence reliable estimation case achievable much le data requirement different effect truncating input tail explained different large deviation behavior heavy versus light tailed system specifically, former pertains one several big jump ie, invoke rare event, one several input component exhibit huge values, latter invokes rare event component contribute small shift adding contribution thus, accurately estimate heavy tailed rare event, one need accurately estimate far tail input component, whereas necessary light tailed system mathematical analysis rigorize intuition relies berry en expansion exact large deviation asymptotics, allow compare rare event probability true truncated distribution particular, expansion asymptotics derived triangular array growing truncation levels, requires elaborate analysis new best knowledge above, go ask whether statistically error arising input uncertainty, specifically point estimate question could bootstrap give rise valid confidence interval account input error would incorporating extreme value theory fitting input tail lead reliable uncertainty quantification address question ran extensive experiment evaluate performance bootstrap extreme value theory enhanced bootstrap technique across various scenario involving different tail distributions, sample sizes, target probability find that, particularly situation exhibiting heavy tailed behaviors, even sample size relatively large, ie, approaching inverse target probability, using empirical bootstrap question significantly ignores tail content would fail estimate rare event quantity vastly estimate uncertainty uncertainty estimation could come power law tail non power law subexponential tail using extreme value theory question extrapolate tail peak threshold method, eg, help extent, could introduce extra bias, least using fitting method introduction bias primarily due presence unknown slowly varying function true data distribution, making generalized pareto distribution misspecified tail model positive side, numerical experiment demonstrates extreme index estimator effectively identifies case prone uncertainty estimation, irrespective whether caused power law tail non power law subexponential tail identification serf indicator additional data collection necessary improve precision reliability estimation uncertainty quantification finally, contrast study question related work especially investigated sensitivity large deviation rate input model deviate within nyi divergence ball showed similar context imposing single ball inputs, thus allowing distortion dependency structure among inputs, lead substantially heavier tail original model kullback leibler divergence used studied robust rare event simulation input tail unknown subject geometric assumption studied impact waiting time tail service time misspecified truncated relating investigated truncation threshold needed retain heavy tailed characteristic system also contrasted light tailed case observed required threshold higher heavy tail observation regard thus similar different setting aggregation iid variable requires derive elaborately berry en expansion exact large deviation asymptotics truncated distribution order compare rare event probability truncated true distribution moreover, focus statistical implication asked question validate theory numerically investigate error assessment scheme remainder paper follows section describes estimation target explains impact tail truncation light versus heavy tailed case section discus data requirement threshold reliable unreliable estimation section show numerical result use truncated distributions, empirical distributions, bootstrapping, detection heavy tail appendix contains proof supplemental result throughout paper, sequence write exists integer exists integer consider estimating overshoot aggregation iid variables, ie, consider iid variable drawn distribution denote generic copy convenience assume density exists denote correspondingly, let tail distribution function let suppose high level grows investigation pertaining question following suppose truncate distribution point density becomes ie, consider truncated distribution function given correspondingly truncated density denotes indicator function convenience, denote probability governed arbitrary distribution simply denote governed would like investigate approximation error definition note that, roughly speaking, situation capture case use empirical distribution plug input model, probability mass zero region outside scope data close zero tail data proportional constant introduced ensure proper truncated distribution little effect mass reasonably big first consider pareto tail case suppose regularly varying tail form slowly varying function suppose generally log case, known approximately least one probabilistically, rare event happens likely due big jump one eg, thus, truncation level small compared big jump contributes dominating mass rare event barred, making substantially smaller situation, becomes negligible compared approximation error effectively words, using truncated input distribution lead substantial estimate bias almost equal magnitude rare event probability alternately, write approximation error again, relatively small compared event least one inside probability least one redundant, making probability asymptotically equivalent asymptotically equivalent summarize suppose iid random variable regularly varying tail distribution form let log assume log discrepancy using truncated distribution original distribution evaluating probability given hand, truncation level large enough, probability least one negligible compared error would asymptotically negligible summarized following theorem suppose iid random variable regularly varying tail distribution form let log assume discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, consider case theorem state log rare event estimation essentially void, least asymptotically hand, theorem ensures estimation reliable larger words, truncation level grow faster linear function get reliable estimation rare event probability number input component large, could difficult sustain accuracy level given finite set input data consider posse finite exponential moment, ie, logarithmic moment generating function log neighborhood define consider constant suppose exists unique solution equation exhibit exponential decay ie, log rate function given legendre transform convex conjugate fact, assumed non lattice, following accurate asymptotic theorem although asymptotic proof applied lattice, ie, integer largest number property called span also get accurate asymptotic remark remark truncated distribution, similarly define logarithmic moment generating function log let consider non lattice case example like asymptotic original distribution, approximate solution equation truncation level large enough, converge fast error caused replacing negligible, ie, fact, assume choice satisfies st exists since approximation made precise follows consider constant suppose exists unique solution equation further, suppose choice satisfies distribution non lattice, suppose lattice distribution, ie integer span assume ie, lattice proof lemma quite lengthy need establish berry en expansion specific triangular array order obtain exact large deviation asymptotic theorem particular, requires many precise estimate characteristic function generalize case iid sequence section xvi theorem section theorem although establishes edgeworth expansion general triangular arrays, unclear technical assumption hold characteristic function appendix thus resort self contained analysis triangular array berry en expansion based lemma see asymptotically equal therefore, relative error using estimate asymptotically negligible summarized following theorem consider constant suppose either lattice non lattice moreover, suppose exists unique solution equation then, long truncation level chosen satisfied, discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, theorem postulate long truncation level chosen high enough satisfied, model error using truncated input negligible contrast heavy tailed case, condition dictate typically logarithmic requirement illustrate choice different distributions, consider following example first show increasingly stringent requirement tail heaviness increase suppose normal distribution direct calculation show choice number satisfying log suppose exponential distribution direct calculation show choice number satisfying log suppose gamma distribution direct calculation show choice number satisfying log example, let generalize three example suppose admits density function satisfying further, suppose choice number satisfying log contrast heavy tail setting, establish result unreliable estimation light tail case since condition subtle example, consider extreme case bounded estimation would eventually zero error long truncation level go infinity moreover, theorem enough support point estimation problem harder heavy tail case see discussion section finally, besides quantity targeting, also consider although reliability result probability estimation truncated distribution change, asymptotics probability change lattice case completeness, present result related appendix section assume fully know truncated distribution section, connect developed theory data combining theorem extreme value theory, aiming give guidance reliability rare event probability estimation term data size consider estimating sum iid random variable unknown distribution suppose iid sample construct empirical distribution want answer question whether estimation true probability reliable closely related question many sample need get reliable approximation natural approach connect theorem data set truncation level threshold informable data, namely use properly defined empirical truncation level know asymptotic order empirical truncation level respect data size transform condition truncation level theorem condition judge estimation reliability term note natural definition empirical truncation level converge infinity otherwise never approximate true distribution even lead inconsistent estimator due restriction, appears good choice define empirical truncation level as, eg, empirical quantile since empirical quantile converges true quantile instead infinity simplicity, set empirical truncation level sample maximum max empirical truncated distribution exactly empirical distribution alternatively, discard fixed number, eg, largest sample data take maximum remaining data truncation level latter affect analysis since asymptotic order truncation level remain corollary remaining task analyze asymptotic order borrow tool extreme value theory following, consider heavy light tailed case separately behaves differently two case summary analysis selected light tailed distribution displayed table heavy tailed case, suppose unknown distribution tail slowly varying function index parameter estimated tail index estimator theorem know fr chet distribution parameter normalizing constant satisfies slowly varying function thus rough approximation according theorem truncation level log fixed number approximation reliable log ie, log log estimate reliable theorem similar argument, reliable moreover, approximately represented true probability plugging condition know unreliable log reliable light tailed case complicated since asymptotic order varies different distribution conclusion also different different distribution illustrate, consider two example first, suppose true distribution exponential distribution exp example log thus rough approximation log according theorem truncation level log approximation reliable log log log ie, estimate reliable like heavy tailed case, approximately represent true probability large deviation principle second order taylor expansion log plugging know estimate reliable log second, suppose true distribution normal distribution example log as, lead approximation log log theorem truncation level log arbitrarily small approximation reliable log log ie, arbitrarily small estimate reliable derive required data size target probability level according large deviation implies following approximation plugging obtain reliably estimating target probability level discussion also explains estimation problem usually harder heavy tailed distribution light tailed distribution suppose target probability level fixed heavy tailed case, reliable light tailed distribution exponential, reliable log since log large see heavy tail requires data light tail estimate level rare event probability caution analysis intuitive fully rigorous however, give guideline sufficiency data size reliably estimating rare event probability next section report numerical result validate analysis herein investigate numerically quality estimating finite input data consider different number summands vary magnitude changing value setting, given certain pair tail distribution viewed variable experiment examine three group parametric distribution representing different type tail regularly varying tails, including generalized pareto distribution student distribution positive half whose density tail index reflects tail heaviness, equal inverse shape parameter generalized pareto distribution degree freedom distribution according karamata theorem distribution satisfy assumption theorem light tailed distributions, including standard exponential, standard normal positive half weibull shape parameter whose density given since weibull shape parameter lighter tail normal, call light tailed weibull distribution experiment three distribution satisfy assumption theorem several distribution scope analyses, namely log normal whose logarithm follows weibull shape parameter call heavy tailed weibull distribution distinguish light tailed weibull distribution power law tail, subexponential exhibit heavy tail behaviors, eg one big jump behavior numerical investigation divided four part section provides empirical validation theoretical finding discussed section considering estimation using tail truncated distribution input model section evaluates validity relation reliable estimation data size section section evaluates performance bootstrap combination extreme value theory tools, particular generalized pareto distribution, quantifying estimation uncertainty lastly, given observed challenge estimation uncertainty quantification, appears dependable strategy ensuring accurate estimation sample size significantly larger case inadequate sample size could result uncertainty estimation section then, discus recommend diagnostic method detecting case validate theoretical finding discussed section demonstrating heavy tailed distribution vulnerable truncated tail set experiment, use true distribution, conditional truncation point, generate sample evaluate target rare event probability use tail quantile truncation point, defined compare rare event probability driven truncated distribution, denoted driven untruncated distribution, denoted use gaussian distribution representative light tail distribution heavy tail measure effect tail heaviness, consider distribution three different degree freedom also consider various number summands enhance computational efficiency, apply various variance reduction technique including importance sampling light tailed case conditional monte carlo heavy tailed case details, see result displayed figure maintain consistent true probability level approximately across settings, shown figure figure show relative errors, appear increase heaviness tail particular, heavier tailed distributions, specifically relative error close indicates poor estimation relative true magnitude probability observation align analysis presented section asserts absence tail information particularly harmful problem involving heavy tailed distribution investigate error rare event probability estimation relation data size, various tail rare event probability level consider problem pair independently generate data set sample size use approximate empirical distribution constructed size data setup, repeat experiment time report relative error ratio approximation error ground truth experimental outcome using box plot plot show median central red mark, top bottom edge box represent percentile whisker extend outside box extreme data within range time box height data outside range considered outlier represented red cross reliability estimate determined coverage box box cover smaller height suggests concentrated estimates, sign approximation relatively accurate box fails cover box would mostly close case mean approximation poor due insufficiency using empirical distribution given data size like section variance reduction needed speed computation heavy tailed problems, apply conditional monte carlo sample size constructing empirical distribution sufficient sample since method relies equation max hold discrete, estimator biased simulation based empirical distribution however, demonstrated appendix bias negligible run crude monte carlo, estimate sample drawn empirical distribution conditional monte carlo cases, use sample problem involving light tailed distributions, conditional monte carlo method also employed sufficient sample size note that, despite availability efficient alternatives, select latter method exclude influence variation among different estimator decision affect essential finding experiments, conclusion would remain consistent regardless use efficient approach unfold experiment result three direction section compare heavy light tailed distribution section compare distribution within family different tail heaviness section investigates impact slowly varying function distribution light power law tail figure a, b, show comparison among generalized pareto distribution tail index heavy tail exponential, gaussian light tailed weibull light tail set figure a, sample size relatively small estimate light tailed case accurate, evidenced coverage box however, heavy tailed estimate significantly estimate rare event probability box fail cover truth three case increase sample size figure b, light tailed case start highly reliable estimates, concentrate within relative error bound meanwhile, heavy tailed box still cannot cover truth figure c, increase sample size observe heavy tailed case similar performance light tailed case figure a, box barely cover truth hand, samples, light tailed estimate already highly accurate mostly relative error similar observation found figure d, e, f, set start small sample size figure d, light tailed estimate inaccurate box edge close box capable covering truth, heavy tailed estimate tend estimate probability even though heavy tailed box cover truth, median estimate close indicates half estimate severe estimation sample size increased figure e, light tailed estimate become concentrated box edge light tailed case around heavy tail cases, estimate close relative error case concentrated box edge still tend estimate median close top edge lower even increase sample size figure f, observe heavy tailed case still cannot obtain reasonable estimates, estimate relative error close result indicate problem associated heavy tail prone estimation light tail amount data, consistent discussion section note that, many heavy tailed case eg, figure relative error approach suggesting estimate significantly smaller actual value coincide theorem addition comparison heavy tailed light tailed distributions, find heavy tailed distribution different tail heaviness exhibit different estimation error instance, figure f, observe tail lighter estimate better accuracy heavier tail eg subsection, drill phenomenon investigate impact tail heaviness within parametric family consider heavy tailed distribution pareto student different tail index set consider two setting figure show heavier tail would increase data requirement obtaining accurate estimate particular, figure, distribution ordered left right decreasing tail heaviness figure c, pareto distribution case show similar pattern tail relatively heavy tail index equal estimate approximately relative errors, represent significant estimation tail index increase observe median estimate gradually grows near pareto case figure student case figure finally, tail relatively light tail index equal half estimate closely concentrated around therefore much reliable similar observation found figure well, setting, estimate fail badly tail index smaller equal pareto distribution cases, shown near median relative error increase tail index, lead lighter tail, estimate improve finally box edge concentrate relative error pareto case figure student case figure comparison within parametric family support finding section demonstrating problem heavier tail lead greater estimation next investigate performance non power law tail note figure d, tail index equal pareto box fails cover truth, whereas distribution box larger range contains since tail index, appears slowly varying function inside distribution affect coverage estimate subsection study issue even further, considering additionally subexponential distribution without power law tails, namely log normal heavy tailed weibull distribution figure order distribution left right decreasing tail heaviness asymptotic sense figure a, use light tailed case exp lweib exhibit accurate estimate distributed within approximately relative error heavy tailed cases, box fail cover truth estimate smaller relative errors, estimate well concentrated within relative error note subexponential distributions, whose tail asymptotically lighter estimate fact much worse particular, observe estimate log normal case even worse estimates, top edge box much closer estimate heavy tailed weibull better log normal ones, box still fail cover truth present similar result figure b, c, figures, observe estimate log normal heavy tailed weibull distribution consistently worse estimate distribution even though tail follow power law hence lighter experiment indicate tail falling pareto light tail lead significant estimation issue like pareto tail moreover, comparative estimation performance relative data size tail appear subtle intuitive notion tail heaviness alone might adequately inform estimation reliability next investigate use bootstrapping input uncertainty, particular whether bootstrap confidence interval ci provide valid coverage following, consider two bootstrap scheme nonparametric bootstrap, bootstrap assisted generalized pareto tail fitting create bootstrapped empirical distribution repeated resampling replacement, resample size equal original data size resampling repeated times, resample used input model drive rare event estimation bootstrap ci constructed using empirical quantiles resample estimate present experimental result two problems, one representing heavy tailed scenario another light tailed scenario particular, consider gaussian distribution light tailed case distribution heavy tailed case scenarios, set rare event probability around focus evaluating efficacy bootstrap cis, specifically whether achieve desired coverage level, set experiment obtain coverage levels, make experimental replications, replication construct bootstrap ci whether cover true probability figure present result figure show that, light tailed problems, coverage ci considered case blue solid line result indicate bootstrap ci valid, provide coverage close target level even number sample relatively small compared probability question example, sample versus probability moreover, observe figure ci width relatively big compared estimated probability example, time larger target probability sample wider interval might seem overly cautious, important effectively identifying instance probability estimate unreliable hand, heavy tailed case, figure show bootstrap ci badly cover truth number sample smaller compared light tailed case, sample size small, given target probability around experimental result suggest bootstrap work well light tailed problems, fails heavy tailed problem tie explanation section impact tail uncertainty profound heavy tailed case experiment suggests heavy tailed problems, lack tail information cause problem estimating probability itself, also deem assessment input uncertainty challenging attempt overcome challenge section using generalized pareto distribution inject additional information tail estimation specifically, bootstrap conducted similarly section key variation resample, fit tail using generalized pareto distribution latter conducted via various estimation technique including maximum likelihood estimation mle method moment mom probability weighted moment pwm detailed identifying tail data required fitting, experiment different truncation points, specifically using empirical tail quantiles data experiment, focus heavy tailed case section follows distribution degree freedom consider sample size ranging which, demonstrated figure insufficient standard bootstrap method function effectively similar experiment section ci calculated number resamples run experimental replication obtain statistic coverage interval width experiment result presented figure table figure show scenarios, improvement coverage compared standard bootstrap, indicated provided coverage close target level hand, coverage provided method notably affected chosen truncation point depicted figure a, coverage decrease significantly, even dropping zero, increase sample size note true distribution case distribution, implies mismatch tail fit due model misspecification interval width shrink increasing number samples, model biasedness start surface among three approach fitting generalized pareto distribution, mle pwm turn reliable mom revealed table coverage mom le two approach case performance match documented fact mom unreliable shape parameter sample size smaller observation pwm give smaller average interval width mle, providing similar coverage eg, tail quantile width mle pwm therefore suggests pwm suitable smaller sample sample size large observation mle upper hand term interval width eg, tail quantile width mle pwm experimental result show although overall performance enhanced bootstrap scheme better standard bootstrap, obtained ci still misleading latter caused model biasedness generalized pareto distribution bootstrap cannot overcome seen evidence theory well experiment heavy tail may cause severe estimation using data inform input model rare event estimation moreover, reliably detecting estimation, word providing ci correctly capture amount uncertainty, could challenging well address these, approach devise procedure detect risk uncertainty estimation, word identify case uncertainty estimation, well probability estimation, prone occur inadequate data procedure detects risk, mitigate collecting data big enough size confidently larger magnitude explained section conversely, procedure detects otherwise, analysis section previous experiment demonstrated obtain reliable estimate moderate sample size, sample experiment discussed section note first case, would need get pilot estimate could obtained collected data along suitable conservative inflation, prior knowledge magnitude however, could well case cannot even get rough magnitude access data, either case mean decision making account estimation risk recommend use properly chosen tail index estimate conduct detection extreme value theory literature, various graphical estimation method applied obtain tail information data, including quantile quantile qq plotting mean excess plotting eg chapter tail index estimation detailed discussion, see chapter chapter approaches, assessment tail heaviness achieved estimating tail index, form slope plot explicit estimator among various choices, focus estimators, denoted designed extreme value index also known shape parameter distribution domain attraction generalized pareto distribution compared classical tail index estimator classical hill estimator extreme value index estimator advantage dissecting light heavy tail negative estimate suggests sample light tailed hand, distribution power law tail consistent estimating particular, consider pickands estimator moment estimator important note tail index estimators, including extreme value index estimators, specifically designed pareto tail mean presence slowly varying function distribution could lead model misspecification address issue, common practice excluding data outside tail portion minimize impact slowly varying function truncation point data selected prior implementing estimation process since estimator might sensitive selection truncation point, convention plot pair denotes number order statistic decreasing order tail data truncation, represents corresponding estimate following experiments, collect data distribution section estimate extreme value index using pickands estimator moment estimator section observed one cannot obtain relatively accurate estimate small sample heavy tailed problem want check whether able detect case similar amount sample hence provide warning estimation caused heavy tail experimental results, including pareto distribution, distribution, distributions, presented figure respectively figure show performance estimator data generated pareto distribution classify data exhibiting heavy tailed behavior estimate majority notably characteristic observed case presented figure, showing estimator capable detecting heavy tail pickands estimator figure estimate values, though estimate unstable varies instance, estimate fall purple solid line however, variation would affect conclusion since rest value compared pickands estimator, moment estimate stable estimate consistently especially increase number sample figure d, estimate estimator clearly stronger warning heavy tail term estimating extreme value index, pickands estimate figure perform worse moment estimate figure le consistent varying additionally, estimate appear accurate enough correctly rank tail heaviness hence cannot reliably imply severity heavy tailed behavior instance, cyan solid line consistently smaller estimate dark red solid line whereas true index respectively next, figure present result data generated student distribution observe pickands estimator may lead misclassification heavy tailed data light tailed yielding estimate smaller value performance le reliable compared performance pareto case particular, sample figure a, observe estimate dark red solid line consistently smaller estimate green solid line cyan solid line also cross value around sample figure c, estimate dark red solid line still hand, moment estimator consistent le variation varying sample figure d, estimate positive similar pareto cases, moment estimate capable detecting heavy tailed behaviors, cannot rank heaviness correctly sample size small eg, figure lastly, consider sample light tailed distribution subexponential distribution non power law tail recall section log normal heavy tailed weibull distribution similar performance pareto tail distribution term estimation figure show extreme value index estimation successfully detect risk estimation classifying non power law subexponential distribution heavy tail distributions, extreme value index estimate consistently positive range mostly again, find extreme value index estimator unable accurately gauge severity heavy tailed behavior evident fact index estimate log normal heavy tailed weibull distribution substantially different figure however, discussed section log normal distribution require larger sample size heavy tailed weibull distribution obtaining reliable estimation experiments, concluded extreme value index estimator effective detecting risk estimation classifying whether data heavy tailed particularly prominent moment estimator appear give correct classification across considered setting however, also note estimator may provide precise estimate tail index and, result, may accurately severity heavy tailed behavior key finding experimental study summarized follows heavy tailed problem vulnerable lack data compared light tail reliable estimation rare event probability heavy tailed scenarios, significantly larger sample size required needed light tailed distribution moreover, assessing uncertainty equally difficult subexponential distributions, even absence power law tail, prone estimation point estimate uncertainty evident similar sample size requirement reliable estimation rare event probability subexponential distribution heavy tailed distribution problem standard bootstrap method effectively provide valid uncertainty quantification heavy tailed problem sample size moderate incorporating generalized pareto tail extrapolation bootstrap improves coverage bootstrap cis, reliability coverage affected model misspecification estimator extreme index, especially moment estimator, appear effective detecting risk estimation point estimate uncertainty classifying whether distribution heavy tailed suggestion dependable approach ensure reliable estimation two step procedure first detect whether data prone risk estimation so, employ sample size confidently larger or, case possible, decision making account substantial estimation risk define target probability governed arbitrary distribution using estimate overshoot make difference heavy tailed case fact, following theorem assumption theorem discrepancy using truncated distribution original distribution evaluating probability given assumption theorem discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, light tailed case, asymptotics probability change lattice case since change asymptotics affect reliability result theorem summarize following theorem assumption theorem non lattice case, lattice case moreover, cases, discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, proof theorem recall prove theorem, suffices show since log exists st log large first let log define variance show normalizing s, note tail distribution function normalized random variable karamata representation theorem theorem see slowly varying proposition iii know slowly varying function applying equation equation also hold defined equation similarly, applying equation karamata representation theorem theorem thus therefore, follows comparing show recall log proposition implies combining get log log since truncated distribution stochastically dominates ie, must have, given non decreasing property usual stochastic order theorem thus hold log concludes proof proof theorem argument proof theorem show formula approximation error suffices show least one inequality asymptotic property prove suffices show recall form choice property proposition prof proof theorem theorem argument proof theorem see also hold probability replaced respectively therefore, following analog hold remaining argument proof theorem applied here, prof theorem theorem proved similarly let turn proof light tailed case explained lemma proof quite lengthy would like provide roadmap go detail recall choice depends therefore truncated random variable actually triangular array varies lemma essentially establishes exact asymptotics triangular array special case truncated distribution varying truncation level theorem give exact asymptotics case iid random variable use technique prove lemma key technique proof berry en expansion order well known iid case need make much effort establish similar expansion truncated distribution varying truncation level ie, lemma since proof light tailed case require notations, use",mathematics
"property set valued tensor complementarity problem main result instruction introduce set valued tensor complementarity problem element involved tensor defined based set valued mapping study several property solution set framework set valued mapping provide necessary sufficient condition zero solution set valued tensor complementarity problem introduce limit property set tensor establish connection limit property level boundedness merit function corresponding set valued tensor complementarity problem keywords set valued tensor complementarity problem, tensor, semi positive tensor, tensor, merit function, limit property subject classification song qi introduced tensor complementarity problem associated function special polynomial constructed help tensor detail see huang qi showed multilinear non cooperative game formulated tensor complementarity problem, establishes connection two class problem given th order dimensional tensor dimensional vector tensor complementarity problem find problem denoted tcp tensor complementarity reduces linear complementarity problem linear complementarity problem defined follows given matrix vector linear complementarity problem, denoted lcp find satisfies following condition concept complementarity take account wide range optimization problem linear programming, linear fractional programming, convex quadratic programming, bimatrix game problem among issue classified linear complementarity problem widely used operation research, control theory, mathematical economics engineering also well recognized literature mathematical programming recent work problem application see reference cited therein well known linear complementarity problem served initial inspiration notion ppt ppt fundamentally involves transforming matrix linear system unknown exchanged relevant entry detail see numerous matrix class subclass undergone extensive research result computing, complexity theory, theoretical foundation linear complementarity problem recent work problem application see game problem multivariate analysis see reference cited therein many mathematical concept extended framework set valued mapping set valued mapping becomes famous kakutani fixed point theorem, generalization brouwer fixed point theorem function set valued mapping map individual element set subset set consider set valued mapping case modeling uncertainties, disturbance error stability issue study ill posed inverse problem solution set topological property semi continuity, well posedness related property case lack bijection continuity issue allow characterize many important property function along domain codomain significant component sensitivity analysis complementarity problem set valued complementarity problem set valued nonlinear complementarity problem provides unified framework nonlinear complementarity problem, exteded complementarity problem, implicit complementarity problem, quasi variational inequality, mixed nonlinear complementarity problem minimax programming problem detail set valued complementarity problem see motivated study, introduce set valued tensor complementarity problem subclass set valued complementarity problem difficult study set valued complementarity problem imposing tensor structure existence uniqueness theorem paper organized follows section present basic notation result needed subsequent section section introduce set valued tensor complementarity problem prove necessary condition feasible solution set establish connection two set study tensor consider merit function set valued tensor complementarity problem establish necessary sufficient condition level boundedness connection limit property set tensor basic idea notation used throughout text outlined section vectors, matrix tensor considered real entry positive integer set denoted denote let denote dimensional euclidean space vector column vector unless specified otherwise let vector component euclidean norm vector defined th order dimensional real tensor multidimensional array entry set th order dimensional real tensor denoted shao introduced product tensor let order order two dimensional tensor product tensor order dimension entry tensor vector defined scalar defined given vector tensor set feasible solution tcp defined fea solution set tcp sol fea consider definition result required next section th row subtensor denoted entry given function said level bounded every level set bounded tensor said tensor every tcp solution tensor said tensor system solution tensor strictly semipositive tensor tensor said tensor tcp unique zero solution tensor solution set tcp bounded mapping define given set valued mapping define lim sup lim inf lim sup lim inf function outer semicontinuous if, lim sup inner semicontinous lim inf function continous outer semicontinous inner semicontinous let two metric space set valued map characterised graph denoted graph defined two different way define inverse image subset set valued map said inverse image said core set valued mapping upper semicontinuous core neighbourhood neighbourhood set valued map lower semicontinuous inverse image open subset intersecting neighbourhood consider metric space two normed space two set valued map respectively, single valued map satisfying following assumption lower semicontinuous convex value continuous affine posit following condition set valued map defined lower semicontinuous nonempty convex value paper always assume set valued mapping closed valued, ie closed begin introducing definition set valued tensor complementarity problem svtcp set valued tensor complentarity problem svtcp defined follows find vector set valued mapping, set solution set svtcp denoted sol theory tensor complementarity problem tensor give condition feasibility solution set tcp consider set tensor complementarity theory tensor nonempty clearly tensor however kind implication fails hold case set valued complementarity problem ie, set imply consider following example illustrates phenomenon let order dimension let element given element zero let otherwise case hold therefore, however present condition tensor claim inner semicontinuous continuous let max denote th row subtensor hence max given since inner semicontinuous theorem theorem sequence implies max implies, equality follows continuity ensured continuity since arbitrary sequence converging obtain implies lower semicontinuity again, let equivalent again, lim inf sufficiently small hence propose necessary condition feasibility svtcp consider svtcp bounded svtcp feasible let mapping bounded therefore suppose satisfy given assumption hence obtain then, particular, observe following process find sequence since taking large enough satisfy max write implies implies feasible point svtcp set tensor said strongly semi positive nonzero weakly semi positive nonzero svtcp following statement hold set tensor strongly semi positive, positive mapping ie, svtcp zero unique solution svtcp zero unique solution, set tensor weakly semi positive prove part showing non zero solution set tensor strongly semi positive note that, positive mapping solution svtcp assume another nonzero solution ie, want prove set tensor strongly semi positive let set tensor strongly semi positive exists hence contradicts condition hence set tensor strongly semi positive prove part showing set tensor weakly semi positive svtcp zero unique solution assume weakly semi positive then, exists nonzero choose let therefore according construction, implies nonzero vector solution svtcp set tensor strongly semi positive sol sol nonempty since set tensor strongly semipositive, svtcp zero unique solution also sol thus every tcp tcp zero solution therefore corollary item conclude tensor implies sol nonempty svtcp tensor sol sol nonempty consider svtcp suppose tensor sol nonempty compact also suppose sol theorem know since sol sol nonempty, starting next result, set valued tensor complementarity problem transfer system equation unconstrained optimization via merit function characterise solution set set valued tensor complementarity problem establishing necessary sufficient condition level boundedness merit function function said merit function residual function complementarity problem solution complementarity problem svtcp define merit function define limit property set tensor definition extends definition tensor case set valued tensor complementarity problem set tensor corresponding svtcp said limit property show limit property provides necessary condition merit function level bounded consider svtcp suppose bounded set continuous set tensor limit property, merit function, min min level bounded establish result showing level bounded svtcp bounded set continuous set tensor limit property approach first assume level bounded sequence bounded then, minimizer attained whose existence ensured compactness since closed bounded taking subsequence necessary, assume converges converges have, since continuous bounded lim taking limit side equation obtain, since nonzero vector, implies set tensor limit property svtcp suppose compact set continuous merit function min min level bounded, prove showing exists svtcp continuous compact set merit function min min level bounded suppose particular, observe following process find sequence therefore, consider following case case consider case using conclude imposing continuity function compactness set conclude max bounded implies sufficiently large max hence, case consider case consider following two subcases subcase subcase obtain using fact thus combining putting fact together obtain, implies level bounded paper, introduce set valued tensor complementarity problem provide necessary condition feasibility solution set svtcp set strongly semi positive tensor svtcp zero unique solution weakly semi positivity involved set tensor provides necessary condition uniqueness zero solution svtcp case tensor fixed one additional assumption, sol nonempty limit property svtcp generalizes concept tensor case set valued tensor complementarity problem show level boundedness merit function exists case limit property set tensor additional assumption",mathematics
"adapting mlops diverse network intelligence era challenge solution introduction ii preliminary iii mlops reinforcement learning rlops iv mlops federated learning fedops mlops generative ai genops vi conclusion instruction reporting error ii mlops ii evolutionary trend ran ii challenge applying mlops advanced ran iii ops challenge rl iii rlops iii rlops open ran baseband placement case study iv ops challenge fl iv fedops iv fedops retail case study ops challenge genai genops experimental seamless integration artificial intelligence ai machine learning ml technique wireless system crucial step ainization however, integration face challenge term model functionality lifecycle management ml operation mlops offer systematic approach tackle challenge existing approach toward implementing mlops centralized platform often overlook challenge posed diverse learning paradigm network heterogeneity article provides new approach mlops targeting intricacy future wireless network considering unique aspect future radio access network ran formulate three operational pipelines, namely reinforcement learning operation rlops federated learning operation fedops generative ai operation genops pipeline form foundation seamlessly integrating various learning inference capability network outline specific challenge proposed solution operation, facilitating large scale deployment ai native network artificial intelligence ai machine learning ml technique shaping various industrial segment wireless network also proactively embracing ai ml technique perspective hardware, software, protocol, standardization next generation networks, envisaged ai ml based design facilitate network protocols, improve operational efficiency, embed native intelligence sustainability corroborate, itu recently agreed recommendation imt framework wherein ai communication regarded pillar framework defines development, standardization, deployment networks, setting stage transforming conventional technological landscape standardization front, etsi operational coordination group ai ocg ai actively standardizing ai across various sector architectural model etsi zero touch service management zsm leverage ai key enabler automation gpp, nearly working group wgs engaged ai ml related activity objective manage entire lifecycle network ai ml models, training emulation deployment inference gpp wg sa studied distribution, transfer, training ai ml model various application sa documented ai ml management specification described generic operational workflow considerable effort dedicated establishing general ai ml framework air interface recent open radio access network open ran initiative consider ai ml capability crucial innovation ran architecture integrates ai ml network ran intelligent controller rics provide base ai ml model deployment actuation different ai ml model deployed depending reaction time target task technological front, various new research activity relying ai native design future wireless system prominent example semantic goal oriented communication leverage ai ml called beyond shannon capability meanwhile, recent advancement generative ai contextual understanding content generation trigger enthusiasm integration wireless network so, wireless network equipped understanding reasoning capabilities, improving efficiency robustness generalization ability ai ml remains long standing issue ai ml model merely work well specific task constant training inference feature pose one critical question network operational ai ml, ie, ensure effectiveness ai ml model complex diversified wireless environment certainly, adapting ai ml model different task using learning technique domain adaption, transfer learning, incremental learning proven solution however, network deployed ai ml application, trigger adaptation important question wireless network need method measure monitor performance ai ml model update model accordingly also termed ai ml model lifecycle management lcm aiming ensure ai ml take effect wireless infrastructure fully controllable lifetime ml operation mlops solution ai ml lcm based operational principle data engineering, ai ml model, continuous integration continuous delivery deployment ci cd pipeline work well ai ml application streamlined engineering environment relatively simple task like supervised learning task however, circumstance getting complicated applying learning paradigm realistic wireless communication system typical learning paradigm peculiarity challenge implementation, would echoed amplified wireless system feature current network virtualization deployment rely upon cloud native tool framework developing deploying application wireless network short living containerized application automatically deployed managed using orchestration tool kubernetes specific data processing, model evaluation updating requirement different ai ml model usually overlooked deployments, hindering service assurance capability network ai article focus crafting network ai ml model mlops pipeline corresponding different learning paradigm believe could serve organic substrate forming ai native capability key contribution summarized follows systematically analyze system pipeline requirement integrating reinforcement learning rl federated learning fl generative ai genai wireless network, perspective lcm identifying uniqueness network functioning ai ml model raise customized ops technique adapt learning paradigm rlops, fedops, genops feature best practice wireless system rlops, fedops, genops presented according engineering experience linked ops framework specific vertical application rlops discussed intelligent management orchestration open ran fedops designed cater requirement large scale iot device edge intelligence genops refers process integrating generative model network broadly foundational element within mlops framework, merging software development dev operation ops enhance efficiency, quality, speed software development delivery devops methodology widely adopted across software development industry set practice tools, devops streamlines automates collaboration software development operations, improving shortening system development life cycle emphasizes collaboration, communication, process automation facilitate faster reliable software development, testing, deployment, maintenance devops aim dismantle barrier development operations, fostering integrated continuous approach software development deployment data engineering specialized domain within data science analytics focused process data collection processing involves designing, constructing, managing infrastructure system needed gathering, storing, organizing data analysis, reporting, data driven activity data engineer work diverse data source technology ensure data accessible reliable context ai ml, data engineering play crucial role two key aspect high quality training data generation data engineering support collection, filtering, annotation process create high quality training datasets continuous data capturing model inference data engineering enables continuous capture processing data required model inference mlops refers methodology aimed managing lifecycle ml models, design, training, evaluation distribution deployment integrates devops, data engineering, ml principle ensure reliable efficient deployment maintenance ml model controllable production setting essentially, mlops data devops model mlops applies devops practice ml development deployment, focusing optimizing accelerating process summary, mlops offer following benefit practical ml automation automates ml pipeline ci cd processes, reducing manual intervention, minimizing errors, accelerating application delivery quality control ensures consistent reliable deployment maintenance ml model production environment, maintaining service quality standard reducing risk error unified workflow provides cohesive framework managing lifecycle ml models, fostering collaboration efficiency across team currently, leading entity ai ml domain, microsoft, aws, google, widely adopted implemented mlops principle additionally, databricks recently introduced unity catalog support full lifecycle ml model leveraging unity catalog capability share asset across databricks workspace trace lineage across data model article focus mlops implementation ran level ran, critical component wireless networks, includes hardware software connects user equipment ue core network via radio link serf network entrance provides service ue recent advancement ran highlight following important feature virtualization refers decoupling hardware resource software function ran, abstracting ran hardware functionality virtualized environment allows flexible efficient use network resource disaggregation recent trend involving separating network hardware software components, allowing sourced different vendor developed independently prime example open ran, split gnb radio unit ru distributed unit du central unit cu hierarchical computing involves co location ran computational entities, multi access edge fog computing, optimize network performance, reduce latency, minimize transport overhead, improve resource utilization complicated network intelligence compelling ongoing research topic network operation stated ai communication key pillar scenario adoption ai ml fully harness benefit network virtualization, disaggregation, hierarchical computing, thereby enhancing performance, improving energy efficiency, fostering innovation prevalence ai ml integration network, holistic model monitoring, management, updating mechanism foundational support correct seamless functioning ml model dynamic environment lifecycle delivered mlops framework however, mlops performs well centralized cloud environment relatively simple controllable, data originates singular source, model involved straightforward instead, applying mlops wireless system becomes problematic scenario get complicated due following reason data variety data source diversified data could come cloud, edge, ran, application function af ues hierarchical network architecture lead hard define common data processing pipeline meanwhile, ml model prone affected input features, highly related model executive environment wireless setting learning variety network optimization may involve different learning paradigms, requiring specific environmental setting instance, rl need interaction network environment explore optimal policy, fl must consider bias factor among clients, variation communication channels, computational capability, dataset balance deployment variety deployment venue ai ml model diverse, including cloud, core network, rics, edge device venue requires tailored ai ml workflow, encompassing interface api definition model distribution method un closed ops loop ai ml training deployment update loop wireless network lack clear definition fig illustrates example ml framework open ran according open ran specifications, task understanding, data processing, model training, actuation carried within component however, monitoring management scheme standardized typically developed implemented system integrator therefore, general purpose mlops pipeline must adjusted accommodate specific feature different learning paradigm moreover, network natively support customized mlops mechanisms, considering effectiveness, timeliness, sensitive data protection embracing customized mlops advanced ran offer clear benefit streamline development automated self organized networks, unifying network control management single pipeline integration enhances scalability ai ml operations, fostering development ai native network new communication paradigm following sections, discus implementation mlops ran different learning paradigm rl, fl, genai detail key constraint learning approach propose countermeasure enhance mlops rl type ml agent learns make decision interacting environment agent receives feedback form reward based actions, goal learn optimal action maximize cumulative reward time deep rl drl deep neural network learns optimal mapping state action maximize reward context ran operation, drl emerges appealing solution due inherent self learning capability drl agent learn optimal ran operational policy across various factor time scales, facilitating attainment cross layer domain, long term, short term balance optimization typical application drl ran include wireless access control, traffic steering, baseband placement optimization, etc large scale adoption drl ran challenge policy learned drl shaped interactive environment optimization objectives, making construction environment critical factor influencing learning process challenge commonly known sim real problem drl within ran system, sim real pertains system modeling issues, including factor reward delays, partial observations, system variation degradation time ensure successful deployment operation drl model practical ran, important guarantee fidelity training environment maintain time conversely, drl training infamous time consuming accelerating drl training process essential meeting diverse deployment need across various scenario two key consideration raise challenge ops rl concept rlops, introduced publication present structured approach rl model lcm, specifically tailored intelligent open ran system principle rlops outlined work offer comprehensive framework, categorizing essential element across design, development, operations, safety security consideration article aim delve deeper analysis rlops focusing two key factor hindering widespread adoption drl environmental fidelity training acceleration integrating digital twin dts within rlops framework deemed fundamental component addressing challenge dt concept practical application extensively discussed foundational technique developing network scope functionality digital modeling, apis, interface design explored wealth literature essentially, dt provides high fidelity virtual representation physical entity facilitating communication real network setting parameters, configurations, pattern synchronization update thus, rlops could leverage dt environment drl training update furthermore, tailored learning knowledge transfer technique module incorporated rlops pipeline accelerate iterative training fine tuning drl model representative scheme include transfer learning, incremental learning, knowledge distillation, domain adaptation, etc selection specific technique based characteristic different drl agent placing baseband function user plane function upf conjunction multi access edge computing mec accommodate diverse service crucial challenge modern network architecture usecase address joint placement problem within context open ran, aiming devise function placement strategy optimizes resource usage reduces network power cost maintaining service quality objective firstly, function placement problem, including du, cu cp, cu up, upf, modeled maze solving task within markov decision process mdp graph convolutional network gcn encoder introduced, enabling drl agent generalize across different network topology approach unifies network features, reduces retraining needs, enhances adaptability scalability diverse ran architecture drl training, dt built serve customized setting optimal rl policy exploration dt model service types, baseband function chains, mec component along energy cost detail problem set found pre simulation stage, drl agent interacts dt explore optimal actions, include decision routing direction function placement state drl framework includes information network resources, current placements, path lengths, service requests, vary one deployment site another therefore, deployment stage, site specific information must updated dt accordingly update drl agent, shown fig drl agent deployed near rt ric open ran, utilising internal interface messaging additionally, drl policy transfer technique, specifically incremental learning, applied speed fine tuning process drl agent one deployment environment another demonstrated fig policy directly applied new open ran mec setup, performance degrades significantly green line however, optimal policy transfer applied, new drl convergence occurs around step red line significant improvement compared training new agent scratch, converges step blue line fl, model trained across multiple decentralized device server fl commonly visible wireless communication system enables ml model trained directly data edge without transmitting sensitive data central server fl reduce communication overhead, preserve user privacy, allow personalized model update tailored individual device network condition paradigm flexibly applied ran setting multiple computational layers, edge, ue, associated iot device applying fl networks, distributed intelligence realized, correspondingly, wireless network efficiency adaptability enabling device model updating improved operational challenge fl stem inherent bias wireless network system fl operates distributed training centralized aggregation algorithm, effectiveness convergence global aggregation hinge characteristic participating devices, representing system bias bias viewed three perspective data, hardware, communication link bias data bias pertains uneven distribution data across clients, like non independent identical distribution non iid hardware bias manifest variation hardware capability among devices, encompassing difference local memory, processing speed, power constraints, etc communication link bias predominantly arises wireless channel, influenced fluctuation communication link quality disparate bandwidth availability, turn cause asynchronous communication affect model parameter updating, aggregation, broadcasting interplay bias necessitates delicate solution data engineering, hyperparameter configuration, model sharing, synchronization aspect traditionally overlooked standard mlops practices, thus requiring fedops ensure long term reliability fl model term fedops introduced proposes framework analyzing client system heterogeneity using small subset client data subsequently, appropriate client selected based consideration communication cost overall model accuracy work mark promising beginning exploring fedops engineering, important address long term stability robustness fl operation beyond solely selecting client article, underscore importance implementing monitoring mitigate hardware communication bias enhance fedops, particularly wireless system environment monitoring fundamental aspect mlops, scope need expanded effective fedops support perspective network fl model lcm, fl monitoring encompass two key dimension global level monitoring client level monitoring global monitoring fedops closely integrated observable metric wireless network, ue connectivity channel quality metric serve crucial criterion client selection algorithm optimization client monitoring fedops aim ensure proper functioning client involves examining operational state container client regular report corresponding metric relayed global model reporting messaging mechanism leverage internal data interface wireless systems, open ran, reduce latency improve efficiency fedops enables robust scalable deployment fl method agnostic particular domain section, consider real world use case deploying fedops context dynamic heterogeneous retail environment retail domain, two primary service category emerge end user services, encompassing personalized recommendation engines, dynamic pricing strategies, trend identification algorithms, retail owner services, including critical application like point sale po device remote maintenance, theft prevention systems, intelligent advertisement service consider utilization fedops agnostic service category could enable critical use case po devices, handle sensitive financial transactions, limited compute resource vulnerable hardware failures, software glitches, security breaches, necessitating robust monitoring maintenance mechanism fedops enable deployment federated anomaly detection model detect anomalous behavior performance issue po device without compromising customer data privacy dataflow fedops deployment begin po device collecting operational data, transaction logs, system logs, sensor reading etcthese stored premise local, private processing see fig locally stored data securely privately used local edge device processing within retail establishment, ensuring sensitive customer data never leaf premises, preserving privacy local edge device, serf client fl system, data multiple endpoint device aggregated used train local model, eg, anomaly detection model po terminal maintenance periodically, fedops client selection scheduling module intelligently selects locally trained model subset retail establishment client module employ strategy like clustering technique rl approach prioritize client based computational resources, network conditions, data quality global model shared selected client via open ran infrastructure, illustrated fig selected client perform local training, ensuring qos optimization training inference policy local training, updated client model transmitted ric wireless link ric service management orchestration smo layer, fedops orchestrates secure aggregation locally trained model using efficient communication protocol tailored fl, structured updates, quantization, sparsification technique aggregation process yield globally trained model capture collective knowledge multiple retail establishment without exposing individual establishment customer data globally trained model distributed back participating retail establishments, local edge device used inference enhance privacy distribution phase, fedops employ differential privacy mechanisms, noise addition data subsampling throughout entire dataflow, fedops ensures efficient utilization wireless resource adapting communication strategy based network condition employ technique like air aggregation protocol eg, coded computing, analog hierarchical aggregation reduce communication overhead minimize impact straggler disconnected client intelligent client selection algorithm leveraging fedops federated anomaly detection capability utilizing local edge device clients, retail establishment proactively identify address potential issue po device improves reliability, security, overall operational efficiency maintaining strict privacy standard customer data accommodating limited computing resource individual po device genai involves technique generate new data instances, text, images, sounds, videos, leveraging pattern learned existing data typical generative model include autoencoders, generative adversarial network gans diffusion models, modality generation remarkable success large language model llm sparked surge development generative model across various domain today, significant stride made text text, text image image text, even text video generation advancement also drawn attention potential wireless communication integration genai wireless networks, design, configuration, operation, become focal point research one prominent approach involves goal oriented semantic communication, information encoded latent space encoder reconstructed decoder aforementioned generative model serve encoder decoder pair incorporating genai different network layers, network enhance operational efficiency reducing overhead energy consumption seamless integration genai wireless network protocol level still explored here, examine potential challenge genai network operation lcm following perspective vast knowledge base kb kb comprises essential data feature generating coherent relevant content context crucial producing accurate, contextually appropriate response interaction given input compared larger cloud based counterparts, optimally usable genais vertical application task specific trained extensive knowledge base pose significant cost energy challenge genops extracting incorporating human value information notable feature large generative model ability gather human feedback enhance performance align human preference value technique human loop hitl reinforcement learning human feedback rlhf enable continuous improvement toward relevant coherent response however, integrating model network complicates scenarios, user feedback collection must pa network extracting, interpreting, incorporating human value network pose long term operational challenge ci cd model integration integrating genais network present challenge due size cost additionally, combining various purpose specific generative model raise concern performance guarantees, potentially compromising superiority single task specific genai models, energy resource consumption, impacting sustainability effort article, genops refers pipeline aimed seamlessly integrating genai application future networks, ensuring long term reliable operation customization maintenance genai model pioneering effort, summarize key solution aforementioned challenges, differentiating genops ops firstly, genops must facilitate loop updating knowledge base fine tuning generative model iterative process occurs external network initiated either network internal task demand external safety security requirement secondly, genops integrate human feedback collection network facilitate model self adaption facilitated by, eg, web based feedback form restful apis mobile apps lastly, genops capable offering different strategy trade consideration based scale generative model smaller models, containerized onboarding feasible, whereas larger models, alternative solution integrating subscription based model considered generative model also monetized exposing apis marketplace, enable tight integration network different business model based requested frequency service level looking ahead, integrating model intent based networking open service platform could enable network network service paradigm approach would facilitate sophisticated orchestration service across various network operated different entities, employing diverse technology like satellite, terrestrial, high altitude platform seamlessly integrated manner mlops within ran represent exciting dynamic field research, yet standardized practice remain nascent gpp initiated discussion generic mechanism overseeing ml training, particularly context core ran, detailed exploration diverse ai ml learning paradigm vertical application remains gap article introduces mlops principle tailored specifically ran, encompassing diverse learning paradigm rlops, fedops, genops outline associated challenge approach propose potential solution author anticipate outlined ops principle contribute future development standardized network mlops framework framework essential advancing reliability efficacy ai ml application within ran beyond peizheng li research engineer bristol research innovation laboratory, toshiba research europe ltd ioannis mavromatis lead future network technologist digital catapult tim farnham chief research fellow bristol research innovation laboratory, toshiba europe ltd recent research includes applying digital twin data space optimizing wireless, water distribution energy network system collaborative evaluation technique performed within eu horizon uk project adnan aijaz currently programme leader beyond bristol research innovation laboratory, toshiba research europe ltd, uk recent research interest include systems, open ran, time sensitive networking, high altitude platforms, robotics autonomous system aftab khan currently distributed ai programme leader bristol research innovation laboratory, toshiba europe ltd, uk research interest include federated learning, ai driven cyber security, computational behavior analysis, pattern recognition",networking and internet architecture
"dynamic content caching waiting cost via restless multi armed bandit introduction ii system model iii infinite caching capacity iv finite caching capacity numerical result vi proof theorem vii proof theorem viii proof lemma instruction reporting error ii optimal content caching delivery problem iii problem reformulation iv single content problem holding cost iv whittle index based policy comparison effect waiting cost experimental consider system base station associated local cache, turn connected backend server user content get continuously updated backend server, local copy subset content upon receiving request user, either fetch fresh version or, serve local copy wait additional request serving fetching content incurs fixed fetching cost, serving locally incurs aging cost, request waiting bs, waiting cost per unit time aging cost relies freshness content, measured metric age version aov aim minimize average cost subject cache capacity constraint pose problem restless multi armed bandit problem rmab propose whittle index based policy performs close optimal policy real time applications, social medium platforms, commerce sites, news websites, hotspot internet user widely use real time applications, timely delivery content essential quality service content generated application highly dynamic quickly become outdated recent version content directly delivered backend server however, due massive demand applications, enormous number content get exchanged users, making timely communication challenging directly delivering content backend server lead network congestion content stored local cache deployed content distributed network address however, essential periodically replace cached content ensure user receive fresh relevant information therefore, dynamic content caching play vital role real time applications, ensuring timely delivery content high quality service metric age information aoi widely used metric freshness, defined time elapsed since last fresh version fetched backend server however, aoi limitation fully reflect relevance content freshness information also depends frequently update occur backend server words, even aoi indicates data recent, may accurately represent actual significance timeliness information based ongoing update age version aov newly introduced metric capture number update since last fresh version fetched backend server accurately measuring freshness content however, aov hard obtain local cache depends upon occurrence content update backend server consider system base station connected backend sever connected via core network end user population server host set dynamic content local cache store content content dynamic get updated server time, one content cache may stale copy user send request specific content requested content, serve locally cached, potentially stale, copy available, fetch fresh copy server serve, choose wait additional request content fetching fresh copy server serving furthermore, fetching content server, may cache evict existing content let denote set cached content local cache time note potentially change content request epoch content get updated according independent poisson processes, update rate content server always hold recent version content let number time content updated since last fetched time refer age version aov content time note aovs cached content observable aggregate request process end user poisson process rate request could content probability independently request denote relative popularity content instance, content popularity world wide web widely modelled zipf distribution wherein popular content proposed request dynamics, content request arrival constitute poisson process rate let number request content waiting served note stay zero long keep serving cached version content however, grows chooses fetch serve fresh copy content wait additional request specifically, request queue evolves follows arrival request content serf cached version fetch fresh copy serves, becomes wait additional request increase content, say content requested time one following scenario may encountered content cached case, may serve cached version incurring ageing cost ageing cost per unit aov alternatively, may wait additional request fetching fresh copy content serving content cached scenario also, may wait may fetch serve latest version content incur fetching cost waiting request also associated waiting cost per unit time so, also incurs running waiting cost per unit time let request content time let represent various action using number whose annotation figure let serve content although could pending request content argued optimal action content request arrival wait request it, optimal action continues wait new request arrives brevity omit proof consider serve action content clearly, action available content using denote action vi vi content aim develop policy prescribes action request arrival epoch minimize long term average content fetching, ageing, waiting cost let denote request epoch requested content respectively let denote aov content action vi vi content respectively, let request queue length content immediately prior arrival request focus cost incurred recall incurs instantaneous fetching ageing cost requested content also running waiting cost content let cost associated content so, incurs total cost further, let denote total number request time max aim minimize average cost formally expressed follows treating state, action random noise, respectively, pose problem mdp recall observable prior taking action so, pomdp hand pomdp suffers curse dimensionality however, notice action state revolution different content coupled cache capacity constraint so, formulate problem rmab problem show rmab problem indexable propose whittle index based policy also provide explicit expression whittle index observe that, unlike classical rmab setting binary actions, state dependent actions, rendering optimal problem complex describing rmab formulation section iv, discus optimal caching problem case infinite cache capacity assume infinite capacity cache, ie, case, action different content need depend so, decouple optimal caching content delivery problem separate problems, one corresponding content let focus optimal caching content delivery problem associated tagged content, say content here, let denote request epoch content brevity, section omit superscript representing content index variable instance, let number pending request aov content respectively, let denote action taken denotes serve cached copy, denotes wait denotes fetch serve let denote cost incurred vi vi content aim minimize average cost, ie, solve pose problem pomdp decision epoch state action noise following, reformulate problem mdp find optimal policy know update content server fetched content particular, know prior taking action nevertheless, know time since last fetch content denote max so, compute expected ageing cost moreover, independent given hence, reformulate mdp considering state now, state space action space continues following state dynamic single stage cost mdp given state exponential expected value single stage cost define stationary policy mapping state space action space let set stationary policy shown exists stationary optimal policy mdp hand hence mdp problem since embedded discrete time markov chain single recurrent class, independent section moreover, bellman equation continuous time mdp written way discrete time problem let relative cost function optimal cost, respectively bellman equation different state follows section proof lemma induction relative value iteration standard optimal policy threshold based policy threshold queue length time since last fetch following theorem provides policy optimal policy follows solution following equation moreover, optimal cost please see appendix vi section, propose whittle index based policy optimal content caching delivery problem cache constraints, ie, subject first consider problem following relaxed constraint minimize optimal caching problem subject relaxed constraint write lagrangian multiplier follows minimizing subject entail first minimizing maximizing optimal values, say optimal policy relaxed problem need feasible policy original problem need satisfy hard capacity constraint however, policy provides whittle index associated different state content turn used design feasible policy original problem section whittle index based policy asymptotically optimal original problem number content approach infinity cache capacity also grows proportionately conjecture observe minimizing optimization problem corresponding different content decoupled moreover, lagrange multiplier interpreted holding cost per unit time cached content so, section iv a, focus single content problem holding cost note optimal policy always keep content resulting non negative whittle index content state hence, consider design whittle index based policy section iv suppose content, say content requested since running cost keeping content cache, evicting content serving also potential action argued optimal action serve cached version wait additional request fetching optimal evict content optimal action serve cached version wait additional request fetching, keeping evicting cached version incur cost so, specify action wait evict instead wait figure moreover, segment action specifying whether content kept evicted serving accordingly, introduce action whose annotation figure associated action set remain figure focus optimal caching delivery problem associated tagged content, say content however, unlike section iii, content acted upon even request epoch content hence, section ii, consider request epoch decision epoch omit content index variable section iii let request epoch across content section ii, let requested content queue length aov, respectively, content let also define binary variable indicating whether requested content content otherwise let another binary variable content cached ie, define state system recall request queue remains empty wait evict action taken point evicted hence state feasible so, state take value frame optimal content caching delivery problem mdp state action random noise exponential bernoulli random variables, respectively next state next state next state observe figure action applicable state action taken state state action pair expected single stage cost follows express mdp problem set stationary policy underlying embedded discrete time markov chain weakly accessible, hence, independent section bellman equation continuous time mdp similar discrete time problem let relative cost function optimal cost, respectively let define bellman equation different state follows section using rewrite bellman equation follows state monotonicity property relative cost function following lemma property used derivation optimal policy non decreasing non decreasing given non decreasing part standard proof using relative value iteration since integrand definition non decreasing establishes part following theorem give optimal policy problem let define let solution following equation furher, let solution following equation finally, let solution following equation optimal policy described table please see appendix vii following lemma characterizes use characterization designing whittle index based policy section iv exists unique solution decreasing increasing functions, respectively, non decreasing function furthermore, please see appendix viii section, introduce concept indexability demonstrate content indexable subsequently, present whittle index based policy observe set action figure requested content cached, ie, need evict content optimal action case given theorem specifically, serve cached copy wait fetch, serve cache solution following equation suppose requested content cached, ie, chooses fetch must also choose content keep state content whereas plotted optimal action single content problem figure state figure optimal action content wait hence, need choose content queue length furthermore, content mean never serve cached content content requested, wait fetch fresh version implies content evicted replaced hence, need choose content content subsequently, propose policy discard content lowest whittle index thus, base station chooses content retain based whittle index policy towards this, first demonstrate content indexable compute whittle index content establish indexability, need define passive set content discussed earlier computation whittle index needed content define passive set content introduce notion indexibility whittle index content called indexable passive set content satisfies following condition rmab problem consideration called indexable every content indexable whittle index associated state content, minimum cost move active set passive set precisely, min whittle index defined following way well max shall use latter establish indexability following, use denote whittle index content state whittle index content max content indexable theorem since decreasing non decreasing function respectively lemma hence, hence, content indexable following theorem provides whittle index different content whittle index content solution following equation whittle index content is, solution following equation proof follows theorem recall, definition whittle index max max recall state optimal action either wait fetch fresh version content requested future hence, cached copy never served content hence, consider whittle index state following outline whittle index based policy requested content cache recall that, state content wait keep content compute whittle index content theorem compare whittle index minimum index evict corresponding content replace freshly fetched version minimum index, wait fetch discard section evaluate performance whittle index based caching policy derived section iv consider number contents, request arrival rate, popularity update rate backend cache content ageing cost per unit time, fetching cost, waiting cost, compare average cost whittle index based caching policy relaxed rmab problem compute optimal cost relaxed rmab problem numerically theorem vary cache capacity demonstrate figure whittle index based caching policy close optimal cost relaxed rmab problem since optimal cost optimal caching problem hard constraint optimal cost relaxed rmab problem, conclude whittle index based policy performs close optimal policy furthermore, compare greedy policy, take action minimize immediate cost figure show whittle index based caching policy significantly outperforms greedy algorithm vary waiting cost plot average cost cache size value figure demonstrate increase average cost increase beyond average cost change since, increasing result depletion number request waiting bs, certain value number request waiting becomes see figure hence, increasing waiting cost effect average cost furthermore, sufficiently large optimal policy single content problem holding cost theorem becomes theorem suggests whittle index based caching policy yield result whittle index based policy figure show average cost aligns average cost whittle index based caching policy let define following lemma characterizes cost function exists that, note that, hence, always optimal serve cached copy irrespective value queue length once, serve cached copy queue length becomes suppose exists optimal wait hence, show cost function suppose, exists optimal action serve cache copy case optimal action wait hence, let consider another action optimal serve cached content cost function case since, non decreasing function hence, beyond optimal serve cached content beyond next lemma obtain value hold finite value solution following equation lemma last equality obtained replacing following similar approach before, establish recursive relationship following, obtain value define obtain value follows depends upon hence, hence lemma moreover, last equality obtained change variablesafter taking derivative wrt obtain equation obtained replacing solving differential equation obtain integrating constant following, obtain value recall moreover, replace value obtain defined earlier, equality obtained replacing value solving quadratic equation obtain equation provides relation obtain value require another equation obtain following since min equality obtained lemma hence, min implies replacing value obtain, exists unique solution following equation first show exists solution equation rewrite compute ratio let define ration hence, take limit side obtain hence, lim since hence large enough line lie curve line lie curve hence exists solution uniqueness follows fact optimal cost",networking and internet architecture
"dynamic spectrum access ambient backscatter communication assisted system quantum reinforcement learning introduction ii system model iii problem formulation iv quantum reinforcement learning performance evaluation vi conclusion instruction reporting error related work motivation main contribution ii communication channel model ii ambient backscatter communication channel model iii state space iii action space iii immediate reward iii long term average throughput optimization formulation iv preliminary reinforcement learning deep learning iv proposed quantum reinforcement learning iv parameter complexity analysis parameter setting simulation result experimental spectrum access essential problem device device communication however, recent growth number mobile devices, wireless spectrum becoming scarce, resulting low spectral efficiency communication address problem, paper aim integrate ambient backscatter communication technology device allow backscatter ambient rf signal transmit data shared spectrum occupied mobile user obtain optimal spectrum access policy, ie, stay idle access shared spectrum perform active transmission backscattering ambient rf signal transmissions, maximize average throughput users, deep reinforcement learning drl adopted however, drl based solution may require long training time due curse dimensionality issue well complex deep neural network architecture that, develop novel quantum reinforcement learning rl algorithm achieve faster convergence rate fewer training parameter compared drl thanks quantum superposition quantum entanglement principle specifically, instead using conventional deep neural networks, proposed quantum rl algorithm parametrized quantum circuit approximate optimal policy extensive simulation demonstrate proposed solution significantly improve average throughput device shared spectrum busy also achieve much better performance term convergence rate learning complexity compared existing drl based method rapid development wireless technologies, expected future communication systems, eg, advanced g, need support enormous number heterogeneous wireless device many wireless device require short range, high rate, low latency communication accommodate requirement increase spectrum efficiency, device device communication proposed particular, communication enables communication adjacent wireless device without use network infrastructure like base station such, communication enable direct communication device reduce end end latency key advantage communication technology reuse spectrum cellular system direct communication devices, resulting better spectrum energy efficiency features, communication expected essential part advanced g, especially iot vehicular communication however, communication may introduce interference cellular user cu reuses spectrum cu currently occupying particularly challenging future wireless network large number wireless device operate dense area that, demand effective spectrum access strategy device opportunistically reusing cellular spectrum numerous method proposed literature enable dynamic opportunistic spectrum access communication example, author considered spectrum sharing problem communication cellular network considering overlay underlay modes, author aimed obtain optimal spectrum sharing strategy enables device orthogonally share spectrum cu opportunistically use frequency time resource occupied cu then, analytical rate expression derived optimize two spectrum sharing mode based weighted proportional fair utility function similarly, author optimized spectrum sharing based ultra reliable low latency communication rate optimization problem considered network first formulated, successive convex approximation based iterative algorithm adopted solve non convex optimization problem differently, author proposed spectrum sharing approach based contract based cooperative technique obtain opportunistic spectrum access policy user maximizing cellular network profit specifically, cooperative spectrum trading process cu device modeled based pre defined principal agent approach approach, cellular network act principal offer power payment contract pair that, pair, act agent, try choose contract maximize utility function based design, author derive optimal contract cellular system offer obtain optimal contract based spectrum sharing policy although demonstrating good performance spectrum sharing communication, application study may limited existing solution mainly based static optimization technique require information system advance formulate problem obtain optimal solution unfortunately, difficult, impossible, obtain complete prior knowledge system due dynamic uncertainty wireless communication mobility user deal problem, deep reinforcement learning drl emerged promising tool recently observing system state outcome performing actions, drl efficiently learn dynamic uncertainty system converge optimal spectrum access policy without requiring prior knowledge cus, bss, user example, author developed drl based algorithm help user dynamically access shared spectrum maximize system sum throughput without using prior knowledge system proposed drl based solutions, transmitter learn characteristic cu decide access shared spectrum simulation result showed proposed drl based approach achieve better sum throughput compared baseline based cooperation unfortunately, aforementioned study others literature may work well large number cu operating shared spectrum scenarios, shared spectrum always heavily occupied transmission cus, resulting low communication efficiency user frequent collision cu address essential issue, paper, propose use ambient backscatter communication ambc technology help user transmit data even shared spectrum occupied cu key fundamental ambc technology transmit information backscattering ambient rf signal without generating active signal that, shared spectrum occupied, user switch ambient backscatter mode backscatter rf signal generated transmit data receiver backscattered signal user introduce noticeable interference cu since active signal demonstrated worth noting ambc technology integrated communication study however, dynamic spectrum access communication considered work particular, author proposed new self sustainable communication paradigm communication using ambient backscatter communication theoretically analyze average throughput, energy outage probability, coverage probability proposed hybrid communication system author instead focused designing passive relay ambient backscatter communication wireless powered system addition, current drl based spectrum access approach may take long time converge optimal policy, especially complex problem high dimensional state space moreover, drl based approach usually require large deep neural network architecture efficiently learn highly dynamic complex environments, resulting long training time thus may applicable application low latency requirement inspired quantum superposition quantum entanglement principles, develop quantum reinforcement learning rl based solution obtain optimal dynamic spectrum access policy communication instead using conventional deep neural networks, proposed solution employ parametrized quantum circuit approximate optimal dynamic spectrum access policy device extensive simulations, demonstrate proposed quantum rl approach achieve faster convergence rate much fewer trainable parameter compared existing drl method worth noting proposed quantum rl approach efficiently run classical computer using tensorflow quantum cirq library far know, first study take account quantum rl ambc technology dynamic spectrum access communication main contribution summarized following propose integrate ambc technology device data transmission backscattering ambient rf signals, eg, signal generated bs, shared spectrum occupied cu new design, device still maintain communication avoid collision cu even shared spectrum always busy use markov decision process model dynamic uncertainty system caused user mobility wireless environment then, develop drl based approach, namely deep learning, find optimal spectrum access policy, ie, stay idle, access shared spectrum perform active transmissions, backscatter signal transmissions, maximize long term average throughput user improve convergence rate reduce training complexity proposed solution, develop novel quantum rl approach learn environment property efficiently quickly particular, parametrized quantum circuit used approximate optimal policy instead conventional deep neural network quantum circuit, proposed algorithm leverage quantum superposition quantum entanglement principle better handle high dimensional system state space achieve better learning system performance conventional drl algorithm finally, extensive evaluation provided verify effectiveness proposed solution particular, ambc technology, user transmit data even shared spectrum occupied, resulting better communication performance addition, proposed quantum rl approach significantly improve convergence rate fewer training parameter much lower training time compared existing solution based drl rest paper organized follows considered system model, including ambient backscatter channel models, presented section ii section iii introduces proposed mdp framework capture dynamic uncertainty considered system that, section iv provides fundamental deep rl proposed quantum rl algorithm section present performance analysis several scenario finally, section vi concludes work paper, consider enabled cellular network consists multiple cu bs, illustrated fig considered network, wireless device communicate without routing packet cellular network using communication without loss generality, assume node cu share spectrum resource time splitting manner similar time slot allocation among cu orthogonal define access probability cu access shared spectrum time slot mentioned, node also access shared spectrum using time slot however, transmitter may generate interference disrupt transmission cu access shared spectrum time such, node must find appropriate time slot communicate avoid introducing interference cu addition, studied cu suffers le interference node near thus, define protected maximum distance cu allows cu communicate without affected interference node define protected probability cu secure area, ie, distance le protected future wireless networks, large number diverse wireless device share communication spectrum dense area such, challenging device opportunistically access shared spectrum transmit data improve spectrum usage efficiency improve system throughput, propose use ambc technology node particular, ambient backscatter circuit, node communicate simply reflecting absorbing ambient rf signals, ie, cellular signal considered system that, node eg, mobile phone iot device equipped rf switch switch two different load reflect absorb cellular signal reflecting state, node transmit bit contrast, node transmit bit absorbing state way, ambc technology help node transmit information even current time slot occupied cu without introducing transmission disruption cu denote set channel state particular, channel idle, channel used cu, channel used pair, channel used cu pair transmission without loss generality, assume considered system saturated node always information transmit node transmit information beginning assigned time slot must finish transmission within time slot paper, aim obtain optimal dynamic spectrum access policy node maximize average throughput following, present channel model communication ambient backscatter communication overall, ambc technology, transmitter simply absorbs reflects ambient rf signal transmission instead generating active signal like communication practically, link modeled using probabilistic path loss model, including non line sight nlos link line sight los link described los path loss expressed follows tr distance transmitter tx receiver rx center frequency similarly, nlos path loss expressed follows average path loss link db calculated follows los los represent probability los link nlos link, respectively based distance tx rx, los calculated follows let transmit power tx average signal power received rx expressed follows connection achievable transmission rate calculated follows bandwidth channel noise power paper, adopt ambc technology allow node communicate even spectrum occupied cu particular, communicating cu share spectrum, node reflect absorb cellular signal transmit information without generating active rf signals, thus interrupt transmission cu interested reader refer information design, principles, circuit ambc technology following, provide channel model formulate achievable rate ambient backscatter communication specifically, rf signal sent expressed transmit power bs, transmitted signal th symbol interval then, ambient rf signal received tx formulated follows st channel coefficient tx let denote reflection coefficient tx denote tx signal th symbol interval, express backscatter signal tx follows backscattered signal received rx expressed follows tr channel coefficient tx rx signal received rx also expressed follows dr channel coefficient rx then, total received signal rx expressed gaussian noise rx zero mean variance ie, similar assume rx equipped successive interference cancellation sic technique decode received signal particular, sic technique, common physical layer approach, usually used handle two signal received receiver sic, rx decode stronger signals, ie, signal, first, subtract received signals, extract weaker signal, ie, backscattered signal, residue way, signal noise snr ratio rx expressed st st tr tr channel power gain tx tx rx, respectively finally, achievable backscatter rate calculated follows work, aim maximize average throughput node obtaining optimal dynamic spectrum access policy particular, node need decide access shared spectrum communication technology, ie, communication ambc, use transmit data given fact cu randomly arrive coverage area access shared spectrum, challenging optimal dynamic spectrum access policy address practical problem, following, present novel quantum rl approach dynamically intelligently learn system property cu behavior approximate optimal spectrum access policy superior convergence rate compared existing solution use markov decision process mdp formulate optimization problem order address dynamic uncertain nature system consideration particular, tuple denotes state space, represents action space, denotes immediate reward function, theoretically used define mdp practically, channel state accurately observed end time slot agent make action beginning time slot such, system state space includes channel state previous time slot addition, help agent learn cu behavior system property efficiently, also consider chosen action location cu previous time slot discussed section ii, achievable rate communication ambient backscatter communication depend greatly distance node well distance tx reason, two factor also included system state space given above, formally defined follows denotes previous action taken agent, denotes previous channel state, denotes cu previous time slot secure area ie, otherwise ie, dt distance tx bs, tr distance tx rx way, system state time slot formally expressed dt tr mentioned section ii, tx choose perform communication ambient backscatter communication transmit data rx addition, choose stay idle that, action space formally defined follows tx stay idle, tx performs communications, tx chooses leverage ambc technology transmission work, aim maximize average throughput device minimizing interference introduced cu that, immediate reward tx take action state defined follows specifically, tx chooses stay idle ie, immediate reward tx transmits information communication ie, cu actively using shared spectrum, immediate reward defined addition, active cu cu secured area, immediate reward also contrast, cu outside secured area, immediate reward low value ensure agent avoid action introduce interference cu finally, tx chooses use ambient backscatter transmit data ie, immediate reward defined long term average throughput maximization problem device given formulated mdp expressed follows spectrum access policy mapping state action represents immediate reward received taking action following policy state average long term throughput policy worth noting formulated mdp, independent initial state system underlying markov chain irreducible thus, optimal dynamic spectrum access policy exists obtained efficiently solve optimization problem section iii, rl algorithm adopted among rl algorithms, learning deep learning dql common algorithm adopted field communication networking fundamentally, learning dql algorithm designed based bellman equation perform simple value iteration update approximate value state action pair specifically, learning algorithm store value possible state action combination table given state algorithm take action based greedy approach approach, random action taken probability action highest value given current state chosen probability then, immediate reward next state system observed taking action observation, learning algorithm update value state action pair represents immediate reward taking action state discount factor determines future reward importance, represents algorithm learning rate theoretically, small value indicates short term reward important differently, algorithm prefers action maximize long term reward approach since aim maximize long term average throughput devices, set high values, eg, differently, learning rate denotes significance new observation existing observation enable stable learning process, learning rate learning set small values, eg, based learning algorithm gradually update value state action pair system converge optimal spectrum access policy however, learning algorithm several limitation particular, requires state space discrete order build table may result information loss addition, learning algorithm cannot work well high dimensional state space due high complexity nature table such, performance learning limited practical problem communication networking demonstrated literature solve practical issue learning, google deepmind introduced dql, combination learning deep neural networks, key idea using deep neural network, called deep network, approximate value instead using table power handling high dimensional data, deep network help dql learn environment effectively compared learning addition, state space continuous, thus avoiding information loss problem learning due discretization process improve learning efficiency stability algorithm, two mechanisms, namely experience replay quasi static target network, adopted experience replay mechanism, memory pool used store previous experience observation algorithm randomly take number experience train deep network training step quasi static target network mechanism, separate deep network employed, called target network parameter target network slowly frequently updated copying parameter deep network target network used approximate target value result, target value estimated value correlated, thus minimizing overestimation stabilizing algorithm loss function dql algorithm expressed follows denotes parameter deep network time slot represents parameter target network time slot update parameters, stochastic gradient descent algorithm extension adopted minimize loss work, adam optimizer used minimize loss update deep network parameter although drl algorithm dql presented section iv widely adopted solving problem wireless communication good performance, still several limitation may hinder application future wireless communication system particular, since drl deep neural network approximating policy, training time long, especially complex problem high dimensional state space may make drl inapplicable highly dynamic communication system system condition changed quickly real time scenario overcome issue, paper, develop novel quantum rl algorithm efficiently approximate optimal spectrum access policy much faster convergence rate compared drl key idea use quantum circuit approximating optimal policy instead using deep neural networks, illustrated fig way, quantum entanglement quantum superposition property quantum computing utilized speed learning process rl, resulting high convergence rate next, present proposed quantum rl approach detail proposed quantum rl approach, employ parametrized quantum circuit pqc approximate optimal policy particular, proposed pqc take system state input output vector expectation value then, output vector processed obtain policy ie, policy based method, approximated value ie, value based method work, use policy based rl train proposed pqc studied pqc design significant impact learning performance among several factors, data encoding strategy play essential role designing pqc based theoretical analysis data uploading technique outperforms others constructing highly expressive learning model particular, instead encoding data variational layer, data uploading method aim encode data several encoding layer interlayed variational layer reason, use data uploading technique build pqc paper illustrated fig proposed pqc first variational layer handle input state vector performing single qubit rotation trainable angle output variational layer processed entangling layer consists several qubit controlled cz gate that, output entangling layer fed encoding layer trainable input scaling parameter next, output encoding layer processed another variational layer pqc multiple entangling layers, encoding layers, variational layer define quantum layer consist variational layer, entangling layer, encoding layer fig illustrates detailed architecture quantum layer worth noting last layer proposed pqc variational layer variational layer help increase circuit expressibility representing quantum state encoding layer addition, encoding layer learn sine function input, resulting le efficient training process estimated policy obtained observing expectation value last variational layer number expectation value number action proposed mdp, ie, similar also employ trainable weight augmented expectation value action optimizing trainable weight learn environment approximate dynamic spectrum access policy device following, present detail proposed pqc process system state ie, classical data quantum state feed system state pqc, number qubits number feature state space ie, paper qubits, pqc represented dimensional complex hilbert space quantum state pqc defined vector unit norm quantum superposition defined follows complex coefficient illustrated fig pqc, several quantum gate defined unitary operation performing variational layers, consider single qubit pauli gate whose matrix defined follows variational layers, classical data encoded quantum state using single qubit rotation corresponding single qubit gate follows rotation angle th variational layer given above, state ie, classical data encoded quantum state follows number dimension state space, ie, number qubits, rotation angle corresponding single qubit rotation th qubit initialized state encoding layers, consider gate together trainable scale parameter entangling layers, use qubit controlled gate defined mentioned, output last variational layer, defined observable used obtain policy however, studied policy obtained pqc may direct adjustable greediness affect exploration exploitation rl process address problem, softmax activation function used generalize expected value projection given state input proposed pqc, quantum state corresponding unitary expressed number qubits number feature system state space defined section iii, ie, considered dynamic spectrum access problem given quantum state, policy associated parameter defined follows inverse temperature parameter set trainable angles, trainable input scaling parameters, trainable weight defined expectation value observed output proposed pqc expressed follows weighted hermitian operator corresponding action iteration similar simplify tensor product pauli matrix computational basis states, ie, updating parameter proposed pqc, approximate optimal policy mentioned, work, consider simple rl approach based policy based mechanism optimize shown algorithm particular, algorithm aim interact environment, ie, ambc assisted system work, update pqc parameter gradient descent value function loss function derived based policy gradient theorem follows batch experience collected interacting environment size experience batch loss function minimized performing gradient descent thus updating pqc parameter work, perform training every iteration instead, algorithm performs training every iteration reduce computational complexity algorithm also stabilize learning process mentioned, quantum rl learn environment efficiently leveraging superposition quantum computing also significantly reduce number training parameter compared traditional deep neural network architecture section, analyze complexity proposed quantum rl algorithm dql algorithm term number trainable parameter dql algorithm usually standard multilayer perceptron architecture, consists multiple fully connected layers, deep neural network that, assume dql algorithm employ deep neural network consists input layer fully connected hidden layer output layer well known trainable parameter deep neural network weight bias such, number trainable parameter connecting layer calculated number neuron layer based this, total trainable parameter deep neural network formulated follows well known typical deep neural network requires several hidden layer neuron layer good training performance, resulting thousand trainable parameter complicated problems, number parameter much larger layer neuron needed efficiently learn complex environment similar above, formulate computational complexity proposed pqc term trainable parameter following particular, variational layer, use three gates, ie, qubit rotation qubit such, qubits, size variational layer differently, encoding layer, use gate qubit that, size encoding layer summary, number trainable parameter quantum layer calculated follows number quantum layer worth noting variational layer end pqc size final variational layer also recall expectation value action, use trainable weight better distinguish potential action impact learning process such, number trainable weight number action action space, ie, given above, total number trainable parameter proposed pqc formulated follows clear complexity proposed pqc relatively small compared dql algorithm example, considered problem, dimension state space, thus three quantum layers, total trainable weight proposed pqc meanwhile, deep neural network dql algorithm may need thousand parameter good performance example, deep neural network consists hidden layer neuron trainable parameter next section, show significantly smaller number parameters, quantum rl achieve much better performance compared dql algorithm low complexity, proposed quantum rl deployed efficiently run devices, eg, mobile phone vehicle resource constrained device wireless sensor iot devices, proposed approach may applicable instead, deployed cluster head gateway, distribute dynamic spectrum access policy device cluster network section provides extensive performance evaluation quantum rl approach compared baseline various scenario particular, first present parameter setting considered system also proposed quantum rl approach then, analyze simulation result term convergence rate, running time, average throughput different scenario unless otherwise stated, probability cu access shared spectrum time slot access set mentioned section ii, considered system, secure area near interference device affect signal reception cu access shared spectrum time that, set probability cu secure area protected paper, consider case device randomly placed considered area without loss generality, distance tx st randomly generated meter meter distance tx receiver tr randomly generated meter meter transmit power set dbm transmit power device set dbm noise power set dbm bandwidth center frequency set mhz ghz, respectively set prevent action cause interference cu ambient backscatter circuit, set reflection efficiency similar set st st tr tr effective area antenna dql algorithm, use standard parameter used widely literature particular, employ hidden layer size neuron activation function tanh learning rate set optimizer adam greedy method, set beginning training gradually reduced decay factor memory pool store experience target update frequency set batch size set proposed quantum rl approach, use quantum layer employ three adam optimizers optimize learning rate respectively tensorflow quantum library used build proposed quantum circuit paper, compare proposed quantum rl approach three baseline term average throughput calculated number bit tx transmit one second three baseline used paper include following random method, tx randomly choose action transmission used show system performance non learning approach greedy method, tx always chooses access shared spectrum actively transmit data method used show advantage ambc technology, especially shared spectrum mostly occupied cu dql baseline, use proposed deep learning algorithm solve formulated mdp section iii comparing method, better highlight advantage proposed quantum rl approach compared state art solution literature fig compare convergence rate proposed quantum rl algorithm dql algorithm different learning rate scenario, deep network two fully connected hidden layer size observed figure, proposed quantum rl algorithm much faster convergence rate compared dql algorithm specifically, proposed quantum rl approach converge average throughput around mbps training step dql algorithm cannot converge performance iteration demonstrates effectiveness using proposed pqc learn considered environment, thanks quantum superposition principle next, increase size hidden layer deep network compare convergence rate deep learning proposed quantum rl method, shown fig observed, neuron hidden layer, dql algorithm learn faster however, still cannot converge better policy iterations, proposed quantum rl algorithm quickly learn environment obtain much better average throughput iteration worth noting dql algorithm achieves best performance learning rate therefore, following simulations, set learning rate dql algorithm table i, compare number trainable parameters, running time training step, achieved performance training step proposed solution dql algorithm different setting observed, number training parameter proposed quantum rl significantly smaller dql algorithm, ie, parameter quantum layer, quantum layers, quantum layers, respectively, compared parameter hidden layer size respectively run proposed quantum rl dql algorithm standard laptop core cpu gb ram observed table i, proposed quantum rl algorithm also run ten time faster dql algorithm, thanks use pqc clearly, quantum layers, proposed quantum rl algorithm achieve best performance such, following evaluation, use quantum layer proposed pqc quantum rl dql algorithm evaluated training step fig vary probability cu access shared spectrum time slot compare average throughput method seen, proposed quantum rl algorithm achieves best performance compared baseline proposed pqc help algorithm learn considered environment efficiently, resulting better performance worth noting access high, performance gap becomes bigger stem fact shared spectrum frequently occupied cus, transmitter cannot actively transmit data receiver contrast, ambc technology, proposed solution still allows transmitter backscatter information receivers, resulting better throughput importantly, access higher average throughput obtained quantum rl dql method increase because, cu likely access shared spectrum communicate bs, device chance backscatter rf signal generated demonstrates effectiveness ambc technology since dql algorithm slow convergence rate, performance fluctuates inferior proposed quantum rl approach finally, vary probability cu secure area compare average throughput obtained methods, illustrated fig observed protected increases, average throughput method increase reason cu likely secure area, le vulnerable interference caused device use shared spectrum, resulting better throughput however, cases, proposed quantum rl approach achieves best average throughout, thanks use quantum proposition principle paper, proposed dynamic spectrum access approach communication leveraging ambc technology quantum rl particular, using ambc technology, device transmit information even cu accessing shared spectrum simply backscattering rf signal sent base station approach particularly effective shared spectrum usually busy common situation future dense heterogeneous wireless network addition, challenging obtain optimal spectrum access policy device given dynamic uncertainty system due nature wireless communication well mobility behavior mobile user address problem, developed quantum rl efficiently quickly learn environment approximate optimal policy leveraging quantum superposition principle extensive simulation demonstrated proposed solution improve average throughput communication also quickly learn environment significantly fewer training parameter compared state art method",networking and internet architecture
"key expansion based internet public key infrastructure anonymous voting introduction convention definition key expansion anonymous voting case study security consideration instruction reporting error internet public key infrastructure elliptic curve cryptography generation original key pair end entity generation temporary public key registration authority generation formal public key certificate authority generation temporary private key formal private key end entity case study social network platform case study citizen digital certificate document focus developing key expansion method based internet public key infrastructure elliptic curve cryptography, applied context anonymous voting method enables end entity maintain anonymity end entities, registration authority, certificate authority, still allowing validity end entity certificate verified, thereby facilitating anonymous voting service keywords internet public key infrastructure key expansion anonymous voting given privacy protection critical issue internet services, safeguarding user privacy process accessing service enhance user satisfaction engagement light this, document develops key expansion method built upon existing internet public key infrastructure pki security assured elliptic curve cryptography ecc ability ensure anonymity via key expansion therefore, section introduce internet public key infrastructure elliptic curve cryptography, followed sequent section covering convention definitions, key expansion, anonymous voting, case study document reference internet public key infrastructure defined encompassing end entity ee registration authority ra certificate authority ca end entity generates key pair, consisting private key public key, sends certificate request registration authority certificate request includes end entity public key registration authority review end entity eligibility access application service and, upon verification, forward certificate request certificate authority certificate authority verifies correctness request issue end entity certificate, includes public key end entity document reference elliptic curve defined include prime number coefficient coefficient base point prime order cofactor specifically, let prime finite field element set solution satisfies equation mod asymmetric cryptography applications, random positive integer generated, within range serving private key public key derived private key base point key word must must required shall shall recommended recommended may optional document interpreted described bcp when, when, appear capitals, shown document reference propose key expansion method anonymous voting, consisting four step generation original key pair end entity, generation temporary public key registration authority, generation formal public key certificate authority, generation temporary private key formal private key end entity temporary public key generated based expanded original public key, formal public key generated based expanded temporary public key similarly, temporary private key generated expanded original private key, formal private key generated expanded temporary private key specific detail presented following subsection first, end entity generates original key pair based elliptic curve cryptography, consisting original private key original public key shown follows end entity hold valid pre existing certificate, includes original public key posse corresponding original private key process obtaining valid pre existing certificate beyond scope document subsequently, end entity generates random integer within range encrypts using public key registration authority, resulting ciphertext end entity also generates advanced encryption standard aes secret key s, encrypted using public key certificate authority, resulting ciphertext encryption algorithm based ecies end entity sends certificate request registration authority, signing request original private key certificate request includes valid pre existing certificate, ciphertext ciphertext signature, relevant request detail upon receiving certificate request end entity, registration authority verifies signature using original public key confirms eligibility end entity validated, key expansion process could performed registration authority first decrypts ciphertext using private key obtain plaintext performs key expansion original public key derive temporary public key calculated follows registration authority forward certificate request certificate authority, replacing original public key temporary public key removing personal sensitive information, signing request private key certificate request includes temporary public key ciphertext signature, relevant request detail registration authority also store hash value certificate request certificate authority receives certificate request registration authority, verifies signature using registration authority public key confirms relevant qualification validated, key expansion process begin certificate authority generates random integer within range performs key expansion temporary public key derive formal public key calculated follows certificate authority creates end entity anonymous certificate, storing formal public key certificate public key field next, certificate authority decrypts ciphertext using private key obtain plaintext aes secret key used encrypt anonymous certificate integer producing ciphertext certificate authority sends certificate response registration authority, signing response private key certificate response includes ciphertext signature, hash value request, relevant response detail registration authority receives certificate response, identify end entity request corresponds based hash value request forward certificate response appropriate end entity upon receiving certificate response, end entity first verifies signature using certificate authority public key signature verified, process private key expansion begin end entity decrypts ciphertext using aes secret key retrieving anonymous certificate integer expands original private key derive temporary private key expands temporary private key obtain formal private key using following equation voting process, end entity use formal private key sign ballot end entity retrieve formal public key anonymous certificate use verify ballot signature mod mod demonstrate proposed key expansion method anonymous voting, two case study provided first case study, using social network platform example, user connect platform using end entity, equipped certificate social network platform serf registration authority, impartial third party certificate authority issue anonymous certificate second case study, using citizen digital certificate example, user connect voting system using end entity citizen digital certificate based certificate local district office server act registration authority, election commission server serf certificate authority, issuing anonymous certificate case study, user device social network platform act end entity, social network platform server function registration authority additionally, impartial third party serf certificate authority, responsible issuing anonymous certificate end entity initially, user device already posse original private key corresponding certificate includes original public key user wish participate anonymous voting social network platform, user device sends request containing certificate social network platform server verifying user eligibility, server generates random integer expands original public key certificate derive temporary public key server forward request, along temporary public key impartial third party impartial third party generates random integer expands temporary public key derive formal public key impartial third party issue anonymous certificate containing formal public key encrypts anonymous certificate random integer sends back user device important note encryption done using shared aes key user device impartial third party, ensuring two entity access anonymous certificate random integer finally, user device expands temporary private key formal private key allowing user sign ballot using formal private key anonymous certificate also included ballot curve id brainpoolp selected case study, test vector shown follows case study, citizen posse citizen digital certificate, installed computer, computer acting end entity citizen digital certificate contains original private key corresponding certificate includes original public key local district office server serf registration authority, election commission server act certificate authority, responsible issuing anonymous certificate end entity citizen wish cast anonymous vote local representative election, computer sends request, including certificate, local district office server verifying citizen eligibility, local district office server generates random integer expands original public key certificate derive temporary public key request, along temporary public key forwarded election commission server election commission server generates random integer expands temporary public key produce formal public key election commission server issue anonymous certificate containing formal public key encrypts anonymous certificate random integer returning citizen computer important note process, anonymous certificate random integer encrypted using shared aes key citizen computer election commission server, ensuring two entity access information finally, citizen computer expands temporary private key formal private key citizen digital certificate formal private key used sign ballot, also include anonymous certificate curve id secp selected case study, test vector shown follows security consideration apply accordingly key expansion method proposed document based elliptic curve cryptography, meaning security primarily relies difficulty solving discrete logarithm problem furthermore, certificate verification method employed based internet public key infrastructure, meaning security limitation associated internet public key infrastructure also apply document based aforementioned security measures, registration authority decrypt ciphertext using private key obtain likewise, certificate authority decrypt ciphertext using private key retrieve certificate authority encrypt generate ciphertext allowing end entity obtain plaintext since registration authority know value cannot determine relationship temporary public key formal public key similarly, certificate authority know value cannot establish link original public key temporary public key pleased share document made available draft ietf website datatrackerietforg doc draft chen anonymous voting would like express sincere gratitude ietf ",networking and internet architecture
"optimal ground station selection low earth orbiting satellite introduction problem formulation experiment conclusion commercial gsaas station list surrogate optimization assumption analysis mission cost minimization problem data volume maximization problem maximum communication gap minimization problem instruction reporting error ip formulation objective function constraint function mission cost minimization problem mission data maximization problem paper present solution problem optimal ground station selection low earth orbiting leo space mission enables mission operator precisely design ground segment performance cost space mission operator increasingly turning ground station service gsaas provider supply terrestrial communication segment reduce cost increase network size however, approach lead new challenge selecting optimal service provider station location given mission consider problem ground station selection optimization problem present general solution framework allows mission designer set overall optimization objective constrain key mission performance variable total data downlink, total mission cost, recurring operational cost, maximum communication time gap solve problem using integer programming ip address computational scaling challenges, introduce surrogate optimization approach optimal station selection determined based solving problem reduced time domain two different ip formulation evaluated using randomized selection leo satellite varying constellation size consider network commercial gsaas provider atlas space operations, amazon web service aws ground station, azure orbital ground station, kongsberg satellite service ksat leaf space, viasat real time earth compare result standard operational practice integrating one two primary ground station provider recent years, easier access space led significant rise new constellation mission launched commercial, government, academic organization change driven new launch providers, cheaper ride sharing launch opportunities, successful demonstration commercial shelf based small satellite historically, mission operator provisioned dedicated ground segment support satellite constellation separately however, lead significant front capital expenditures, poor asset utilization rates, limited communication opportunities, low data downlink volume address challenges, industry moved increasingly gsaas model ground station provider build global network station location mission operator subsequently contract provider integrate network model reduces mission operator capital expenditure cost spreading cost multiple customer simultaneously increasing usage antenna mission operator also benefit increased scalability able access existing global antenna networks, increasing number potential communication opportunity turn improves data downlink volumes, reduces communication gaps, enables greater operational flexibility, reduces mission lead time however, new model also come challenge integration operational cost associated using provider additionally, overall mission performance parameter data downlink volume contact frequency depend combined selection station location well satellite orbit selecting provider station support mission involves weighing consideration desired coverage, operational costs, latency data throughput, uplink downlink capabilities, reliability, scheduling availability selection complicated number different potential providers, large selection potential locations, varying cost model provider largest ground station providers, ground station location currently operation provider station considered listed appendix global distribution coverage station shown fig paper present solution ground station selection problem based integer programming ip formulation early work proposed idea federated ground station networks, loose, virtual association global station increase mission data downlink access simultaneously lowering cost reducing integration barrier primary focus work software engineering challenge architectural approach networking, scheduling, data dissemination multi mission, multi operator ground station network term station selection, past author focused improving ground station placement reducing downlink latency promoting site diversity evade problematic weather condition research area focused leveraging historical cloud data optimize optical ground station network site selection, significantly impacted adverse weather, ensure high availability minimize number required station subsequent work account variable cloud coverage using advanced models, historical data, machine learning technique efrem et al consider ground station installation costs, optimize outage probability independent weather condition work focus ground station activity planning scheduling various optimization techniques, maximize contact time prioritize mission requirement though work consider problem selecting station instead optimize mission plan pre selected set station similar problem ground station placement include sensor placement facility warehouse location placement antenna selection computing resource allocation ambulance routing surveillance drone deployment problem often consider multiple objective including coverage, network connectivity, detecting desired event targets, monitoring environment factors, redundancy fault tolerance, placement future, dynamically changing condition often optimized genetic algorithm mission operator face challenging decision problem determining ground station provider ground station select support mission optimize overall system performance paper present solution ground station selection problem integer programming solve surrogate optimization selecting individual contact opportunity maximize selected objective within bound system constraint constraint provider location extracted based selected contact opportunity approach applied optimize station selection across six current gsaas provider atlas space operations, aws ground station, azure orbital, ksat, leaf space, viasat consider three different optimization objective maximizing total data downlink, minimizing total cost, minimizing maximum time gap contact viability approach demonstrated comparing optimized station selection traditional fixed provider solution simulated scenario provider associated cost randomized trial consider problem selecting ground station network optimizes single performance objective adhering relevant selection constraint mission may include one satellite defined set set potential ground station provider station location known problem simply determining location selected mission start time end time define optimization window total duration oracle could compute possible contact opportunity spacecraft entire mission duration using perfect knowledge object predicted trajectory, ground station selection problem would equivalent satellite task planning problem selecting ground contact opportunity optimize desired objective however, due non conservative orbital perturbations, possible accurately predict spacecraft orbit leo multi year mission therefore, instead consider surrogate problem optimizing provider location selection short segment mission duration defined simulation start time end time total duration optimal station selection duration considered optimal selection entire mission assumption appropriate long simulation window long enough distribution contact simulation period representative distribution contact entire mission appendix discus depth, find propagation window day sufficient, though least day recommended alternatively mission repeat ground track orbit simulation window match repetition period, optimization provider location surrogate problem exactly optimizing entire mission duration problem provider location selection becomes problem optimizing selected contact opportunity set satellite optimal provider location simply provider location corresponding selected contact planning problem extensive work domain satellite task planning many different algorithmic approach presented literature since first presented hall et al solution approach include dynamic programming ant colony optimization mixed integer linear programming monte carlo tree search maximum independent set local search heuristic paper, adopt integer programming approach inspired past mixed integer linear programming work due unique benefit approach optimization problem expressed ip, solved using software library gurobi coin library fast, efficient, undergone extensive validation use across numerous discipline importantly, part solution problem, solver return optimality certificate state whether returned solution globally optimal, suboptimal, problem infeasible possible valid solution certificate useful system engineering understanding overall performance mission ground segment next step express ground station optimization problem ip integer program variation linear program objective constraint linear function decision variable integer express ground station optimization problem ip, consider set ground station provider provider, tuple design variable provider selected otherwise, data object provides constant information associated specific provider provider set ground station location denoted set station denoted station associated design variable location fixed data rate ground network optimized respect individual satellite satellite fixed data rate compute set contact simulation window defined contact binary decision variable indicates whether contact selected number constant variable associated individual contact contact start time contact end time total duration contact contact data rate location associated particular contact denoted satellite associated contact denoted formulate different constraint considering different subset contact associated particular provider station satellite finally, introduced auxiliary decision variable indicate whether satellite location also introduce number constant problem one time expense associated engineering work integrate provider cost setup location includes one time cost procuring radios, servers, equipment support operation location monthly recurring cost associated using location cost includes, limited to, cost associated internet, power, security charged location used incurred even one contact taken location one time cost associated licensing satellite communicate specific station fixed cost taking contact location cost per minute associated using antenna provider implement either fixed cost per pa cost per minute pricing, three potential objective function mission designer might want consider optimization problem depending primary system engineering goal mission minimum cost objective represents goal minimizing total cost mission concern may appropriate budget constrained mission total cost downlinked entire mission constant weighting factor front term monthly contact cost ensures objective function represents total cost entire mission duration maximum data downlink objective represents desire maximize total amount data transmitted mission duration objective appropriate mission expected data constrained designing station network able maximize total data return mission primary concern total data downlinked entire mission objective weighted optimal value objective total data volume able downlinked mission last objective minimum max gap objective, seek minimize maximum time gap contact satellite objective reflects desire design operationally responsive ground network ensures vehicle regular contact ground earth observation mission objective would bound maximum latency uplinking new tasking request downlinking data data collection implement constraint introduce auxiliary binary decision variable contact next contact contact taken given satellite, optimization problem auxiliary variable introduced represent maximum contact gap across pair sequentially scheduled contact constraint equation enforces one contact next contact contact expression force auxiliary variable bound gap every sequentially scheduled pair contact finally, expression enforce associated contact also number required constraint must introduced ensure collect selected, decision variable corresponding provider location also set first, ensure contact selected, associated location also scheduled enforce similar constraint single location given provider selected provider selected well finally, contact satellite station scheduled, associated vehicle indicator variable must set ensure per station, per satellite license cost counted constraint expressed also possible introduce number different constraint function impose system engineering requirement resulting solution constraint need added formulation problem, may included model design requirement minimum constellation data downlink constraint enforces total data volume downlinked across constellation minimum threshold appropriate constellation inter satellite communication long minimum data downlink volume achieved data downlinked across constellation constraint constraint enforces total data downlink contact across satellite within duration exceeds minimum threshold constraint applied contact discrete time window separated useful ensuring minimum amount data downlinked specific cadence every orbit every day minimum satellite data downlink constraint enforces total data downlinked satellite minimum value given period similar constellation downlink constraint, however requirement applied satellite separately constraint maximum operational cost constraint ensures recurring operational cost monthly station charge combined cost associated taking contact exceed set monthly threshold used mission budgeting ensure expected cost stay within set limit constraint constraint similar equation though considers operational cost normalized cost term dollar per month station contact exclusion constraint ensures location communicate one satellite time enforces physical constraint planning arise one antenna given site could modified limit number antenna set number, though consider single antenna per location work constraint added problem constraint satellite contact exclusion constraint ensures satellite communicate single location time constraint added problem unless satellite support simultaneous contact multiple location simultaneously constraint expressed maximum contact gap constraint ensures maximum time gap two contact le specific duration similar minimum maximum contact gap objective instead trying minimize gap, ensures requirement gap met constraint expressed maximum provider constraint ensures number ground station provider selected minimum contact duration constraint ensures contact duration greater considered planning constraint eliminates short duration contact might operationally useful minimum contact per period constraint ensures satellite take least contact given period duration constraint enforced discrete period incremental offset simulation window required provider constraint ensures specific provider selected required location constraint ensures location selected station number constraint ensures least station selected selected evaluate performance ip optimization solution, simulate optimization problem randomizing cost data downlink parameter across provider station appendix range potential value used generate random scenario listed table spacecraft randomly sampled set object altitude km km celestrak active satellite database spacecraft dynamic propagated using sgp propagator simulation window set day long optimization window set day case simulation window selected propagating spacecraft dynamic various simulation window analyzing point number contact per day mean gap contact duration level result shown appendix minimum elevation mask applied location calculating contact opportunity simulation run workstation core ghz intel amd epyc processor consider two primary problem variation total mission cost minimization problem data downlink maximization problem problem variation constructed represent practical system design trade study might undertaken part designing space mission ground segment problem variation constructed composing objective function subset possible constraint function section evaluate ip formulation performed trial constellation satellite type optimization problem trial, generate new problem scenario randomly setting simulation parameter uniformly sampling value table provider solve ip formulation gurobi optimizer provide solution baseline, calculate optimal solution restricted problem location selected one two provider mimic behavior mission operator integrating one two gsaas provider support mission compare performance ip optimized solution fixed solution mission cost minimization problem variation seek minimize total cost ground station network mission duration, also enforcing minimum per satellite data downlink requirement met problem formulation includes station contact exclusion satellite contact exclusion constraint minimum contact duration constraint added ensure short duration contact excluded minimum per satellite data downlink constraint required ensure non degenerate solution, utilizing locations, provider otherwise result optimal zero cost solution full set equation defining problem formulation found appendix value constraint design parameter used simulation listed table figure show optimal solution cost minimization problem compare average one provider two provider solution expected, ip optimization problem free optimize potential ground station provider performs best possible network one two ground station provider considered one surprising result that, despite minimizing total cost, ip optimzied solution also outperforms one two provider solution term total data downlinked well, would normally expected since objective include explicit regularization term would encourage data downlink maximization see ip formulation relatively fast average solution time second constellation satellite one interesting trend observed total normalized cost appears plateau two provider solution constellation size reach satellite explained saturation ground station network inability support contact new satellite is, constellation size become large enough antenna nearly constant use, saturating network, adding satellite lead increase number contact taken therefore added cost mission data maximization problem seek maximize total amount data downlinked mission, also ensuring solution adheres maximum operational cost constraint problem formulation includes station contact exclusion satellite contact exclusion constraint minimum contact duration constraint also included maximum operational cost constraint required ensure optimizer simply select provider location provide potential downlink opportunity resulting degenerate solution design constant problem maximum allowed monthly operational cost minimum acceptable contact duration full set equation defining problem formulation found appendix design parameter used simulation listed table figure show optimizing ground station network maximizing data downlink significantly increase total amount data compared one two provider ground station network without significantly increasing cost satellite mission data optimized ground station network able downlink data entire life mission increase cost compared one provider solution, able downlink data compared two provider solution satellite constellation optimized ground station network still downlink nearly data one two provider network increased cost explanation significant performance improvement ip formulation able use lowest cost station region overlapping station coverage eg europe well add single station non saturated region eg pacific ocean increase total capacity runtime solution increase nearly linearly constellation size optimal network satellite constellation found within second average paper introduced solved problem ground station provider location selection space mission designer problem posed integer programming problem three different objective function fourteen different potential constraint function presented objective function constraint function composed conduct different type design study satellite ground station network two primary class optimization problem analyzed mission cost minimization data volume maximization mission cost minimization, ip solution shown reduce total mission cost simultaneously improving total data downlink data volume maximization problems, ip optimized ground station network seen increase total data downlink compared optimal single provider network compared optimal two provider network future work, would desirable consider multi objective optimization ground network instead optimizing single design parameter, network optimized simultaneously multiple consideration additionally, would desirable investigate unconstrained network design problem, instead selecting set fixed locations, network optimized viable terrestrial location finally, map gap objective constraint introduce large number auxiliary variable equation significant negative performance impact, finding alternative formulation solution approach desireable software utilized formulate contact optimization problem prepare publication available githubcom sisl ground station optimizer list current major commercial gsaas location provided table please note due security concern exact station coordinate coordinate provided two decimal place accuracy request participating provider non participating providers, station location obtained correlating publicly available data provider stated ground network accuracy sufficient analysis purpose site list location inferred publicly available data site list provided gsaas provider paper employ surrogate optimization approach ground station network optimized short simulation window le entire mission duration assumed good proxy optimizing entire mission provides benefit reducing problem size, thereby improving runtime performance also serf address challenge accurately predicting contact window potentially multi year space mission eliminating need simulate entire mission duration surrogate optimization appropriate long distribution contact contact property surrogate problem similar longer propagation test whether appropriate assumption randomly sampled different active satellite altitude km km propagated orbit varying time durations, computed contact opportunity duration, computed statistic distribution contact contact property figure show result experiment see mean gap duration start level day propagation near steady state value day propagation appears significant variation mean contact duration average number contact per day, absolute number total range variation relatively small second contact per day respectively cause variation need investigated, though may artifact propagation method sample size may large enough result recommend simulation optimization window least days, however day preferred computationally possible mission cost minimization problem detailed section aim reduce overall expense ground station network throughout mission duration ensuring satellite achieves specified minimum data downlink requirement formulation incorporates constraint station contact exclusion satellite contact exclusion maintain schedule physically realistic additionally, constraint minimum contact duration included guarantee contact meet required minimum length enforcement minimum data downlink per satellite necessary prevent degenerate solutions, ground station provider selected, resulting optimal non functional zero cost outcome design constant problem required per satellite, minimum data downlink volume, duration minimum data downlink amount must achieve, discrete increment adherence minimum data downlink constraint checked full optimization problem problem presented section designed maximize total volume data downlinked throughout mission period imposing constraint maximum allowable operational cost formulation includes station contact exclusion satellite contact exclusion constraint ensure scheduling remains physically feasible additionally, constraint minimum contact duration incorporated ensure contact meet necessary minimum time requirement maximum operational cost constraint needed prevent optimizer selecting available provider locations, would maximize downlink opportunity result impractical degenerate solution design parameter problem denotes highest permissible monthly operational cost, representing minimum acceptable duration contact full problem problem minimizing maximum communication gap final problem variation problem variation represents design optimization study performance oriented mission design seek minimize communication gap subject station exclusion, satellite exclusion, minimum contact duration constraint minimum satellite data downlink constraint also must included otherwise problem admits degenerate solution contact scheduled additionally, maximum monthly cost constraint need introduced prevent degenerate solution scheduling contact design constant problem maximum monthly cost, per satellite, minimum data downlink amount, duration minimum data downlink amount must achieve, discrete increment adherence minimum data downlink constraint checked full problem",networking and internet architecture
"improved contact graph routing delay tolerant network capacity buffer constraint introduction ii background motivation iii contact capacity node buffer challenge dtns iv proposed global capacity buffer management solution benchmark source routing cgr vi simulation environment setup vii simulation result viii conclusion instruction reporting error ii key notion ii contact graph routing ii source routing cgr iii contact capacity management iii buffer management iv model parameter modification iv capacity buffer management iv booking resource forwarding safety margin iv information sharing network vi environment vi communication parameter vi simulation parameter assumption vi simulation tool vii impact contact capacity management vii impact buffer management satellite communication present challenging characteristic continuous end end connectivity may available due large distance satellite moreover, resource link capacity buffer memory may limited routing satellite network therefore complex crucial avoid packet loss long delay delay tolerant network dtn paradigm emerged efficient solution managing challenging network contact graph routing cgr deterministic routing algorithm, one popular dtn algorithm cgr compatible store, carry, forward principle, whereby node receives message store buffer transmission opportunity becomes available however, cgr relies simplified model incorporate potential constraint route search instance, linear volume assumption often used consider capacity constraint moreover, capacity management buffer management mostly performed forwarding phase, issue occurred paper, propose take measure route search order find route respect contact capacity limit node buffer limit introduce contact splitting edge pruning operation effectively account routing constraint ensures cgr output optimal solution among subset valid solution proposed approach also used book resource used case issue forwarding step satellite communication belong category intermittently connected network icns characterized intermittent connectivity node network, preventing continuous end end connection resulting high delay intermittent nature induces multiple discontinuous episode communication opportunity pair node called contacts, see following section transmission thus delayed immediate communication opportunity node must therefore operate store, carry, forward principle result, since traditional internet protocol suited challenges, need new protocol arose delay tolerant network dtn architecture new protocol layer proposed internet engineering task force ietf handle issue bundle protocol bp considered consultative committee space data system ccsds instance protocol mentioned above, routing challenging discontinuous time dependent connection main routing issue icns inability establish complete route due lack connectivity moreover, addition delivery time objective, optimizing delivery rate resource consumption also considered instance, use transmission resource must carefully optimized limited availability additionally, data unit often held node buffer long periods, optimizing storage resource avoid congestion loss crucial efficient routing algorithm therefore needed addition suitable network capability via mentioned protocol routing algorithm dtns classified three category depending availability network information opportunistic probabilistic deterministic, depending whether contact unpredictable, determined certain probability, completely predetermined, respectively paper, focus space communications, natural artificial satellite deterministic motion thus, contact predetermined, making deterministic routing algorithm suitable widely used deterministic routing algorithm dtns contact graph routing cgr since invention, cgr gained attention research community several improvement proposed instance, using dijkstra algorithm route search choosing best case delivery time bdt objective presented then, earliest transmission opportunity eto introduced compute time bundle transmitted contact eto take account time bundle wait transmitted scheduled bundle transmission contact later, complementary overbooking management added eto improve routing decision enhancement among others result currently used version cgr nevertheless, version provides local reactive contact capacity buffer occupancy managements, lead sub optimal solution therefore, important explore alternative approach one modern application, capacity buffer management may critical, cislunar communication advent artemis program many project lunar environment arose, triggering high need communication resource another application low earth orbit satellite constellation constellation expected utilized extensively future however, future constellation large enough maintain end end connectivity time even large constellation may deploy satellite initial stage, requiring establishment network limited number satellite initial phase result, many constellation expected temporarily buffer data main contribution paper, provide routing solution based cgr global proactive congestion control propose perform contact capacity management buffer limit management route search obtained route optimal respect two constraint objective achieved follows propose managing contact capacity route search modifying network information, provided contact lists, using contact splitting contact splitting remove part contact used routed bundle propose track node buffer occupancy function time using forecast buffer table buffer occupancy managed temporarily modifying network information, also via contact splitting, routing specific bundle avoid buffer overflow temporarily forbidding edge contact route search specific bundle avoid buffer overflow modified network information enables remove route respect constraint route subsequently, route search algorithm, cgr, find optimal solution among subset valid solution proposed approach also considered book resource utilized case failure event forwarding phase resources, referred safety margin paper, used intermediate node limited information network state structure paper paper structured follows section ii, first introduce key term used paper provide review cgr section iii, focus existing capacity buffer management challenge dtns introduce motivation proposed solution introduced section iv benchmark source routing cgr, considered benchmark, detailed section simulation assumption result comparing method benchmark given section vi vii, respectively first define key term used paper node satellite communication scenario, node satellite ground station illustrated figure contact contact defined communication opportunity two node thus characterized sender receiver nodes, start time end time data rate capacity bit per second bps volume contact rate multiplied duration contact plan cp cp list contact time period reflects evolution network topology time example provided figure edge edge exists two contact receiver one contact match sender second contact, end time latter later start time former bundle bundle data unit encoded bp bundle characterized size bit bundle generated source node provided destination node route route path series contact used deliver bundle source node destination node cgr divided three main phase first, cp, example constructed mission control unit, forwarded node network second, forwarding ie, transmission phase, node receiving bundle performs route search using dijkstra algorithm determine next hop third, check performed intermediate node transmission verify system constraint respected deterministic network case, cp constructed source node using network information transmitted intermediate node route search phase given destination, route source node destination node computed using dijkstra algorithm however, adaptation algorithm used consider discontinuity icns main idea use contact graph representation network rather node graph representation dijkstra algorithm thus implemented contact graph representation network output dijkstra search route source destination bdt yen algorithm enables determine list shortest route iteratively exploring route source destination, using dijkstra contact graph representation avoiding loop previously discovered path standard cgr implementation, node computes list shortest route node network using yen algorithm, input parameter then, bundle reach given intermediate node, node determines feasible precomputed route route list determine next hop forwarding phase, local queuing state buffer bundle property available remaining contact volume buffer queuing time bundle scheduled contact taken account checks, among others, help verify validity previously computed route route list prevent local congestion list candidate valid route thus determined shortest route valid route guarantee contact volume availability given size bundle moreover, one also check that, taking account transmission queuing time, bundle effectively transmitted end corresponding contact, see eto best route among valid route selected determine bundle next hop route selected, bundle queued transmission, available volume contact used decreased size bundle although widely used, cgr computationally complex node perform many check bundle determine next contact use moreover, since check performed route search, valid solution may found among candidate route may trigger time consuming iterative search process dijkstra algorithm check one solution reduce cgr complexity source routing sr unlike per hop routing, idea sr compute route source node encode bundle extension block bundle, whose route already calculated, arrives intermediate node, node check validity encoded route case invalidity, traditional cgr performed intermediate node following two type sr implemented bundle independent sr, source performs route search without bundle property queuing information forwarding time, check cgr eto volume availability performed validity encapsulated route checked using available information bundles, like size, local queue state available initial route search time, bundle properties, eg, size priority, utilized case bundle dependent sr then, forwarding phase, information local queue taken account viability route checked solution go paradigm incorporating network information alongside bundle property initial route search mentioned previously, cgr capacity consumption availability managed forwarding phase common approach take contact capacity account route search check available volume contact greater size bundle called linear approach however, prevent exceeding capacity limit track time bundle contact linear volume model represented right side figure see also detail issue example figure example, using linear model, one may think bundle hatched rectangle reaching node use contact immediately nevertheless, reality contact volume consumed represented left side figure case, bundle reaching node cannot transmitted using contact immediately bundle striped rectangle transmitted capacity specific time traditional cgr, problem detected forwarding step, route search, using eto example transmission bundle thus delayed accordingly nevertheless, delaying transmission bundle forwarding phase may cause multiple problem inaccurate estimate delivery time, end unavailability current future contact planned route, reaching bundle delivery deadline delivery collision problem better managed, even avoided, capacity consumption modeled differently example, use precise moment known advance, alternative route might effective solution delivering bundle dtns, node buffer management important task, bundle wait long time node buffer transmitted addition, available buffer capacity may limited buffer management strategy usually consist addressing problem occurred example buffer full, decision reroute drop bundle take place spot, like reactive custody transfer author suggested strategy refuse custody order preserve buffer space node however, strategy rely information coming local neighbor node alternative approach would global vision buffer occupancy handle buffer space issue initial route search note however that, unlike volume capacity managed contact level, buffer occupation managed node level instance, multiple bundle using distinct contact affect buffer node therefore, one careful addressing challenge contact graph representation network framework considered bundle dependent sr cgr see section ii propose address buffer capacity constraint route search reminder, opposed approach reported state art action taken issue occurred solution ensures route found respect buffer capacity limit moreover, proposed modification remove viable solution, enables route search find optimal solution given constraint achieved modifying cp starting route search, capacity buffer constraint moreover, buffer constraints, allowed edge contact also modified route search words, modify parameter cgr performs search among valid solution optimal route respect buffer capacity limit encoded bundle, forwarded network manner sharing bundle transmission path source routing cgr solution consists two key element first, propose modify cp used route search algorithm eg, dijkstra search via contact splitting differentiate two kind cp modification definitive ones, shared network, temporary bundle specific modifications, performed locally one node within route search process specific bundle second, propose imposing additional restriction allowed edge contact rule respected inside route search algorithm restriction implemented locally node, route search specific bundle assume cp shared entity performing route search eg, source node introduce contact splitting operation let consider original arbitrary contact data rate sender node receiver node contact splitting consists replacing original contact cp, two split contact node one one see figure split contact data rate original contact note part original contact erased moreover, one split contact might last time, meaning contact splitting result contact shortening define edge pruning act forbidding edge contact action taken pair contact original split example, figure one choose forbid edge contact mean that, route search, option choose route contact followed contact explain contact splitting edge pruning used address capacity buffer constraint discussed section iii assume knowledge bundle size first, route search first transmitted bundle performed contact skipped bundle size greater contact volume similarly linear volume approach shortest path selected bundle, cp modified follows remove part contact consumed bundle cp performing route search subsequent bundle length contact erased tx, starting start time contact arrival time bundle contact sender node, whichever occurs later variable tx, represents time needed transmit bundle contact selected path operation contact splitting operation creates two new contact two new contact added cp original contact removed operation performed contact selected route then, subsequent route search use modified cp cp modification, performed selection route bundle, definitive shared node performing route search example example figure route search route selection initial bundle striped rectangle cp becomes represented figure new cp used route search subsequent bundle case, part contact tx,a option future bundle collision therefore occur first introduce notion forecast buffer table goal table store buffer occupancy status node function time, including future time similarly cp, assume table shared entity performing route search explain use table respect buffer constraint forecast buffer table assume node maximum buffer capacity limit max overflow occurs limit exceeded proposed buffer management solution temporary bundle specific cp modifications, shared network see following subsection however, route selected, forecast buffer table updated accordingly shared entity performing route search words, route validated, one check bundle reach given node long stay buffer according validated route since buffer table updated soon route validated, routing node know advance status buffer function time, even bundle travel network algorithm respect buffer constrains main idea proposed algorithm enforce buffer limit constraint follows since bundle size forecast buffer table available route search time, one check whether bundle buffer node time not, algorithm must forbid route leading storage bundle potentially problematic buffer hence, performing route search, cp temporarily modified using contact splitting then, edge pruned using edge pruning inside route search algorithm algorithm formulated four following main step step begin with, size bundle virtually added node buffer table time potential overflow detected determined location node time start end time set node potential overflow bundle denoted number potential overflow forming set overflow denoted start end time overflow denoted respectively example figure present example bundle arrives source node need routed figure depicts one node two potential overflow potential overflow identified virtually adding size bundle vertically striped rectangle buffer level node dotted rectangle buffer level node virtually adding size bundle b, determined validated route previous bundle dotted rectangle corresponding forecast buffer table node shown figure step then, original cp temporarily modified accordingly starting route search one remove part contact cp might forward bundle node overflow start end time using contact splitting problematic contact contact start end overflow end start example problematic contact potential overflow descried previous example shown figure contact node receiver regardless sender node start end problematic duration intersects period overflow problematic portion contact horizontally striped figure may forward bundle potential overflow duration part contact intersect overflow duration temporarily removed using contact splitting applies potential overflow node step removing problematic contact potential overflow part sufficient one also address problematic contact succession problematic contact succession occur contact end time beginning potential overflow succeeding contact route start time beginning overflow succession contact problematic result bundle buffer node potential overflow step therefore consists identifying problematic contact succession described via following example example step contact receiver span duration figure nevertheless, contact receiver ending using one contact eg, bundle arrives potential overflow however, bundle must leave beginning overflow avoid potential problem bundle leaf node contact succeeding previous one route succeeding contact eg, sender, regardless receiver result, succeeding contact start overflow avoid otherwise, succession route cause overflow therefore problematic step finally, last step forbid edge contact yielding problematic contact succession words, edge contact starting late pruned edge pruning performed route search example example figure route search, contact forward bundle node edge contact third node accepted start applies overflow node described steps, invalid route removed modification proposed contact capacity buffer management solution words, proposed modification route search omit feasible solution hence, subsequent use cgr give optimal route subset valid solution proposed solution source node keep track buffer contact capacity occupancy status due feature, avoid overflow overbooking nevertheless, due unpredictable disruptions, like antenna pointing error node power outage intermediate node may perform routing forwarding time since intermediate node may access buffer capacity status, routing decision may cause overflow overbooking reason, propose let part original contact buffer resource unused source node unused portion referred safety margin utilized intermediate node reroute bundle without resulting overflow overbooking quantity resource allocated method determined function network disruption level safety margin implemented follows first, regarding contact capacity management, two cps created contact splitting, slot kept margin, performed safety margin therefore removed original cp obtained cp provided used source node safety margin part contact removed original cp forwarded intermediate node may perform routing unpredictable situation term buffer management, source node utilize fraction buffer capacity, leaving rest available intermediate node solution therefore enhances robustness potential unexpected events, despite poor knowledge current network status intermediate node mentioned above, modified network information contact splitting except bundle specific cp modification modified forecast buffer table allocating route bundle shared source node performing route search similar sharing date cp source node standard sr cgr safety margin resource shared node network low frequency mentioned first part manuscript, network issue handled route search standard sr cgr retransmission mechanism exist long round trip time communication, licklider transmission protocol ltp retransmission mechanism case failure standard sr cgr well described literature many manner address issues, describe detail assumption made considered sr cgr benchmark proposed algorithm compared benchmark section vii, simulation result presented begin with, benchmark algorithm, bundle transmitted contact, assumed link occupied time required transmit bundle words, whole link capacity used ie, time division multiplexing tdm approach initial cp constructed source broadcasted node network then, source node performs route search using yen algorithm dijkstra search list yen constant shortest route generated list kept change occurs cp, end contact case, route list discarded new list generated, route list pruning list candidate route constructed explained section ii candidate route found list, bundle delayed route search performed one time step regarding capacity buffer management performed route search route found, volume occupied bundle selected route deducted available volume corresponding contact cp ie, linear volume approach described section iii buffer information available considered source finally, route encoded bundle bundle sent network bundle encapsulated route transmitting node source intermediate node subject check verify whether route used contact capacity buffer management forwarding phase benchmark detailed hereafter first, time corresponding contact must used bundle transmission verified case collision another bundle, transmission bundle highest id delayed similar behavior determining eto id increase bundle generation time source two case occur delaying bundle cause problem, time future hop simply updated encapsulated route according delay caused bundle using contact delaying bundle cause transmission time later corresponding contact end time, new route computed node problem happened, avoiding problematic contact time new route search call problem detection time provide detail regarding second case reroute bundle, date cp problem detection time loaded instantly source node note advantageous assumption benchmark moreover, since remaining part old route longer used, volume future contact old route updated locally cp node ie, incrementing available volume unused contact size bundle cp update performed intermediate node reported source newly computed route, any, encapsulated within bundle forwarding none shortest route valid, bundle sent instantly source rerouting source performed one time step forwarding phase, assume node access state buffer neighbor node contact bundle transmitted, current node verifies enough room buffer receiving node case, next node buffer occupancy increased book space bundle bundle transmitted waiting time evaluated determine long bundle remain buffer next node time equal transmission time current node next node tx, well wait time start next contact wait exists wait transmission time next node distant node route tx, tx, wait total bundle size assumed occupy buffer next node tx, space occupied bundle linearly reduced time pa ie, bundle leaf buffer according data rate contact used transmission room bundle buffer next node, bundle rerouted current node via route avoids problematic neighbor well previously visited node avoid loop note node whose buffer fully occupied considered problematic must therefore avoided this, problematic contact used route removed cp rerouting bundle node note bundle pa problematic node later route, buffer emptied example valid route found among shortest routes, bundle instantly sent back source rerouted one time step alternative solution, considering, would continue trying transmit via fully booked node time step valid route found place becomes available buffer problematic node, whichever come first note solution requires lot computing resource route search repeated time step suitable solution found simulations, consider sat satellite orbiting orbital plane distributed according walker delta constellation zero phasing orbital plane evenly distributed range hence, angle right ascension ascending node raan two satellite adjacent plane furthermore, plane, true anomaly sat satellite evenly separated sat consider circular orbit eccentricity inclination radius m, earth radius constant consider two bundle generated source bundle transmitted source destination satellite intermediate node network cp constructed hour scenario starting pm august assume contact rate snapshot one walker constellation sat pm august illustrated figure generated using matlab satellite communication toolbox using cislunar constellation evaluate algorithm considered future work see also conclusion considered constellations, orbital plane sat satellite define plane hop number plane communication two satellite cross table depending communication parameter satellite dynamics, satellite located orbital plane communicate satellite located plane zero plane hop, raan adjacent plane one plane hop, one difference raans satellite distant plane one plane hops, meaning plane restriction case number plane limited characteristic used constellations, also depending communication parameter provided following subsection, given table satellite mounted transmit receive gaussian antenna dish diameter aperture efficiency transmission frequency power hz db, respectively receiver gain noise ratio energy noise sensitivity equal db kelvin db, respectively source equipped transmit antenna whose property similar satellites, except transmission power considered db destination equipped receive antenna whose property similar satellites, exception sensitivity db free space channel model considered considered minimum required elevation angle communication two satellite communicate line sight power received receiving satellite transmitting satellite greater sensitivity receiving satellite satellite communicate gs, elevation angle former relative latter must greater minimum elevation angle latter, addition line sight within communication range condition met, link closure two node contact extends beginning end link closure two node example figure constellation represented figure illustrates, green, link closure pair node sat sat sat sat sat example link closure happens time snapshot link sat limit one time sample one second later, link longer exists two node cease respect elevation angle constraint link closure thus interrupted even though remain line sight communication range addition, sat sat may within communication range, communication blocked earth, preventing line sight time step, one bundle byte generated source bundle generated period seconds, starting beginning scenario time, equal inter arrival time total bundle generated forwarded mean one bundle generated second bundle inter arrival time decrease total number bundle generated source, increase yen constant chosen equal finally, assume external disruption network is, provided cp valid rerouting needed intermediate node due external factor given assumptions, therefore need consider safety margin contact capacity buffer space section iv use matlab satellite communication toolbox simulate presented satellite communication scenario calculate link closure pair node function time obtain cp used benchmark solution, also implemented matlab alternative algorithmic implementation would use interplanetary overlay network ion however, chosen main focus cgr evaluate performance using two main metric first metric average time bundle spends network computed difference destination arrival time bundle generation time source includes buffer waiting time, transmission time, potential rerouting delay metric number rerouting event sr cgr, includes rerouting source route found among shortest one well bundle instantly sent back source also includes, sr cgr proposed solution, rerouting intermediate node buffer capacity check fails evaluate impact contact capacity management buffer management separately course, two management technique used together obtain greater gain section, evaluate performance proposed contact capacity management therefore, consider constraint associated buffer limits, ie, maximum node buffer capacity max node figure show average time spent network sat constellation function number bundle generated source three value contact data rate considered bps contact expected, one see time spent network increase number bundle decreasing data rate low load eg, bps proposed algorithm sr cgr similar performance increases, gap curve increases, le time spent network using proposed method due increased number rerouting event forwarding time using sr cgr number rerouting event shown figure sat constellation value function low load, overbooking event happening contact case, traditional sr cgr satisfactory performance number bundle increases, overbooking phenomenon increases, making rerouting likely case overbooking event, intermediate node try overcome issue rerouting bundle location toward destination new route longer one avoiding overbooking computed using proposed algorithm moreover, route found node, bundle rerouted source see assumption benchmark also causing additional delay proposed algorithm efficient shortest route always computed directly source node, always avoiding overbooking indeed, expected, rerouting required proposed solution simulation due contact capacity check failure moreover, although case time spent network sr cgr similar proposed solution, node complexity significantly higher benchmark due multiple check rerouting event then, figure illustrates time spent network satellite constellation respectively contact data rate considered equal bps four satellite one satellite per orbital plane number node limited distant compared constellation higher number satellite thus, number communication opportunity limited, limiting routing degree freedom case, proposed algorithm show improvement compared benchmark number satellite increase algorithm present improvement compared benchmark, particular high load section, evaluate performance proposed buffer management contact capacity restriction implemented, ie, average time spent bundle network function buffer size per node, expressed number bundle buffer store, given figure consider sat constellation buffer storage size identical intermediate node source node infinite buffer size result shown bundle generated second expected, storage capacity buffer increases, time spent network reduced gain significant proposed solution, especially buffer size limited reach performance infinite buffer capacity solution requires buffer store bundles, compared bundle almost half achieve performance benchmark difference even higher reach performance infinite buffer buffer size bundle small box figure using solution benchmark, respectively similarly capacity case, difference due number rerouting event intermediate node shown figure also sat constellation using sr cgr moreover, expected, rerouting performed proposed solution due buffer check failure finally, figure show impact different constellations, namely performance related buffer constraint number node limited, frequently used limited storage capacity induces additional delay solution sat two solution reach infinite buffer performance buffer capacity bundle per node nevertheless, constellation lower buffer size per node, proposed solution manages significantly reduce average time bundle spends network increasing number node constellation using proposed solution lead low delay even low buffer capacity per node work, proposed enhanced contact capacity management buffer management improve state art cgr routing algorithm proposed managing resource taking action route search solution global solution considers track evolution contact capacity buffer occupation contact node network resulting route optimal respect contact capacity node buffer constraint manage contact capacity, introduced contact splitting allows consideration previously consumed portion contact routed bundle buffer management, proposed temporary bundle specific contact splitting edge pruning avoid portion succession contact might result buffer overflow temporary modification depend forecast buffer table track future state node buffer occupancy level function time compared performance proposed solution benchmark sr cgr solution offer considerable gain term time spent network intermediate node complexity, measured number rerouting call limitation although proposed solution offer improvement state art meeting capacity buffer constraints, limitation could taken account improvement solution based sr cgr, usually used reduce cgr complexity reduction achieved performing one route search per bundle rather multiple route search per hop routing nevertheless, solution split contact two contacts, bundle occupies contact capacity buffer space splitting action increase size cp, directly impact complexity route search solution, additional complexity tractable route search performed source node low power intermediate node nevertheless, moving distributed solution, one consider additional complexity centralized solution also limitation study examination efficient distributed solution therefore interesting research direction improvement work future work plan proposed cislunar constellations, communication perspective, using presented routing technology believe proposed routing algorithm may help design communication storage system embedded satellite lunar constellation also plan investigate traffic level solution rather per bundle solution state art work, route chosen based optimal criterion bundle level, entire traffic transmitted therefore, per bundle strategy likely optimal overall communication performance finally, mentioned previous limitation subsection, investigating distributed solution rather centralized one also interest",networking and internet architecture
"towards safer heuristic plain introduction heuristic analysis case comprehensive analysis challenge plain proposal related work acknowledgement appendix formalizing plain dsl instruction reporting error domain specific language adversarial subspace generator explainer generalizer instance generator plain node description plain model linear optimization name pantea, color orange pk many problem cloud operator solve computationally expensive, operator often use heuristic algorithm faster scale better optimal solve efficiently heuristic analyzer enable operator find much heuristic underperform however, tool provide enough detail operator mitigate heuristic impact practice discover single input instance cause heuristic underperform full set explain propose plain, tool extends analyzer help operator understand heuristic underperform present promising initial result show extension viable operator use heuristic approximate algorithm faster scale better optimal counterpart production system solve computationally difficult expensive problem heuristic perform well across many typical instances, break unexpected way network condition change namyar et al, goel et al, arun et al, arashloo et al, community developed tool enable operator identify situation namyar et al, agarwal et al, goel et al, arun et al, agarwal et al, tool find performance gap one heuristic algorithm compared another heuristic optimal identify example instance input cause given heuristic underperform example, metaopt namyar et al, describes heuristic deployed microsoft wide area traffic engineering solution show could underperform see mean company would either overprovision network support traffic, drop traffic, delay potential benefit heuristic analyzer clear allow operator quantify risk heuristic want deploy although heuristic analyzer already shed light performance gap many deployed heuristics, still nascent stage limited use operator sufficient expertise formal method optimization theory crucial feature missing operator model heuristic want analyze term mathematical construct tool support manually analyze output tool understand fix heuristic scenario tool provides performance gap example input caused produce full space input cause large gap describe heuristic underperformed instance latter problem limit operator ability use output tool fix problem either improve heuristic, create alternative solution underperforms, cache optimal solution instance earlier examples, operator look tool example demand matrix understand heuristic route le traffic optimal state heuristic analyzer today reminiscent early day community exploration network verifier potential help network operator configure manage network way network verifier enabled operator identify bug configuration yang lam, kazemian et al, khurshid et al, zhang et al, lope et al, mai et al, horn et al, jayaraman et al, beckett et al, fayaz et al, gember jacobson et al, tang et al, kakarla et al, heuristic analyzer help find performance gap algorithm deploy tool allow operator leverage heuristic analyzer easily, identify heuristic underperform, devise solution remediate issue serve similar purpose tool community crafted explained impact configuration bug tang et al, kakarla et al, jayaraman et al, tian et al, producing set packet bug impacted configuration line caused impact propose plain vision generalizer augment existing heuristic analyzer help operator either improve heuristic helping find heuristic underperform use safely finding region underperform propose domain specific language allows concretely describe heuristic behavior benchmark want compare automated analysis rooted network flow abstraction, allows model behavior many heuristic operator use today networks, including namyar et al, goel et al, compiler convert input language existing heuristic analyzer efficient iterative algorithm analyzer, extrapolates adversarial input finds, find adversarial subspace heuristic underperforms use language visualize ie, different decision heuristic made compared optimal caused underperform heuristic underperforms case also discus open question possible approach built solution propose work uncover property input problem instance cause heuristic underperform proof concept implementation idea metaopt namyar et al, underlying heuristic analyzer open source proposal applies heuristic analyzer agarwal et al, goel et al, agarwal et al, well heuristic analyzer namyar et al, agarwal et al, goel et al, take heuristic model benchmark model eg, optimal input goal characterize performance gap heuristic compared benchmark recent tool namyar et al, goel et al, use optimization theory first order logic solve problem return single input instance cause heuristic underperform example heuristic work include demand pinning dp deployed microsoft wide area network dp heuristic traffic engineering problem optimal algorithm assigns traffic demand path maximizes total flow route network without exceeding network capacity operator use dp reduce size optimization problem solve dp first filter demand pre defined threshold route pin shortest path route remaining demand optimally using available capacity see fig metaopt author modeled dp directly optimization problem also provided number helper function allow operator model easily metaopt solves bi level optimization produce performance gap demand cause flow easy see missing operator examine single output find dp underperformed dp amenable manual analysis see namyar et al, heuristic also hard operator extrapolate example adversarial input find region input space dp may underperform limitation exacerbated move larger problem demands, harder pinpoint heuristic decision route particular demand interferes ability route others vector bin packing vbp place multi dimensional ball multi dimensional bin minimizes number bin use operator use vbp many production systems, place vms onto server barbalho et al, vbp problem apx hard woeginger, one heuristic solves vbp first fit ff greedily place incoming ball first bin fit show encode metaopt metaopt produce adversarial ball size percentage bin size example ball equal sized bin use single dimensional ball optimal bin ff show complex version fig again, operator reason example identify ff underperforms input cause problem harder ff vbp heuristics, best fit first fit decreasing, evidenced year research theoretician space panigrahy et al, paper, use dp vbp running example example representative heuristic prior work studied namyar et al, goel et al, scheduling example virley study conceptually similar vbp, think discussion directly translate use case prior work arashloo et al, show that, using single adversarial instance, difficult understand heuristic underperformed even harder generalize adversarial input cause heuristic underperform single problem instance instance property input problem instance cause underperform prior work namyar et al, agarwal et al, arashloo et al, show explaining adversarial input benefit improve dp performance gap order magnitude produce congestion control algorithm meet pre specified requirement agarwal et al, result require manual analysis namyar et al, problem specific model agarwal et al, arashloo et al, see opportunity new tool enables operator identify full risk surface heuristic set input heuristic underperforms identify heuristic underperforms automatically produce description entire area heuristic high performance gap description choice heuristic make cause underperform difference action heuristic optimal point heuristic underperforms outputs, tool make safer operator use heuristic practice mitigate case underperform maybe even design safer heuristic three level information provide given problem instance, set input cause heuristic underperform given problem instance, reason heuristic underperforms contiguous region adversarial input space general case, characteristic input problem instance cause heuristic underperform take dp example ideal tool would produce type given topology, adversarial input set form represents contiguous subspace dimensional dimensional demand space given entry demand pinning threshold small positive value multiple path node call demand pinnable demand portion path node intersects shortest path pinnable demand min here, set contains capacity link path adversarial instance example fit behavior type given topology, dp route pinned demand shortest paths, optimal route alternate path expect pinned demand contiguous subspace would common pattern shortest path, dp shortest path routing demands, whereas optimal type heuristic performance worse length shortest path pinned demand longer capacity link along path lower pinned demand limit heuristic ability route demand hard arrive low level model heuristic order use existing analyzer namyar et al, goel et al, agarwal et al, operator need expertise either formal method goel et al, agarwal et al, optimization theory namyar et al, boyd vandenberghe, see analogy writing imperative program assembly code write program assembly take time, high risk buggy, make code review ie, explanation difficult low level model operate variable construct often hard connect original problem greek letter auxiliary variable instead human readable text model first fit behavior, metaopt auxiliary, binary variable capture whether bin first bin ball fit in, set value hard derive explanation model harder still connect heuristic work explain behavior need better descriptive language encode behavior heuristic also need find adversarial subspace validate subspace input space input fall subspace cause heuristic underperform find them, need search algorithm iterates extrapolates adversarial input existing analyzer find similar sat problem mcmillan, grumberg et al, yu et al, input space large, cannot blindly search find adversarial input namyar et al, find potential adversarial subspace, validate need check whether heuristic performance gap higher input belong adversarial subspace compared statistical significance find input subspace cause bad performance reasonable assume input contiguous adversarial subspace trigger bad behavior heuristic find explain behaviors, need automatically reason heuristic action compare benchmark need concretely encode heuristic benchmark choice part language design solution challenge ensure language applies broad range problem amenable type automation desire generalize beyond single instance perhaps hardest challenge generalize instance based explanation one applies heuristic behavior general case find valid extrapolation instance based example discover pattern apply heuristic behavior across different problem instance propose plain fig user describe heuristic benchmark domain specific language main purpose domain specific language dsl concretely define behavior heuristic benchmark, allows automated system analyze, compare, explain behavior compiler translates dsl low level optimization construct adversarial subspace generator generates set contiguous subspace input subspace cause heuristic underperform significance checker filter output ensures subspace statistically significant check input fall subspace produce higher gap compared statistical significance explainer describes heuristic action differ benchmark contiguous subspace given problem instance generalizer extrapolates instance based observation produce property input instance cause heuristic underperform instance based explanation across many instance use instance generator create instance auto generate information described need dsl concretely encode heuristic benchmark algorithm need dsl represent diverse heuristic use automatically compile optimization efficiently solve existing solver support introduce many additional constraint variable compared hand written model easy intuitive use design abstraction based network flow problem bertsimas tsitsiklis, network flow problem optimization that, given set source destinations, optimize route traffic respect capacity constraints, maximize link utilization, etc network flow problem impose two key constraint total flow link link capacity, come node go flow conservation advantage using network flow problem intuitive graph representation bertsimas tsitsiklis, operator know reason flow traffic graph easily translate convex optimization feasibility problem bertsimas tsitsiklis, many variant use build upon use network flow model extend set new node behavior ensure apply broad class heuristic node behavior set constraint operate flow coming going node split node enforce flow conservation constraint pick node enforce flow conservation constraint allow flow single outgoing edge copy node copy flow come onto outgoing edge source sink node produce consume traffic etc node enforce multiple behavior simultaneously include node behavior enforce flow conservation constraint copy node capacity constraint default model broad set heuristic user also add metadata node edge, use later improve explanation produce user encode problem, heuristic, benchmark dsl abstract term example, model vbp specify problem operates abstract sequence different node type correspond ball bin vbp problem user also encode action heuristic optimal make term relationship different sequence node edge connect rule govern flow traverse one node next analyze specific instance vbp problem, user input number ball bin plain concretizes encoding show concretized example one dimensional ball bin dsl allows model example prior work model dp split, source, sink node use pick node limited capacity allow ball assigned single bin model ff prove represent linear mixed integer problem small set node behavior abstraction sufficient app easily compile node behavior efficient optimization encoding allows solve optimization faster compared hand coded optimization dsl allows find redundant constraint variable this, turn, reduces number variable constraint metaopt add writes implemented complete dsl linq torgersen, style language compared original metaopt implementation, compiled dsl analyzes dp example faster metaopt write ff, provide run time gain case open question describe heuristic metaopt analyze dsl support analyzer eg, goel et al, may need change compiler add node behavior also need understand metadata user provide enable plain may require co design plain component although proved mixed integer program mapped dsl app mean mapping efficient representation heuristic dsl may achieve better performance model heuristic directly dsl need research formalize guide user optimize representation random search cannot find adversarial subspace may even find adversarial point namyar et al, propose algorithm extrapolate heuristic analyzer output use analyzer find adversarial example find adversarial subspace around example exclude subspace repeat longer find adversarial example heuristic significantly underperforms outside subspace found far find adversarial subspace, first find rough candidate region sample cubic area around initial adversarial point given heuristic analyzer expand sampling area based density adversarial bad sample find direction define direction based sub cube slice lie respect initial adversarial point metaopt found stop density bad sample drop possible expansion direction go slice slice investigate cubic region around initial bad sample adversarial subspace may uniformly spread around initial point extend sampling region around slice density bad sample high pick number sample use based dkw inequality massart, subspace boundary far exact big pick slice much expand iteration influence many false positive fall subspace refine subspace based idea prior work diagnosis chen et al, train regression tree predicts performance gap sample rough subspace predicate form path start root tree reach leaf contains initial bad sample accurately describe subspace adversarial subspace significance checker ensures subspace find statistically significant point subspace cause higher performance gap compared immediately outside report subspace low value le adversarial use wilcoxon signed rank test wilcoxon, allows dependant sample subspace fully describes point inside point sample two pool dependent find subspace dp vbp value respectively approach allows find statistically significant subspace meet exploration granularity include adversarial input subspace outside region explored analyzer find next iteration user control plain ability find adversarial scenario use smaller cube size explore space detail come cost slower runtime also elect include part initial subspace plain find apply decision tree part metaopt decision space need include number time willing examine area avoid infinite cycle may region statistically significant plain would revisit contain input instance produce high gap open question decision tree help identify predicate form feature threshold describe subspace feature train tree influence predicate get small instance use raw input larger instance would require deep decision tree fully describe space output becomes computationally difficult use next step step need define function input allow describe subspace efficiently use analyzer execute step ie, exclude subspace run analyzer may better apply adversarial subspace generator step directly projected input space function describes one dimension dimensional space note, need dimension input space space defined adversarial subspace sparse approach may allow find adversarial subspace efficiently may need additional mechanism help scale plain may take long time find adversarial subspace analyze large problem instance many disjoint subspace hypothesize input contiguous subspace share root cause cause heuristic underperform network flow based dsl explicitly encoding decision heuristic benchmark algorithm prof useful run sample within contiguous subspace dsl score edge based benchmark heuristic send flow edge score benchmark sends flow score heuristic sends flow score heatmap difference benchmark heuristic show input subspace interfere heuristic given subspace samples, pinnable demand share shortest path red arrow path optimal route alternative path blue arrow path open question instance size scale problem want analyze grows, heatmap may become harder interpret need mechanism allow summarize information heatmap way user interpret use improve heuristic heuristic benchmark also differ much flow route edge need define appropriate data structure represent information user interpretable actionable enable operator improve heuristic know apply mitigation extrapolate type explanation form type property adversarial input cause heuristic underperform aspect problem instance exacerbate need find trend across instance based information find instance agnostic explanation heuristic underperformed discover patterns, need consider diverse set instance identify trend output subspace generator explainer build instance generator problem description dsl create instance feed pipeline imagine generalizer would contain grammar metadata user provides dsl along network flow structure describe trend instance based explanation example, one may consider predicate hypothetical grammar grammar, generalizer go observation sample instance generator produced check predicate grammar statistically significant example, describes set shortest path pinnable demand dp, generalizer might produce increasing dp underperforms predicate suggests gap larger shortest path pinnable demand longer open question one may envision solution similar enumerative synthesis gulwani et al, alur et al, huang et al, search grammar, find predicate hold particular heuristic, form clause explain heuristic behavior need work define generalizer grammar build valid clause knowledge, first work focus general framework provide insight output heuristic analysis tool namyar et al, goel et al, provides explainability feature tool build prior work domain customized performance analyzer work plain also applies custom performance analyzers, apply specific heuristic arun et al, arashloo et al, arun et al, explainable ai plain resembles prior work explainable ai, provided context around different ml model predict ribeiro et al, lundberg lee, wachter et al, part solution including three type inspired work amershi et al, arzani et al, phillips et al, enumerative synthesis field generates program meet specification systematic enumeration possible program candidate gulwani et al, alur et al, huang et al, believe idea help design generalizer large language model llm may able use llm yan et al, various part design include generate dsl, summarize type explanations, generate grammer need produce type explanation llm prone hallucination huang et al, liu et al, also require additional step step mechanism guide wang et al, kambhampati et al, may able build natural language interface help automatically generate dsl interface enable non expert easily use plain this, too, interesting topic future work would like thank basmira nushi, ishai menache, konstantina mellou, luke marshall, amin khodaverdian, chenning li, joe chandler, weiyang wang valuable comment also hotnets program committee valuable feedback prove model linear optimization plain preliminary network flow based dsl directed graph denote set node set directed edge treat edge variable non negative flow value impose constraint flow variable needed define incoming edge node edge directed towards ie, outgoing edge exiting incoming outgoing traffic node sum flow arrives node incoming outgoing edge following node behavior split node split incoming traffic outgoing edge enforce traditional flow conservation constraint also optionally enforce upper bound traffic outgoing edge capacity constraint traffic incoming edge constant pick node satisfy flow conservation allow one outgoing edge carry traffic indicator function otherwise multiply node one incoming one outgoing link multiply incoming traffic constant sending satisfy flow conservation equal node require incoming outgoing edge carry amount traffic make simpler encode heuristic dsl, also add following node type dsl copy node copy total incoming flow outgoing edge recreate node behavior combine split node equal node fig however, using copy node directly intuitive straightforward users, include dsl reason use source sink node define objective source node special case split pick node represent input problem example, illustrates input traffic demand modeled source node enforce split node behavior also, show input ball size source node pick node behavior ball placed one bin sink node specific node incoming edge measure performance problem total incoming traffic edge dsl represents optimization problem, sink node designated objective, compiler translates value sink node optimization objective model linear optimization linear programming mixed integer linear programming flow network using six node behavior optimization problem maximizes minimizes objective subject input fall within feasible space optimization constraint characterize express linear optimization problem linear programming mixed integer linear programming show dsl complete, need show capture feasible space objective correctly flow model every possible linear optimization first present general algorithm express feasible space given linear optimization flow model prove correct next, show use algorithm express linear objective represent feasible space flow model express feasible space linear optimization denote matrix vector bold vector continuous binary variable size respectively constant vector size constant matrix size respectively note enforce equality constraint two inequality constraint eq represent integer variable sum multiple binary variable map variable flow model need transform optimization model node behavior transformation matrix vector may contain negative entry conflict non negativity requirement flow flow model address this, decompose matrix vector positive negative component element non negative one non zero every note hold every matrix size originating matrix substituting decomposition eq transformation eq split node qualitatively represent similar behavior split node split incoming traffic across outgoing edge ensure traffic edge exceed capacity constraint ideally, enforce eq constraint using split node flow conservation constraint problem eq also involves coefficient associated variable split node accept weight address replacing term coefficient multiplied variable eq constraint auxiliary variable define express eq term auxiliary variable vector element equal size respectively auxiliary variable appear exactly one inequality constraint transformation encounter problem enforce constraint eq using multiply node multiply node one input one output edge edge also corresponds one variable mean variable appear two constraints, corresponding two node two end edge however, variable eq appear twice example, appear time address introducing additional variable constraint modifications, variable appears exactly two constraint final resulting optimization transformation equation above, notation mean possible value considered according specific constraint condition given equation constructing flow model encode constraint using flow model first create one edge per variable enforce constraint using one node encode eq using split node node possible input node one edge per variable left hand side constraint one edge constant rate one additional edge associated output one edge per variable right hand side constraint one additional edge constant rate fig show encoding done express eq using multiply node edge originate split node multiply node edge opposite direction so, node model eq input edge output edge conversely, input edge output edge eq hold fig show step model eq using equal node note fixed since one non zero, equation eq eq needed hold eq eq consequently, needed eq hold eq input edge output edge fig illustrates step input variable variable represent binary variable eq using pick node one incoming edge constant rate two outgoing edge one output corresponds binary variable node selects specific edge carry flow, binary variable otherwise, eq inherently satisfied flow non negative flow model provably capture optimization feasible space one one correspondence constraint optimization constraint enforced node capture optimization objective express objective linear optimization max constant vector reformulate add constraint enforces objective optimization change maximizing then, use similar transformations, explained before, capture constraint within flow model add sink node one incoming edge way, express linear optimization objective model",networking and internet architecture
"solution sustainable resilient communication infrastructure disaster relief management scenario introduction ii background global picture iii energy communication technology enablers iv pre disaster communication energy planning warning disaster response communication energy planning vi post disaster communication energy planning, rescue evacuation vii existing vendor product service viii standardization project ix case study turkiye earthquake open issues, challenge future direction xi conclusion instruction reporting error related survey review comparing survey related survey contribution organization iii communication enablers iii energy enablers iv technology enablers communication pre disaster scenario iv technology enablers energy support pre disaster scenario iv lesson learnt recommendation technology enablers communication disaster response scenario technology enablers energy support disaster response scenario lesson learnt recommendation vi technology enablers communication post disaster scenario vi technology enablers energy support post disaster scenario vi lesson learnt recommendation ix reason network failure ix response network operator ix evaluation lesson learned open issue challenge realizing resilient sustainable infrastructure future direction natural disaster become frequent severe, ensuring resilient communication infrastructure paramount importance effective disaster response recovery disaster resilient infrastructure also respond sustainability goal providing energy efficient economically feasible network accessible everyone end, paper provides comprehensive exploration technological solution strategy necessary build maintain resilient communication network withstand quickly recover disaster scenario paper start survey existing literature related review establish solid foundation, followed overview global landscape disaster communication power supply management introduce key enablers communication energy resource technology support communication infrastructure, examining emerging trend improve resilience system pre disaster planning emphasized critical phase proactive communication energy supply strategy significantly mitigate impact disaster also explore essential technology disaster response, focusing real time communication energy solution support rapid deployment coordination time crisis paper present post disaster communication energy management planning effective rescue evacuation operation main finding derived comprehensive survey also summarized disaster phase followed analysis existing vendor product service well standardization effort ongoing project contribute development resilient infrastructure detailed case study turkiye earthquake presented illustrate practical application technology strategy finally, address open issue challenge realizing sustainable resilient communication infrastructure provide insight future research direction incorporating lesson learned various disaster scenarios, paper present strategic recommendation enhance resilience adaptability communication system context disaster relief management major natural disaster public safety incident significantly disrupt communication network infrastructure aftermath major disasters, earthquake storms, primary telecommunication infrastructure public infrastructures, power sources, often severely damaged completely destroyed result unavailability cellular network internet connectivity telecommunication infrastructure crucial basic life need like shelter, food, clean water disaster without reliable uninterrupted communication channel, challenging coordinate rescue operation find affected also crucial organize provide basic life need rescued people therefore, discontinuity communication severely restrict central controlling authority obtaining timely information, critical ensuring coordination rescue teams, quickly transmitting vital information, responding call help disaster area example, two significant earthquakes, magnitude turkiye february hundred cellular tower damaged resulted lack cellular internet connectivity city reason, crucial critical communication preserved efficient temporary communication infrastructure disaster area conventional communication infrastructure restored temporary network help connect various stakeholders, including volunteer rescue relief teams, enabling exchange information seamlessly timely manner help facilitate effective well coordinated rescue, relief, recovery effort context, public protection disaster relief ppdr agency exploring reliable wireless communication system ensure public safety sector, efficient coordination first responder necessary support affected region reducing likelihood casualty economic damage affected area ppdr communication system primarily rely private professional mobile radio pmr technologies, offer comprehensive range voice service tailored specific need ppdr systems, push talk call priority therefore, data transmission capability comparatively limited lag behind current telecommunication technology initial effort aimed improving communication capability ppdr agency introduction fourth generation technology go beyond capability pmr system emergence rd generation partnership project gpp release originally fifth generation seen crucial standard, encompassing broader range functionality although user access broadband voice, data, video capabilities, including support mission critical services, key limitation interoperability different technology hinder time critical emergency management robust secure ppdr network therefore still required emergency management involves coordination various function deal major emergencies, including prevention, preparedness, response, rehabilitation emergencies, coordination different function crucial law enforcement focus prevention, investigation, apprehension individual suspected convicted criminal offense emergency medical service em provide critical care, transportation, disaster medicine, involving professional doctors, paramedics, volunteer firefighting deal extinguishing hazardous fire threaten people property protection environment involves safeguarding ecosystem monitoring intervention organization forest guard volunteer search rescue aim find missing person bring safety, often carried organization like firefighter em border security, carried police specialized guard services, focus controlling border ensure security economic well overall, emergency management centralizes command control public safety agency emergency realize function within ppdr services, real time access information via broadband connection critical open door variety data centric, multimedia application greatly enhance capability communication emergency scenario white paper proposes next generation disaster data infrastructure successfully collect, process, display disaster data reducing impact natural hazard data collection play crucial role proposed solution time, data collection completed mobile network therefore, uninterrupted connectivity required however, likely affected disaster strike hand, mobile network technology require energy source operate also prone disaster strike united nation un aiming reach net zero co emission energy consumption radio access network ran component base station data centers, powered mainly non renewable sources, pose significant challenge sustainability effort transitioning green energy model powering ran infrastructure energy efficient solution crucial reducing carbon footprint ensuring next generation communication system align global sustainability goal paramount since information communication technology ict sector expected account percent global energy consumption hence, green energy technology integrated communication architecture considered development disaster resistant communication system order emphasize importance communication energy issue disaster scenarios, many survey paper presented section, brief summary explained understand gap literature filled survey paper network solution different phase disaster examined approach network vulnerability assessment strategy enhancing robustness existing network, solution achieving resilient routing, including disaster aware routing, presented hybrid communication network architecture combine ground, air, space level examined emergency communication scenarios, also challenge hybrid network discussed detailed survey design choice current status major wireless based emergency response system proposed literature examined, comprehensive comparison wireless based emergency response technology based various consideration including bandwidth, range, throughput performed concept called network box ie, network characterized low number physical device presented network designed provide demand connectivity rescue operator survivor disaster scenario support soldier battlefield mobile ad hoc network manet technology, established temporarily disaster stricken areas, studied different routing protocol systematic review study focused recent technology emergency communication system also presented widely used communication technology applied setting emergency communication network mitigate disaster aftermath examined author presented detailed survey paper post disaster communication mentioned wireless technology physical network layer issue proposed use case scenario work wireless technology classified three topic recovery terrestrial networks, installation aerial networks, using space satellite network physical layer issues, related work evaluated term channel modeling, coverage, capacity, radio resource management, localization, energy efficiency moreover, existing literature classified discussed term routing, delay tolerant networks, edge computing, integrated space air ground architecture network layer issue extensive research emergency communication technology, including satellite networks, ad hoc networks, cellular networks, wireless private network also presented network currently used emergency rescue future development direction emergency communication network also analyzed technological advancement like remote sensing, satellite imaging, social medium analyzed opportunity challenge different phase natural disaster internet thing iot solution field early warning natural disaster described detail discussed unmanned aerial vehicle uav utilized various task assessing extent damage, identifying affected areas, aiding search rescue mission natural disaster additionally, importance integrating uav wireless sensor network enhance data collection communication capability disaster stricken area emphasized importance uav based solution possible challenge disaster management discussed deeply systematic review focus uav path planning problem emergency situation also given public safety network psns crucial public protection disaster relief, reviewed different technology regulatory standardization issue psns reviewed potential device device communication dynamic wireless network dwns psns analyzed addition, progress standardization dwn public safety communication investigated psns also examined detail long term evolution lte technology respectively advantage uav different areas, including public safety, summarized importance iot technology disaster management system public safety communication highlighted disaster management issue integrated novel concept artificial intelligence ai machine learning ml blockchain also analyzed detail different survey systematic review conducted ai application analyze process social medium big data efficient disaster management overview current application ai disaster management mitigation, preparedness, response, recovery phase provided ml algorithm combined technology address disaster pandemic management examined detail survey integration blockchain aerial communication disaster management provided literature provided present communication solution disaster management however, sustainable eg, supported green energy resources, accessible everyone, economically feasible communication infrastructure withstand challenge disaster also must infrastructure resilient damage, easy repair, energy efficient also affordable accessible potential application recommendation renewable energy source sector discussed paper focus essential energy management approach improve energy efficiency well reduce fuel consumption grid cellular network whose powered hybrid power source including solar photovoltaic pv system diesel generator dg paper proposes new approach configure operate provide ancillary service smart grid depending various system parameter lte, simulation based feasibility analysis hybrid optimization model electric renewables homer used evaluate optimal system, energy production, total net present cost npc cost electricity coe greenhouse gas ghg emission considers cellular system fed renewable grid energy source author provide critical review current resilience definition metric examine widely used approach various organization researcher author review power system resilience term generation, networks, load also discus resilience enhancement strategy involving distributed generation, conventional renewable generators, energy storage, microgrids, load shifting, demand response importance addressing power system resilience standard resilience definition discussed author also review benefit smart microgrids enhancing system resilience demonstrate effectiveness numerical simulation case study author explore resilience framework metric analyzing damage cost risk associated extreme event moreover, examine case study network risk estimation effectiveness resilience improvement technique enhancing grid resilience comparative analysis survey relevant survey presented table indicated defined focused three main topic making comparison disaster phase pre, in, post key contribution energy, communication network structure space, air, ground, sea many devastating disaster series earthquake rkiye revealed importance considering communication energy solution together build resilient sustainable infrastructure earthquakes, communication disrupted even area communication infrastructure remained functional could used due power outage previous literature contains certain study concentrated communication solutions, others concentrated energy solutions, addressing aspect separately compared studies, best knowledge, study first one consider communication energy supply solution jointly different point view, survey focus integrated network model cover ground, air, space sea level contrary many existing survey literature integrated network model vital disaster management provides complete view situation combining information satellites, planes, ground sensors, sea source system offer real time data, improving accuracy damage assessment response planning also enables smooth communication coordination among different organization stakeholder unified data platform utilizing various data sources, integrated network model help risks, respond emergency effectively, allocate resource efficiently overall, integrated network strengthens disaster resilience improves management immediate long term impact another feature set article apart others communication energy technology examined detail phase disaster individually many publications, distinction thoroughly considered several emerging technology integrated disaster management enhance effectiveness across stage life cycle however, existing survey tend focus either communication technology energy solution isolation, missing critical integration enablers paper discus prospective solution sustainable communication infrastructure disaster relief management scenario key issue addressed paper follows paper identifies evaluates emerging key technology enhance communication network pre disaster, disaster, post disaster phase specifically examines technology effectively deployed support disaster relief management, emphasizing role maintaining communication continuity paper underscore critical importance developing robust resilient communication network withstand impact disasters, particularly scenario like turkiye earthquake highlight necessity integrating energy requirement sustainability resiliency, ensuring communication infrastructure remain operational even challenging condition paper explores main advantage emerging communication technologies, uav s, high altitude platform station hap mesh networks, satellite communication, bring disaster relief scenario compared traditional network discus technology enhance efficiency, speed, reliability communication emergencies, thereby improving overall disaster response effort paper address limitation existing new communication technology disaster relief management scenario evaluates challenge implementing technologies, including energy constraints, deployment difficulties, need continuous innovation overcome barrier paper review progress made constructing robust communication infrastructure support disaster scenarios, particular focus energy sustainability resiliency highlight case studies, including turkiye earthquakes, demonstrate infrastructure tested improved real world situations, ensuring enhanced preparedness response capability structure paper schematically displayed fig section ii provides comprehensive background global perspective current state disaster communication energy management section iii discus key enablers communication energy technologies, focusing emerging trend enhance resilience section iv address pre disaster communication energy planning, emphasizing importance proactive strategy mitigating disaster impact section provides detailed exploration technology enablers disaster response phase, including real time communication energy solution support rapid deployment coordination section vi cover post disaster communication planning, focusing rescue evacuation efforts, technology support critical operation section vii examines existing vendor product service section viii provides standardization efforts, ongoing project contribute building resilient infrastructure case study turkiye earthquake presented illustrate practical application discussed technology strategy section ix section paper discus open issues, challenge future direction realization sustainable resilient communication infrastructures, finally, section xi give conclusion paper disaster management life cycle consists pre disaster mitigation preparedness response, post disaster recovery activity phase play critical role mitigating effect disaster facilitating effective recovery detailed explanation phase given follows pre disaster phase pre disaster phase focus activity aimed mitigating effect disaster preparing occurrence phase includes mitigation mitigation involves identifying implementing measure reduce vulnerability community infrastructure disaster may include land use planning, building code regulations, infrastructure improvements, public awareness campaign preparedness preparedness activity include developing plans, procedures, resource respond effectively disaster includes developing emergency plans, conducting exercises, building communication networks, training emergency personnel goal pre disaster phase minimize potential damage loss life proactive well prepared disaster strike response phase response phase take place immediately disaster focus immediate action taken save lives, protect property, meet basic need affected people key element response phase include emergency warning communication rapid accurate communication critical response phase includes issuing early warnings, activating emergency alert systems, establishing communication channel emergency responder affected community search rescue search rescue operation carried find rescue people may trapped immediate danger includes coordination emergency team specialized equipment technique locate rescue survivor emergency shelter relief providing emergency shelter, food, water, medical assistance, essential affected people important aspect response phase emergency shelter distribution center set meet immediate need people affected disaster post disaster recovery phase post disaster recovery phase focus recovery reconstruction disaster affected community post disaster recovery phase aim build stronger resilient community incorporate lesson learned disaster reduce future vulnerability phase includes damage assessment assessing extent damage infrastructure, buildings, environment essential planning reconstruction process includes conducting structural assessments, evaluating damage critical facilities, identifying area require immediate attention infrastructure restoration repairing rebuilding damaged infrastructure roads, bridges, utilities, communication network important part reconstruction phase ensure restoration essential service facilitate return normalcy rehabilitation community recovery phase also includes helping affected community rebuild life includes psycho social support, facilitating access medical care education, assisting restoration livelihood overall, disaster management life cycle described encompasses comprehensive approach addressing challenge posed disaster focusing mitigation, preparedness, response, recovery, agency community work together minimize impact disaster improve resilience current terrestrial mobile network infrastructure inherently vulnerable disaster prone failure interruption event therefore, resilient mobile network structure needed cope natural disasters, becoming frequent due climate change hand, also meet un sustainability goals, least sense becoming cost energy effective operational point view, infrastructure also scalable easy deploy infrastructure redundancy one way ensure sustained operation even infrastructure layer severely damaged fig show multi layered communication infrastructure consisting integrated space based, air based, sea based, ground based networks, interconnected create comprehensive resilient communication system, especially disaster scenario traditional infrastructure may compromised space based network comprises geostationary earth orbit geo medium earth orbit meo low earth orbit leo satellite form mesh network global communication coverage satellite interconnected via cross network link communicate air based network via dedicated downlinks air based network represented hap uavs, act intermediary point space based hap ground based infrastructure hap stationed stratosphere connect uavs aircrafts, forming dynamic network layer provides communication service large areas, including disaster affected area sea based network consists maritime platform ship equipped communication capability platform connected air based network ground stations, facilitating seamless communication ocean large water body ground based network consists various element bss, gateways, autonomous vehicles, smart device component interconnected via network connection facilitate communication within ground network figure also show ground based network connected layer via inter network link ensures network layer work together provide continuous reliable communication various environment satellite network play crucial role disaster response communication planning, particularly context earthquakes, due wide coverage, resilience, ability provide connectivity geographically remote damaged area operate independently terrestrial networks, providing reliable resilient communication infrastructure support emergency response effort remote hard reach area used establish temporary communication infrastructure disaster prone area example, satellite based mobile network deployed provide connectivity emergency responder local community aftermath disaster, terrestrial network may damaged non functional satellite network offer wide area coverage, allowing communication reach even remote inaccessible region affected earthquake provide connectivity disaster response teams, emergency personnel, affected communities, facilitating real time communication, coordination, information exchange large geographical area rescue teams, government agencies, relief organization use satellite connectivity share vital information, coordinate resources, efficiently manage rescue relief operation satellite equipped remote sensing capability provide valuable data disaster response planning decision making capture high resolution imagery, monitor ground movements, create accurate map affected area information aid identifying critical infrastructure damage, assessing extent disaster, guiding resource allocation deployment regarding early warning systems, satellite imagery remote sensing technology used monitor natural hazard enabling early warning better preparedness pre disaster phase, satellite network used establish communication channel emergency responders, local communities, stakeholder network provide connectivity remote hard reach areas, terrestrial network may available may unreliable satellite network also used support exchange critical information, maps, images, video feed emergency responder command center also used support warning dissemination critical information local community example, satellite based warning system used alert people disaster prone area impending natural disaster emergency warning system used deliver text messages, voice messages, form communication people remote hard reach area another use satellite network pre disaster communication planning support situational awareness information sharing among emergency responder satellite network provide real time information extent damage, location survivors, critical information used support emergency response effort although satellite communication offer significant benefits, satellite link susceptible rain atmospheric conditions, disrupt communication storm hurricane additionally, latency communication pose limitation space service specialized equipment often required satellite communication, might easily accessible emergency air based network incorporate innovative technology like haps, tethered balloons, uav haps, particular, hold significant potential enhancing resilience integrated space air ground sea network natural disaster earthquake hap offer several advantage expansive surface area enables almost self sufficient energy generation solar panel single hap serve substitute multiple damaged terrestrial bs, providing extensive coverage essentially, single hap function multi sector directional bs, establishing direct line sight los connection outdoor users, compensating distance related path loss scattering loss without need additional intermediate device like relays, unlike satellite starlink leo constellation, limited los window unlike satellites, hap remain stationary, ensuring stable continuous service without orbital movements, thus facilitating rapid deployment, especially crucial immediate aftermath earthquake ground access affected area challenging hap serf vital alternative ran infrastructure also backhaul efficiently redirect backhaul traffic unaffected area via free space optic fso terahertz thz communication link remote hap ground station additionally, earthquakes, fiber optic line may sustain damage, rendering inactive, hap remain physically unaffected weather event mentioned hap expected function stratospheric climate condition moreover, according international telecommunication union itu decision world radiocommunication conference wrc sub ghz frequency band band allocated high altitude international mobile telecommunication base station hibs compared ka ku band used satellites, band relatively le affected weather event way, uninterrupted service delivery ensured tethered balloon based emergency network system balloon deploy wireless communication network disaster area used wide range communication service including voice, data, video comparatively inexpensive scaled meet need different disaster scenario fully wireless communication solution relying tethered balloon deployed immediately, reliably, easily during, even disaster proposed tethered balloon already used number disaster scenarios, including puerto rico peru disaster respectively uav usage aerial monitoring communication transmission earthquake zone innovative approach gained popularity recent year used establish temporary communication infrastructure disaster prone area example, uavs equipped wireless communication equipment deployed create ad hoc network extend range existing networks, providing connectivity emergency responder local community uavs also equipped thermal imaging camera locate people need assistance identify area high temperature, may indicate gas leak hazard uavs also used support situational awareness information sharing among emergency responder aerial assessment monitoring, drone equipped camera sensor provide real time information extent damage rapid aerial assessment disaster affected areas, location survivors, critical information used support emergency response search rescue effort one important application uavs disaster relief ability provide high resolution aerial imagery used damage infrastructure, identify area requiring search rescue, plan evacuation route hand, drone may difficulty massive packet loss handling enormous traffic used post disaster reconnaissance service area traditional communication network disrupted, uavs equipped communication equipment serve temporary solution act communication relay establish communication first responder affected community particularly useful mountainous remote area cell tower communication infrastructure may damaged order benefit uav full efficiency, problem energy supply trajectory design must overcome ground based network comprise diverse element cellular networks, terrestrial internet utilizes physical cable like fiber optic copper wire data transmission long distance mobile ad hoc network unlike air based networks, ground based network topology tends fixed le mobile natural disaster like hurricanes, earthquakes, floods, ground based communication infrastructure face significant risk severe damage complete destruction technology, offering decentralized resilient communication, effective approach address challenge ground based network disaster response scenario mostly useful scenario use grid power inaccessible, use battery power feasible used enhance communication capability improve coordination among responder affected individual aftermath earthquake, cellular network may congested disrupted, communication provide reliable mean communication responders, allowing share critical information, coordinate efforts, exchange update situation even absence infrastructure ad hoc network formed group mobile device communicate directly, without need centralized infrastructure cellular tower wireless fidelity wi fi access point eg, wireless mesh network wmn based ad hoc network support dissemination emergency alerts, location sharing, resource coordination, survivor tracking search rescue operations, rescuer equipped capable device establish direct communication survivors, allowing gather information location, status, immediate need wireless personal networks, bluetooth, long range lora wi fi technology used establish ad hoc network operate independently cellular network traditional communication infrastructure network established using personal device equipped wireless communication capability vehicular network used variety way disaster response scenario improve speed, efficiency, effectiveness emergency response traditional communication transportation infrastructure severely damaged disrupted first, used establish communication responder affected areas, especially area traditional communication infrastructure damaged overwhelmed second, facilitate transport relief supplies, medical personnel, resource affected area third, vehicle network used collect data road conditions, infrastructure damage, information used create map help responder navigate affected area fourth, vehicle network used coordinate search rescue efforts, especially hard reach area area traditional search rescue method impractical finally, used coordinate emergency response effort among various agency organization ensure resource used effectively efficiently sea based network crucial importance conventional communication infrastructure coastal region collapse disaster situation within network structure, various components, ship unmanned surface vehicles, enhance communication utilizing uavs, haps, satellite technologies, depending respective position expand coverage resilience, offering alternative routes, mitigating risk network congestion failure moreover, facilitate interoperability among diverse network type eg, naval vessels, aircraft, ground based command control center standard customizable protocols, facilitating seamless communication across different service agency emerging technology communication enablers integrated sensing communication isac technology offer significant utility earthquake disaster relief combining multiple sensing technology communication system provide real time, actionable data ground condition first, isac variety sensing method seismic sensors, radar, lidar light detection ranging wireless radio frequency sensing accelerate damage assessment post earthquake sensor used monitor structural integrity, ground movement change environment transmit data immediately via communication system rapid transfer information help prioritize recovery effort locate area require urgent action second, isac help locate survivor trapped debris using thermal imaging, sound vibration sensors, rf based motion detector detect movement, sign life, body heat vital data immediately relayed rescue team speed search rescue operation third, isac provides real time update location survivors, severity damage, progress relief effort made possible combination wireless sensor networks, drone surveillance, ground based radar, enabling informed decision making coordinated response finally, isac support seamless communication response team enabling exchange information real time secure communication links, optimizing resource allocation, streamlining relief effort integrated access backhaul iab technology used pre disaster scenario enhance resilience communication infrastructure ensure connectivity remains available disaster iab combine functionality wireless backhaul access networks, enabling wireless network use frequency band access backhaul allows easier deployment small cell wireless access points, well efficient use available spectrum pre disaster scenario, iab used provide enhanced connectivity critical infrastructure service hospitals, emergency services, government office technology also used establish network small cell wireless access point high risk areas, providing redundancy backup connectivity case emergency ai based solution also used address several problem pre disaster communication risk assessment predictive analytics, ai driven model analyze historical data, climate patterns, variable predict disaster risk specific region paper provides overview current application ai disaster management four phase mitigation, preparedness, response, recovery open ran emergent technology build open interface telecom operator build network mixing equipment multiple vendor vision create cost effective network new innovation enhanced competition modular nature useful disaster situation broken component rapidly replaced new component vendor instead waiting original vendor deliver exact copy broken component make telecom network compliant open ran well suited maintain connectivity facilitate emergency response recovery operation methodology deploying optimizing fl task ran deliver distributed intelligence application studied software defined networking sdn offer vital solution disaster situations, enhance network control, communication efficiency, overall stability survey disaster resilient sdn network presented hierarchical, failure disaster resilient transport software defined network sdn control plane designed, heuristic post failure switch controller reassignment proposed result indicate proposed scheme achieve much higher disaster failure resiliency, cost slightly larger network resource utilization geographical information system gi technology provide powerful tool visualizing, analyzing, interpreting data related disaster risks, vulnerabilities, resource gi help identify vulnerable area analyzing geographic demographic data, enabling better planning preparedness disasters, gi integrates real time data like weather report satellite imagery provide date situational awareness gi optimizes resource allocation identifying efficient route location aid distribution analyzing transportation network population density, gi help design effective evacuation route plan disasters, gi damage informs recovery effort mapping affected area identifying critical infrastructure gi tool also enhance public communication providing clear visual information risks, safety measures, recovery effort microgrids microgrids designed enhance reliability, resilience, efficiency electrical energy distribution, particularly remote area operate autonomously parallel main grid, ensuring uninterrupted electricity generation failure outage energy grid expected shift centralized energy production distributed localized model near future microgrid component include renewable energy source solar panel wind turbines, distributed generation units, energy storage systems, electric vehicle electric vehicle ev utility grid combining multiple energy source eg, solar, wind, diesel generator decentralized energy solutions, microgrids enhance reliability flexibility grid response disaster additionally, powering terrestrial communication system microgrid structure significantly reduce energy related issue disaster renewable energy source given increasing global concern climate change imperative reduce energy costs, especially grid areas, growing interest leveraging also play crucial role improving energy sustainability resilience within microgrids solar, wind, biomass, hydropower example provide clean, sustainable, decentralized power generation terrestrial networks, become focal point integrating res, solar wind power adopting renewable energy terrestrial network component offer numerous opportunity energy conservation, sustainability, resilience disaster battery energy storage system designed store energy renewable source utility grid high capacity battery system stored energy support system peak energy demand main grid meet energy need power outage play critical role communication network providing backup power outages, ensuring continuous operation essential communication infrastructure integration communication system energy storage system solution significant potential various applications, including mobile bss, data centers, emergency service communication, railway communication systems, maritime communication advanced future power management system reliable electrical power essential functioning modern infrastructure, powering homes, businesses, bss, smart grid advanced power grid system incorporates digital technology enhance efficiency, reliability, sustainability electrical energy production, distribution, consumption integrating distributed energy resource solar panels, wind turbines, besss, smart grid ensure continuous power supply critical communication infrastructure, even widespread outage smart grid automatically detect isolate faults, minimizing downtime maintaining service continuity also help conserve energy balance load demand response strategies, crucial emergency energy resource may limited implementing demand response strategies, energy usage adjusted based supply conditions, ensuring critical communication infrastructure remains powered backup generator power supply tool backup generator power supply tools, uninterrupted power supply ups essential ensuring communication system remain operational disaster system provide crucial layer redundancy supplying power main source disrupted, thus preventing critical communication infrastructure going offline ups system provide immediate, short term power outage, allowing seamless transition protecting sensitive equipment damage caused sudden power loss fluctuation hand, despite requiring fuel replenishment operate extended periods, backup generator offer longer term power solutions, ensuring sustained operation communication network prolonged outage tool vital maintaining emergency communication services, supporting coordination efforts, ensuring continuous flow information, crucial disaster response recovery integration reliable backup power system significantly enhances robustness dependability communication networks, enabling function effectively adverse condition energy efficient communication technology energy efficient technologies, low power communication device energy efficient network equipment, crucial ensuring sustainability resilience modern communication system low power communication device help extend battery life, critical situation energy limited, disaster remote grid area restricted intermittent power supply similarly, energy efficient network equipment improves overall efficiency communication infrastructure, allowing data transmitted using le energy enabling use produce le power traditional source save cost contributes sustainability reducing carbon footprint terrestrial communication network furthermore, disaster scenarios, energy efficient technology help maintain critical communication service extended period using backup power sources, thus improving resilience communication system approach energy harvesting significantly reduce energy consumption constraint mobile device disaster also important battery powered system uavs, support terrestrial communication extend coverage natural disasters, operate efficiently meet energy requirement finally, table ii show summary technology disaster response planning phase communication energy domain consider approach taken disaster occurs save guard network, communication energy perspective pre disaster communication planning warning system include various communication technology protocol fema provides disaster emergency communication geographically dispersed mobile emergency response support detachment pre positioned fleet mobile communication office vehicle common alerting protocol used enhance messaging disaster early warning communication system present emerging disruptive technology communication protocol employed internationally early warning communication system information communication tool internet, gis, remote sensing, satellite communication used disaster preparedness, warning, forecasting remote sensing technology enables collection environmental data distance, typically use satellite aircraft beneficial monitoring tracking natural disaster like hurricanes, wildfires, flood also valuable creating map model illustrate damage caused natural disasters, helping decision maker prioritize response effort allocate resource effectively requires proper tool like gi handle large amount data obtained remote sensing thus, remote sensing gi technology discussed different type natural disaster warning monitoring duty radar satellite imaging technology also vital tool monitoring managing natural disasters, provide critical data surface atmosphere earth author demonstrate research design mobile based decision support flood early warning system ad hoc network used pre disaster communication planning warning providing flexible dynamic communication infrastructure quickly deployed disaster prone area pre disaster phase, ad hoc network used create communication channel emergency responders, local communities, stakeholder network established using mobile device quick easy set emergency ad hoc network also used alert disseminate important information local community example, community member receive alert warning impending natural disaster emergency via mobile device another use ad hoc network pre disaster communication planning support situational awareness information sharing among emergency responder ad hoc network facilitate exchange real time information maps, image video emergency responder command center different ad hoc communication paradigm manet, vehicular ad hoc network vanet wmn, tetra, etc discussed detail disaster management scenario uavs, generally known drones, valuable tool pre disaster communication planning warning, providing versatile platform gathering disseminating critical information disaster prone area supporting emergency response effort one use uavs pre disaster communication planning conduct aerial survey disaster prone area identify potential hazard vulnerability survey used generate detailed map model terrain, well identify infrastructure, buildings, critical asset may risk disaster another use uavs pre disaster communication planning support warning disseminate important information local community uavs equipped loudspeaker audio visual device broadcast warning alert people disaster prone area uavs also used deliver essential supply first aid kit food water people remote hard reach area uav used data gathering tool iot device also platform energy transfer energy limited iot devices, distributed disaster area iot offer significant potential detection management natural disaster iot sensor deployed collect data monitor environmental factor temperature, humidity, air quality, seismic activity, providing early warning potential natural disaster data used detect anomaly may indicate presence natural hazards, earthquake data also used identify vulnerability risk critical infrastructure, bridges, dams, power plants, support situational awareness hazard identification wireless sensor network wsn used environmental monitoring iot device sensor collect data environmental condition real time, critical early warning system situational awareness iot wsn used pre disaster communication planning warning providing real time data analytics used support situational awareness, hazard identification, early warning systems, particularly critical infrastructure gas oil refinery iot network also used support situational awareness information sharing among emergency responder iot based sensor provide real time information extent damage, location survivors, critical information used support emergency response effort distributing many iot devices, usually heterogeneous, communication protocol data formats, large scale disaster may face challenge manage diversity iot device applications, gateway required connect traditional communication network iot domain however, gateway typically centralized, making impractical use manet environment often encountered large scale disaster thus, distributed network function virtualization nfv sdn based iot gateway architecture presented ai, particularly ml deep learning, demonstrated significant advantage risk mitigation, assessing vulnerability urban area seismic hazards, evaluating site suitability, enhancing early warning systems, managing natural disaster existing literature paper focus supporting mission critical application emergency scenario enhancing network adaptability intelligence ai ml algorithm envisioned edge network analyze data make real time decision addition, cognitive radio technology dynamically allocate spectrum resource based network condition demand application digital twin emergency management civil infrastructure emci surveyed author use digital twin model simulate predict impact disaster urban infrastructure basically combine ai iot technology real time monitoring decision making data driven approach also employed enhance disaster preparedness response social medium platform serve three critical role disaster quickly gathering situational awareness information, ii facilitating self organized peer peer help, iii allowing disaster management agency hear public disaster, social medium leveraged pinpoint area people need assistance search rescue, medical aid, access food water additionally, social medium serf vital tool disseminating information coordinating relief effort need moreover, training simulation, augmented reality ar virtual reality vr technology used train responder simulated disaster scenario improve readiness real world situation technology enablers energy support pre disaster scenario refer use various technological solution ensure availability resilience energy system disaster occurs enablers aim improve energy infrastructure, increase energy generation storage capabilities, strengthen overall resilience energy supply potential disaster play crucial role advancing sustainability terrestrial communication system communication system consume approximately four time energy system implementation technology massive multiple input multiple output mimo radio frequency rf chain electronic components, result rising trend power consumption even energy efficiency also improves since data capacity increase faster power demand energy intensive communication infrastructure continues grow, integrating offer pathway significantly reduce system carbon footprint study explores incorporating cellular system affect overall power consumption, revealing annual power saving surpassed system relied solely conventional energy grid study investigates sustainable energy solution bss, incorporating reduce energy consumption carbon emission integrating terrestrial communication system support sustainability goals, enhances energy security, reduces operational cost time moreover, contribute resilience communication system providing decentralized diversified energy supply, particularly critical remote grid area traditional power source may unreliable unavailable integrating solar wind, communication infrastructure significantly reduce carbon footprint, contributing environmental sustainability study examines model evaluates energy performance grid, eco friendly cellular bs, incorporating solar power system, system, hydrogen energy storage study investigates relati",networking and internet architecture
"binary code similarity detection via graph contrastive learning intermediate representation introduction related work irbindiff experimental setup experimental result conclusion ethical consideration appendix data pre processing sumpplements appendix language model pre training sumpplements appendix dataset statistic appendix one many search supplement instruction reporting error binary code similarity detection bcsd llvm ir data pre processing language model pre training graph momentum contrastive learning similarity detection datasets baseline metric implementation one one comparison one many search ablation study extract control flow graph sumpplements instruction simplification sumpplements binary code similarity detection bcsd play crucial role numerous fields, including vulnerability detection, malware analysis, code reuse identification iot device proliferate rapidly evolve, highly heterogeneous hardware architecture complex compilation settings, coupled demand large scale function retrieval practical applications, put forward higher requirement bcsd method paper, propose irbindiff, mitigates compilation difference leveraging llvm ir higher level semantic abstraction, integrates pre trained language model graph neural network capture semantic structural information different perspective introducing momentum contrastive learning, effectively enhances retrieval capability large scale candidate function sets, distinguishing subtle function similarity difference extensive experiments, conducted varied compilation settings, demonstrate irbindiff outperforms leading bcsd method one one comparison one many search scenario binary code similarity detection via graph contrastive learning intermediate representation binary code similarity detection bcsd aim determine whether two binary code snippet similar functional semantics, hold significant importance various domain vulnerability detection david et al malware analysis nguyen hung et al software supply chain analysis basit jarzabek etc particularly, explosive growth iot device statista high heterogeneity hardware architecture software platform across different device led increase diversity complexity binary files, thus posing higher demand bcsd technique recent years, advancement natural language processing technologies, deep learning driven bcsd method gradually emerged du et al haq caballero typically embed binary code assembly form high dimensional vector space evaluate functional similarity code snippet calculating vector similarity instance, vulseeker gao et al gemini xu et al ordermatters leverage graph embedding technique encode control flow graph binary code vectors, capturing control flow data dependencies, asm vec ding et al safe massarelli et al palmtree li et al employ language model directly learn representation instruction sequences, capturing instruction order contextual semantics although method shown significant potential capturing syntactic semantic feature binary code, still face challenge complex diverse practical application scenario complex compilation option iot device firmware typically based different architecture us various compiler optimization options, resulting binary may appear entirely different form, even compiled codebase, shown example figure therefore, bcsd method must robust complex compilation setting large scale candidate function retrieval real world large scale firmware analysis, often necessary retrieve similar function vast number unrelated function requires bcsd method ability capture subtle semantic difference large scale datasets paper, present irbindiff, novel intermediate representation based graph contrastive learning method, aim address aforementioned challenge support real world binary code similarity detection firstly, lifting binary file llvm ir, flexible architecture independent intermediate representation, effectively mitigate discrepancy caused underlying hardware compilation option barchi et al llvm ir provides unified high level semantic abstraction machine code, making ideal choice handling complex compilation settings, thereby enabling model apply highly heterogeneous scenario iot device firmware secondly, irbindiff combine pre trained language model graph neural network extract functional feature semantic structural aspect pre trained language model capture semantic syntactic pattern serialized representation simplified normalized llvm ir instructions, graph neural network encodes extracted control flow graph, capturing structural information dependency within function finally, introduce momentum contrastive learning enhance model retrieval capability large scale candidate function maintaining dynamic queue large number negative samples, model learn diverse set negatives, effectively distinguishing semantically similar function unrelated one additionally, momentum update mechanism gradually adjusts parameter key encoder, ensuring stability throughout training process contribution summarized follows comprehensive pipeline construct comprehensive pipeline lift binary code llvm ir address challenge posed complex compilation options, extracting optimizing syntactic structure semantic information innovative methodology introduce irbindiff, combine pre trained language model graph neural network deeply learn functional feature llvm ir semantic structural levels, respectively, utilizes momentum contrastive learning enhance ability capture subtle difference large set candidate function effective experimental conduct extensive experiment across various compilation options, demonstrating irbindiff outperforms baseline one one comparison one many search scenario traditional bcsd method often rely raw bytecode manually crafted rule assess code similarity example, diff liu et al us raw binary byte input siamese network based convolutional neural network compute similarity however, fails capture program unique logic functional feature method like discovre eschweiler et al binfinder qasem et al extract statistical feature function, constant strings, similarity detection, gemini xu et al vulseeker gao et al use hand crafted feature represent basic block apply graph embedding technique function level similarity however, feature based approach overly rely domain expertise struggle generalize diverse application recently, inspired natural language processing techniques, representation learning based bcsd method gradually become mainstream innereye zuo et al safe massarelli et al treat assembly instruction word use word vec mikolov model representation, asm vec ding et al palmtree li et al take finer grained approach treating instruction sentence opcodes operand words, leveraging sequence language model paper, adopt representation learning approach, focusing instruction sequence control flow structure llvm ir typical, well formatted universal intermediate representation compilation process, bridge source code machine code, provide common optimization platform multiple high level language compiler backends lattner adve compared directly handling assembly code, llvm ir offer higher level semantic abstraction, allowing binary different architecture compilation setting lifted unified representation additionally, good readability standardized syntax enable model accurately extract core semantics specific example llvm ir shown appendix section elucidates rationale architecture designed method irbindiff, consists four parts, illustrated figure lifting binary llvm ir binary files, use reverse engineering tool retdec oustek et al decompilation, call bin llvmir lift binary llvm ir format, obtaining file extension extract control flow graph previous work xu et al gao et al ding et al shown structural information binary code, control flow graph cfg provides crucial semantic insight similarity detection end, employ regular expression matching parse llvm ir files, performing function boundary division, basic block division, cfg extraction detailed process explained appendix so, represent function llvm ir graph, node represent basic block edge represent control flow relationship block instruction simplification instruction sequence llvm ir contain many instruction unrelated function semantics, introduce additional computational overhead also dilute importance key instructions, thereby impairing embedding performance address this, empirically devise instruction simplification strategy, pruning redundant instruction preserving essential one approach, detailed appendix enables language model extract precise semantic information function instruction tokenization normalization ir instruction relatively complex internal structures, fully understanding internal detail crucial representing instruction therefore, instead treating entire instruction single word, apply fine grained tokenization strategy, regarding instruction sentence token word specifically, split instruction based spaces, punctuation eg, underscore instance, give llvm ir instruction call cxa begin catch result divide call cxa begin catch result mitigate data sparsity vocabulary oov issue caused diversity identifier constants, inspired related research gao et al empirically establish instruction normalization rule replace identifier form dec label pc xxxx label replace global variables, global var global treat numeric string absolute value less constant value replace positive negative according sign treat numeric string absolute value greater address replace address remove prefix suffix number identifier like reg mem reload storemerge brmerge select thread intuitive explanation given appendix random walk sampling generate training input language model, use random walk li et al algorithm sample instruction pairs, input graph structure section already extracted cfg function, node represents basic block, instruction within basic block executed sequentially extend cfg node represents single instruction set instruction starting point sampling, randomly select node successor current node sampling endpoint probability random walk node successor node given denotes number successor node performing random walk sampling, obtain corpus instruction pair language model training llvm ir language model based bert devlin multi layer bidirectional transformer vaswani encoder take instruction pair input shown figure first token cl mark begining sequence, token sep used separate instruction pair additionally, combine position embedding, segment embedding token embedding input language model position embedding represent position token within input sequence, segment embedding indicate whether token belongs first second instruction pair use two unsupervised learning task pre training task masked language model introduce mlm task help model understand internal structure detail llvm ir instruction figure show example, first randomly select token replace replaced mask replaced random token, remain unchanged model required predict original token corresponding replaced position loss function us cross entropy loss follows represents actual token, represents predicted token, masked token set size vocabulary task next sentence prediction set nsp task enable model capture control flow relationship adjacent instruction task involves determining whether two instruction control flow neighbor shown figure input instruction pair b, next instruction following a, regarded positive example labeled isnext otherwise regarded negative example labeled notnext positive negative example constitute training data feed final hidden state cl token nsp head binary classification loss function computed using cross entropy loss represents actual label, represents predicted result, represents training set total loss function llvm ir language model combination two loss function completing pre training llvm ir language model, input instruction sequence model unit basic blocks, obtain embedding basic block level gated graph neural network obtaining embedding basic blocks, use ggnn li et al transfer aggregate information adjacent basic block cfg learn function embedding feature specifically, input cfg represented initial state node dimensional embedding, ie, time step, basic block node adjacent node transfer information, follows matrix transformation matrix adjacent node represents aggregate representation node step node fully updated, information basic block node used calculate output representation entire cfg, follows represent two mlp, sigmoid function momentum contrastive learning bring similar function ie, positive sample closer feature space, pushing dissimilar function negative sample apart, use contrastive learning training specifically, shown figure given function sample one positive sample negative sample encoded using two ggnn shared weight existing research gao et al shown increasing coverage negative sample improve contrastive learning performance therefore, adopt solution proposed moco et al maintains embedding queue facilitate training larger batch size minimizing memory consumption however, due size queue, directly back propagating update key encoder challenging, use momentum update instead represents parameter query encoder, represents parameter key encoder, momentum coefficient use infonce loss function temperature hyperparameter, embeddings respectively function pair determine similarity based source file name function name ie, whether compiled source code assigning label similar dissimilar cosine distance used calculate similarity embedding vector formula shown represents th component vector referring previous work marcelli et al ding et al use following project widely used practice related works, ie binutils coreutils clamav curl diffutils findutils gmp imagemagick libmicro libtomcrypt nmap openssl putty sqlite unrar zlib cross compile project obtain binary file different compilation environment specifically, use two compiler family gcc clang four version each, five optimization level o five target architecture arm arm mips disable function inlining compilation avoid introducing noise total, obtain binary completing data pre processing section devided training test set project subsequent step datasets detail provided appendix validate capability irbindiff complex compilation environments, identify seven different tasks, ie xc cross compiler xo cross optimization xa cross architecture combination example, task xo xa represents function pair different optimization level architecture use compiler experimental setup previous work pei et al li et al construct balanced testset task, consisting positive function pair negative function pairs, well unbalanced testset consisting positive function pair negative function pair complete dataset construction process shown figure compare irbindiff seven baseline zeek shalev partush performs dataflow analysis basic block level computes stands, train two layer fully cnn learn similarity task gemini xu et al extract manually crafted feature basic block construct acfg, us gnn representation asm vec ding et al utilizes random walk cfg sample instruction sequences, us unsupervised learning model pv dm learn assembly function representation safe massarelli et al us word vec model generate assembly instruction embeddings, adopts rnn attention mechanism generate function embeddings gmn li et al directly us graph matching network based control flow graph calculate similarity two function trex pei et al us transfer learning based framework generate function embeddings based micro trace function palmtree li et al add pre training task related code structure improve bert model, performs self supervised pre training large scale unlabeled binary corpus generate instruction embeddings following previous research marcelli et al pei et al conduct experimental evaluation two scenario one one comparison given pair binary functions, return similarity score determine whether similar regarded binary classification task, use area curve auc receiver operating characteristic roc curve evaluation metric, comprehensive measure incorporates possible classification threshold one many search given query binary function f, binay function pool p, contains function similar f, dissimilar functions, objective retrieve top function pool ranked similarity rank retrieved function denoted rank indicator function recall defined follows represents total number query recall emphasizes retrieval coverage rate, mrr place greater emphasis order positional relationship within rank list calculated asm vec palmtree support cross architecture xa task experimental environment machine running ubuntu os, equipped nvidia geforce rtx gpu core intel xeon gold cpu use python pytorch implement irbindiff experiment data pre processing stage, filter function less basic blocks, tokenize simplified normalized instructions, generate vocabulary size language model pre training stage, use adam optimizer initial learning rate hidden layers, hidden dimension, multi head attention, training batches, epoch basic block embedding generated represented dimensional vector graph contrastive learning stage, divide training validation set ratio use adam optimizer initial learning rate weight decay value loss function infonce model encoding layer unit per layer, training batches, epoch momentum coefficient embedding queue length function embedding generated represented dimensional vector function similarity detection one one scenario basic relatively simple task bcsd referring setting previous work li et al pei et al marcelli et al use balanced unbalanced testset mentioned section evaluate table show auc score irbindiff baseline overall, irbindiff outperforms method xc, xo, xa combined task balanced testset specifically, irbindiff auc score seven task improved average compared baseline method example, difficult xc xo xa task, irbindiff get second highest gemini get gmn safe perform significantly worse, worth noting asm vec palmtree support instruction set architecture, cannot compared cross architecture xa task unbalanced testset, irbindiff also performs well despite challenging data distribution xo xa task, although irbindiff fell slightly behind gemini trex margin still exhibit robust overall performance compared zeek, gemini, safe, gmn, trex, average auc score irbindiff improved conclusion, superior robust performance irbindiff attributed ability lift binary code unified llvm ir representation, effectively mitigating discrepancy caused different compilation option one many search present greater challenge highly practical scenario, example, large scale firmware analysis vulnerability detection, usually necessary retrieve similar function large scale candidate function zhao et al evaluate this, use unbalanced testset described section specifically, query function, construct candidate function pool size consisting similar dissimilar function table present recall mrr score irbindiff baseline notably, irbindiff achieves average relative improvement recall across seven task compared seven baseline method especially challenging xc xa xo tasks, irbindiffrelatively improves recall score mrr scores, irbindiff trail gemini xa mere point overall, compared one one comparison, irbindiff demonstrates significant performance advantage one many search scenario performance boost primarily attributed introduction momentum contrastive learning, effectively enhances model ability distinguish subtle functional difference large scale candidate pools, enabling accurately identify similar function figure report recall score method different value shown, task xo xc xo xa, difference compilation option increases, search performance bcsd method show downward trend however, task, value increases, irbindiff consistently surpasses baseline methods, recall curve remaining others, demonstrating higher accuracy every recall level asm vec palmtree support cross architecture xa task conduct ablation study comparing irbindiff following variant better understand contribution component norm removing instruction normalization process first part section plm removing pre trained language model described section graph removing graph momentum contrastive learning described section shown table table removing component negatively impact overall performance irbindiff among them, instruction normalization component least impact performance, norm variant causing average performance drop point one one one many scenarios, respectively, contribution reducing training resource time overhead extremely substantial contrast, plm variant, remove pre trained language model, result average drop point two scenario highlight significance llvm ir higher level semantic abstraction fine grained semantic understanding provided pre trained language model finally, graph momentum contrastive learning component prof critical irbindiff graph variant, excludes component, lead significant performance drop points, particularly task involving xa conclusion supported recall curve different values, shown figure underscore essential role three component overall performance paper, present irbindiff, novel graph momentum contrastive learning approach based intermediate representation llvm ir binary code similarity detection approach successfully tackle challenge complex compilation option large scale candidate function retrieval real world applications, consistently outperforming existing leading solution across various experimental task scenario conclusion, irbindiff offer robust practical research solution binary code similarity detection although proposed irbindiff performs well experiments, still certain limitation need addressed subsequent study first, irbindiff currently take account code obfuscation code obfuscation commonly used evade static analysis significantly alter logic structure program, making challenging analyze consider code obfuscation orthogonal issue, future advancement handling obfuscation technique could complement existing capability irbindiff secondly, work us sixteen engineering project construct binary code datasets, may encompass possible application scenario nevertheless, project widely utilized related research practical application fully reflect diversity software real world, thus alleviating potential concern generalizability method finally, irbindiff overall performance partly dependent generation preprocessing llvm ir, remains computationally intensive task particularly evident processing large scale binary files, efficiency retdec decompilation tool may present bottleneck state research strictly adheres ethical scientific research principle field computer science llvm ir language clear semantics, file generated decompiling binary file readable form example function shown figure obtained bind engine function afalgso file openssl project example, observed llvm ir resembles risc instruction set, supporting simple operation addition, subtraction, branching, comparison, instruction presented three address format function boundary division shown figure function llvm ir begin keyword define sequentially traverse llvm ir statements, using regular expression identify define add subsequent statement current function block encounter next define reach end file, thereby marking end function block basic block division llvm provides opt command obtain graphical cfg, need extract text form therefore, employ regular expression matching identify identifier indicating basic block call relationship function block construct cfg observed figure identifier dec label pc xxxx indicates start basic block, preds dec label pc xxxx indicates predecessor current basic block instance, line dec label pc ac preds dec label pc c, dec label pc indicates basic block dec label pc dec label pc predecessor dec label pc ac therefore, within function block, scan statement, using regular expression identify dec label pc xxxx numbered identifier stored list node cfg subsequently, statement following identifier added current basic block encounter next identifier reach end function block, thus concluding current basic block control flow graph extraction completing division basic blocks, check whether basic block contains preds identifier present, locate dec label pc xxxx follows identifier list form pair current basic block identifier, representing edge cfg, stored another list extraction node edge complete, extraction cfg also finalized order prune redundant instruction preserving essential ones, empirically design following instruction simplification strategy basic block identifier llvm ir, identifier dec label pc xxxx preds dec label pc xxxx indicate start basic block predecessors, respectively, without actual semantics since already divided basic block boundary extracted cfg appendix retaining identifier unnecessary, remove address information statement insnaddr xx following instruction indicates address instruction different address different files, may disrupt model semantic learning lack inherent meaning, delete memory order directive shown figure function body concludes list order directive uselistorder directive appears terminator last basic block encodes memory order usage list actual instruction affect semantics ir, delete provide intuitive illustration process instruction tokenization normalization, present example table rule id column corresponds normalization rule number discussed section figure present example random walk sampling instruction pair specifically, original cfg consists basic block jump control flow, node represent basic blocks, edge represent jump control flow splitting basic block individual instruction adding sequential control flow them, cfg extended instruction level cfg, node represent single instruction edge represent either jump sequential control flow subsequently, perform random walk sampling instruction level cfg, described section statistic training test datasets shown table asm vec palmtree support cross architecture xa task recall recall one many search unbalanced set shown table ",software engineering
"identifying factor contributing bad day software developer mixed method study introduction ii related work iii method iv finding limitation vi conclusion implication instruction reporting error ii role emotion developer productivity ii measuring understanding developer productivity iii data collection iii data analysis iv rq factor cause bad day developer iv rq way developer describe bad day factor impact work iv rq use telemetry data validate factor cause bad day developer software development dynamic activity requires engineer work effectively tools, processes, collaborative team result, presence friction significantly hinder productivity, increase frustration, contribute low morale among developer contrast, higher satisfaction level positively correlated higher level perceived productivity hence, understanding factor cause bad experience developer critical fostering positive productive engineering environment research, employed mixed method approach, including interviews, surveys, diary studies, analysis developer telemetry data uncover triangulate common factor cause bad day developer interview involved developer across different level role survey captured perception developer factor cause bad day frequency, impact job satisfaction daily diary study engaged developer day document factor caused bad day moment examined telemetry signal consenting participant validate impact bad developer experience using system data finding research revealed factor cause bad day developer significantly impact work well discus implication finding suggest future work enhancing developer experience crucial improving software productivity several reason positive developer experience reduces unnecessary blocker enables developer concentrate core responsibility writing, testing, deploying code rather held back tool process prior research also provided reason importance improving developer experience instance, forsgren et al highlighted developer time deep work demonstrated remarkable increase productivity compared counterpart less uninterrupted time recent work noda et al srivastava et al also showed company provided suitable work environment developer achieved revenue growth five time greater competitor suboptimal work environment vein, prior research doerrfeld showed developer experience play crucial role talent retention, developer study mentioning consider experience workplace key factor deciding remain leave organization building upon foundational insights, recent work scholar explored different way improving developer experience includes studying constitutes good day developer investigating impact flow state developer satisfaction productivity examining intersection developer unhappiness, productivity, developer attrition rate systematic analysis research studied specific tool process like pull request build time contribute negative experience developer despite valuable contributions, yet, limited work engaged developer holistically investigate perspective factor cause bad day impact productivity well being, suggestion mitigate experience even so, limited study paired developer feedback telemetry data examine validate developer concern poor developer experience offer definition bad day mean interested using subjective term bad day elicit common problem make developer feel bad day work particularly, focused able detect problem drive mean improving developer experience research, employed mixed method approach, including interviews, surveys, diary study, telemetry data analysis investigate validate factor cause bad day developer study engaged software developer interview sessions, developer participated survey study, developer participated diary study result three approach validated using telemetry data consenting developer examine difference log data reported bad day versus report bad day combining approaches, sought uncover, triangulate, examine factor cause developer bad day multiple viewpoint validate measurable aspect finding using telemetry data result allowed u answer research questions, including rq factor cause bad day developer rq way developer describe bad day factor impact work rq observe bad day factor using telemetry data research make following contribution comprehensive view factor cause bad day developers, including technical non technical factor factor lead poor developer experience, insight impact negative developer experience developer satisfaction well being, thus providing better understanding phenomenon developer could supported, validation telemetry analysis, concrete impact factor build time pull request process developer satisfaction, establishing quantifiable threshold correlate negative experience overall, research, contribute new insight concept bad developer day beyond available current literature rest paper organized follows following section, build prior work motivate contribution study, next, provide detailed description methods, followed finding discussion result research, conclude highlighting implication finding section, highlight prior research discussed connection emotional state developer productivity well level also highlight prior work explored approach capturing measuring developer productivity challenge build work contribution make research bad work day often lead negative emotion low developer productivity several scholar investigated connection developer emotion productivity, seeking foreground negative positive emotional state developer influence work outcome graziotin et al investigated relationship developer affective state emotion mood creativity, analytical problem solving skill engaged computer science student study measure emotional state correlated performance problem solving task research found happy software developer better problem solvers, least term analytical ability finding suggests fostering positive emotional state among developer may lead improved productivity ller fritz also investigated developer emotional state better understand emotion frustration happiness correlate performance developer ability focus flow state research revealed positive emotion enhance flow state developer and, thus, ability developer good work meyer et al also explored make developer day good study collected self reported data developer four months, analyzing developer spent time factor contributed perception good workday finding research revealed satisfaction productivity developer significantly influenced ability control workday minimize unplanned disruption along similar vein, graziotin et al explored consequence unhappiness among software developer developing software conducted qualitative analysis survey response developer identify categorize negative effect unhappiness developer themselves, software development process, resulting product create study, found highest impact unhappiness productivity performance finding also showed unhappiness lead mental health issue among developer issue like low self esteem, high anxiety, burnout, stress, potentially serious disorder like depression several scholar explored approach characterizing, measuring, predicting productivity level fluctuation developer forsgren et al introduced space framework, comprehensive model designed measure understand developer productivity implicit framework developer productivity complex multi faceted requires balanced comprehensive approach measure capture dimension brown et al developed log based metric identify period focused work flow software engineer study employed mixed method approach, including diary study longitudinal surveys, validate metric self reported data finding research revealed data log based metric correlated significantly self reported experience focus flow showing promise approach egelman et al also investigated negative interpersonal experiences, termed pushback, developer encounter code review surveyed developer mixed method approach analyzed code review log identify prevalence predictor negative feeling associated code review found developer reported experiencing negative feeling related code review least quarter, experiencing feeling monthly showed although pushback code review relatively rare, still significant negative impact developer satisfaction occurs meyer et al investigated software developer perceive assess productivity conducted two study survey professional developer observational study developer understand developer perceive productive v unproductive activity measure productivity study showed developer perceive day productive complete many task large task without significant interruption coding seen productive activity, meeting viewed productive unproductive, depending nature murphy hill et al investigated factor predict productivity developer surveying developer across three company survey included question self rated productivity, productivity factors, demographic variable study revealed technical non technical factor improve productivity practical viewpoint, research lu et al highlight flaky test disrupt continuous integration process also increase debugging efforts, thereby diminishing developer productivity similarly, prior work ko et al highlight inadequate documentation negatively impact developer different ways, including increasing learning curve new tools, impeding troubleshooting maintenance tasks, ultimately leading frustration reduced productivity among developer wang et al also pointed slow build time critical bottleneck lead poor developer concentration workflow efficiency finding suggest direct correlation faster build process improved developer satisfaction productivity study, employed mixed method approach investigate factor cause bad day developer specifically, approach paired qualitative methods, including interview diary studies, quantitative method including survey study telemetry data analysis elicit measure factor cause bad day developer different viewpoint across methods, varying level participation developer figure show number participant study method, following section go detail methodology data collection interviewed software developer understand perceptive, factor causing bad day development work recruited developer diverse backgrounds, roles, experience level ensure capture perspective broad range developer within organization recruitment employed snowball sampling conducted internal company medium involved posters, word mouth, email outreach recruitment message outlined purpose study, investigate everyday work experience software developers, particular focus challenge frustration occur workday cause bad day inclusion criterion participating study required participant software developer engineer within organization hence, non engineer included study collected interview data using semi structured interview protocol prepared ahead time interview lasted approximately minute conducted via video conferencing platform interview audio recorded consent participant later transcribed analysis ensured recruit across levels, role types, location table list demographic spread interviewee good distribution interviewee across level band although representation individual contributor interviewee usa, distribution representative developer population company interview, explored four main area developers, including asking define understand term bad day developer describe constitutes bad day work, including associated thought feelings, differ typical challenging day developer also prompted share recent example bad days, discussing frequency, factors, event contributed experience also asked pattern recurring situation tend trigger day third section interview, focused eliciting participant bad day affect productivity, work performance, emotions, well being, impact interaction teammate colleague final stage interview, developer asked coping strategies, helpful resources, potential change work environment could prevent mitigate bad day overall, interviews, generated qualitative data perception developer within organization factor make developer day go bad work following interviews, conducted survey study developer investigate factor causing experience bad day wider audience aimed find common theme interview survey reflect developer sentiment within organization participant recruited organization wide email inviting take part study email included informed consent form outlining purpose study, confidentiality measure around privacy, data handled end study participant directed online survey platform took survey study approved organization ethic review board followed best practice protect privacy well developer participated study member research team trained researcher access data study survey consisted four section wanted survey deeply relevant developer grounded unique experience opposed generic developer experience survey end, used much gathered interview inform survey, using interview report caused bad day form question likert scale open ended potential bad day scenario section collected basic demographic information participants, including experience level, role, development type, location, work home status, gender identity figure show demographic spread respondent survey interestingly, many senior developer respond survey gender role demographic skewed towards male individual contributors, reflect overall developer population section focused perception participant definition constitutes bad day developer, frequency currently experiencing bad day perceived likelihood various scenario encounter work contributing bad day presented likert scale question likert style question included query rating likely blocker long build times, flaky tests, pull requests, call duties, meeting times, legacy code changes, issue engineering system cause bad day small example set question survey last month, many bad day bad day impact work personal life following questions, presented various issue scenario related work please select frequently scenario cause bad day option always, often, sometimes, rarely, never, applicable long build time code backed out, fault code review taking long time vpn keep dropping debug system half day filled meeting get negative feedback pr hard time getting support issue section offered participant opportunity opt participate daily short diary study participant signed would receive message toward end every workday asking whether experienced bad day work responded yes, asked brief, open text follow question contributing factor survey respondent participated daily diary study participation rate figure section sought participant consent collect anonymized telemetry data related work, including check ins, pull requests, code review time, meeting hours, incident report goal telemetry data allow researcher quantitatively measure baseline data people reported bad day differed people report bad day different specific issue listed second section survey survey respondent consented telemetry data analyzed research team consent rate figure conducted diary study participant capture daily data experience developers, looking uncover factor causing bad day work longitudinal approach complemented retrospective nature interview survey allowed u observe challenge emotion fluctuate time response specific event condition impact productivity developer within organization specifically, diary study allowed u see actually caused bad day moment, opposed people believed would cause bad day described previous survey section, participant diary study recruited question end survey asking sign consented participate prompted every day workweek visit online questionnaire asked experience day first question asked rate day either good, neutral, bad participant selected either good neutral, survey would end however, selected bad, freeform textbox activated, encouraging share experience made bad day overall, approach, obtained longitudinal data factor causing bad day developer associated information developer share collected telemetry system data developer consented investigate correlation poor system experience report bad developer day specifically, telemetry analysis focused measurable factor listed interview survey sought validate bad day factor identified actual system data analysis focused mainly pull request build time telemetry data protect privacy developers, telemetry data anonymized accessible member research team collected metadata development outcomes, much time took approve pull requests, number people participated code review, long build took complete, among related metadata provided developer detailed explanation data collected informed could opt telemetry collection time without affecting employment participation aspect study data interview analyzed using thematic analysis process involved three step first, immersed data reading reading transcript better understand content context allowed member research team part interview session familiarize data next, commenced data analysis conducting open coding interview transcript identify relevant concept pattern following open coding, transitioned axial coding allowed u group initial code together potential theme sub theme next, reviewed refined final theme generated process ensure accurately represented data used theme conduct thematic analysis yielded data reported study analyzed categorical data survey using descriptive statistics, correlation analysis, cross tab analysis first, conducted descriptive statistic analysis gain general understanding data followed frequency distribution analysis determine prevalence reported bad day common scenario blocker identified survey achieve this, converted categorical response numerical value scale question answer type shown frequency occurrence question always often sometimes rarely never applicable agreement level question strongly agree agree neither agree disagree disagree strongly disagree applicable likelihood question likely somewhat likely neither likely unlikely somewhat unlikely unlikely applicable next, conducted cross tabulation analysis examine response varied across different demographic groups, experience level, role, location, revealing potential difference frequency bad day using chi square test pair variable method helped u identify potential association between, example, experience level frequency encountering specific blocker finally, conducted open coding survey response uncover key theme causing bad day developer since daily diary study questions, looked descriptive statistic first question hand coded open ended answer find common theme cause bad day developer collected six month system telemetry data developer signed investigate potential relationship telemetry data reported bad day crucial aspect analysis involved linking survey response telemetry data anonymized identifier developer reported pull request caused bad day assigned group developer reported cause bad day within time frame study assigned group approach allowed u conduct deeper investigation technical factors, lengthy build time delayed pull requests, might contribute reported bad day conducting independent test mean metric group group since data continuous categorical roughly normal distribution overall, multiple research approaches, able identify factor cause bad day developers, describe impact them, validate concern developer telemetry analysis two measurable factor identified interviews, survey, diary study report finding analysis detail following section triangulated finding research question using result interviews, survey, diary study interview revealed three major theme cause bad day developer tooling infrastructure issues, process inefficiencies, issue around team dynamic within issues, deeper concern identified shared following section participant complained consistently unreliable tool infrastructure major source frustration factor caused bad day issue identified included flaky build tests, issue around slow build deployments, outdated clunky user interfaces, generally unreliable broken tool block completing task instance, one developer mentioned, build tools, environment tools, ado, pull requests, git, visual studio automation, every single tool use feel like barely working days, highlighting pervasiveness poor tooling engineering system disrupting workflow issue around unclear project ownership, lack documentation knowledge sharing, rapidly changing team priority common factor caused bad day developer instance, one developer mentioned whole initiative around documentation shut down, huge bummer documentation definitely solved problem find knowledge need get work done, frustrating another developer mentioned process inefficiency around item tracking commenting remarkable amount confusion about, like work tracked, remarkable for, know, company old, still unsure track work leading cascade inefficiency issue common among senior principal developer developer often complained difficulty collaboration, communication breakdowns, unresponsive team members, interpersonal conflict developer highlighted technical issue often lead bad day infect overall team morale often degrade trust level instance, developer remarked sure energy frustration facing technical issue carry impact team, know like smile contagious grumpiness contagious developer highlighted intra team conflict caused bad day past resolved it, saying bad time working prior team solving honestly, largely matter changing the, know, working group collaborating day day basis issue common among junior developer due length question type asked survey, result broken three section developer definition bad days, top factor causing bad days, frequency bad day analysis demographic stated previously, goal prescribe definition bad day rather, wanted hear developer thought caused bad day figure show top coded response developer asked bad day mean top engineering system friction, feeling blocked stuck, poor productivity similar finding interview likert style questions, able rank factor causing developer bad day table ii list top mean score pr delayed due reason beyond team control flaky tests, transient issues, build failure, unresponsive reviews, etc common factor cause bad day developer mean score addition, many subjective factor like team dynamic lack support surfaced top line observed interview reviewed response different demographics, found sde ii senior developer report hard time getting support issue common factor cause bad day compared level concern around slow laggy laptop distributed across different levels, slightly prevalent among sde ii senior developer contrast, half day filled meeting challenge prevalent among principal senior developer furthermore, concern around slow laggy laptop causing bad day prevalent among working home similarly, individual working primarily home report higher prevalence meeting heavy day shown figure survey respondent say experienced bad day last month, distribution roughly normal also cross tabulation using chi square test frequency bad day demographic cohort chose chi square test assesses whether statistically significant relationship two categorical variable find statistically significant difference good thing since want demographic cohort experience higher prevalence bad day others unique respondent submitted diary duration study response said developer bad day also analyzed freeform text response submitted developer bad day revealed development environment infrastructure technical issue common challenge caused developer bad day similar finding interview survey interestingly, health emotional challenge close second finding analysis revealed complex picture developer experience within organization particularly showed bad day simply matter technical challenge finding go typical expectation improving technical infrastructure enhance developer experience instead, aligns result prior research shown technical non technical issue impair developer experience, suggesting need pay closer attention exploring theme interact examine way mitigating holistic approach focus multifaceted nature issue result interview survey study showed developer reported bad day negatively impact work well senior junior developer described impact bad day different way specifically, analysis showed frustration, annoyance, anger stemming unexpected roadblock perceived inefficiency common way senior developer described impact bad factor work described feeling typically leave exhausted due long hour mental strain dealing bad day constant occurrence bad day also lead disillusionment cynicism perceived lack action organization mitigate factor instance, hinting disillusionment, senior developer commented eventually like, even driving road anymore signaling frequent bad day cause disillusioned consider looking new job another senior developer also shared disillusionment saying, well, mean lot consecutive bad day like start pulling job board seeing, know opportunity another senior developer also mentioned would say worst bad day had, day actually stopped working go linkedin start looking job feeling need quit jobs, developer mentioned feeling left behind treated unfairly, like saying, could tell impact less satisfied work general feel like, well, know, see people chilling eating food like, feel treated unfairly analysis interview revealed common impact bad day factor junior developer lead guilt self doubt attribute cause problem incompetence, instead systemic issue organization instance, junior developer mentioned whenever encounter issues, start think like, yeah, like, competent enough fix getting super unlucky right like pretty frustrating finding analysis open ended question impact bad day survey revealed four key theme bad day impact developers, including concern reduced productivity impact career, self doubt, imposter syndrome arising frequent occurrence bad days, extended work hour due self guilt, overall increased stress anxiety level spill personal life figure show frequency answers, stress health make top response regarding concern around reduced productivity career implications, analysis showed bad day consistently linked decreased productivity, term quantity quality work specifically, developer reported feeling unable focus, losing motivation, struggling complete task instance, developer shared experience productivity, stress, career, mentioning bad day make progress difficult feel like spinning wheel wasting time creates anxiety depression, fear job security due lack progress goals, lead frustration entire day time another developer shared experience productivity loss result bad day mentioning bad day impact work reducing productivity, causing delay project timelines, leading lower quality work, missing edge case following bad day developer often experience self doubt imposter syndrome, leading question ability feel like meeting expectation instance, developer sharing experience following bad day mentioned bad day, begin feel frustrated guilty getting work done get hit imposter syndrome bad day work definitely carry personal life hour bad day caused unproductivity, think task bug working feel stressed getting done another developer mentioning impact bad day confidence remarked bad day made feel less confident abilities, resurfac ing imposter syndrome extended work hour due self guilt another common impact bad day developer scenario typically arises developer attempt compensate lost hour workday resorting working longer hour catch dynamic disrupts work life balance leading less time rest, decompress, recover work instance, developer sharing experience dynamic mentioned bad day make difficult stop work pm spend time family feel like fact accomplish anything mean pulling weight therefore, need spend time evening catching justify existence employee another developer sharing similar experience mentioned work hour weekend able focus finish work resulted enough personal time spend kid extracurricular activity sadly feel like hurting academic future career also able keep exercise time prepare healthy meal rely takeout overall, developer frequently reported bad day led increased level stress anxiety spill personal lives, affecting sleep, relationships, overall well dimension emotional impact bad day developer included report emotional exhaustion, feeling drained, frustrated, overall negative mood developer sharing experience remarked often time feel emotionally exhausted day full frustrating event evening also essentially write highlight bad day impact ability enjoy personal time engage activity outside work another developer sharing experience mentioned trouble sleeping day keeping chore emotionally exhausted work finding analysis revealed senior developer often experience frustration, annoyance, anger stemming unexpected blocker inefficiencies, junior developer often experience guilt self doubt finding provides pathway understand kind support developer different level might need way best support instance, junior developer could supported mentoring program within organization designed increase self confidence, knowledge, productivity, senior developer could benefit participating co creation activity play role designing system process used within organization ensure work survey, asked respondent share u improvement could made reduce number bad day experienced many respondent clearly articulated concrete change could made reduce bad day fewer meetings, improved documentation, faster build times, change authentication, faster code reviews, change manager could work giving autonomy developer proposed change detailed therefore proprietary showed asking question important discover change could made reduce bad day result telemetry analysis reported two heading including pull request build time telemetry data decided focus examining pull request build telemetry data among highest ranking bad day factor survey result measurable using system data instance, high ranking factor like feeling like get anything done easily measurable using system data process editing improving code involves sharing change pull request reviewed author teammate colleague merging main project repository reviewer pull request review code logical completeness, code quality, security key part software engineering process employed metric cover part pull request, result, analysis based mean comparison following metric totalpullrequesttimehours total duration pull request open non draft state close hour dwelltimehours time pull request open pull request touched reviewer codereviewtimehours time pull request touched reviewer pull request closed totalreviewers number reviewer pull request table iii report finding statistical analysis group indicated said code review cause bad day group indicated said code review cause bad day performed independent test since data continuous categorical roughly normal distribution found two statistically significant result group value higher totalpullrequesttimehours also higher dwelltimehours value find significant difference code review time number reviewer build process measure duration required compile, test, package code deployable format since product large build time dependent upon availability cache binary prior builds, developer may encounter especially long build time, even made changes, due none dependent binary cached report result build process telemetry analysis based mean comparison following metric totalbuildtimeminutes total duration build minute corebuildtimeminutes total duration core aspect build minute noncorebuildtimeminutes total duration non core aspect build minute buildsuccessrate number successful build total number build table iv report finding analysis tabular format group indicates said long build cause bad day, group indicates said long build cause bad day again, performed independent test since data continuous categorical roughly normal distribution group significantly longer mean build time min compared group min difference value summary, group statistically significant longer time total pull request time, pull reuqest dwell time, overall build time therefore, conclude concern expressed member group verifiable telemetry telemetry data analysis provided empirical validation self reported bad day factor validation critical step toward building data driven approach assessing improving developer experience instance, leveraging telemetry data, organization develop predictive model anticipate bad day enable proactive intervention overall, approach limitation potential influence variable captured telemetry data demonstrates value combining qualitative quantitative data better understanding factor cause bad day developer impede developer productivity experience limitation might impact reproduction study sample population limited sub population within organization thus, possible sampling different population yield different ranking factor cause developer bad day therefore, organization seeking replicate study focus process eliciting bad day factor less result since outcome likely differ organization addition, participant responded call participate interviews, survey, diary study might experienced bad day past, hence data collected engagement might represent view developer within organization different culture also varying level comfort expressing view stronger weaker manner may influence response well again, organization replicate study focus research method outlined rather specific result finding research revealed variety factors, including technical factor like frequent auth prompts, slow build times, long pull request times, non technical factor like many meetings, difficulty finding help blocked, intra team conflict cause developer bad day work importantly, research revealed vicious cycle arising bad day warrant attention scholar research instance, finding analysis revealed bad day often cause sleep issue developer get home know prior research cognitive fatigue affect performance mean get home get enough rest, come back work next day tired making feel unproductive becomes cycle theme need attention scholar focus often directed towards looking tool friction isolation factor cause bad day developers, rarely take holistic look lens developer experience friction blocker impact professional personal life way leave unproductive potentially, cognitively physically drained thank participant completed interview, survey joined diary study helping u shape complete research would also like thank tim bozarth, originator bad developer day microsoft, insightful feedback throughout stage project constructive insightful feedback throughout stage project",software engineering
"waffle multi modal model automated front end development introduction approach experimental setup result related work limitation conclusion appendix appendix instruction reporting error training data mutation structure aware attention contrastive learning model training test data evaluation metric effectiveness waffle ablation study structure aware attention effect multi model large language model attention mechanism ui html generation mutation rule case study tuning integration waffle structure aware attention contrastive learning effect infrastructure web development involves turning ui design functional webpages, difficult beginner experienced developer due complexity html hierarchical structure style large language model llm shown promise generating source code, two major challenge persist ui html code generation effectively representing html hierarchical structure llms, bridging gap visual nature ui design text based format html code tackle challenges, introduce waffle, new fine tuning strategy us structure aware attention mechanism improve llm understanding html structure contrastive fine tuning approach align llm understanding ui image html code model fine tuned waffle show pp absolute percentage point higher html match, higher cw ssim, higher clip, pp higher llem new benchmark websight test existing benchmark design code, outperforming current fine tuning method waffle multi modal model automated front end development shanchao liang purdue university liang purdueedu nan jiang purdue university jiang purdueedu shangshu qian purdue university qian purdueedu lin tan purdue university lintan purdueedu large language model significantly advanced automation code generation popular programming language python java jiang et al touvron et al fried et al nijkamp et al rozi et al guo et al li et al lozhkov et al automation html code generation ui design remains explored challenging core front end development, task requires model understand transformation natural language nl programming language pl also visual design pl recently, multi modal large language model mllms brought much progress generating text image description radford et al zhai et al li et al liu et al b, li et al dai et al blecher et al chen et al wei et al vikhyat top this, mllms fine tuned using ui image code datasets eg, websight lauren et al design code si et al nonetheless, approach mainly apply standard fine tuning fail address specific html code generation challenge two key challenge exist translating ui design image html code teach model learn effectively domain knowledge html structures, significantly influence rendered ui design, teach model learn subtle difference visual understanding ui image text understanding html code regarding first challenge, three basic structural aspect html code firstly, style parent element directly passed child unless specifically overridden secondly, layout sibling affect thirdly, node affected subtrees sibling last principle might less obvious compared first two, explain example figure show html code file rendered webpage use blue, orange, green block map code chunk corresponding visual rendering webpage top level body element refers whole webpage, child element div id left column refers left part webpage, another child element div id right column refers right part modification child div id left column change div id right column look webpage even remove content inside div id left column show learn domain knowledge html code structure, propose novel structure aware attention mechanism structure aware attention capture structure information html code explicitly allowing token focus three type previous code segment relevant detail section structural information html code, waffle focus part code influence resulting ui design, thus benefiting overall performance figure illustrates second challenge, ie, learning fine difference detail visual input figure figure two highly similar different ui image rendered webpages, ie, color text identical, width column slightly different vlm websight lauren et al state art mllm webpage image html code generation, fails capture small difference thus, generates identical html cs code figure different ui image figure figure model fails generate fr fr highlighted code segment red background screenshot case, vlm websight vision model fails recognize visual difference, text model unable use encoded visual information produce accurate textual output enable mllms recognize subtle difference ui image due minor change code, adopt contrastive learning zhai et al radford et al gao et al current task teach mllms focus important visual difference combining two approaches, paper introduces waffle, fine tuning pipeline specifically designed ui image html code generation, following contribution design structure aware attention html code generation, enables mllms learn structure knowledge html code apply contrastive learning algorithm boost mllms understanding detail rendered ui image html code create new dataset pair webpage html code, could facilitate future research web mllms conduct comprehensive experiment two backbone mllms waffle improves backbone mllms achieving pp higher html match, higher cw ssim, higher clip, pp higher llem highlight waffle fine tuning approach, model independent applied improve mllms ui html code generation availability githubcom lt asset waffle figure represents overview waffle create new mutated html dataset section training fine tuning addition, design structure aware attention section model fine tuning teach model focus important html segment finally, use contrastive learning training teach model learn visual difference align model visual hmtl cs code understanding section specifically, construct training dataset applying mutation rule html code subset popular dataset, websight generate corresponding source code ui image teach mllms important visual differences, create waffle contrastive training data websight fine tuning dataset built huggingfacem contains pair html code corresponding screenshots lauren et al study common mistake existing web mllm, vlm websight, enabled u create realistic mutation rule mutate html cs code websight conduct failure analysis vlm websight validation data instance every mismatched webpage, manually inspect root cause failure eventually conclude seven common category error shown table category, create set rule mutate existing html, shown appendix based mutation rule, randomly sample instance websight dataset, creating four distinct mutant sample mutation rule applied based frequency failure computed validation set final mutated dataset removing rendering failures, identical mutants, blank image groups, group containing four pair html code corresponding rendered webpage image html code clear structures, certain structural property directly reflected rendered ui design domain knowledge benefit generation process mllms three important element rendering element layout parent element, sibling elements, element waffle implement novel attention mask provides element pruned view previous tokens, including parent attention, sibling attention, self attention attention mask allow token pay specialized attention parent elements, sibling elements, figure show simple example waffle structure aware attention figure show html code snippet show dom tree html code root node body element div id leftcol div id rightcol two child node body sibling div id leftcol one child, text selection div id rightcol one child, element text customer review inside according domain knowledge element mostly affected parent sibling elements, waffle build structure aware attentionas shown parent attention parent attention element token parent element token waffle utilizes fact child element inherit parent element style structure instance, token element div id leftcol pay parent attention token element body token element selection pay parent attention token element div id leftcol sibling attention sibling attention element token preceding sibling element token waffle utilizes fact sibling element parent affect arrangement style other, element need pay attention preceding sibling instance, token element div id rightcol pay sibling attention token element div id leftcol self attention standard self attention mechanism, allows token focus previous token within element, excluding child element illustrate, token specific element self attention yellow cell figure token belonging element waffle applies structure aware attention language model decoder only, keep vision encoder waffle applies structure aware attention mechanism one fourth attention head language model decoder enables quarter attention head learn structural domain knowledge explicitly, three quarter head keep standard full self attention pre training knowledge number attention head use structure aware attention hyper parameter, tuned section example illustrated figure highlight critical gap current model limited ability effectively map variation html code corresponding webpage screenshot address this, waffle utilizes contrastive learning, allowing model learn comparison contrast similar example concretely, training dataset consists group html code ui image pairs, group pair training, group, image code image rendered webpage image code webpage image split list pixel patch depends configuration backbone mllm patch encoded vision model fused text model latent space using adapter result list patch embeddings hyper parameter backbone mllm html code tokenized token number token html code token encoded embeddings language model using structure aware attention use average patch embeddings represent embeddings webpage image, average overall token embeddings represent embedding whole html code, denoted calculate cosine similarity score text embeddings image embeddings, bipartitely contrastive learning objective maximize similarity embeddings html code corresponding ui image, achieved minimizing contrastive learning loss along standard language modeling fine tuning loss follows contrastive learning loss aim maximize similarity score diagonal similarity matrix green cell similarity matrix shown figure train mllm vision model, encodes webpage, closely match encoded embeddings text model, corresponding html code, language modeling loss, hand, aim maximize probability generating correct token given previous token input webpage image standard objective training mllm generate text image waffle jointly optimizes two objective follows hyper parameter constant controlling effect contrastive learning overall optimization implement waffle two backbones, vlm websight, moondream lauren et al vikhyat backbone first fine tuned websight dataset using standard language modeling objective vlm websight, use released fine tuned checkpoint detail lauren et al checkpoint fine tuned using dora liu et al variant parameter efficient training, lora hu et al rank set moondream also fine tune model using dora liu et al rank set lora alpha set model weight updated using adamw loshchilov hutter optimizer, learning rate set batch size top fine tuned mllms first step, apply structure aware attention contrastive learning approach structure aware attention applied attention head attention layer llm decoder model trained dora using combined learning objective contrastive learning dataset equation set model weight updated using adamw optimizer, learning rate set batch size evaluate waffle using two test datasets websight test, consists synthetic webpages, design code, consists real world webpage since websight already used training, created websight test following process websight lauren et al total, websight test contains test samples, webpage image respective ground truth html source code design code open source benchmark manually processed real world website screenshots, much complex websight evaluation design code indicates generalization ability model fine tuned waffle training dataset real world scenario si et al html match html match percentage generated image match ground truth image perfectly pixel level comparison, style attribute removed ground truth generated html process emphasizes model ability accurately recognize text content dom tree structure html code clip clip score radford et al si et al measure similarity rendered webpage inferred html code ground truth webpage based clip vit embeddings webpage low level element matching llem previous work si et al proposes llem measure percentage matched text blocks, text content, position matched text block, font color within text block cw ssim complex wavelet structural similarity index cw ssim computes structural similarity image sampat et al human evaluation two human annotator asked compare rendered webpage generated different technique subset test data ground truth webpage rank gemini pro result test instance generates answer remaining instance table table show performance various fine tuning strategy two testing datasets, websight test sample design code sample comparison standard fine tuning compare waffle baseline, standard fine tuning ft method tables, waffle achieves significant improvement standard ft metric moondream vlm websight backbone websight test, waffle achieves pp higher html match v higher cw ssim v standard ft moondream backbone vlm websight backbone, waffle outperforms standard ft pp html match, cw ssim, averaged llem design code, waffle achieves greater improvement compared standard ft technique backbone note that, waffle generalizable fine tuning pipeline benefit pre trained mllms linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary overall, waffle significantly improves metric backbone test datasets standard fine tuning pp html match, cw ssim, clip, pp llem comparison sota commercial model due lack comparable baselines, also compare waffle top commercial models, include gpt mini, gpt o, gemini pro apply direct prompting method following prior work si et al result shown table websight test dataset, model fine tuned waffle perform better sota commercial model vlm websight overperforms gpt pp html match v cw ssim v similarly, smaller backbone, moondream exceeds gpt pp html match v cw ssim v shown table vlm websight fine tuned waffle better gpt cw ssim better gpt mini design code dataset however, gpt better two metric versus vlm websight moondream fine tuned waffle lower performance compared gpt gpt mini metric likely due smaller size, could influence generalizability complex, distribution data design code dataset case study provided appendix linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary simpler data, waffle achieves better comparable result sota commercial models, pp improvement html match improvement cw ssim complex data, waffle enables vlm websight outperform commercial model cw ssim comparison ablation model compare waffle two ablation model waffle attn waffle contrastive learning without use structure aware attention waffle contra waffle structure aware attention table show ablation study result waffle attn brings improvement compared standard ft metrics, waffle contra brings pp improvement html match design code dataset, waffle dominating performance metric model fine tuned backbone across two backbones, model fine tuned waffle higher fine tuned waffle attn cw ssim linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary contrastive learning structure aware attention significantly improve performance standard fine tuning simpler websight test data, model trained waffle achieve highest html match cw ssim score complex design code data, waffle still delivers best result across metric backbone human evaluation result select test sample websight test design code total sample four generated html code rendered webpage standard ft, waffle attn waffle contra waffle human raters rank generated webpage based similarity ground truth webpage without knowing model produced one table show human evaluation result vlm websight fine tuned standard ft, waffle attn waffle contra waffle across datasets, waffle best averaged rankings, outperforming ablation baseline specifically, waffle reach time rank placement design code, showing great generalizability complex datasets waffle contra second best technique two testsets, reaching time rank average ranking hand, waffle attn third best technique still outperforms standard ft linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary human evaluation show structure aware attention contrastive learning contribute code generation quality, waffle generated html cs code consistently rated higher code generated standard fine tuning demonstrate structure aware attention help mllms focus correct element like parent sibling element generation, simulate case generation error occur mid process ideally, mistake within sibling element disrupt generation main element select high performing sample generated vlm websight fine tuned waffle waffle attn using html code generated models, manually crop mutate section simulate error model tasked completing html code starting error goal evaluate whether model robust enough handle intermediate error without causing major failure subsequent generation table show result completion following intermediate mistake waffle attn averaged cw ssim across sample drop model make intermediate mistake contrast, waffle, averaged cw ssim drop linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary integrating structure aware attention brings great stability model generation, making model robust intermediate mistakes, reducing performance drop recent advance vision language model greatly improved mllms capability task like image captioning radford et al zhai et al li et al mckinzie et al alayrac et al lauren et al text image generation ramesh et al rombach et al visual question answering dai et al liu et al b, bai et al popular model like llava liu et al b, qwen vl bai et al vary wei et al perform well general image tasks, focus converting ui image html code address this, propose waffle, fine tuning method equips mllms domain specific knowledge needed ui html generation attention mechanism key part modern transformer vaswani et al architectures, effectively capture hidden feature input data handle challenge certain domains, specialized attention mechanism explored, pyramid attention chai li hierarchical attention guo et al shi et al nguyen et al yang et al designed long range, cross file code understanding generation, well regularized attention assembly code su et al different existing work, waffle target html code, new challenge restricted structure waffle design novel structure aware attention learn structure knowledge early direction ui code generation utilizes sketch webpage figures, eg, hand drawn website sketches, generate ui code rendered similar image sketch image robinson yet, direction practical, front end developer want draw sketch website need help automated tool contrast, leveraging advancement mllms, huggingface recently released websight, trained websight dataset lauren et al although specific detail model disclosed, represents significant shift towards end end ui code generation similarly, design code model using cogagent backbone using subset websight si et al hong et al however, neither websight design code try adapt domain knowledge html task contrast, provide structure aware attention apply contrastive learning mutation teach model fine grained difference html image one limitation waffle implemented two model vlm websight moondream waffle could potentially applied mllm, exploration limited computing resource experiment show waffle brings significant improvement standard fine tuning two models, indicating level generalizability another limitation metric use fully capture human evaluation html match overlook cs styling, metric like cw ssim, clip, llem similarity based, lead unreliable score evaluating html code automatically challenging, include clip llem, used previous work si et al gui et al along cw ssim html match ensure fair evaluation work present waffle, fine tuning pipeline ui html code generation waffle introduces structure aware attention mechanism capture html structure employ contrastive learning align visual textual understanding, aiding mllms distinguishing subtle webpage difference waffle outperforms standard fine tuning two backbone mllms, improvement pp html match, cw ssim, clip, pp llem ablation study confirm key component waffle contribute better cross modality understanding robust code generation notably, waffle model independent enhance mllms ui html code generation table show mutation rule used mutate html code create contrastive learning dataset html code cs style element mutated according failure type manual analysis cs styles, mutate property color, size, margin, font size, type element bounding box display positioning element column specification table show detail valid value property html codes, randomly duplicate one html element excluding one cause render failure ie, head header html body figure show generation result one instance websight test generated webpage gpt cw ssim significantly lower vlm websight standard fine tuning hand, webpage generated vlm websight fine tuned waffle reach almost perfect cw ssim score, example show effectiveness using waffle ui image html code task waffle applies structure aware attention attention layer mllm decoder study portion attention head use structure aware attention, fine tuned vlm websight subset training dataset pair html code webpage screenshots set portion attention head using structure aware attention all, incrementing setting model trained batch size learning rate model evaluated validation dataset use two metric decide final hyper parameter averaged llem score training loss figure show averaged llem score applying structure aware attention attention head result top three validation score also consider training loss figure although applying structure aware attention ie, attention head yield high llem score, also result high training loss, likely due regular attention head retaining prior knowledge pre training contrast, show similar lower training loss combining results, select ie, final hyper parameter controlling portion attention head use structure aware attention show contrastive learning effect mllms visual textual understanding, design two experiment first experiment analyzes whether mllm understanding image code aligned integration contrastive learning, second experiment analyzes whether contrastive learning teach model capture subtle difference image aligning model two modality specifically, procedure, compute averaged text embeddings image embeddings subset sample websight test dataset test sample section using moondream model fine tuned waffle attn standard ft pair averaged image embeddings text embeddings, normalize compute euclidean distance cosine similarity table show result measurement technique euclidean distance embeddings two modality waffle attn lower distance embeddings standard ft, similarly, cosine similarity embeddings encoded waffle attn higher standard ft v addition, figure demonstrates contrastive learning teach model align text image understanding vision embeddings red circle far away corresponding text embeddings blue triangle calculated standard ft contrast, vision embeddings grouped corresponding text embeddings waffle attn capturing subtle visual difference using computed embeddings, compute averaged distance similarity image embedding centroid corresponding group mutant formally, group mutants, consisting image embedding centroid image embeddings computed table show distance cosine similarity image embeddings average distance image embedding respective centroid computed waffle attn greatly surpassing average distance computed standard ft likewise, cosine similarity image embeddings much lower waffle attn v showing waffle attn better ability distinguish image figure also show standard ft encodes four different image almost latent space ie, four red circle overlapped waffle attn able encode differently approach implemented following package transformer pytorch selenium, deepspeed accelerate datasets experiment conducted shared computing cluster four nvidia gpus continuing",software engineering
"context code text learning bimodal software engineering introduction ii background iii inctrl context code text learning iv inference experimental setup vi result analysis vii discussion viii related work ix conclusion instruction reporting error iii architecture overview iii task configuration iii prompt configuration iii configurable prompt generation iii response generation research question task datasets model metric implementation vi rq effectiveness context learning vi rq impact retrieval augmented generation vi rq performance specific datasets vi rq case study vii threat validity vii limitation vii fine tuning inctrl bimodal software analysis initially appeared within reach advent large language model unfortunately, complex interplay natural language text code software engineering, present unique challenge prevent pretrained model generalize variety task postulate context learning code text bimodality promising avenue paper thus introduces comprehensive study context code text learning, focusing leveraging pretrained codellama model consider diverse dataset encompassing software engineering tasks, transform context learning format effectively extract informative features, propose configurable prompt template proposed pipeline, inctrl, unifies prompt learning across various software engineering task extensive evaluation study datasets demonstrates superiority inctrl model shot performance, surpassing state art model including support model, codellama typically, observe applied codellama model, inctrl brings improvement term precision least recall various task example, task program repair, inctrl improves bleu score codellama points, clone detection, inctrl achieves improvement percentage point moreover, inctrl model offer state art performance using retrieval augmented generation individual downstream task finally, qualitatively analyze benefit inctrl codellama open source model broader impact make code dataset publicly available software development complex endeavor characterized inherent interplay code natural language significant advancement made code analysis natural language processing, effectively integrating two modality remains critical challenge yet, integration essential addressing complex task require deep understanding code syntax semantic context setting, large language model llm appear promising due ability process generate text code, offer unprecedented potential automate tasks, improve code quality, enhance developer productivity critical factor llm effectiveness quality diversity training data source code foundation, incorporating additional data type bug report patch vulnerable code snippet proven invaluable specific task program repair vulnerability detection yet, building general purpose code text model remains challenging due varied nature code complexity bridging gap natural language formal logic indeed, source code inherently bimodal, composed formal algorithmic component informal natural language component consisting example identifiers, comment text artefact research predominantly examined channel isolation, attempt comprehensive approach using machine learning proposed literature two channel indeed interconnected, natural language often providing context, explanations, summary underlying code jointly analyzing channels, researcher potentially enhance understanding analysis software system unfortunately, building general purpose code text model present unique challenge due diverse input distribution task variation bimodal software engineering face complex challenge identifying synchronization point code text well managing noise, come form ambiguity natural language channel imprecision code algorithmic channel effectively address specificity bimodal software engineering, llm often require carefully crafted datasets process demand deep understanding downstream tasks, code context comprehension, code text alignment ensure consistency quality across diverse task type essential enhancing llm performance software engineering, current data generation methods, outlined luo et al wang et al frequently rely limited task set heuristic approach reliance inadvertently introduce systemic bias inherited llm predefined task indeed, previous approach addressing challenge primarily fallen two category multitask learning task specific component extension multitask learning attempt formulate various code based task uniform input output format, offering versatility often struggling capture nuanced difference diverse task task specific component extension augments pre trained llm additional component trained task oriented data, allowing tailored solution facing challenge scalability generalization novel task approach demonstrated limitation ability generalize effectively unseen datasets task paper response aforementioned challenges, propose novel framework designed significantly enhance llm capability handling diverse software engineering task refer context code text learning inctrl central approach unified code text interface generalizes task oriented code text instruction consolidating code text data single format, significantly expand training data available llms, resulting model versatile less biased tackling software engineering problem research contributes significantly emerging field context code text learning, critical component achieving bimodal software analysis establishing foundation effective code text interaction, envision future system capable accurately understanding generating modality contextually aware manner model instrumental bridging human computer divide, enabling fluent translation high level instruction executable code key aspect proposed methodology include unified code text interface introduce novel interface bridge gap diverse code related tasks, allowing cohesive representation various se problem task oriented instruction generalization approach focus generalizing task specific instructions, enabling llm better understand adapt wider range se task experimental results, based seven typical software engineering task applied datasets, provide sufficient data support claim inctrl enhances llm software engineering task effectively leveraging context learning without requiring model retraining experiment show inctrl improves codellama code generation tasks, text generation tasks, classification task inctrl significantly improves classification performance incorporating retrieval augmented generation module, addressing key limitation traditional context learning experiment show rag module contributed average increase point score datasets achieve point improvement inctrl demonstrates strong performance across various software engineering tasks, particularly excelling code generation repair impact, however, varies across task datasets, influenced factor dataset complexity, input length intrinsic nature task inctrl structured prompt design provides rich context learning opportunities, exemplified effectiveness code summarization wide array existing software engineering research typically specializes one particular downstream task either code analysis natural language processing bimodal software engineering represents emerging field seek bridge gap code natural language within software development lifecycle integration essential addressing complex task require deep understanding code syntax semantic context primary challenge lie aligning code text representation effectively, discrepancy lead errors, vulnerabilities, hindered developer productivity traditional approach often silo modalities, illustrated figure limiting potential synergy indeed, different task datasets require various input outputs, require creation training deep learning model capable handling multiple downstream tasks, clone detection code generation range requirement underscore need integrated versatile tool bimodal software engineering, capable addressing complex interplay code natural language across diverse software development scenario overcome limitations, propose unified framework leverage general purpose interface ie, adapter help handle various software engineering task seamlessly integrating code text analysis approach empowers model extract valuable insight domains, enhancing capability perform complex se task like detecting vulnerability explaining code identifying code clone greater accuracy efficiency thus, technique unifies prompt learning large language model across various software engineering tasks, ensuring effective processing diverse input achieve state art result context learning icl key capability large language model llm allows adapt new task without explicit training incorporating task demonstration within input prompt, llm generate relevant outputs, first highlighted gpt indeed gpt demonstrated remarkable performance across range task simply conditioning task demonstration embedded input context unlike traditional machine learning, icl leverage model extensive pre trained knowledge perform task minimal supervision, zero shot shot learning research indicated effectiveness icl influenced factor number, order, quality context example sensitivity prompted development prompt engineering technique aimed optimizing presentation information model precise mechanism underlying icl still investigation, study suggest model may learn identify pattern correlation within provided example work capitalizes icl strengths, enabling rapid adaptation model inctrl framework without extensive retraining multi task learning mtl advanced machine learning paradigm contrast single task learning approache involves concurrent learning multiple related tasks, leveraging shared information enhance overall performance mtl offer powerful framework utilizing supervised data across related tasks, thereby reducing reliance task specific labeled data approach inherently combat overfitting encouraging model learn generalizable features, effectively acting form regularization application mtl boost task performance extensively explored successfully implemented across diverse domain scenario mtl enables model learn multiple related task simultaneously, offer rather complementary perspective work indeed, context code text reasoning approach differs mtl emphasizing flexible, task agnostic interface capable handling wide range software engineering problem mtl indeed typically focus sharing parameter across predefined task reduce overfitting improve generalization mtl typically involves predefined task structure shared task specific parameters, context code text reasoning method emphasizes flexibility, allowing dynamic handling various software engineering task configurable prompt learning postulate method address directly unique challenge bimodal software engineering, desynchronization code text, explicitly targeted traditional mtl technique pre trained language model significantly advanced natural language processing nlp consistently achieving state art performance across wide range task model offer several key advantage extract universal representation extensive corpora, provide enhanced model initialization better generalization downstream tasks, serve form regularization combat overfitting working limited datasets researcher typically employ two main strategy harness pre trained language representation feature based approach consider pre trained representation additional features, fine tuning approach adapt entire pre trained model specific downstream task however, model often specialize either classification generation task contrast, aim take holistic view, unifying prompt learning across diverse software engineering tasks, yielding model capable addressing multifaceted requirement software engineering field, including code analysis natural language processing aspect inctrl framework designed integrate code natural language text various se tasks, leveraging context learning enhance model performance section detail construction inctrl approach, key components, configuration used inctrl architecture, depicted figure comprises several interconnected component designed handle, together, complex software engineering task task module initializes task specific setting based configuration file task configjson prompt module load prompt configuration prompt configjson outlining prompt structure content context learning configuration serve foundation configurableprompt component, dynamically generates prompt combining predefined template relevant example retrieved retrieval augmented generation rag module approach ensures prompt tailored specific tasks, enhancing model ability generate accurate contextually appropriate response enabled, rag module retrieves relevant example training set retrieval process represented equation query task prompt document corpus training set retrieved example enrich prompt question module handle specific query posed user, integrating configurable prompt ensure comprehensive tailored prompt task requirement enriched prompt fed generator, which, study, leverage codellama model produce final response model input, combination prompt question, represented generator generated response, prompt, question consider three different type task depending output class output, code output, text output task depicted figure executed across datasets cf section process begin task module, initializes specific task setting determines whether use retrieval augmented generation rag module based task requirement specified configuration file task configuration file contains parameter essential defining task environment include task type eg, code generation, code summarization input output formats, evaluation metrics, whether rag enabled let denote task setting vector derived configuration file, represents individual configuration parameter task module parses initializes environment accordingly task requires use rag module, task module set binary flag indicates activation rag decision rule formalized follows decision impact subsequent steps, whether retrieve example training set task module also initializes input output data structure let represent input data configuration output data configuration mapping input output described function parameterized transforms input data according task setting defined furthermore, task module configures evaluation metric used assessing model performance let denote set metrics, representing specific evaluation criterion, bleu score text generation accuracy classification task evaluation function expressed represents evaluation result based generated output selected metric systematically configuring task environment, input output mappings, evaluation criteria, task module ensures inctrl framework correctly initialized specific requirement software engineering task concurrently, prompt module load prompt configuration configuration file configuration define structure content prompt used context learning prompt configuration crucial generating task specific prompt guide model understanding processing input data effectively let denote prompt configuration vector derived configuration file, represents individual configuration parameters, including template structures, placeholder input variables, instruction model prompt module parses create prompt template dynamically adjusted based input data formally, let function represents structured prompt used guide model generate final prompt prompt module substitute placeholder actual value ensures model receives coherent contextually relevant prompt additionally, prompt configuration includes rule augmenting prompt supplementary context, example clarifying information let denote augmentation function enriched prompt represents context question configurableprompt component central inctrl framework take input prompt module additional context provided rag module enabled rag module retrieves relevant example training set, enriching prompt contextual information resulting prompt combination predefined structure dynamically retrieved examples, making highly adaptable various task formally, let represent initial prompt generated prompt module, denote function rag module retrieves set relevant example based input data configurableprompt component combine input form enriched prompt combination process expressed follows function integrates initial prompt retrieved example denotes union operation appends example prompt finally, performing inference, treat certain data entry test set question, concatenate obtain final prompt date entry used input model conducting extensive experiments, summarized high quality template construction scheme set default structure configurable prompt specifically, inctrl default scheme divide configurable prompt following six section previously illustrated lower right part figure introduction provides background context generator definition give basic requirement task pre instruction give detailed requirement task demonstration provides several input output example post instruction emphasizes detailed requirement task question contains query example configurable prompt provided figure task code summarization final prompt constructed, fed generator module ie, codellama case generator leverage structured prompt produce accurate contextually relevant response response generation process modeled function map augmented prompt response vector, ensuring output aligns user query context code related tasks, utilizes underlying capability codellama perform various operation code generation, code completion, providing natural language explanation generated response refined ensure precision relevance example, task involves generating function definition based query, response might include syntactic check semantic validation ensure code correct optimal enhance robustness response, additional post processing step applied, incorporating feedback loop iterative improvement let post processing function refines response, finalized response final comprehensive approach ensures inctrl framework handle wide range task efficiently, producing high quality output meet user requirement code natural language context inctrl framework designed accommodate diverse range software engineering tasks, including classification generation problem leveraging modular architecture effective prompt handling, inctrl address task tailored inference strategy generation oriented tasks, code generation open ended code comprehension, model directly prompted produce output generated sequence evaluated ground truth using metric like bleu contrast, classification tasks, including vulnerability detection clone detection, utilize vocabulary ranking approach model generates potential candidates, option highest log likelihood selected final prediction enhance performance, especially binary classification, expand label set include semantically similar term eg, yes true positive class aligning model output natural language pattern mathematically, classification process expressed predicted class, set candidate classes, input prompt generation tasks, generator produce sequence tokens, given input prompt, sequence length, probability generating token given previous token input prompt prompt baseline codellama experiment without inctrl apply simple prompt define task provide input data example, vulnerability detection, prompt follows given following code snippet, classify whether vulnerable code prompt used replailcation package rq effectiveness context learning considering various code text task software engineering, extent model performance improved context learning inctrl rq impact retrieval augmented generation extent use rag selecting example prompting necessary beneficial rq performance specific datasets fine grained perspective, inctrl influence model performance individual datasets task rq qualitative case study actual input output example inctrl, qualitative assessment provide regarding capability table i, provide detailed information datasets used experimental setup datasets collected huggingface nonetheless worth noting that, datasets, used subset case remark column indicates subset considered categorize software engineering task three type based modality output data code output, text output, class output task fall code output category include code generation, code translation, code completion, program repair, encompassing datasets text output category consists code summarization task, includes datasets task class output category vulnerability detection clone detection, covering datasets use codellama base llm select llm open source among popular software engineering research specifically, evaluated four set model parameter codellama b, codellama instruct, codellama b, codellama instruct difference model without instruct name lie trained type data exposed training process furthermore, choose codebert pre trained language model designed understand represent programming languages, embedding model rag module model parameter used downloaded official hugging face model repository code output text output tasks, since text generation tasks, adopt bleu evaluation metric automatic metric evaluating quality machine generated text comparing reference, calculating similarity score based overlap gram generated text reference text evaluation, use smoothed bleu metric gram class output tasks, adopt precision, recall, score evaluation metric class output task involved evaluation binary classification task ie, outputting yes setting, precision measure accuracy positive predictions, recall measure completeness positive predictions, score harmonic mean precision recall, providing balanced measure classifier performance rag module inctrl powered llamaindex evaluation inctrl implemented based vllm ease reproducibility dataset considered work, provide corresponding configuration automatically build interface experiment conducted server equipped nvidia tesla gb gpus section, present overall context learning effectiveness inctrl sec vi a, necessity effectiveness rag module sec vi b, performance individual datasets sec vi qualitative case study sec vi instruct indicates instruct version model abbreviation code generation cg code translation ct code completion cc program repair pr code summarization c vulnerability detection vd clone detection cd mean precision mean recall subsection, investigate overall performance inctrl software engineering task first obtain result datasets mentioned using model without applying inctrl then, aggregate output result compute overall performance metric task type model inctrl, prompt consists solely task definition input data table ii present performance model across three major category code output, text output, class output, subdivided seven specific task considered work code generation cg code translation ct code completion cc program repair pr code summarization c vulnerability detection vd clone detection cd observed seven tasks, inctrl significantly enhance capability model specifically, smallest improvement point increase cg, largest point surge pr enhancement transforms model nearly ineffective highly effective, demonstrating inctrl impact code output task additionally, inctrl still mark substantial improvement baseline performance text output tasks, perform well tasks, compared code output task finally, class output tasks, direct model inference initially completely unfeasible successful case codellama studied datasets inctrl therefore equipped model capability tackle task table, observe without enhancement provided inctrl, instruct version model typically underperform compared non instruct counterpart underperformance attributed instruct version requiring specific instructions, directly provided initial prompt however, application inctrl, instruct version outperform non instruct model term cg, ct pr improvement suggests inctrl effectively activates instruct model inherent capacity learn solve problem based configurable prompt provided inctrl specifically, inctrl improves codellama code output tasks, text output tasks, class output task rq example, intuitively analyze prompt generated inctrl activate model indicates instruct version model unlike generation task randomly selecting sample training set construct context prompt enable model certain ability complete task classification task higher requirement relevance example ie, demonstration question directly using randomly sampled data example usually cannot make model output valid result therefore, consider whether introduce rag module make inctrl also adaptable class output task specifically, enabling rag module, inctrl treat question test set query data sample training set document retrieved us cosine similarity semantic vector embeddings provided codebert retrieve relevant training sample question, used fill demonstration slot prompt table iii show result ablation study rag module inctrl class output task noted datasets large amount training data, time cost retrieving full training set high therefore, set ratio perform retrieval subset training set specifically, data point training set, first randomly sample data instance perform rag different datasets, value achieves best rag effect varies table iii, omitted value default best result seen rag module inctrl almost always improves model performance various classification task classification task across six datasets, rag module demonstrated improved performance five significant enhancement observed dataset increase point score however, devign dataset rag module show improvement closer examination data reveals datasets rag module performed well generally consisted shorter function codes, whereas devign dataset, module performed poorly, much longer input sequence discrepancy understandable, longer function code imply complex problem greater retrieval difficulty performance rag module therefore significantly influenced average length sample nonetheless, overall, rag module contributed average increase point score indicates rag module effective, indeed solves, certain extent, problem context learning setup cannot often obtain effective result class output type task indicates instruct version model code generation, code translation, code completion, program repair code summarization tasks, metric value table bleu clone detection vulnerability detection tasks, metric value table score section examines inctrl performance across individual datasets assess effectiveness various software engineering task results, summarized table iv, demonstrate inctrl ability enhance model performance across datasets result reveal inctrl significantly enhances model performance across datasets, albeit varying degree effectiveness depending task type code output task code generation, code translation, code completion, program repair, impact inctrl pronounced instance, apps dataset code generation, inctrl boost performance model bleu score highlighting substantial improvement similarly, codexglue dataset program repair, model performance leap term bleu score contrast, text output task code summarization, improvement less significant, though still notable example, codexglue dataset, bleu score model increase application inctrl, indicating inctrl provides benefit, task inherent complexity model baseline performance limit magnitude improvement class output task like clone detection vulnerability detection, inctrl prof essential enables model perform task could otherwise address effectively datasets like bigclonebench bigvul, non inctrl model fail produce valid output models, however, supported inctrl, achieve score respectively improvement underscore importance inctrl equipping model capability handle classification task providing relevant contextual information via rag module overall, inctrl impact varies across task datasets, influenced factor dataset complexity, input length intrinsic nature task provide specific example illustrate analyze prompt constructed inctrl content output taking code summarization task example text output task where, given piece code, task consists providing description code natural language see specific prompt content output content inctrl figure first, prompt contains six section mentioned seciii introduction section, provide scenario, set role experienced software developer llm, briefly introduce section appear entire prompt then, definition, give basic requirement task, generate docstring given java function next, pre instruction, emphasize content model need pay attention come demonstration section, longest important section entire prompt provides model several input output example taken training set allowing model directly learn ability handle target task within prompt that, post instruction section, emphasize issue model need pay special attention finally, question section input part certain test data test set, hope model answer question seen model correctly output docstring function given question example, see prompt constructed inctrl provides model rich context knowledge, including situation setting instruction task definition definition caution pre instruction post instruction question answering example demonstration among these, demonstration part usually occupies largest proportion prompt content provide sufficient reference model answer new question meticulously constrain model output therefore, difficult understand model still exhibit certain ability solve problem even configured according prompt template instruct version model furthermore, inctrl default prompt construction scheme adapt task given example, previous experimental result show solve various code text problems, making highly generalizable internal threat validity lie implementation framework result experiment first, ensure robustness implementation, framework inference feature rag feature powered widely recognized project vllm llama index respectively avoids uncontrollable factor introduced repeated implementation then, term experiments, conducted large number test different configurations, including replacing text section prompt, changing number shot demonstration, adjusting sampling rate rag module obtaining candidate training set, etc, order achieve best model performance external threat validity lie correctness parameter data model used address issue, model codellama series used generator codebert rag module datasets downloaded officially open sourced repository huggingface platform limitation proposed method mainly reflected diversification base model efficiency rag module due limitation experimental resources, conducted experiment using model codellama series base model however, many state art se related llmsavailable use base model make stronger case inctrl moreover, although framework enable model handle code text related problem without fine tuning training save lot time, task require rag module completed effectively, method still incurs substantial time overhead work, opted fine tune codellama several reason first, fine tuning typically tailored specific tasks, limit model ability generalize across different domain adapt new task without retraining specificity reduce versatility model, making less suitable scenario requiring adaptability various software engineering task second, computational cost resource demand fine tuning large model like codellama significant, often necessitating specialized hardware extended training time prohibitive term time financial resources, especially compared leveraging context learning, allows model utilize pre trained knowledge adapt fly task specific prompt avoiding fine tuning, maintain flexibility efficiency approach, allowing rapid adaptation wide range task without overhead associated fine tuning process code llm codet code gen codellam deepseek coder pre trained largecodebases scratch, show ability general code generation understanding since extensive study fine tuning task specific code llm perform software engineering task like automatic program repair code translation code summarization furthermore, base code model also finetuned prompted unlock full potential specializing solving domain specific coding task code text pre training become mainstream, context learning bimodality remains explored paper introduces comprehensive study code text context learning, focusing leveraging pre trained large language model shot prompting popular technique enhancing llm performance specific task providing example within prompt, model adapt new task without extensive training previous research successfully applied shot prompting various software engineering downstream task work introduces novel approach general purpose interface eliminates need task specific training unlike traditional shot prompting, relies carefully curated examples, method offer flexible adaptable solution handling diverse se task introduced inctrl, novel framework address challenge inherent building general purpose code text model leveraging context learning unified code text interface ie, adapter inctrl empowers llm effectively handle wide range software engineering task without requiring extensive retraining empirical evaluation codellama base model demonstrates inctrl ability significantly enhance model performance across diverse tasks, particularly code generation program repair key component, retrieval augmented generation module, enables inctrl support codellama software engineering classification task ineffective research represents step forward bimodal software engineering, several avenue future exploration include investigating cost inctrl v cost task specific fine tuning, developing method evaluating model robustness open science artefact available ",software engineering
"flexible process variant binding information system software product line engineering introduction fundamental previous work flexibility pais product line proof concept discussion related work conclusion instruction reporting error problem statement contribution outline variability modelling feature interaction featurehouse feature refinement feature binding phase software product line engineering featureide variation point variability modelling feature interaction requirement assumption multiple implementation activity varying data structure static dynamic feature binding property data structure composition multiple implementation activity static dynamic feature binding tool support requirement property limitation single multi model approach configurable process model software product line engineering variable business process innerleftmargin pt, innerrightmargin pt, innertopmargin pt, customexampleexample different organisation often run similar digitised business process achieve business goal however, organisation often need slightly adapt business process implemented information system order adopt various approach proposed manage variant process model approach mainly deal control flow variability, previous work introduced approach manage implementation variant digitised business process context software product line spl engineering applied manage set common core artefact including process model process aware information system pais derived, differ implementation process activity deriving pais, implementation selected process activity included pais compilation time one challenge yet solved giving user digitised business process option selecting several feature runtime, ie selecting multiple activity implementation runtime paper extends previous work allowing selection activity implementation compile time, also start time runtime consequently, becomes possible defer decision feature selected start time runtime furthermore, multiple implementation particular activity may selected executed concurrently another challenge different organisation may want collect base decision different information digitised business process consequently, presented approach also allows customising input output data activity deriving pais specific organisation right self administration german municipality lead various variant business process example, craftspersons may apply special parking permit, allows park area regular citizen pay generally parking permitted special parking permit craftspersons available, inter alia, german city munich constance stuttgart business process checking application special parking permit similar municipality however, slight difference among municipality municipalities, special parking permit issued automatically, whereas others municipal employee need issue parking permit manually researcher observed investigated business process variability municipality well focusing control flow variability approach proposed deal business process variability reference process base process respectively, introduced may configured meet need individual organisation however, approach focus variation control flow business process rather implementation level software product line spl engineering address challenge developing maintaining set similar software product software product line comprises common set core artefact feature may selected order build specific software product literature, process selecting feature spl building software product referred product derivation process aware information system pais corresponds software product executes business process involving human actors, applications, information source previous work applied simplified concept spl engineering pais pais product line build time, implementation selected activity however, static approach lack flexibility, utmost importance practice previous approach, activity pais product line specified input output data structures, ie specified data activity expects data collected execution activity combined input output data structure activity denoted process data structure process data structure pais product line assumed immutable, ie deriving product pais product line process data structure cannot customised data structure implemented source code eg java class process data structure customised product derivation eg user form adapted order collect different data corresponding source code java class need adapted, eg removing adding field java class pose challenge removing field java class might lead compile error field used elsewhere furthermore, implementation activity need selected build time selection start time runtime possible order give process engineer business process option selecting features, decision activity implementation selected must deferred startup time runtime previous work, used build tool apache maven conditionally package selected activity implementation activity implementation selected startup time runtime build tool cannot used anymore challenge find adopt mechanism spl engineering allowing selection activity implementation startup time runtime however, note becomes possible select and, consequently, deselect activity implementation runtime, need specified shall happen data running implementation get deselected finally, far one implementation may selected activity order give process engineer business process option selecting multiple implementation one activity, becomes necessary execute selected implementation concurrently concurrent running activity implementation might access data result unintended overwriting data work address aforementioned limitation problem pais product line main contribution work threefold concept tool spl engineering adopted applied approach pais product line enable customising process data structure deriving pais product technique known spl engineering selected combined enable selecting activity implementation build time, startup time, runtime approach presented allows selecting running multiple activity implementation concurrently, ensuring data unintentionally overwritten moreover, assured process designing, developing, selecting activity implementations, deriving product known phase spl engineering tool supported remainder paper structured follows section present basic concept spl engineering, lay foundation approach necessary understanding approach pais product line introduced described section section approach extended enable flexibility data structure may customised pais product derivation, multiple implementation one activity may selected, implementation may bound different time flexibility presented approach discussed section section discusses related work section concludes paper provides outlook open challenge research topic section, basic concept spl engineering presented, constitute foundation approach concept deal variability among similar software product may derived set common core artefact kang et al introduced notation capture functionality software product perspective user applying notation, becomes possible outline feature software product well relationship tree structured feature model root node represents software product feature software product connected edge root node feature may consists feature inter connected via edge well little circle end edge refer optional features, whereas alternative feature identified arc corresponding edge feature diagram help developer identify configured software product example feature model displayed figure software product consists three feature, ie feature optional, mandatory furthermore, consists either feature besides optional mandatory features, group alternative feature may assigned cardinality multiplicity respectively cardinality feature group defines number feature selected group feature model depicted figure represents software product comprises four alternative feature ie cardinality specifies software product least two feature three feature selected typical constraint feature requires mutually exclusive described text form common practice use dashed arrow indicate feature requires another one dashed double headed arrow illustrate two marked feature must co selected eg finally, figure show feature model contains software product three optional feature ie due constraint requires, selecting feature feature must selected well feature interaction combination multiple feature might behave differently isolation feature interaction subject research many domain long time example feature interaction given described example feature interaction telecommunication consider feature call forwarding call waiting busy phone line phone consists one two features, work fine however, behaviour phone comprising feature unclear either way requirement one feature satisfied, maybe even requirement feature interaction pose challenge spl engineering well opposed regular software engineering, spl engineering, feature selected composed product derivation, ie feature present every derived software product consequently, feature interaction might occur derived software product testing derivable software products, however, feasible practical perspective due exponential growth derivable software product increasing number feature instead testing derivable software product ie every feature combination allowed according feature model detect feature interaction, pairwise feature interaction testing applied context spls pairwise feature interaction testing subset derivable software product generated every feature pair comprised better feature interaction detection, work discus general approach wise testing, ie testing software product contain every combination features, ,n representing coverage strength however, researcher propose pairwise feature interaction testing approach spls, resolution feature interaction cannot hard coded product derivation feature selected individually obeying constraint set feature diagram however, additional code resolve unintended behaviour may conditionally included two interacting feature present software product proposed optional feature problem feature contains code depends another optional feature, second feature becomes mandatory contrary specification, known optional feature problem different approach propose extracting dependent code separate module, called derivative lifter consequently, feature may included independently used software product however, using feature combination, derivative module included well derivative module constitutes resolution technical dependency feature consequently, added feature model furthermore, order resolve interaction two feature may marked mutually exclusive feature model, precedence priority may defined review resolution technique feature interaction refer interested reader featurehouse framework tool chain composing software artefact software system us superimposition merge software artefacts, ie substructure software artefact merged order compose software system hierarchical structure software artefact represented feature structure tree fst example, java artefact may consist packages, classes, method correspond fst node node may non terminal ie child node terminal depending hierarchy level artefact shall merged, structural element latter need chosen terminal node if, example, java artefact shall merged class level, class may terminal node superimposing two fsts entail merging node beginning root node featurehouse support composition artefact written various languages, including java, xml feature refinement corresponds program increment represents feature within related software products, eg software product line feature refinement comprise software fragment incrementally composed build software product whereby software fragment may source code artefact jak extension programming language java contains key word feature refinement class contained jak file may refined another jak file using modifier refines eg class member method may added ahead tool presented turn, able compose translate jak file java file ahead tool also support incrementally composing xml document written xak xak language refine xml document provides attribute xak module mark tag module ie tag may refined base xml file, starting point composing xml document tag xml tree module considered implementation must refined separate xak files, refinement module ie xml increment may specified composition, refinement applied corresponding module tag base xml file, ie tag xml refinement appended corresponding module tag xak refinement file constitute increment rather complete xml, file mostly schema compliant order use optional feature spl, selected respective software product called feature binding feature may bound different time context, distinguishes three feature binding time compile time, start time, runtime feature bound compile time composed source code compilation, whereas feature bound start time selected software product launched finally, feature bound runtime may exchanged software product running proposition categorise feature binding time static binding ie feature binding software product execution dynamic binding ie feature binding start running software product static dynamic binding advantage disadvantage one hand, dynamic binding entail flexibility respect adding removing feature runtime hand, also implies software product contains feature size software product impact required resource memory cpu contrast, static binding requires fewer resource lack flexibility runtime dynamic binding implies adding removing feature runtime hence, becomes necessary specify happens running feature shall removed summarises option running feature removed immediately current state feature saved removal running feature removed execution completed running feature removed furthermore, removal running feature might impact feature share data system process ie background task operating system proposes grouping feature feature binding unit development time bound unbound runtime feature binding unit consider implication data system process feature unbound working variation point corresponds location information system variability occurs, ie feature bound method implement variation point ie binding feature called variability mechanism earlier approaches, binding time feature selected design time implementing variability appropriate variability mechanism instance, variability mechanism discussed subsection like featurehouse ahead allow static feature binding, solely approach presented aim support static dynamic feature binding without deciding design time code basis spl developed independently feature binding time using feature refinement feature spl shall bound statically, existing tool used composing feature refinement order bind feature dynamically, code base transformed use decorator pattern feature selected compile time using factory method feature decorator thus, feature included compile time available afterwards approach allows selecting either static dynamic feature binding feature contrast, proposes approach build result allows selecting binding time per feature changing order feature bound may change behaviour consider example feature binding order assume feature need executed feature then, feature need bound feature however, feature bound statically feature dynamically order reversed approach presented ensures execution order feature even feature different binding time achieved generating hook method overridden dynamic feature binding, mutually exclusive feature included together software product bound runtime therefore, binding feature runtime, given constraint eg mutually exclusion implication need obeyed use runtime api enables checking corresponding feature model whether selected feature spl product consistent edict constitute aspect aspect oriented programming variation point may various edict feature shall bound compile time edict containing feature included contrast, implementation variation point shall determined runtime, edict containing code design pattern eg decorator pattern enables choosing feature runtime included opposed single software products, developing spl requirement various similar, yet different, software product need collected, managed implemented spl engineering divided four phase domain analysis includes activity collecting requirement describing domain feature spl, ie collecting requirement software product derived spl domain implementation deal implementing feature described domain analysis way allows composing individually derived software product requirement analysis deal selecting feature domain analysis specific software product derived spl selected feature form configuration software generation deal building software product composing feature specified configuration requirement analysis featureide eclipse based integrated development environment ide spls cover four phase software product line engineering set section support domain analysis, featureide provides graphical editor model feature dependency feature model feature model contain constraints, stored xml files, imported exported featureide furthermore, featureide provides user convenient refactoring tool inconsistency detection featureide assist developer configuration editor create configuration specific software product requirement analysis developer may mark feature feature diagram contained software product configuration editor prevents configuration obeying constraint feature diagram finally, configuration stored configuration file featureide support various framework implementing feature domain implementation includes featurehouse ahead tool software generation, featureide take configuration file input composes software artefact corresponding selected feature featureide place composed software artefact specified output directory artefact output directory natively compiled artefact language framework domain implementation based previous work, introduced approach process aware information system product line pais product line approach applies concept spl engineering development maintenance similar paiss order reduce development effort cost enabling reuse common core artefact pais product line constitutes common set core artefact including core process model pais product may derived various activity core process model may declared variation points, ie different implementation may selected activity pais product derivation bpmn activity corresponds step work performed, either atomic compound call activity call subprocess, comprise activity constitute compound activities, task atomic activity cannot broken sake approach, bpmn send task, script task, service task, business rule task regarded automated task represent automatic step business process without user interaction neither manual task receive task considered approach manual task occur digitized business process receive task may substituted receive event bpmn user task corresponds step business process user interacts pais consequently, approach considers following three activity type call activity, automated task, user task figure show example business process comprising two activities, whose activity type specified, ie activity constitute variation point pais product derivation, implementation selected activity hence activity type determined depending selected implementation, activity might automated activity ie executing business logic user task ie user form call activity ie calling subprocess activity might also remain without type, ie implementation selected consequently, activity neither call activity automated task user task untyped activity function pais process instance pass untyped activity nothing, ie neither user form invoked automated logic executed approach transfer concept feature spl engineering process activity enables u create process feature models, depict implementation may selected activity, activity optional mandatory process feature model depicted figure reflects process model figure process feature model, two activity one two implementation may selected furthermore, activity optional, ie implementation may selected, mandatory process feature model consists three layers, ie process level, feature level, implementation level process level represents entire business process feature level includes activity business process specifies whether mandatory ie implementation selected optional ie implementation may selected mandatory implementation level list available implementation activity activity corresponds subprocess, another process feature model structure level constructed subprocess activity business process input output data whose data structure specified design time term process data structure used refer combined input output data activity business process thus, input output data structure activity determines part process data structure activity read write access two activity output data structure write access hence, activity output data structure preceding activity might overwrite data predecessor, ie data predecessor lost requirement engineering, order activity well output data structure ie write access specified therefore, behaviour activity foreseen data inadvertently overwritten aside passing accepting data, interaction activity executed predefined order parallel consequently, unintended feature interaction pais product line approach pais product line currently lack flexibility one implementation chosen activity pais product derivation furthermore, process data structure cannot adapted individual need organisation derived pais product share process data structure finally, approach pais product line currently support feature binding compile time, solely section show eliminate limitation flexibility enhancing approach pais product line first, requirement enhanced approach elicited then, assumption enhanced approach stated finally, shown aforementioned limitation concerning flexibility eliminated used business process special parking permit craftspersons simplified version example, deduced cooperation german municipality work extend example towards complete version business process example describes business process special parking permit process various german municipality offer special parking permit craftsperson may park car zone regular citizen need pay parking prohibited business process checking application parking permit among considered municipality displayed figure first, craftsperson applies parking permit then, application checked application justified, parking permit issued application justified, applicant notified rejection described control flow common across municipalities, implementation business process varies municipalities, application check carried municipal clerk whereas municipality application checked automatically comparing data application data craftsperson officially registered authority besides, application rejected applicant may notified via mail, sms, municipal clerk depending municipality choice applicant applicant might choose way notified list available notification mean furthermore, process data structure also varies municipality require applicant fill different data municipalities, parking permit valid every car whereas others applicant need provide number plate parking permit shall valid order prevent misuse parking permit craftsperson private car addition, able automatically check application, craftsperson need provide commercial register number registered authority nutshell, pais product line need comprise common core artefact including process model similar pais product derived order reduce development effort comparison developing similar pais product separately one implementation shall selectable activity constitutes variation point implementation shall selectable compile time, start time, runtime process data structure shall customisable pais product well business process checking application special parking permit resulting requirement studied cooperation german municipality previous work used simplified version business process example, work use comprehensive version deduce requirement enhanced approach accordingly enhanced approach pais product line shall meet following requirement pais product need derivable pais product line denotes set common core artefact including core process model order avoid development redundant software artefact similar paiss multiple implementation one activity shall selectable pais product derivation process data structure shall adaptable allowing different organisation use different process data structure derived pais product need formally specified implementation activity may selectable constraint need met selection combining certain implementation different activity might produce unintended behaviour feature interaction method need established order detect prevent unintended feature interaction enable selecting activity implementation start runtime based input user dynamic feature binding becomes necessary using dynamic feature binding, challenge described section need tackled activity implementation dynamically unbound runtime ie implementation deselected data processing might get lost need specified whether activity implementation may unbound yes how, eg saving current state unbinding activity implementation runtime, shared data system process might affected method need established ensuring shared data system process corrupted using static dynamic feature binding, activity implementation might bound different order intended must therefore assured different binding order must lead unintended behaviour approach work, following assumption hold control flow core process model included pais product line specified immutable, ie process model change pais product derivation hence, derived pais product process model thus identical control flow work focus implementation variability, approach deal control flow variability concept applied activity centric business process object data centric approach business process management like discussed excluded approach previous work, deriving pais product, activity constituting variation point one implementation may selected, ie implementation may selected activity either manual task consisting user form automated task executing business logic figure extract business process special parking permit depicted activity check application type hence corresponds variation point two implementation available, ie automatic check manual check previous work, one two implementation may selected furthermore, activity business process executed pre specified order, eg activity check application executed activity apply special parking permit execution order well read write access activity attribute process data structure determined requirement engineering figure seen activity apply special parking permit write access application data structure, whereas activity check application read access application write access decision data structure consequently, activity influence data read write read write access carefully specified unintended feature interaction allowing multiple implementation activity, execution order implementation specified if, example, figure activity check application implementation automatic check manual check selected, implementation run parallel process instance pass activity implementation activity may executed isolation unintended technical feature interaction however, implementation one activity may influence via data write due non determinism might foreseeable implementation finish last thereby overwrites data predecessors, ie result unpredictable consider example feature interaction pais product line figure activity check application writes decision whether application justified process data structure consequently, implementation may write decision well, ie application checked automatically municipal clerk selecting implementation ie manual automatic activity check application, implementation finish last determines whether application justified example, result automatic application check overwritten decision municipal clerk take longer automatic application check lead unpredictable result depending implementation writes data last seen unintended feature interaction tackle challenge, activity reading writing need distinguished activity read access data pose challenge term feature interaction example selecting sm mail notifying applicant matter implementation finish first implementation write data hence influence order prevent feature interaction activity write data, prevention technique spl engineering might taken consideration section mutual exclusion interacting features, precedence priority discussed solution prevent feature interaction however, due requirement becomes necessary able co select multiple implementation one activity, mutual exclusion cannot used prevent feature interaction specifying precedence priority mean implementation highest priority always overwrite data implementation consequently, sense including multiple implementation one highest priority always overwrites data others another option would grant different implementation write access data work either implementation implement business requirement different way therefore need write data example, application check implementation need write data whether application justified note concept derivative module cf section may used context well additional code included two implementation write data structure example, additional code could determine application justified soon least one two implementation decides application justified additional code aggregate data different implementation refer additional code aggregation code another aggregation code might constitute majority vote multiple application check implementations, application rejected majority implementation consider application unjustified opposed derivative modules, aggregation code need placed process feature model aggregation code solely resolve technical dependency aggregation code introduces resolution business level might multiple aggregation code one may selected pais product derivation choice need indicated process feature model process feature model implementation one activity grouped well available aggregation code activity dashed arrow introduces constraint one aggregation code need selected one implementation activity selected consider following example aggregation code figure show process feature model example activity check application two implementation may selected, form manual check automatic check addition, two aggregation code implementation available feature model notation described section extended figure two implementation activity check application well two aggregation code implementation grouped using dashed box dashed arrow connects implementation group aggregation code group activity label state read follows number selected implementation greater one, one aggregation code implementation need selected, ie two item group selected, one item group need co selected well dashed arrow, represents conditional requires, taken literature cf section supplemented label previous work, pais product derivation process data structure could customised individual need organisation derived pais product shared process data structure however, example describes scenario becomes necessary adapt process data structure pais product derivation varying process data structure pais product line applying special parking permit, municipality require applicant fill number plate whereas parking permit municipality valid vehicle placed furthermore, automatically check application, application requires commercial register number consequently, process data structure varies municipality seen example different organisation need customise process data structure deriving pais product pais product line consequently, optional part process data structure activity read write data optional part process data structure accessed least activity implementation otherwise selection former useless never used hence, dependency activity implementation data structure including process data structure optional part process feature model allows pointing dependency activity implementation optional part process data structure point dependency dashed arrow like one used literature employed pais product derivation, activity implementation selected, corresponding optional part process data structure need included pais product order enable compilation latter business requirement perspective, included optional part data structure need accessed least writing reading, exactly order otherwise, one part data structure accessed reading writing, data structure empty furthermore, one part data structure accessed writing, solely, point collecting data data never processed used following, process checking application special parking permit cf example used explain concept varying data structure figure show process data structure associated example uml class diagram application corresponds composition data applicant, data company, car information, whereas latter field commercial register number data company optional indicated question mark optional part data structure included necessary activity implementation requires access specific part data structure, eg automatic application check requires commercial register number field data company addition process feature model, bottom figure contains feature model representing data structure figure activity implementation need specific optional part data structure dashed arrow required data structure part label indicating whether implementation need read write access activity apply parking permit multiple alternative implementation exist three form simple form, form applicant need fill commercial register number, complex form contains input field setting commercial register number number plate form need write access corresponding data structure part automatic application check implementation need read access commercial register number able compare application data data commercial register activity issue parking permit, two alternative form one require optional part data structure, whereas form requires read access number plate field number plate need present issued parking permit activity implementation independent technical inter dependency single point interaction among activity implementation write read access process data structure consequently, order activity implementation bound influence behaviour activity implementation run process execution, bound process start selected user, implementation unbound execution selected process instance, activity implementation always finish execution hence, data lost shared data system process pose problem activity implementation independent technical dependency furthermore, activity implementation may unbound process execution selected validate presented approach, example implemented proof concept camunda platform used workflow management system first, property stated need provided proof concept then, technical perspective proof concept shall show customize process data structure pais product derivation, bind multiple implementation one activity, bind implementation different time finally, portrayed development maintenance may supported tool line requirement cf section proof concept need provide following property addition, development phase pais product line shall tool supported similar spl engineering, result pais product derivable pais product line derivable pais product include mandatory activity implementations, may differ selection alternative activity implementation proof concept show pais product derived pais product line technical perspective, ie variability mechanism used multiple implementation activity might selected executed suitable mechanism need chosen allows execute multiple implementation one activity variability mechanism need used compose process data structure pais product derivation meet organisation individual need process feature model outline activity incl implementation furthermore, illustrates whether activity mandatory optional using multiple implementation one activity, output data must collected aggregated order prevent overwriting data aggregation code need conditionally included one implementation activity selected order support static dynamic feature binding adequate variability mechanism must chosen phase domain analysis, domain implementation, requirement analysis, product derivation shall tool supported previous work, build tool apache maven used compose artefact pais product derivation data structure among pais product activity implementation designed independent logical unit compiled jar java application conditionally included implementation selected based apache maven profile is, apache maven used compose fully compiled artefact note worked, logical unit self contained could put together like building block contrast, process data structure need customizable cf example change class level, ie compilation process data structure need customised therefore, instead composing jars, java class need composed compose java classes, featurehouse ahead tool may used featurehouse require additional key word like refines, featurehouse used compose java class process data structure proof concept figure class company optional field commercialregisterno parent class application optional association class carinformation listing show base java class company attribute extension class company attribute commercialregisterno depicted listing sake brevity, getter setter method class listing omitted class composed featurehouse base class extension shown listing base class, extension, composed class pure java class specific activity shall constitute variation point, ie one implementation shall selectable activity implementation may service task, user task, call activity, call subprocess pais product derivation, core process model need composed implementation context, implementation may considered refinement base process model language xak used compose process model note latter modelled term bpmn xml representation however, using xak, refinement ie implementation schema compliant, ie file activity refined process model well cannot edited displayed bpmn modelling tool one advantage, bpmn xml graphical representation process model graphical representation serf mean communicating process model domain expert process model serving implementation schema compliant, advantage bpmn ie graphical representation, come effect furthermore, selecting lot implementation implementation need included core process model element need rearranged order make room additional element implementation although work provide mean automatically layouting process models, increasing number included implementation process model get unclear confusing therefore, xak used compose base process model implementation instead, multi instance call activity used, call implementation subprocesses implementation ie automated task user task embedded process model, called variation point activity figure show simple process variation point activity corresponds multi instance call activity call two implementation implementations, turn, simple process consisting activity, either automated task user task variation point multi instance activity may invoke implementation parallel allowing execution multiple implementation time figure show process model example proof concept activity check application notify craftsperson variation points, one implementation may selected therefore activity multi instance call activities, ie call corresponding implementation subprocesses detailed description implementation bound called core process model provided section able bind activity implementation statically well dynamically, approach like one presented section might used activity implementation code might composed compilation implementation statically bound language construct eg design pattern like decorator generated allow choosing implementation runtime however, activity consist graphical xml representation business logic service task html code user task therefore, design pattern like decorator pattern cannot applied language mixture pais product line instead, plugin approach used activity implementation eg automated task user task embedded process model consisting start event, end event actual activity implementation refer process model embedding activity implementation implementation process model figure show core process model top variation point activity two implementation process model bottom invoked variation point activity plugin mechanism allowing static dynamic feature binding pais product line illustrated figure compilation, implementation process model may included excluded static binding, cf figure implementation process model unique identifier id used unambiguously identify former implementation process model included compilation, registered plugin using id corresponding variation point activity cf figure excluded implementation cannot registered plugins available runtime implementation automatic figure included compilation consequently registered plugin start time, developer and, runtime, user may deselect one implementation registered variation point activity setting parameter figure show user form used start process selecting excluding specific plugins ie implementation variation point activity call registered implementation process model checked whether one latter excluded via parameter cf figure implementation process model invoked excluded via parameter dynamic binding selecting multiple implementation variation point activity writes data, aggregation code need included well order prevent unintended overwriting data activity implementation realised implementation process models, aggregation code need map data returned subprocesses ie implementation process model parent process model ie core process model aggregating consolidating data different implementation technical point view, static binding, featurehouse used composing activity implementation like process data structure composition core process bundled implementation process model implementing logic, namely html code user task java code automated task bundling file one folder, pais product compiled start time runtime, parameter may prevent certain implementation selected executed conditional statement software programs, frequently parameter used decide whether specific feature executed based value parameter providing values, parameter exploited variability mechanism feature binding runtime note use parameter variability mechanism well known literature example used demonstrate static dynamic binding activity implementation work registering plugins customexample feature binding time pais product line activity notify craftsperson figure business process special parking permit craftsperson used notify applicant application rejected activity variation point multiple implementation available applicant may notified via sms, mail, manually clerk compile time start time, implementation may selected developer runtime, applicant decide want notified available notification mean included developer figure show configuration activity notify craftsperson camunda platform aforementioned, activity implementation correspond implementation process model embeds implementing functionality ie automated task user task corresponding code base, ie java code implement automated task html code user task spring service notificationpluginprovider provides id implementation process model registered activity implementation then, camunda platform process engine iterates list id using iteration variable process call implementation process model spring service notificationpluginprovider depicted listing contains field notificationplugins type notificationpluginregistration, contains registered implementation notification activity applying parking permit, applicant may select one notification mean registered one selection applicant persisted process data structure calling method getprocessids listing registered notification plugins retrieved, iterated over, checked whether applicant selected method return id implementation process model registered user selected spring service notificationpluginregistration listing field plugins type list, pick injects spring service implement interface notificationplugin illustrated listing every implementation notification activity need implement interface order get registered plugin interface contains method get id plugin, id associated implementation process model, label plugin displayed application form cf figure furthermore, spring service notificationpluginregistration field excludedplugins, pick parameter command line application start example, following command start spring boot application using apache maven specifies mail notification plugin shall excluded thereby selectable application form spring service notificationpluginregistration comprises two method first method iterates registered plugins, eliminates excluded plugins, collect return label remaining plugins method called via graphical user interface application form, cf figure offer applicant selection available notification mean second method also iterates registered plugins, eliminates excluded plugins, collect return id implementation process model remaining plugins second method called spring service notificationpluginprovider figure show extract application form special parking permit craftspersons observed applicant choose notification mean mail, sms, notification clerk available selection extract, ie plugins included compilation, registered, deselected startup time graphical user interface call spring service notificationpluginregistration, get label registered plugins display applicant submits application form, id selected notification mean persisted process data structure selected notification mean used notifying applicant aggregation code special parking permit process activity check application data figure depicts business process special parking permit craftsperson, used check whether parking permit shall granted activity constitutes variation point two available implementation application checked automatically comparing data application data commercial register besides, application checked manually clerk implementation write result check process data structure consequently, implementation selected result data need aggregated, ie aggregation code need included reject application least one implementation reject application using subprocesses camunda, variable mapper implemented specify data data subprocess transferred parent process one implementation activity check application data selected pais product derivation, simple variable mapper included pass field justified subprocess parent process activity implementation included, variable mapper included collect field justified activity implementation evaluates soon one activity implementation find application unjustified variable mapper pas unjustified parent process variable mapper java class referenced process model spring bean name may included using featurehouse figure configuration activity check application data shown id implementation process model included compile time provided spring bean used call implementation process model furthermore, section delegate variable mapping configuration spring bean applicationcheckvariablemapper referenced act aggregation code summary, every activity constitutes variation point plugin mechanism every implementation need implement interface activity want register compile time ie static binding activity implementation may included excluded using featurehouse activity implementation consists implementation process model associated code base java code automated task html code user task start time, command line parameters, and, runtime, user input may used deselect activity implementation dynamic binding support phase spl engineering tool, featureide used proof concept feature model cf figure visualises variability pais product line domain analysis note feature model figure structured left right fit page featureide capture constraint text form feature model opposed arrow used approach requirement analysis, featureide support developer providing configuration editor cf figure configuration editor developer select desired activity implementation shall included pais product implementing variability pais product line, featurehouse chosen, supported featureide deriving pais product, featureide us selection configuration editor input figure compose variable activity implementation presented approach shown derive product pais product line varying process data structures, use multiple implementation one activity, bind feature compile time, start time, runtime following, approach assessed respect whether meet requirement set section furthermore, proof concept tested see whether provides listed property finally, limitation disclosed pais product line corresponds set common core artefact pais product may derived hence, requirement satified multiple implementation selected one activity activity may write process data structure, aggregation code need included order prevent implementation overwriting others data consequently, requirement met activity implementation may require adaption process data structure selecting specific activity implementation required part data structure need selected well therefore, requirement satisfied requirement met process feature model represents variability pais product line corresponding constraint unintended feature interaction occur activity implementation write process data structure aggregation code prevents implementation overwriting others data requirement satisfied runtime, activity implementation selected per process instance selected, cannot unselected anymore furthermore, activity implementation run independently technical dependency among consequently, activity implementation share system process data might corrupt addition, data get lost due terminated activity implementation hence, requirement satisfied well pais product line proof concept us featurehouse include optional activity implementation including activity implementation register plugin corresponding activity consequently, proof concept provides property featurehouse used compose process data structure well hence, property provided process feature model outline variability pais product line property, provided aggregation code implemented camunda variable mapper class, conditionally included using featurehouse therefore, property provided static dynamic feature binding supported using mix featurehouse parameter thus, property provided since featureide used tool support proof concept property provided using featurehouse, feature corresponds folder, contains code feature opposed previous work, code feature feature folder cannot compiled deriving product, code feature composed composition code compiled consequently, hard develop feature independently although feature folder might constitute repository version control, difficult reference compatible version feature compiled artefact version furthermore, featureide currently lack convenience feature code completion available selected feature package view feature folder especially cumbersome long package name displayed hierarchical folder instead grouped package following, related work assessed one way deal multiple variant business process include variant one process model linking gateway however, process model containing multiple variant business process may become large thereby complex, unclear, hard maintain besides combining variant one process model, multiple process model various variant may maintained thus, similarity investigated process variant independently modelled evolve challenge propagate change process models, tedious error prone aforementioned approach deal variability process model rather variability activity implementation level, approach focus managing lot similar business processes, various approach emerged allow configuring variability process model approach hiding blocking transferred process model reference process model contains process variant concrete process model derived configuration hiding blocking path process engineer may fill questionnaire configure reference process model outgoing path process element blocked configuration, path available runtime, whereas hidden path skipped runtime instead using reference process model contains process variants, provop us base process model various change pattern may applied order configure concrete process model modelling base process, adjustment point defined indicate adaption may applied model according provop approach, possible adaption include insert, delete move process fragment well modify process element attribute contrast hiding blocking, provop allows also adding process behaviour adjustment point process configuration instead removing process element eg hiding blocking besides configuring control flow process models, element process model may configurable la rosa et al propose approach individualise role object modelled configurable process model system literature review process variability, interested reader referred aforementioned approach differ approach provide mean configure element process model like paths, roles, objects, neglect configuration activity implementations, ie approach take engineering perspective account concept spl engineering applied business process work author introduce mean mark element process model variation point different variant well binding time may specified realisation variation point proof concept built top eclipse plugin architecture however, work focus modelling aspect variation point process model rather implementation detail variation point work lack detailed description variability mechanism used bind variant description management feature interaction approach, present depth approach use existing variability mechanism bind feature compile time, start time, runtime furthermore, approach describes handle feature interaction applying concept spl engineering variable business process spl engineering used well compose business process author argue service called business process may owned third party vendor may highly configurable order compose business process comprising service service treated spl whereas business process considered multiple spl author focus aggregating feature model spls, automatically checking feature selection aggregated feature model, determining service able accept output data service input data although author describe check whether service compatible eg regard data structure fail describe service automatically composed, technical mechanism shall used automatically bind connect service furthermore, dynamic binding service multiple binding one activity neglected work besides, considered business process include automated activity contain user task concept spl like feature modelling applied cross organisation business process however, approach holistic describe systematically automatically instantiate software product derived spl customer requirement corresponding part business process implement requirement mapped decision table, used configure derive business process product line however, author describe configuration work technical perspective spl engineering concept also applied automatically generate process model variant change process model automatically propagated derived process model variant work distinguishes one focus automatic generation paiss automatic generation process model pais product line comprises common set core artefact including core process model activity core process model may identified variation point different implementation eg user form, automated service developed pais product may derived pais product line selecting implementation variation point thereby, development effort cost reduced implementing similar pais product sharing common feature presented work complemented approach pais product line towards flexibility plugin mechanism introduced based featurehouse parametrization using plugin mechanism, activity implementation may bound compile time, start time, runtime furthermore, featurehouse used compose process data structure different organisation may require varying process data structure business process composing process data structure using featurehouse, process data structure may adapted organisation specific need pais product derivation addition, plugin mechanism enables selection multiple implementation activity deduced aggregation code required selecting multiple implementation one activity write part process data structure prevent implementation overwriting others data aggregation code additional code included multiple implementation one activity selected aggregate output data implementation finally, featureide used tool support phase domain analysis, domain implementation, requirement analysis, product derivation presented approach limitations, addressed future research focus varying activity implementation assumes fixed immutable control flow process model pais product derivation future research shall reveal control flow may adapted pais product derivation approach base reference process model might combined included approach pais product line besides, activity may constitute variation point, ie implementation activity may selected substituted future research shall outline event may constitute variation point implementation may substituted continuing ",software engineering
"structure language model protein conformation generation introduction related work protein conformation generation language modeling esmdiff masked diffusion instantiation experiment conclusion limitation learning sequence structure distribution structure language modeling revisiting discrete diffusion distribution interpolation conditional masked diffusion language model bidirectional encoder denoising network structural dynamic bpti conformation changing pair intrinsically disordered protein runtime analysis protein adopt multiple structural conformation perform diverse biological functions, understanding conformation crucial advancing drug discovery traditional physic based simulation method often struggle sampling equilibrium conformation computationally expensive recently, deep generative model shown promise generating protein conformation efficient alternative however, method predominantly rely diffusion process within geometric space, typically center around vicinity metastable state often inefficient term runtime paper, introduce structure language modeling slm novel framework efficient protein conformation generation specifically, protein structure first encoded compact latent space using discrete variational auto encoder, followed conditional language modeling effectively capture sequence specific conformation distribution enables efficient interpretable exploration diverse ensemble mode compared existing method based general framework, instantiate slm various popular lm architecture well proposing esmdiff, novel bert like structure language model fine tuned esm masked diffusion verify approach various scenarios, including equilibrium dynamic bpti, conformational change pairs, intrinsically disordered protein slm provides highly efficient solution, offering speedup existing method generating diverse conformations, shedding light promising avenue future research protein structure dynamic fundamental understanding biological function protein ability protein adopt multiple conformation crucial function influencing interaction biomolecules environment traditional computational methods, molecular dynamic md simulations, long used explore dynamic however, method computationally expensive time consuming structure prediction models, alphafold jumper et al, rosettafold baek et al, made significant stride predicting static protein structures, yet often fail accurately capture dynamic nature protein multiple conformation chakravarty porter, recently, significant progress made adopting deep generative model conformation sampler efficiently explore complicated protein conformational space example, et al adopts normalizing flow match underlying boltzmann distribution learning simulation data despite potential, normalizing flow based method et al, klein et al, face significant challenge modeling large protein system hundred amino acids, invertibility constraint becomes major obstacle scaling model parameter remedy, denoising diffusion approach jing et al, lu et al, wang et al, zheng et al, efficiently learn structural data, achieve good generalization, perform amortized inference however, modeling high dimensional protein structure explicitly euclidean space demand intensive computation usually requires accounting special equivariant property hler et al, furthermore, based training objective denoising score matching song et al, tend predict local perturbation rather capturing remote mode alternative conformation wang et al, consequently, model may overallocate capacity learn structural noise training data instead focusing low frequency structural change chou, complement existing approaches, present structure language modeling slm novel framework protein conformation generation performs generative modeling latent space protein structure inspired recent progress developing structural vocabulary protein representation learning su et al, hayes et al, approach first encodes structural flexibility distribution latent token using discrete variational autoencoder, illustrated fig discrete latent encoding remove high frequency detail protein structures, forming structure language effectively capture uncertainty complex protein conformation fig conditional language modeling applied latent structure tokens, using amino acid type context capture sequence specific conformation distribution fig protein conformation finally reconstructed mapping structure token space learned decoder fig leveraging generative language modeling discrete latent space, slm bypass complexity equivariant constraint associated geometric symmetry benefit enhanced model capacity general framework, slm fully compatible existing language model lm architecture show promising scalability demonstrate versatility approach, introduce esmdiff, novel bert like structure language model instantiation fine tuned esm hayes et al, masked discrete diffusion austin et al, zhao et al, grounded slm framework experimental result across various conformation generation scenario demonstrate state art performance slm including representative esmdiff model, achieving order magnitude faster speed compared existing generative method proposed framework pave way new research avenue addressing protein conformation sampling challenge summarize key contribution follows comprehensively explore innovative conformation generation framework based language modeling latent space, open potential research avenue introduce esmdiff, novel fine tuned variant state art protein language model, built masked discrete diffusion demonstrate superior capability structure language model evaluating various conformation generation setting comparing existing method protein language model recent years, several language model protein sequence built among these, esm series rives et al, lin et al, hayes et al, similar model elnaggar et al, alley et al, garnered great attention wide range downstream application protein engineering meier et al, hand, auto regressive protein language models, based either recurrent neural network alley et al, transformer including progen madani et al, protgpt ferruz et al, able generate de novo sequence input controlling token specially, inverse folding model ingraham et al, jing et al, hsu et al, dauparas et al, gao et al, learn perform structure based protein design geometric aware encoders generative conformation sampling given intensive computation traditional md simulations, generative model used learn conformation distribution data driven fashion boltzmann generator et al, us normalizing flow fit boltzmann distribution target specific simulation data art et al extends using denoising diffusion model coarse grained protein conformation furthermore, eigenfold jing et al, str str lu et al, alphaflow jing et al, confdiff wang et al, dig zheng et al, leverage diffusion flow matching conditionally sample protein conformation learning pdb data recently, alphafold abramson et al, revised structure decoder alphafold diffusion based module diversified structure prediction quantized representation protein structure beside prevailing diffusion model protein structure, representation learning protein structure using discrete variational autoencoders dvae gained increasing attention recent year foldseek van kempen et al, one earliest attempt build dvae fast structure search alignment based this, saprot su et al, construct learned representation sequence structure token input, prott heinzinger et al, fine tuned existing language model accept structure token input pvqd haiyan et al, applied latent diffusion embedding space dvae conditional protein structure generation prosst li et al, trained autoencoder mean clustering applied latent space gaujac et al gao et al respectively build dvae large vocabulary learning protein structure representation remark work closely related concurrent research direction leveraging lm model efficiently perform conformation generation quantized representation protein structure refer framework structure language model describe detail notation protein residue identified sequence amino acid type vocabulary standard amino acid protein backbone structure represented composing atom position including backbone heavy atom encoder structure encoded sequence latent code pre specified vocabulary latent code structure token decoded first mapping embedding vector structure address conformation generation problem, start modeling sequence structure translation distribution interest derive learning objective section circumvent explicitly learning structure space, roto translation invariant latent representation introduced encode atomic protein structure given this, target distribution derived marginalizing joint distribution factorize joint distribution according bayes rule isolating latent variable denotes decoding distribution protein structure given structure token sequence, denotes conditional distribution structure tokens, respectively modeled neural network parameter set give rise evidence lower bound likelihood model distribution protein structure conditioned sequence introduced parameterized posterior distribution latent representation please refer appendix label app elbo full derivation eq directly optimizing right hand side eq intractable difficult since unknown posterior result, adopt one step expectation maximization em approach dempster et al, first jointly learning simple parameter free prior distribution followed optimization learned yield overall two stage separable training pipeline learning quantized representation structure prior fixed, begin maximizing elbo respect encoder decoder using protein structure sample context discrete latent spaces, process analogous training discrete vae dvae van den oord et al, learn quantized representation protein structure here, encoder map structure latent tokens, decoder reconstructs structure token prior fixed uniform stage learning prior latent token stage, fix learned parameter train prior maximizing elbo arg max since fixed, reconstruction term elbo cancel out, training reduces minimizing kl divergence kl equivalent performing maximum likelihood estimation, respect given categorical variables, formulation resembles translation task, allowing parameterized language model prior learned previous stage applied conformation generation, framed conditional generative modeling problem sequence structure seq str translation given input condition determines molecular topology, goal sample conformation ensemble this, first sample set latent variable prior distribution learned earlier, decode latents using decoder decoder jointly trained encoder first stage, ensuring sampled latents align reconstruction framework support roto translation invariant inference described algorithm next, illustrate approach two straightforward example structure language model slm encoder decoder decoder architecture encoder decoder given conditional nature translation, prior explicitly modeled encoder decoder architecture like raffel et al, decoder condition context factorizes structure token sequentially represents quantized structure token training objective negative log likelihood nll loss conditioned log decoder alternatively, latent prior modeled autoregressively using decoder architecture, gpt radford et al, serf prompt define training involves maximizing likelihood via nll minimization log iid sample data distribution structure associated amino acid sequence condition practice, add additional special token sep differentiate two modality inference involves sampling left right decoding order, defined autoregressive factorization language model figure briefly illustrates two modeling strategy building foundation slm, propose esmdiff instantiation based discrete diffusion model austin et al, esmdiff incorporates inductive bias seq str translation leverage protein foundation model esm hayes et al, masked diffusion fine tuning effectively fine tuning esmdiff also exemplifies large pretrained bert like masked language model adapted acquire additional generative capabilities, making well suited broader downstream task conformation generation discrete diffusion model austin et al, lou et al, sun et al, campbell et al, zheng et al, generally defined sequential process progressive noisy variable categorical variable denote one hot row vector discrete time case austin et al, forward marginal probability time following form composition markov kernel defined indicates transition probability matrix time represented cat indicates categorical distribution probability simplex eq also induce form marginal distribution cat cat correspondingly, posterior obtained reverse process austin et al, zhao et al shi et al discus discrete time diffusion process generalized time domain akin diffusion continuous space song et al, demonstrating continuous time limit notably, stationary distribution explicitly specified denoted choose state independent transition kernel simple form thus simplifying continuous time forward marginal strictly monotone decreasing function equation demonstrates discrete diffusion, defined explicit stationary distribution, viewed interpolation two categorical distribution controlled according eq reverse process diffusion defined eq take following form posterior distribution, indicator function concision reader referred appendix label app dd detail deriving eq unlike open ended text generation, protein conformation generation well defined within discrete diffusion models, condition input amino acid sequence, allowing output token correspond uniquely position input thus enjoy fixed length context window masked diffusion austin et al, lou et al, shi et al, sahoo et al, represents special case transition includes absorbing state denoted mask formulation, stationary distribution eq assigns probability mass unique special token mask mask mask convenience, define mask one hot vector representing mask masked diffusion, stochastic forward process map mask remains state thereafter ie, absorbing conversely, reverse process gradually unmasks denoises mask token produce data sample see appendix label app proof eq implies mask backward process simply copy unmasked token ie cat otherwise probability mass interpolates posterior approximated using parameterization neural net neural network output probability vector remains conformation generation, consider conditional case masked diffusion given amino acid type goal sample structure token eq utilizing conditional posterior posterior parameterized similarly incorporating condition backbone model, resulting achieve goal, reverse process simulated must effectively approximate data distribution feasible training objective optimize estimation conditional elbo within continuous time integral, resulting following loss see appendix label app loss detail sampled learned encoder corresponding amino acid condition data distribution implies loss applied latents st mask practice, employ monte carlo estimation compute integral discus implementation conditional denoising network using bidirectional encoder language models, bert devlin, first, consider sequential generalization masked diffusion sequence categorical variable let sequence discrete structure token due interpolation scheme eq eq assume conditional independence factorize posterior distribution across output tokens, represents th output channel neural network implement coincides bert style transformer architecture allow u take advantage existing protein foundation model, example esm hayes et al, sequence tokens, masked log term training objective eq replaced summation log notation defined modification following special consideration network position coupled encoding unlike general translation problem, slms maintain strict position position correspondence amino acid type latent token inductive bias enables u construct input embedding position follows embedding function linear transformation copying unmasked token mask remain spite model output zero mask since parameterize approximated clean data fully unmasked mask token cannot present output probability zero equivalent adding logit study, pre trained lm head esm replaced randomly initialized head augmented vocabulary fine tuning base setting start pre trained dvae established hayes et al structure tokenizer frozen structure quantization perform residue level receptive field local geometric neighborhood protein structure structure language model described section based state art language model follows adopts raffel et al, architecture bidirectional encoder autoregressive decoder gpt model joint distribution uni directional decoder like gpt radford et al, esm zero shot pre trained bert model multi modality data perform zero shot inference gibbs sampling esmdiff fine tuned variant pdb data using masked diffusion objective eq gpt, embed sequence token pre trained esm encoder provide model condition esmdiff, two different sampling paradigm gibbs ddpm considered see appendix detail cccccc codebefore body block method j pwd j tic j rg validity tm en rmsd en block msa based msa sub alphaflow block seq based eigenfold str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm baseline consider multiple open source model evaluation baseline protein multiple conformation generation, mainly categorized msa based method includes msa subsampling del alamo et al, bryant alphaflow jing et al, method rely inference time retrieval multiple sequence alignment msa single sequence based method eigenfold jing et al, leverage harmonic diffusion process conditioned omegafold wu et al, embeddings generate protein structures, str str lu et al, simulates round trip local diffusion conditioned input structure explore hypothetical conformations, esmflow jing et al, replaces alphaflow esmfold backbone specially tailored intrinsically disordered protein idp generation idpgan janson et al, result reported baseline obtained running inference pipeline based open source code detailed pipeline found appendix training data training data structure language model controlled contain pdb entry may st, cutoff aligned previous work jing et al, lu et al, hayes et al, trained pdb data make fair comparison training set filtered include monomeric structure max resolution length ranging form total size training data participating benchmark set discover potential slms conformation sampling, several relevant datasets considered benchmarking purpose simulation dynamic bpti shaw et al, conformational changing pair including fold switching chakravarty porter, ligand induced apo holo state salda et al, intrinsically disordered protein idp deposited protein ensemble database ped lazar et al, benchmarking task reflect different characteristic challenge conformation generations, provides comprehensive evaluation model first experiment, evaluate model generating conformation protein bovine pancreatic trypsin inhibitor bpti structural dynamic pattern bpti well acknowledged shaw et al m long md simulations, based five kinetic cluster revealed similar lu et al report jensen shannon j divergence distribution pairwise distance pwd time lagged independent component tic radius gyration rg clash free validity ensemble tm score root mean square deviation rmsd wrt kinetic cluster benchmark result shown table following wang et al also evaluate best distance generated sample cluster, shown table rmsd tm score calculated using tm score binary zhang skolnick, structural alignment note cluster difficult remote folding mode wang et al, yet slms achieve significant improvement modeling smaller matching rmsd ccccc codebefore body method rmsd rmsd rmsd rmsd rmsd msa based msa sub alphaflow seq based eigenfold str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm continue study task modeling predicting conformational change structural protein author jing et al curated two benchmarking set pairing data including pair fold switching protein chakravarty porter, apo holo pair ligand induced conformational change salda et al, evaluate modeling capacity conformation diversity following setting evaluation metric jing et al randomly sample shot ensemble five structure per target evaluate based correlation metric residue flexibility ensemble tm score zhang skolnick, evaluation result test set shown table nicetabular cccccc codebefore body block method block apo holo block fold switch resflex gl resflex pt tm en resflex gl resflex pt tm en block msa based msa sub alphaflow block seq based eigenfold str str pf str str sde esmflow block slm gpt esm zero shot esmdiff gibbs esmdiff ddpm different structural proteins, intrinsically disordered protein idp fixed stable tertiary structure normal condition idp possess inherent flexibility usually exist dynamic ensemble conformations, allowing adapt different binding partner cellular environment curated total entry protein ensemble database ped lazar et al, benchmarking set specific, select experimentally validated eg nmr spectroscopy structure ensemble excluding similar protein record training set avoid data leakage see appendix due disordered structural characterization idps, alignment based metric tm score applicable different target different size ensemble ten thousand follow metric used janson et al evaluate mean absolute error mae specifically pairwise distance, radius gyration, contact map predicted ensemble ground truth ensemble ccc codebefore body block method pairwise distance radius gyration contact map msa based msa sub alphaflow eigenfold idpgan str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm demonstrate efficiency slm, benchmark runtime slm compare diffusion based baseline measurement based elapsed wall clock time sampling ensemble across different protein length see appendix shown fig slms exhibit superior scalability respect protein size faster diffusion model like alphaflow, highlighting potential real world application work, propose novel conformation generation framework structure language model slms overall task divided two stage conditional sampling latent structure token roto translation invariant structure decoding develop train variety conditional language models, especially masked diffusion based esmdiff, fine tuned variant enhance capability esm adapting conformation generation unlike existing methods, slms perform amortized distribution learning within invariant latent space, leading efficient inference alleviating need geometric modeling, slms fully exploit scalability modern language model architecture take advantage advanced hardware optimization benchmarking result across various conformation generation task demonstrate compelling performance application potential slms summary, proposed method open intriguing novel research direction related community explore limitation current study present several limitation worth exploring future work firstly, one design advanced dvae architecture balance structure disentanglement reconstruction fidelity addition discrete latent space, continuous latent space also considered, example using latent diffusion model rombach et al, secondly, worthwhile exploring alternative slm instance specially tailored sequence structure translation consideration proper inductive bias lastly, outstanding performance msa based method also indicates potential build msa conditioned structure language model",biomolecules
"topoqa topological deep learning based approach protein complex structure interface quality assessment introduction result discussion conclusion material method appendix supporting text appendix table figure instruction reporting error graph representation protein complex proteingat topoqa model datasets topoqa even significant advance alphafold multimer af multimer alphafold af protein complex structure prediction, accuracy still comparable monomer structure prediction efficient effective quality assessment qa estimation model accuracy ema model evaluate quality predicted protein complex without knowing native structures, key importance protein structure generation model selection paper, leverage persistent homology ph capture atomic level topological information around residue design topological deep learning based qa method, topoqa, assess accuracy protein complex interface integrate ph topological data analysis graph neural network gnns characterize complex higher order structure gnns might overlook, enhancing learning relationship topological structure complex interface quality score topoqa model extensively validated based two widely used benchmark datasets, dbm af haf along newly constructed abag af dataset facilitate comparison af three datasets, topoqa outperforms af multimer based af rank show advantage af nearly half target particular, dbm af dataset, ranking loss lower af multimer based af rank obtained further, af multimer af also extensively compared nearly state art model far know found topoqa achieve highest top hit rate dbm af dataset lowest ranking loss haf dataset ablation experiment show topological feature significantly improve model performance time, method also provides new paradigm protein structure representation learning structure protein complex essential importance understanding molecular mechanisms, drug design discovery, protein design, etc even though experimental method resolve protein structures, tend time consuming expensive suitable large scale analysis data driven model developed protein structure prediction among them, alphafold significantly advanced protein structure prediction, achieving performance predicting monomer structure rival experimental method recently, alphafold multimer af multimer alphafold af developed predicting protein complex structure particular, af significantly improved accuracy antibody antigen complex prediction af diffusion model based framework considered various protein complex configuration generated using different random seed native structure absent, model quality assessment qa estimation model accuracy ema used selection top ranked configuration predicted structure qa ema model critical enhancing prediction reliability estimating model quality absence native structure fact, ema qa method important component critical assessment technique protein structure prediction casp biennial experiment advance benchmark protein structure prediction method first introduced separate category since casp ema method evolved years, primarily designed protein monomer mathematically, ema method grouped three category including consensus models, pseudo single models, single model consensus method assume near native predicted structure similar other, poorly predicted structure differ greatly assess model quality certain predicted structure pairwise comparison structure model pool, collection generated structure target sequence pairwise comparison measured score like q lddt dockq modfoldclust multicom qa notable example average score used assess quality structure consensus method usually employ well established model pool contrast, pseudo single model method generate model pool structure comparison two type approach computationally expensive performance rely accuracy model pool single model methods, model pool longer required, thus limitation single model divided two category energy statistical potential based deep learning based first type method energy function based physico chemical information constructed judgment made statistical result large amount observational data deep learning based method gnn dove dproqa complexqa graphgpsm usually represent protein structure graphs, design amino acid sequence, structural physico chemical feature node edge apply graph neural network model gnns qa approaches, protein often represented graphs, residue node contact residue edge model also consider atom node provide detailed representation general, gnn based qa method excel propagating information across entire graph, help capture global structural pattern provides insight overall folding protein molecule recently, topological data analysis topological deep learning developed explore high order topological geometric information within data one effective approach integration persistent homology ph provides robust mathematical framework capturing quantifying topological invariant across multiple scale enables identification complex, higher order structure beyond traditional gnn model integration demonstrated promising result across various domains, including biology chemistry, physics, image analysis ph incorporated different gnn modules, feature representation aggregation process pooling layer even loss function combining ph gnns, model better equipped capture complex structure show significant potential, particularly predicting property related large biomolecules, protein here, propose topological deep learning based model topoqa protein complex interface quality assessment first time model combined ph gnn protein structure representation learning one hand, simultaneously utilized powerful learning ability gnn representation ability ph capture high order local residue level structural information hand, local residue level information updated aggregated give global representation message passing module graph neural network local residue level, extract atom around residue point cloud, generate series simplicial complex according filtration process, calculate barcodes, vectorize using statistical property part initial node feature edge features, addition distances, also calculated pairwise distance atom two residues, facilitated detailed geometric representation protein complex interface global protein complex level, used module called proteingat update node edge embeddings, followed pooling information interface quality score prediction result show method topoqa one state art qa methods, showing outstanding performance across three benchmark datasets among these, dbm af haf widely used benchmark datasets, newly generated abag af dataset af validates robustness broad applicability approach three datasets, topoqa showed advantage af multimer based af rank, especially dbm af dataset, achieved ranking loss lower compared af multimer based af rank compared af qa module, advantage nearly half target compared state art qa method far know, topoqa achieves highest top hit rate dbm af dataset lowest ranking loss haf dataset ablation experiment show topological feature significantly improve model performance, increase time dbm af haf datasets, respectively approach provides new paradigm qa term topology, facilitating better protein structure learning topological representation protein complex directly influence performance deep learning model propose bipartite multipartite graph representation characterization protein complex interface shown figure a, since interface key importance protein complexes, focus interaction within interface represent bipartite multipartite graph figure show complete protein complex corresponding protein interface, respectively based extracted protein interface, construct bipartite interface graph model inter chain interaction shown figure d, bipartite graph, residue represented vertex inter chain contact represented edge bipartite structure allows u effectively capture complex interaction different chain within protein further, detailed residue level information incorporated graph representation considering special node feature edge feature different previous models, incorporate higher order geometric topological information local residual environment model using persistent homology analysis specifically, compute ph local point cloud residue apply element specific skill extract coordinate atom target residue surrounding atom point clouds, divide point cloud different subset according atom type carbon nitrogen oxygen c,n c,o n,o c,n,o construct simplicial complex using subset point cloud using ph, original point cloud data characterized topological barcodes use five statistic barcode vectorization minimum, maximum, mean, sum standard deviation compute dimensional dimensional barcodes vectorized dimensional topological features, added node feature computationally, node dimensional features, including dimensional basic feature dimensional topological feature basic feature include dimensional one hot encoding residue types, dimensional one hot encoding secondary structure types, dimensional relative solvent accessible surface area, dimensional torsion angle atomic interaction adjacent residue within protein interface key importance quality assessment generated protein complex leverage detailed atomic information, total edge feature based atomic distance two residue specifically, edge connecting two residues, atom residue divided two point cloud pairwise distance atom point cloud calculated grouped bin bin, count distance falling within bin used corresponding feature, capturing distribution atomic interaction residue extra edge feature distance atom considered, resulting dimensional edge feature propose special gnn architecture known proteingat shown figure b, proteingat model us multi head attention update node edge features, leverage predict interface quality score target node embedding layer attention coefficient computed using node embeddings edge embedding normalized final weight via softmax function updated node embedding layer computed using attention weighted information neighboring node updated edge embedding layer obtained concatenating updated node embeddings original edge embedding followed projection new vector space updating embeddings, apply average pooling node edge embeddings linear layer reduces pooled edge embeddings half dimension pooled node embeddings, highlighting importance node information concatenated embeddings passed multi layer perceptron mlp final output train model using mean squared error mse loss function, minimizing difference predicted value dockq score compared performance model two recently developed qa methods, complexqa dproqa demonstrated competitive performance recent studies, using training, validation, test set fair comparison blind capsp experiment, dproqa one top performer among single model method term tm score ranking loss following previous work also include two deep learning methods, gnn dove trscore well two classical energy based methods, goap zrank shown high hit rate evaluation specifically, referring compared method interface score iptm predicted af multimer self assessment module utilized extended version af rank method, based self assessment module af multimer, repurposed scoring protein complex generate iptm score af rank composite confidence score significantly outperformed ema method entered casp also use iptm af comparison, one advanced protein complex prediction model shown figure stacked ranking loss different datasets dbm af haf datasets, followed previous work used dockq reference metric abag af dataset, used dockq wave reference metric, evaluate interface complex figure a, across dbm af haf datasets, topoqa achieves lowest stacked ranking loss among eight method topoqa loss lower dproqa second best loss lower goap loss, lower af multimer based af rank loss shown figure b, topoqa also achieves lowest stacked ranking loss across three datasets dbm haf abag af topoqa ranking loss lower dproqa loss lower af multimer based af rank aggregating result across different datasets, topoqa demonstrates best overall performance table report ranking loss method dbm af dataset method achieves second lowest average ranking loss, higher loss dproqa lowest loss achieved ranking loss lower goap third lowest ranking loss lower complexqa fourth lowest ranking loss lower af multimer based af rank fifth lowest ranking loss three target etq, al topoqa correctly selects top model according dockq, achieves ranking loss table show hit rate different method dbm af dataset topoqa achieves highest hit rate three level selecting acceptable higher, medium higher high quality decoy worth noting topoqa achieves best possible top result medium high quality level shown table also report average result multiple experiment different random seed compared dproqa, topoqa achieves lower mean ranking loss demonstrates stable performance, standard deviation dproqa additionally, according top hit, topoqa outperforms dproqa acceptable level target table report ranking loss method haf dataset topoqa achieves lowest average ranking loss topoqa achieves ranking loss lower af multimer based af rank second lowest ranking loss lower zrank third lowest ranking loss lower dproqa ranking loss moreover, topoqa achieves lowest loss two target amv table show hit rate different method haf dataset topoqa achieves highest hit rate two level selecting medium higher quality high quality decoy acceptable level, topoqa hit rate slightly lower best result achieved method topoqa achieves best possible top result high quality level shown table haf dataset, topoqa outperforms dproqa lower mean lower standard deviation ranking loss additionally, topoqa better average hit rate acceptable medium levels, target average dproqa table report ranking loss top mean dockq wave method abag af dataset except af topoqa achieved lowest ranking loss highest top average dockq wave value, demonstrating advantage method select better conformation different conformation target achieved ranking loss lower complexqa ranking loss lower dproqa ranking loss worth noting that, dataset, topoqa also demonstrates better performance af multimer based af rank although topoqa outperform af overall, shown table achieves lower ranking loss target better top mean dockq wave score total target although training data significantly smaller af topoqa still show advantage nearly half targets, demonstrating potential topoqa model shown figure stacked correlation coefficient three datasets figure c, topoqa achieves highest stacked pearson correlation coefficient, value higher second best correlation coefficient achieved dproqa figure d, topoqa also achieves highest stacked spearman correlation coefficient, measured representing increase compared second best correlation coefficient overall, topoqa also show good performance correlation coefficient evaluation metric dbm af haf dataset, primarily used dockq capri criterion evaluate models, following previous work metric assess single protein interface, recent metric like q score dockq wave bdm evaluate interface shown table topoqa performed consistently well across different metrics, ranking loss dockq dockq wave q score additionally, correlation coefficient demonstrating robustness stability topoqa evaluating interface accuracy evaluate impact node topological atomic distance related edge features, performed ablation study removing specific component topoqa model, result shown table figure removed topological feature node kept basic feature result showed performance model greatly affected specifically, dbm af dataset, ranking loss worsened representing increase pearson correlation coefficient spearman correlation coefficient decreased reduction reduction respectively haf dataset, ranking loss worsened indicating increase, pearson spearman correlation coefficient decreased reduction reduction respectively removed atomic distance related edge features, keeping distance led decline model performance dbm af dataset, ranking loss worsened increase pearson correlation coefficient increased spearman coefficient dropping haf dataset, ranking loss worsened pearson spearman coefficient decreased respectively result show node topological feature edge feature related atomic distance effect improving model performance among them, shown figure node topological feature significant impact, removing topological features, sum model metric ranking loss negated dbm af haf datasets topoqa, respectively show powerful ability combining ph gnn great potential protein structure learning af multimer af developed protein complex structure prediction, compared monomer structure prediction, still room improvement accuracy propose topology based quality assessment method enhance model selection improve accuracy protein complex structure prediction previous studies, residue commonly used node construct graph gnn based prediction, help capture global structural pattern provides insight overall folding protein molecule integrate persistent homology gnns quality assessment, using ph capture atomic level topological information around target residue, thus enhancing model representation protein structure ablation study demonstrate incorporating ph significantly improves model performance method show great potential extended protein structure representation task ema qa method important part casp experiment recent casp ema, task involved target model including complex ranging dimer chain team casp ema, guijunlab rocketx chaepred, trained large datasets million decoys, respectively contrast, model trained smaller dataset decoys, primarily oligomeric protein believe larger dataset, topoqa could demonstrate greater potential compared method, topoqa, af multimer based af rank af across three datasets topoqa outperformed af multimer based af rank datasets, particularly dbm af dataset, ranking loss lower notably, trained topoqa using small dataset generated af multimer, significantly less training data used af multimer although overall performance topoqa high af demonstrates advantage nearly half targets, indicating potential furthermore, af currently provides quality score predicted structures, method offer greater applicability versatility model quality assessment currently, model, topoqa, designed assess global interface accuracy protein complex ema methods, however, also encompass evalutions global fold local accuracy global fold accuracy focus overall correctness complex structure, utilizing metric tm score gdt score evaluate global topology contrast, local accuracy assesses residue level precision, employing metric like lddt cad score reference value future,we plan incorporate multi task learning broaden model capability interface accuracy evaluation comprehensive assessment accuracy work, present topological deep learning based method, topoqa, protein complex structure interface quality assessment constructing graph residue node combined gnns common approach, allow modeling complex interaction residues, thereby capturing important global structural pattern enhance protein structural representation incorporating topological information using ph residue, extract topological feature neighboring atom based specific atomic combination ablation experiment reveal introduced topological feature significantly enhance model feature removed, model performance drop original level two datasets, respectively compared models, method achieves highest hit rate dbm af dataset lowest rank loss haf dataset additionally, multiple experiment different random seed evaluation reference metric show topoqa produce stable results, demonstrating robustness three datasets, model demonstrates advantage af multimer based af rank, particularly dbm dataset, topoqa loss lower af multimer additionally, compared af qa module, topoqa show advantage nearly half target used training validation set dproqa complexqa combined two datasets divided training validation set multimer af dataset maf dataset comprises complex structure predicted alphafold af multimer, protein complex target sourced evcoupling deephomo datasets maf dataset contains decoy dockground dataset dockground dataset contains protein complex targets, average correct incorrect decoy used following three test datasets test model docking benchmark af dbm af dataset, comprises antibody antigen complex target decoy model heterodimer af haf dataset also generated af multimer, contains heterodimer target decoy model abag docking benchmark af abag af dataset previous work compiled non redundant antibody antigen dataset selected protein released target used af generate conformation per target, running five time different seed abag af dataset consists target conformation simplicial complex simplicial complex collection simplices geometric object points, edges, triangles, higher dimensional counterpart combined way preserve geometric structure simplex fundamental building block simplicial complex, defined convex hull affinely independent point simplex vertex, simplex edge, simplex triangle, simplex tetrahedron dimension simplex number vertex minus one simplicial complex encodes richer, higher dimensional information graph, making ideal framework describing shape structure complex object ability capture relationship beyond pairwise connection allows deeper analysis object topological geometric property homology group homology group algebraic structure capture topological invariant simplicial complex, providing information shape structure specifically, describe feature connected components, loops, void different dimension group crucial distinguishing space similar local structure different global topological properties, making powerful tool analyzing intrinsic characteristic simplicial complex given simplicial complex chain formal sum simplices coefficient field, typically set chain form abelian group, denoted boundary operator map simplex dimensional face represents simplex obtained omitting vertex simplex key property applying boundary operator twice result zero allows u define cycle group ker element boundary boundary group im boundary higher dimensional simplices th homology group defined quotient rank known betti number represents number dimensional hole simplicial complex persistent homology classical homology capture topological feature space, contain geometry information like scale object persistent homology address tracking appearance disappearance homology class filtration, providing additional geometric scale related information make powerful tool analyzing shapes, capturing feature persist across multiple scale simplicial complex filtration sequence nested subcomplexes filtration progresses, topological feature like connected components, loops, void created eventually disappear persistent homology track feature filtration persistent th homology group defined measure long homology class persists across different filtration level use persistent homology feature, track birth time death time generator persistent homology group birth time mark filtration level generator first appears, death time indicates either merges another generator vanishes time provide valuable insight persistence topological feature across different scale assess interface quality, retained interface residue within atom residue chain focus inter chain interactions, consider inter chain edges, defined connection residue different chain distance less construct interface graph residue represented atom vertex inter chain contact edge residue, use ph extract topological information specifically, residue consider coordinate set includes coordinate neighboring atom within cut distance choose atom target residue apply element specific skill divide point cloud different subset according atom type c,n c,o n,o c,n,o point cloud atom type, apply vietoris rip complex calculating dimensional ph, simplicial complex generated set point metric space connecting point edge pairwise distance threshold specifically, simplex formed every pair vertex apart filtration value apply alpha complex calculating dimensional ph given set point metric space radius parameter alpha complex simplicial complex constructed follows simplex included vertex enclosed ball radius contains point inside boundary ball, apart vertex using given simplicial complexes, construct filtration simplicial complex compute associated ph barcodes barcode visual representation bar corresponds specific generator ph groups, generator different dimension represent distinct topological features, connected component dimension loop dimension void higher dimension left endpoint bar mark birth generator, right endpoint mark death length bar, representing difference birth death values, quantifies persistence generator, providing insight significance within underlying topological space get fixed sized feature vector persistent homology barcodes, consider five statistic average avg standard deviation std maximum max minimum min sum sum dimensional barcode, since birth always use death calculation dimensional barcode, take birth, death persistence bar statistic calculation also filtered barcodes bar late death time dimensional barcode bar short lifetime bar typically considered noise data use following criterion filter summary, residue, methodology yield feature vector dimensionality statistic dimensional barcode statistic birth, death, persistence bar dimensional barcode providing robust foundation subsequent quality prediction task added dimensional edge feature edge formed two residues, first dimension represents distance atoms, remaining dimension capture atomic distance two residue specifically, feature derived constructing bipartite graph two point clouds, point cloud representing atom corresponding residue computed pairwise distance atom two point cloud divided interval bin bin, constructed bipartite graph using edge corresponding distance within bin, count edge bipartite graph used feature corresponding dimension edge connecting two residue proteingat module designed update node edge embeddings based multi head attention, perform graph level regression prediction embedding update use multi head attention mechanism below, take calculation one head example illustrate calculation process assume node embedding edge embedding layer respectively, node edge embedding layer respectively update formula equation computes attention coefficient node node trainable weight matrix map source node, end node edge feature new feature space respectively activation function equation us softmax function normalize attention coefficient obtain final weight set neighbor node node equation update node embedding, trainable weight equation us node embeddings layer edge embeddings layer update edge embeddings layer represents trainable weight matrix denotes vector concatenation operation graph level regression graph level prediction, use node edge information assume final node embedding edge embedding respectively, node feature edge feature pooling updates, applied average pooling embeddings node edge edge embeddings, added linear layer reduce dimension half node embeddings, emphasizing greater importance node information compared edge feature integrated node edge information, fed concatenated vector mlp three stacked linear layer final put training, model optimized minimize mse loss work supported part singapore ministry education academic research fund tier grant rg tier grant moe ep moe ep program china scholarship council grant interdisciplinary innovative research program school interdisciplinary studies, renmin university china also supported public computing cloud, renmin university china intuitively illustrate performance topoqa classifying decoys, use principal component analysis pca distributed stochastic neighbor embedding sne reduce dimension encoding generated topoqa visualization pca linear dimension reduction method project data new coordinate system orthogonal transformation sne nonlinear dimension reduction method preserve local structure similarity data minimizing kullback leibler divergence extracted feature embedding vector penultimate layer model input data dimension reduction mapping high dimensional feature two dimensional space, observe distribution acceptable higher quality incorrect quality sample lower dimensional space shown figure applied two dimension reduction technique two test set dbm af haf acceptable decoy incorrect decoy relatively separated low dimensional space, topoqa distinguish two type decoy case visualization result show topoqa strong classification generalization capability unseen data, learned feature representation effectively capture relationship structure quality feature scale selected different order improve stability model avoid impact scale difference model, normalized feature node edge use min max normaliztion, assume node edge feature graph normalized feature evaluation metric divided reference metric statistical metric reference metric assess accuracy structural models, statistical metrics, ranking loss, evaluate ability qa method predict reference metric utilized following reference metric dockq combine three interface similarity metric rmsd, ligand model relative reference structure rmsd, interface region decoy model reference structure fraction atom pair correctly predicted decoy model dockq continuous value larger value, higher interface quality capri criterion combine rmsd, rmsd classify predicted structure four level high quality, medium quality, acceptable quality, incorrect dockq wave variation dockq obtained weighting dockq score interface q score represents fraction shared interface contact residue different chain distance two structure range q score q score close mean interface similar decoy let predicted quality score reference value used following statistical metric pearson correlation coefficient used measure linear relationship predicted quality value reference value spearman correlation coefficient used measure monotonic relationship two variable rank ranking loss used measure ability qa model correctly select top model ranking loss difference highest reference value reference value corresponding top decoy selected qa method top hit rate represented three number separated character three numbers, order, represent many decoy acceptable higher quality, medium higher quality, high quality among top ranked decoy continuing ",biomolecules
"mofflow flow matching structure prediction metal organic framework introduction related work preliminary method experiment conclusion ethic statement appendix data statistic appendix glossary appendix implementation detail appendix defining local coordinate building block appendix model architecture instruction reporting error representation mof structure flow matching riemannian manifold construction local coordinate flow matching mof structure prediction model architecture structure prediction property evaluation scalability evaluation comparison self assembly algorithm metal organic framework mofs class crystalline material promising application many area carbon capture drug delivery work, introduce mofflow, first deep generative model tailored mof structure prediction existing approaches, including ab initio calculation even deep generative models, struggle complexity mof structure due large number atom unit cell address limitation, propose novel riemannian flow matching framework reduces dimensionality problem treating metal node organic linkers rigid bodies, capitalizing inherent modularity mofs operating space, mofflow effectively capture roto translational dynamic rigid component scalable way experiment demonstrates mofflow accurately predicts mof structure containing several hundred atoms, significantly outperforming conventional method state art machine learning baseline much faster metal organic framework mofs class crystalline material recently received significant attention broad range applications, including gas storage li et al, gas separation qian et al, catalysis lee et al, drug delivery horcajada et al, sensing kreno et al, water purification haque et al, particularly valued permanent porosity, high stability, remarkable versatility due tunable structure particular, mofs tunable adjusting building blocks, ie, metal node organic linkers, modify pore size, shape, chemical characteristic suit specific application wang et al, consequently, growing interest developing automated approach designing simulating mofs using computational algorithm crystal structure prediction csp task central importance automated mof design simulation importance task lie fact important function mofs, pore size, surface area, stability, directly dependent crystal structure conventional approach general csp based heavily ab initio calculation using density functional theory dft kohn sham, often combined optimization algorithm random search pickard needs, bayesian optimization yamashita et al, iteratively explore energy landscape however, reliance dft computation computationally expensive, especially large complex system mofs deep generative model promising solution accelerate prediction mof structure especially, diffusion model ho et al, flow based model lipman et al, shown success similar molecular structure prediction problems, eg, small molecule xu et al, jing et al, folded protein jing et al, lin et al, protein ligand complex corso et al, general crystal without building block constraint gebauer et al, xie et al, jiao et al, miller et al, model iteratively denoise random structure using neural network act similar force field guiding atom position toward minimum energy configuration contribution work, introduce mofflow, first deep generative model tailored mof structure prediction mofflow leverage modular nature mofs, decomposed metal node organic linkers figure label decomposition enables u design generative model predicts roto translation building block match ground truth structure achieve this, based riemannian flow matching chen lipman, propose new framework generates rotations, translations, lattice structure building block design underlying neural network composition building block encoder parameterized equivariant graph neural network based new attention module encoding roto translation lattice parameter mof note method competes existing deep generative model gebauer et al, xie et al, jiao et al, miller et al, general csp encompass mofs special member however, method specialized mof structure prediction exploiting domain knowledge local structure mof building block shared across different mof structure particularly useful reducing large search space mof structure consider mofs atom per unit cell boyd et al, whereas crystal general csp consist atom per unit cell jain et al, jiao et al, fact, confirmed experiments, recent deep generative model jiao et al, general csp fails scale large system size mofs also aligns torsional diffusion jing et al, improved existing molecular conformer generation algorithm xu et al, eliminating redundant degree freedom benchmark algorithm mof dataset compiled boyd et al consisting structure compare conventional deep learning based algorithm crystal structure prediction notably, mofflow achieves match rate unseen mof structures, whereas existing methods, despite computationally expensive, barely match also demonstrate mofflow capture key mof property scale efficiently structure containing hundred atom crystal structure prediction csp traditional approach csp rely density functional theory dft identify energetically stable structure generate candidate structures, heuristic technique random sampling pickard needs, simple substitution rule wang et al, employed, alongside sophisticated optimization algorithm bayesian optimization yamashita et al, genetic algorithm yamashita et al, particle swarm optimization wang et al, address computational burden dft calculations, many study used machine learning surrogate energy evaluation jacobsen et al, podryabinkin et al, cheng et al, recently, deep generative model emerged promising alternative optimization based method court et al, hoffmann et al, noh et al, yang et al, hu et al, kim et al, ren et al, notably, jiao et al proposes equivariant diffusion based model capture periodic invariance crystal structure distributions, lin et al jiao et al additionally consider lattice permutation space group constraints, respectively miller et al us riemannian flow matching generate high quality sample fewer integration step however, method face significant challenge predicting mofs structures, often consist hundred atom per unit cell mof structure prediction unlike general csp, variety algorithm developed, mof structure prediction remains significant challenge conventional mof structure prediction method heavily rely predefined topology connect mof building block marleny rodriguez albelo et al, wu jiang, restricting discovery structure new topology address limitation, darby et al proposes combine ab initio random structure searching airs pickard needs, wyckoff alignment molecule wam method however, reliance airs make computationally expensive also note recent work fu et al, considered related, yet different problem mof generation based deep generative model include structure generation flow matching flow matching simulation free approach training continuous normalizing flows, originally introduced lipman et al since introduction, various extension proposed, generalization riemannian manifold chen lipman, efficiency improvement optimal transport tong et al, pooladian et al, due flexibility computational efficiency, flow matching made notable progress several related domains, including protein generation yim et al, bose et al, molecular conformation generation song et al, csp miller et al, mof representation crystal structure mof represented periodic arrangement smallest repeating unit called unit cell unit cell containing atom represented tuple atom coordinates, atom type denoting set possible elements, lattice parameter describes periodicity structure miller et al, luo et al, particular, lattice parameter transformed standard lattice matrix defines infinite crystal structure set integer representing periodic translation unit cell block wise representation mofs introduce blockwise representation mofs decompose given unit cell constituent building blocks, ie, metal node organic linkers blockwise representation tuple corresponds building block corresponds set building block roto translation moreover, block atom atom type local coordinate main assumption building block composed roto translation form mof structure, ie, atomwise representation expressed blockwise representation result roto translated local coordinate represented group action express global coordinate concatenation without loss generality flow matching method train continuous normalizing flow cnf chen et al, without expensive ordinary differential equation ode simulation lipman et al, here, introduce flow matching generalized riemannian manifold chen lipman, cnf riemannian manifold consider smooth connected riemann manifold metric point associated tangent space inner product consider learning cnf defined ode time dependent smooth vector field vector field transforms prior distribution according following push forward equation divergence operator conditional flow matching riemannian manifold goal cnf learn vector field transforms simple prior distribution closely approximates target distribution given vector field corresponding probability path one train neural network flow matching objective norm induced metric however, flow matching objective lack analytic form transforms prior target key insight conditional flow matching objective instead learn conditional vector field data point defined follows let dirac distribution key idea conditional flow matching one derive conditional vector field marginalizes data point accordingly induce vector field transforming prior desired distribution construct chen lipman proposes defining conditional flow geodesic path minimum length curve connecting two point exp log exp log exponential logarithmic map point respectively desired conditional vector field derived time derivative, ie, optimum, generates starting point end point inference, sample prior propagate using one existing ode solver note training step faster method based adjoint sensitivity chen et al, since conditional flow matching require solving ode defined neural network section, introduce mofflow, novel approach mof structure prediction based rigid body roto translation building block express global atomic coordinate end, using riemannian flow matching framework, learn cnf predicts blockwise roto translation lattice parameter given building block compared conventional csp approach defined atomic coordinate jiao et al, lin et al, miller et al, mofflow enjoys reduced search space, ie, dimensionality blockwise roto translation atomic coordinate respectively incorporate mof symmetries, devise scheme consistently define local coordinate regardless initial pose building block given building block goal define global local function defines consistent local coordinate system is, function satisfy random conformation building block define property satisfied composition translation subtracting centroid rotation aligning principal component analysis pca ax here, denotes subtraction centroid denotes rotation align building block pca ax whose sign fixed reference vector, following gao nnemann see appendix detail section, present approach training generative model using flow matching framework first explain method ensures invariance introduce metric independent treatment component next, outline key element flow matching ie, definition priors, conditional flows, training objective preserve crystal symmetries, design framework generative model invariant rotation, translation, permutation atom building block rotation invariance guaranteed using rotation invariant lattice parameter representation canonicalizing atomic coordinate based standard lattice matrix miller et al, luo et al, translation invariance achieved operating mean free system building block centered origin ie, way ensure translation invariance invariant probability measure exists yim et al, permutation invariance addressed using equivariant graph neural network satorras et al, transformer vaswani, backbone metric following yim et al treat independently defining additive metric here, inner product defined tr denoting lie algebra prior rotation translation prior chosen uniform distribution standard normal distribution respectively lattice parameter follow miller et al use log normal uniform distribution specifically, lengths, let lognormal parameter learned maximum likelihood objective appendix angles, use niggli reduction grosse kunstleve et al, constrain distribution range conditional flow following chen lipman train model match conditional flow defined along geodesic path riemannian manifold here, exp exponential map log logarithmic map point definition, conditional vector field derived time derivative training objective instead directly modeling vector fields, leverage closed form expression enables parameterization network predict clean data intermediate mof structure achieve this, train neural network approximate clean data, expressed regression clean data dataset, uniform distribution defined interval loss coefficient see appendix here, describe architecture neural network used predict clean data two key module atom level update layer obtain building block embeddings atomic resolution, building block level update layer aggregate update information mof building block resolution predict final building block embeddings follows, describe module one one atom level update layer atom level update layer figure process building block representation output building block embedding graph neural network operating undirected graph constructed adding edge pair atom within cutoff distance initializes atom wise feature atom type edge feature atomic distance layer update atom feature follows set updated atom features, denotes neighbor atom graph multi layer perceptrons mlps finally, building block embedding obtained applying mean pooling node embeddings last layer followed concatenation sinusoidal time embedding vaswani, mlp block level update module layer update module figure iteratively update prediction along block feature pairwise feature prediction initialized intermediate flow matching output node feature initialized atom level update layers, edge feature initialized follows dgram computes distogram binning pairwise distance equally spaced interval finally, block level update module defined follows updated prediction feature importantly, nodeupdate operator consists newly designed mofattention module followed pre layer normalization transformer xiong et al, mlp residual connection edgeupdate backboneupdate module implemented yim et al latticeupdate identity function lattice parameter except last layer final layer, lattice parameter predicted mean pooling block feature followed mlp complete detail update module appendix particular, mofattention module modification invariant point attention module proposed jumper et al processing protein frame modification consists adding lattice parameter input simplification removing edge aggregation information particular, lattice parameter embedded using linear layer added offset attention matrix building block provide detail algorithm input node feature edge feature rotation translation lattice parameter number building block number head number non rotating channel number rotating channel output updated node feature goal experiment address two question accuracy structure prediction accuracy mofflow compare approach scalability performance mofflow vary increasing number atom building block address first question, section compare structure prediction accuracy mofflow conventional deep learning based method furthermore, section evaluates whether mofflow capture essential mof properties, validating accuracy prediction second question answered section analyze performance mofflow increasing system size additionally section compare mofflow self assembly algorithm fu et al, integrating approach dataset use dataset boyd et al containing mof structure following fu et al apply metal oxo decomposition mofid bucior et al, decompose structure building block filtering structure fewer blocks, split data train valid test set ratio full data statistic appendix baseline compare model two type method optimization based algorithm deep learning based method traditional approach, use cryspy yamashita et al, implement random search r evolutionary algorithm ea deep learning, benchmark diffcsp jiao et al, generates structure based atom type mof specific method excluded due lack public availability metric evaluate using match rate mr root mean square error rmse compare sample ground truth using structurematcher class pymatgen ong et al, two set threshold stol ltol angle tol used alignment general csp literature jiao et al, chen lipman, account difficulty predicting large structure mr proportion matched structure rmse root mean squared displacement normalized average free length per atom also measure time required generate samples, averaged across test set implementation r ea use chgnet deng et al, structure optimization generate sample rs, ea start initial, populations, generation due high computational cost large crystals, generating sample feasible diffcsp, follow hyperparameters jiao et al train epoch method us adamw optimizer loshchilov, learning rate use maximum batch size run inference integration step generate sample diffcsp method implementation detail appendix result table present results, mofflow outperforms baseline optimization based method yield zero mr, highlighting challenge using conventional atom based approach large system diffcsp also performs poorly, underscoring need incorporate building block information mof structure prediction achieve mr stol threshold lenient practical application however, include multi level comparison visualization comparing sample mofflow diffcsp shown figure section, demonstrate mofflow accurately capture key property ground truth mof structures, offering detailed assessment prediction quality beyond match rate rmse property crucial various mof applications, gas storage catalysis specifically, evaluate volumetric surface area vsa gravimetric surface area gsa largest cavity diameter lcd pore limiting diameter pld void fraction vf density dst accessible volume av unit cell volume ucv definition detail property provided appendix comparison, use diffcsp representative general csp approach exclude optimization based baseline yield meaningful result test structure section generate single sample compute relevant property using zeo willems et al, filter sample match criterion section use integration step model measure performance rmse result table show mofflow consistently yield lower error diffcsp across evaluated property demonstrates ability produce high quality prediction preserving essential mof characteristic additionally, figure visualizes property distributions, model closely reproduces ground truth distribution capture key characteristic contrast, diffcsp frequently reduces volumetric surface area void fraction zero, highlighting limitation conventional approach accurately modeling mof property here, demonstrate mofflow enables structure prediction large systems, challenge general csp method evaluate performance scale system size, analyze match rate function number atom building block compare result diffcsp representative general csp approach generate single sample test structure use threshold visibility result figure present findings, axis representing number atoms, binned range final bin includes atom count beyond last range, without upper limit mofflow consistently outperforms diffcsp across atom range approach show gradual performance degradation atom count increases, diffcsp suffers sharp decline system atom fails predict structure atom contrast, method maintains high match rate even structure exceeding atom per unit cell, highlighting effectiveness leveraging building block information mof structure prediction additionally, figure show match rate scale number building block result show minimal performance degradation, demonstrating model effectively handle larger number building block efficiently scale large crystal structure make evaluation comprehensive, also consider self assembly algorithm used fu et al baseline, although performance directly comparable self assembly sa algorithm optimization based method predicts rotation maximizing overlap building block connection point since algorithm requires input, directly applicable structure prediction therefore, conduct ablation combining self assembly algorithm predicted value note self assembly algorithm defines centroid center mass connection points, account offset implementation result table show mofflow alone outperforms combination self assembly algorithm, indicating learning building block orientation lead accurate mof structure prediction heuristic based overlap optimization additionally, method offer faster inference, demonstrating efficiency compared optimization based approach propose mofflow, building block based approach predicting structure metal organic framework mofs approach significantly outperforms general crystal structure prediction algorithm quality efficiency fail account modularity mofs additionally, mofflow scalable, successfully predicting structure composed thousand atom describe experimental detail hyperparameters appendix provide code model checkpoint anonymous openscience mofflow framework target advance porous material discovery, deeply related carbon capturing, catalysis design, drug discovery believe work improve quality human life assisting resolving global warming drug design however, notice caution due misuse developing hazardous material product may harmful specific usage section, present data statistic represent characteristic mof dataset consider mof dataset boyd et al dataset generated mof generating algorithm based topology graph theory dataset distributed materialscloud mention section us filtered strucutures fewer block dataset divided train, valid test ratio statistic data split represented table label label structural property section, introduce structural property measured property calculated using zeo software package developed willems et al zeo provides high throughput geometry based analysis crystalline porous materials, calculating critical feature pore diameters, surface area, accessible volume, essential evaluating material performance application gas storage catalysis specifically, calculated property including volumetric surface area vsa surface area per unit volume gravimetric surface area gsa represents surface area per unit mass largest cavity diameter lcd represents diameter largest spherical cavity within material pore limiting diameter pld defined smallest passage molecule must pas access internal void void fraction vf martin haranczyk, ratio total pore volume structure total cell volume density dst refers mass per unit volume material accessible volume av indicating volume available center given probe molecule within pore unit cell volume ucv representing total volume repeating unit cell crystal structure parameter provide critical insight mof porosity, surface area, ability store transport gases, recent study show correlation property bulk material krishnapriyan et al, training detail employ timestepbatch algorithm yim et al, efficiently construct batch method generates batch applying multiple noise level single data instance, ensuring uniform batch size manage memory constraints, cap batch size number atom model trained eight gb nvidia rtx gpus epochs, taking approximately day hyperparameters table table show model training hyperparameters mofflow, respectively practice, generate independently, allowing distinct dimension non rotating channel represented tuple, specified order set log normal distribution parameter lattice length computed training data closed form maximum likelihood estimation baseline diffcsp jiao et al, change edge construction method original fully connected radius graph cutoff since fully connected graph feasible large size crystal like mofs use batch size cope memory constraint option followed default hyperparameter diffcsp trained epochs, taking approximately day convergence gb nvidia rtx gpu random search r evolutionary algorithm ea structure prediction, considered cryspy yamashita et al, software deep learning based structure optimizer deng et al, set symmetry based search r constructed structure per sample also, set ea initial r ran maximum generation crossovers, permutations, strains, elite population considered tournament selection function tournament size used energy based optimization r ea, since exists publicly opened software mof crystal structure prediction code implementation built upon githubcom microsoft protein frame flow, githubcom microsoft mofdiff, githubcom gcorso diffdock, githubcom vgsatorras egnn appreciate author yim et al, fu et al, corso et al, satorras et al, contribution following, gao nnemann use principle component analysis pca backbone since equivariant sign specifically, denote pca order decreasing eigenvalues, is, sign preserved upon rotation define consistent direction, gao nnemann suggests use equivariant vector function then, final equivariant ax defined however, find definition insufficient application building block dimensional exhibit symmetry respect origin thus cases, define ie, vector centroid closest atom since building block symmetric, still fulfills equation permutation, handled gnn transformer here, provide detail nodeupdate edgeupdate backboneupdate module implementation follows yim et al jumper et al exception mofattention module transformer use pre layer normalized version xiong et al, module introduced notation function algorithm defined input output input output input output continuing ",biomolecules
"quickbind light weight interpretable molecular docking model introduction method result discussion outlook acknowledgment disclosure funding supplementary information appendix si algorithm appendix si protein ligand feature appendix si cropping appendix si hyperparameter screening appendix si training detail appendix si exemplary prediction appendix si pb failure mode appendix si correlation physicochemical feature appendix si additional interpretability study appendix si binding affinity prediction appendix si virtual screening result appendix si retrospective comparison af instruction reporting error dataset evaluation metric model architecture model performance model interpretability case study predicting ligand bound pose target protein key component early stage computational drug discovery recent development machine learning method focused improving pose quality cost model runtime high throughput virtual screening applications, expose capability gap filled moderately accurate fast pose prediction end, developed quickbind, light weight pose prediction algorithm assess quickbind widely used benchmark find provides attractive trade model accuracy runtime facilitate virtual screening applications, augment quickbind binding affinity module demonstrate capability multiple clinically relevant drug target finally, investigate mechanistic basis quickbind make prediction find learned key physicochemical property molecular docking, providing new insight machine learning model generate protein ligand pose virtue simplicity, quickbind serve effective virtual screening tool minimal test bed exploring new model architecture innovation model code weight available github repository small organic molecule ligand major class drug act binding protein targets, thereby affecting functionality interfering molecular pathway disease distinct advantages, including ease synthesis, administration, cell permeability, render indispensable pharmaceutical modality early stage drug discovery, structure determination protein ligand complex critical scientific tool, provide understanding molecular determinant binding enable optimization drug affinity selectivity however bottlenecked costly cumbersome experimental procedures, computational molecular docking promise overcome supplemented estimate strength binding interaction, computational tool used virtually screen large space drug like molecule viable drug candidate serve starting hypothesis subsequent experimental investigation development existing computational method achieve high quality prediction cost increasingly long runtimes, caused, case conventional physical methods, need sample numerous binding location poses, case machine learning ml based method complexity underlying neural computation implicitly modern method largely divided molecular docking co folding molecular docking, approximate protein structure assumed known, whereas co folding protein ligand structure predicted scratch although new development, co folding become focus much recent research activity, including rosettafold atom rfaa neuralplexer umol alphafold af nonetheless, drug discovery campaign known potentially well studied protein target, often unnecessary predict protein structure independently every ligand, making molecular docking attractive alternative given higher speed due assumed rigidity protein ml based docking method divided targeted docking, requires specifying approximate binding pocket, blind docking, first ml method tackle latter equibind predicts isolated, bound conformation ligand us keypoint alignment mechanism identify rotation translation needed dock ligand binding pocket subsequent method employ complex architecture particular, tankbind bind first partition protein functional block using rank predict interaction given ligand block, choose final pose based predicted binding affinity tankbind confidence score bind architecture include component inspired alphafold af evoformer module importantly, tankbind predicts intermolecular distance map converted final coordinate numerical post optimization, whereas bind operates ligand coordinate directly fabind build upon bind integrating prediction location binding pocket main model, whole process becomes end end differentiable another leap forward made diffdock diffusion based generative model that, starting input conformer, predicts change torsion angle well transformation needed dock ligand protein inductive bias focus relevant degree freedom coupled generative formulation led large improvement accuracy increased runtimes recently, advance come integration protein language model pretraining technique geared towards molecular docking tasks, substantial increase model size, shift towards generative approach combination, trend led considerable increase computational cost ml based molecular docking, level prohibitive virtual screening work develop quickbind, light weight method rigid, blind molecular docking aimed virtual screening application trading accuracy speed quickbind performs well pdbbind test set, particular unseen protein considered, substantially faster diffdock leveraging af architecture problem formulation figure quickbind reason protein using residue level representation lieu atomistic one, permitting fast implicit accounting side chain flexibility accommodate additional degree freedom introduced small molecule ligands, quickbind incorporates new framing strategy invariant point attention ipa module af also include binding affinity prediction module facilitate virtual screen applications, capability typically absent docking co folding method showcase utility versatility quickbind predicting binding affinity structure multiple important drug target across various protein families, investigate interpretability model better understand biophysical basis prediction train test quickbind using pdbbind dataset additionally assess using posebusters pb benchmark pdbbind widely used assess molecular docking method using temporal split proposed equibind contains crystal structure binding affinity protein ligand complex training validation set comprise complexes, respectively, published test set contains complex published later ligand overlap three partition pb contains diverse complex unique protein drug like ligand released since therefore disjoint complex pdbbind training set quantify success based percentage prediction symmetry corrected ligand heavy atom root mean squared deviation rmsd less success rate criterion widely used, residual deviation true bound conformation materially impact downstream analysis optimization evaluating model purely success rate account chemical physical validity, assess criterion using pb suite prediction pas pb test whose rmsd deemed pb valid quickbind adapts alphafold architecture task protein ligand pose prediction figure take input protein sequence structure well chemical graph ligand conformer generated rdkit input combined yield unified first order single representation second order pairwise pair representation passed modified evoformer stack omits column wise self attention multiple sequence alignment used processing evoformer, structure module take updated single pair representation input well residue ligand reference frame using new framing strategy ligand atom described iteratively update ligand heavy atom coordinate structure module modified af ipa module gated cross attention performed single representation ligand protein coordinate update step algorithm protein atom held fixed quickbind us evoformer structure module block full algorithm detail given section si af us reference frame represent geometry protein residue translation vector corresponds coordinate atom rotation matrix, anchored coordinates, canonically constructed n, coordinate encode orientation residue backbone representation natural linear branched polymer atom arbitrary small molecules, canonical frame construction approach emergence co folding methods, two recent model proposed framing strategy small molecule quickbind employ new approach first, atom index reordered based canonical atom ranking rdkit heavy atom, coordinate treated atom coordinate two adjacent atom lowest index treated atom atom one bond, use dummy atom algorithm construct atom reference frame using procedure employed residue frame using framing strategy, found ipa component structure module, updating rotation matrix ligand atom frame improves performance, unlike approach neuralplexer rfaa update translation component passively reconstruct frame note af use reference frame reason protein ligand complexes, use framing strategy calculate predicted aligned error af reference frame constructed using two closest atom given center atom, atom two neighbors, frame ignored experimented analogous strategy found approach work better loss function adopt modified version frame aligned point error fape used af fape computed performing set alignment predicted reference frame residue aligned original reference frame target structure fape average, clamped rmsd predicted target structure alignment molecular docking, fape reformulated combination two component rmsd predicted target ligand atom position based ligand frame alignment residue frame alignment final quickbind model trained using combined fape loss, intermediate fape loss acting output every structure module block, kabsch rmsd loss corresponding ligand rmsd superimposition predicted target ligand using kabsch algorithm model detail given section si si training final quickbind model, aspect architecture optimized using two smaller variants, quickbind quickbind section si result hyperparamater screen summarized table si first assess quickbind pdbbind test set figure compare ml based rigid docking method including equibind, tankbind, bind, fabind, diffdock, neuralplexer employed blind molecular docking rather co folding exclude co folding method comparison evaluated pdbbind virtual screening involve billion molecule docking runtimes critical consideration average runtime s, quickbind order magnitude faster traditional docking method diffdock, recent co folding method accuracy wise, quickbind middle pack, outperforming ml based rigid docking method except fabind, diffdock, neuralplexer, particularly generalizing protein excluded training set excepting fabind, method considerably slower, fabind still us order magnitude parameter next, assess quickbind challenging pb benchmark figure include comparison recent co folding method quickbind generally outperforms rigid docking method except diffdock including fabind trail co folding method however, speed gap quickbind co folding method take minute single prediction even considerable, making quickbind compelling compromise speed accuracy figure si show example highly accurate quickbind prediction quickbind forgoes post processing step common ml based method enhance chemical validity prediction result, quickbind raw prediction generally pas pb chemical physical plausibility tests, largely due incorrect bond length angle figure si see also noted however, failure typically addressed running force field based energy minimization post prediction substantially improve physical validity quickbind prediction even slightly improves success rate figure given speed, natural use case quickbind binding affinity prediction virtual screening application test potential, trained simple neural network use quickbind single representation algorithm predict protein ligand affinity used pdbbind split training quickbind pdbbind affinity data resulting model competitive affinity predictor table si despite optimized architecturally hyperparameter tuning indicates quickbind immediate utility virtual screening may improved using advanced top model affinity prediction trained quickbind, set investigate whether learned ligand characteristic relevant molecular docking beyond binding affinity, molecular feature lipophilicity cell permeability influence outcome drug discovery program feature strongly linked physicochemical property ligands, hydrophobic surface area molecular weight, extent expert rule drug design often explicitly restrict drug like molecule based property model implicitly encodes may thus hold promise drug design beyond accurate pose prediction end, extracted single ligand representation evoformer transformed molecule level representation averaging across atom figure pipeline schematic every resulting channel value, computed pearson value total hydrophobic surface area, molecular weight, number hydrogen bond acceptor donors, polar surface area, number rotatable bonds, octanol water partition coefficient, number aromatic ring calculation performed using rdkit mordred carried computation every molecule pdbbind test set figure scatter plot found channel significantly correlated one property table si value least correct multiple hypothesis testing channel indicating quickbind fact learned physicochemical characteristic protein ligand binding selecting strongly correlated property per channel, found number bond acceptor donors, total hydrophobic surface area, number rotatatable bond strongest feature include additional result section si better understand quickbind utility real world deployments, predicted bound pose new ligand five protein pdbbind test set, selected based extensive experimental characterization clinical significance uniprot id mdi uli table si mdi trna guanine methyltransferase, bace beta secretase relevant development alzheimer disease galectin galactose specific lectin involved cancer uli human immunodeficiency virus hiv protease, gtpase ras, key cancer target used protein crystal structure three lowest affinity binder pdbbind test set input, predicted binding affinity complex structure compound pdbbind test set treated compound explicitly crystallized five target protein decoy figure si si table si likely resulted binder mislabeled non binder found quickbind capable discerning ligand binding characteristic across diverse ligand scaffold protein target specifically, quickbind distinguished binder non binder across various targets, including bace value one sided wilcoxon rank sum test galectin ra despite bace ra binder low average tanimoto similarity bace galectin quickbind also accurately predicted pose ligand rmsd consistently majority ligand success rate respectively based comparison pdbbind test set structure hiv protease, predicted binding affinity significantly differentiate binder non binders, quickbind still excelled predicting pose structure high accuracy prediction figure si analysis also shed light limitation quickbind struggled confronted protein whose conformation change dramatically binding target ligand versus low affinity ligand used template instance, kras structure average backbone rmsd input true conformations, resulted notable proportion pose exhibiting high ligand rmsds prediction fell wholly unseen trna guanine methyltransferase, quickbind struggled predict significantly higher binding affinity binder v non binder predicted moderately accurate pose ligand rmsd case quickbind ml model blind molecular docking optimizes runtime speed retaining competitive pose prediction accuracy, providing compelling option high throughput virtual screening furthermore capture physicochemical ligand property known influence molecular docking interpretability informs aspect underlying physic model captured may, sufficiently well developed, help guide design drug compound consideration important given large cost involved identifying prioritizing compound experimental testing optimization augmentation quickbind affinity prediction capability make suitable identifying new ligands, showcase using multiple highly relevant drug target except tankbind, existing blind docking co folding model predict binding affinities, therefore applicable screening application combination ligand pose interaction strength help optimizing potency selectivity drug candidates, although remains seen sensitive quickbind minor structural changes, profound effect binding called activity cliff added advantage quickbind formulation binding affinity prediction lack reliance experimental co complex structure unlike tankbind due trained separately main docking model embeddings protein ligand pair used, whether structure predicted experimentally derived mean quickbind affinity module trained bindingdb binding affinity database comprising million protein ligand pairs, order magnitude structural complex user also rapidly finetune binding affinity model target protein evaluation using pb benchmark showed quickbind struggle generate physically chemically valid poses, many recovered force field based energy minimization energy minimization increase model runtime, binding affinity module used first select subset promising compounds, whose pose energy minimized major shortcoming quickbind ml based molecular docking method dependence rigid docking, task trained evaluated rigid docking, method provided holo protein structure originally co crystallized query ligand, protein structure predicted reflect many real world us molecular docking user access apo unbound structure holo structure co crystallized another ligand although quickbind showed promise cross docking case study conducted, long input protein deviate much true structure ideally, model trained evaluated flexible cross docking setting, fact ml based blind, flexible docking method recently emerged future version quickbind adapted flexible docking method capable using apo, holo, even predicted protein structure input updating protein residue frame well ligand frame alternatively, side chain made flexible updating rotational component residue frame side chain torsion angle conceptually, one goal quickbind investigate af architecture may adapted task docking co folding docking co folding method previously demonstrated idea component af used protein ligand pose prediction, quickbind us essentially entirety af provided multiple insight first, suggests quickbind could benefit af native confidence estimate recycling, found important af success quickbind could also benefit complicated, af inspired loss functions, example structural violation loss would likely lead pb valid prediction second, quickbind provides rough estimate well af like model perform molecular docking fact achieve state art performance suggests certain aspect af ideally suited task anticipates change introduced af including minimized msa module atomistic reasoning ligand including innovation af likely result improved molecular docking tool section si turn, finding also implication af instance, since quickbind single representation capture physicochemical feature ligand, likely af single representation highly information dense well, may therefore useful task beyond pose prediction would like thank psivant therapeutic providing computational resource wt acknowledges financial support max planck school matter life sck supported nih grant gm residue type one hot encoded ligand atom following feature atomic number h, c, n, o, f, p, s, cl, br, i, chirality, degree formal charge number connected atom hybridization, presence ring, presence aromatic ring early version included atomic number degree formal charge implicit valence, number connected hydrogen number radical electrons, hybridization, presence aromatic ring, number ring in, presence ring size similar ref additional feature improve performance omitted ligand coordinate initialized using random rdkit conformer reduce quickbind memory footprint training, input protein sequence cropped residue model without evoformer module, respectively since model performance drop noticeably shorter crop sizes, final model finetuned crop size residue inference time, full protein sequence used depending available gpu memory, inference might therefore run cpu using resources, restrict inference gpus protein shorter residue multi chain proteins, sequence concatenated order appear pdb file tested different cropping strategy random contiguous cropping setting residue whose atom closest ligand atom midpoint contiguous cropped fragment binding site cropping, bsc selecting residue closest ligand atom spatial cropping setting protein cropped randomly spatially probability extensive hyperparameter screening full quickbind model would computationally expensive, optimized many hyperparameters architectural choice using two smaller variants, trained without ligand frame still updating atom position quickbind s, lack evoformer module contains four eight structure module block unshared weights, trained without batching quickbind m, lack triangle attention evoformer stack expensive module trained batch size main result hyperparameter screening summarized table si furthermore, several way generate ligand coordinate update final single representation tested general, final single representation separated protein ligand single representation then, either ligand single representation passed linear layer produce coordinate updates, protein single representation summed along sequence dimension corresponding mean taken, pooled protein representation concatenated ligand single representation passing linear layer, outer product protein ligand single representation summed along sequence dimension corresponding mean taken, passed linear layer, output attention layer query vector coming ligand key value vector coming protein concatenated ligand single representation passed final linear layer last approach led best result also tested scaling coordinate update factor done af find improve model performance furthermore, briefly experimented first applying global rototranslation ligand coordinates, either finetuning ligand coordinate changing torsion angle rotatable bonds, find lead better result using gated variant ipa module improved model performance compared standard ipa module addition, also tested two idea alphafold multimer af multimer moving outer product mean beginning evoformer block multimer version relative positional encoding, neither improved model performance quickbind implemented using pytorch pytorch lightning openfold rdkit model trained using adamw optimizer learning rate weight decay coefficient early stopping patience epochs, batch size binding affinity prediction model trained using adam optimizer learning rate early stopping patience epochs, batch size using mean squared error mse loss model weight best performance validation set chosen evaluation test set training final quickbind model took several week eight nvidia gpus, quickbind quickbind variant trained two week less final model trained different seed replica got stuck local minimum success rate best performing model finetuned crop size plausible model got stuck local minimum would reached similar performance final model finetuning stage, test training time including triangle attention scale unfavorably sequence length force field minimization performed described ref using script kindly provided one author visualization generated using nglview wanted understand quickbind obtains initial guess docked ligand pose pair representation contains protein ligand block, well mixed diagonal element among features, protein ligand block constructed pairwise distance ligand atoms, respectively, diagonal element contain spatial information hypothesized model would use diagonal element information interaction protein ligand, including initial guess pairwise distance therefore took diagonal element pair representation evoformer block, symmetrised transposing lower diagonal block computing element wise mean, finally took mean along ligand dimension obtain dimensional matrix, number atom hidden channel dimension figure si indeed, found already mean along channel dimension weakly correlated logarithm mean ligand atom distance pearson value correlation much stronger channel particular, channel correlate logarithm mean ligand atom distance pearson value table si summarizes important characteristic five protein pdbbind test set highest number complex structure pdbbind test set, well quickbind cross docking performance particular, contains number complex structure pdbbind test set binder number complex structure pdbbind train set train ex average rmsd input true protein structure bb rmsd average tanimoto similarity lowest, second lowest, third lowest affinity binder remaining binders, calculated using extended connectivity fingerprint radius t evaluate quickbind cross docking performance using fraction prediction ligand rmsd fraction prediction ligand rmsd aligning atom input true protein structure using kabsch algorithm alignment calculating bb rmsd consider atom successfully extracted complex applicable, provide mean standard deviation across three run crystal structure lowest, second lowest, third lowest affinity binder proteins, tested predicted binding affinity binder higher non binder using one sided wilcoxon rank sum test section discus observation difference introduced af quickbind versus made af first, af longer us residue reference frame eschews se equivariance entirely early internal experiment quickbind, similarly observed higher success rate ligand reference frame omitted opted include model would otherwise equivariant inputted global orientation protein ligand complex, desirable docking application decision however driven fact quickbind us existing protein structure instead predicting scratch co folding model, abandoning reference frame se equivariance therefore consistent finding second, af replaces evoformer pairformer module quickbind modified evoformer architecturally middle ground two similar pairformer, operates single pair representation without column wise attention case quickbind, design informed use input protein structure, obviated need multiple sequence alignment corresponding representation pairformer, single representation update pair representation via outer product mean opm module, update order single pair representation swapped af multimer opm moved beginning evoformer found original opm position optimal see section si try omitting it, swapping single pair update order third, af us larger crop size af af multimer af initially trained crop size finetuned two stage crop size whereas af af multimer trained crop size finetuned crop size respectively initially trained quickbind residue crops, finetuned using residue crop found finetuning larger crop important model performance, observing consistent improvement crop size increased given af training procedure, suggests quickbind would benefit additional finetuning stage incrementally larger crop fourth, af randomly chooses contiguous, spatial, spatial interface cropping quickbind cropping strategy, binding site cropping, considered compromise af two spatial cropping strategy contiguous cropping tested spatial contiguous cropping found binding site cropping lead better result unlike quickbind, af cropping applied token model may see part ligand, quickbind protein cropped fifth, af contains distogram head similar one af including minimum distance bin overly large small molecule bond long suggests primarily benefit overall complex prediction rough positioning ligand atoms, consistent observation distogram head improve quickbind performance finally, agreement fact found better result distinguishing different bond type ligand adjacency matrix, af bond feature binary continuing ",biomolecules
"characterizing rna oligomers using stochastic titration constant ph metadynamics simulation introduction method result discussion conclusion data software availability instruction reporting error cphmd simulation using amber ol force field system setup mod calibration mm md cphmd setting poisson boltzmann monte carlo simulation metadynamics integration setting analysis error calculation testing force field modularity protonable nucleobases adenine cytosine deprotonable nucleobases guanosine uridine rna molecule exhibit various biological function intrinsically dependent diverse ecosystem highly flexible structure flexibility arises complex hydrogen bonding network defined canonical non canonical base pair require protonation event stabilize perturb interaction constant ph molecular dynamic cphmd method provide reliable framework explore conformational protonation space dynamic structure robust calculation ph dependent properties, titrable site despite growing biological evidence concerning ph regulation certain motif biotechnological applications, ph sensitive silico method rarely applied nucleic acid work, extended stochastic titration cphmd method include rna parameter standard ol amber force field highlighted capability depict titration event nucleotide single stranded rna validated method using trimer pentamers single central titrable site integrating well tempered metadynamics approach st cphmd methodology cph metad using plumed approach enhanced convergence conformational landscape enabled efficient sampling protonation conformation coupling estimate agree experimental data, validating method ability reproduce electrostatic change around titrable nucleobase single stranded rna finding provided molecular insight intramolecular phenomena, nucleobase stacking phosphate interactions, dictate experimentally observed shift different strand overall, work validates st cphmd metadynamics integration reliable tool studying biologically relevant rna system si alsoaffiliationscuola internazionale superiore di studi avanzati, trieste, italy alsoaffiliationscuola internazionale superiore di studi avanzati, trieste, italy ph ubiquitous environmental factor significantly influence various biomolecules structure, chemistry, function influencing protonation state chemical moiety depending intrinsic ph affect overall charge thermodynamic equilibrium ph dependent modulation pivotal regulating multiple biological processes, protein protein interactions, nucleic acid binding, drug interactions, conformational change response shift ph environment nearby electrostatics usually, nucleic acid particularly sensitive small physiological ph change nucleotide quite far physiological one even away common canonically base paired nucleotide however, non canonical base pairing diverse array inter intramolecular interaction promote complex ph sensitive electrostatic environment instance, non canonical base pairs, wobble hoogsteen pairs, involve protonated form adenine cytosine instances, certain modified nucleobases, like methyladenosine methylcytidine deprotonate basic condition compared unmodified counterparts, significantly shifted value closer physiological ph shift highlight modified nucleobases prone protonation deprotonation events, energetically promote hinder ph dependent conformational rearrangement depending electrostatic environment medium ph although several experimental study explored related property nucleobases nucleoside nucleotide recent research increasingly focused role ph dependent secondary tertiary structures, motif triplexes structure important biological function like catalysis structural stability also hold significant potential biotechnological applications, including biosensors drug delivery system molecular switch yet detailed insight mechanism action system difficult obtain experimental protocol alone molecular dynamic md method strongly complement experimental rna study providing atomistic description, although shorter timescales however, standard md simulation typically assume fixed protonation state based molecule physiological ph, ignoring dynamic nature protonation event modulated instantaneous conformation surrounding electrostatic environment limitation provide incomplete picture biomolecular behavior, especially rich biological system protonation event drive relevant conformational interaction constant ph molecular dynamic cphmd technique developed overcome limitation method introduce residue titration within md framework, hence enabling prediction protonation state value titratable group importantly, allows u probe dependency protonation state molecular conformation cphmd method broadly categorized continuous discrete approach continuous methods, typically based dynamic phmd pme based cphmd gromacs scalable cphmd version sample conformation fractional protonation state extending hamiltonian ph dependent particle fictitious mass method divided based implicit solvent model explicit solvent model successfully applied different biomolecules eg, nucleic acid protein using various force field eg, charmm, amber previous work nucleic acid titration done goh coworkers work focused continuous multi site dynamic constant ph implementation cphmdms using charmm force field adenosine cytidine used model compound calibration obtaining good experimental agreement test compound adenosine monophosphate amp cytidine monophosphate cmp dinucleotides combination cyt cyt, ade ade, cyt ade discrete methods, hand, usually employ start stop monte carlo mc md approach accepts reject protonation state switch, titrable residue, metropolis criterion criterion depends protonation free energy given residue, calculated frozen conformation using implicit solvent model, either generalized born phrem poisson boltzmann pb method example, stochastic titration constant ph method st cphmd originally developed baptista protein using gromos and, currently, also charmm force field within approach, model compound used nonphysical fragment ie nucleobase encapsulates chemical moiety within molecule instance, calibration mod would necessary nucleobases using experimental data nucleoside procedure, mod fine tuned systematic deviation experimental due pb parameter intricate detail st cphmd method extensively discussed literature best knowledge, discrete method never tested nucleic acid building previous work standard aminoacid calibration protocol extended st cphmd method include nucleic acid parameter ol amber force field approach involves parametrization charged state non modified rna nucleobases, first stage calibration individual mod using nucleoside data, second stage validation recalibration value differently sized oligonucleotides available experimental data protocol integrates effect phosphate backbone shifts, similarly aminoacid mod calibration using pentapeptides shift typically result higher value compared observed nucleoside aqueous environment closer expected behavior biomolecule trimer pentamer system nucleobase flanked non titrating residue simulated assess effect increasing backbone length measuring value agree experimental data, corroborating accurate pb description changing electrostatic environment important consider short flexible nucleotide challenging system md simulation well known properly sample necessary use enhanced sampling technique hence, integrated cph procedure metadynamics required coupling cphmd plumed plugin integration focus improving sampling system specific collective variable cv without introducing bias protonation space titratable site site conformation protonation state intrinsically coupled, enhanced conformational sampling improves accuracy average protonation predictions, particularly well solvated site result demonstrate successful extension st cphmd method nucleic acid titration incorporating novel cph metad approach, successfully corroborated value short oligonucleotides experimental data also characterized underlying electrostatic dynamic accordingly, work present reliable robust framework studying ph dependent conformational dynamic nucleic acid cphmd extension introduced paper build upon standard amber parameterization solely introducing charged state nucleotide using neutral state reference parameter adapted original force field parameter derived compatible opc water model new charge set parametrization used two step restrained electrostatic potential resp procedure optimized geometry protonated deprotonated state nucleobases, ribose replaced methyl group previous work geometry optimization used lyp functional dataset using gaussian software then, resp charge nucleobase neutral charged state derived partial charge charged state determined follows calculated, atom, resp partial charge difference charged neutral state added calculated resp difference atom neutral ol partial charge original charge set neutral state preserved charge shown table label table si charge set label table si charge set supporting information poisson boltzmann calculations, built delphi database atom radius charge radius procedure, lennard jones parameter atom type used, based lorentz berthelot combination rule determine radius atom opc water molecule radius derivation assumed cutoff energy minimum estimated parameter original ol force field plus kbt factor, done similar protocol atomic partial charge database built original ol force field partial charges, newly derived charge set charged state nucleobases restricting nucleobase net charge onto model compound required tweaking point charge atom purine pyrimidines, respectively ensure nucleobase moiety integral charge small modification also applied neutral state validate them, performed n md simulation canonical rna nucleoside using original ol force field recomputed energy trajectory using topology generated modified charge set comparative analysis done using experimental nmr computational coupling data mentioned parameter found following github repository githubcom tomfersil cph metad test system chosen match available experimental data namely single stranded ru a, ruu a, uu protonable system based work gonzalez olvera et al although study focused dna strands, absolute value may differ, relative shift due phosphate consistent across system relative single nucleoside single stranded ragc,d rcagca, rcuc ruuuuu constructed test guanosine uridine deprotonation system built using pymol neutral protonation state system placed solvated rhombic dodecahedron box highlighted sequeira et al important note adapting force field amber charmm st cphmd treatment long range electrostatics pme charge variation associated titration event hence, system net charge neutralized using appropriate number counter ion neutral state oligomer experimental ionic strength pme background correction used compensate charge variation due system titration choice model compound important step cphmd method protonation deprotonation event occur nucleobase, purine pyrimidine respectively, limited long range electronic effect remaining atom hence, model compound charge variation restricted nucleobase fragment assumption, modified force field constructed within modular based rationale, phosphate group, ribose, hydroxyl group cap nucleobase defined unique residue major advantage modular approach future inclusion modified nucleobases force field require defining nucleobases respective protonation state following work protocol work, calibrated model compound mod applying similar rationale used calibration titrable amino acid residue though additional initial step first step, assigned initial mod value run iterative procedure short n cphmd simulation adenine n cph metad nucleoside equivalent experimental condition cv biased metadynamics simulation glycosidic angle promote syn anti transition sugar puckering variable promote transition endo state single n cph metad run exhibited faster conformational convergence compared nscphmd run see figure label fig si cph metad supporting information obtaining titration curve, corrected possible shift relative initial guess mod iteration, final mod reproduces experimental data obtained resulting shift smaller ph units, indicating electrostatic potential derived pb properly describe titrable site surrounding environment nucleobase system second step occurred oligonucleotide cph metad simulation see table label table si simsettings oligonucleotide sequence simulation parameter referenced introduction section discussed result section, phosphate backbone modulates protonation behavior nucleobases complex biomolecular environment therefore, applied posteriori correction final mod value accurately reproduce experimental value shift referenced experimental data cphmd cph metad simulation run using version gromacs package open source, community developed plumed library version version simulation used previously described modified ol amber force field opc water model verlet nm cutoff scheme applied pme treatment non bonded interaction van der waals interaction truncated integrator time step f conformation sampled npt ensemble unless otherwise specified, used temperature bath scheme rescale relaxation time ps, coupled solute solvent separately system pressure kept constant rescale barostat bar, relaxation time p compressibility bar delphi program used perform poisson boltzmann calculation solute molecular surface defined radius probe, ion exclusion layer ionic strength depending experimental condition system see table label table si simsettings supplementary information dielectric constant used solute solvent, respectively two step focusing procedure conducted electrostatic potential calculation defining two grid vertex coarse grid spacing grid points, smaller grid defined relaxation parameter linear non linear interaction, respectively background interaction calculation truncated electrostatic potential convergence threshold kt petit program performed mc calculation residue protonation states, using free energy term obtained pb calculation conformation, mc cycle performed cycle corresponds trial change site pair site interaction larger pk unit work, integrated well tempered metadynamics algorithm within md production phase cphmd cycle well tempered metadynamics, system biased smoothly converging history dependent potential along chosen cv md phase cycle, metadynamics restarted bias potential generated previous cycle deposited new gaussian potential restarts performed reading potential grid final conformation saved used pb mc calculation oligomer simulations, ran single cph metad simulation trimer pentamer system cv biased metadynamics simulation glycosidic angle ermsd glycosidic torsion promotes transition phosphate exposed syn phosphate shielded anti state ermsd relates relative arrangement nucleobases molecule reference fully stacked conformation, thus quantitative measure base stacking interaction single strand rna molecule system ph range number simulation specifically chosen interpolate titration curve specific detail system found supporting information see table label table si simsettings karplus equation used back calculate scalar coupling torsional angle experimental reference data used validate ensemble nucleoside parameter karplus equation torsional angle obtained munzarova et al sugar parameter obtained condon et al characterized oligonucleotides structure using chosen collective variable ermsd, nucleic acid specific measurement evaluates nucleobases orientation relative positions, glycosidic angle analysis done using plumed software reweighted obtain unbiased population estimated value obtaining titration curve system taking mid titration point titration curve obtained fitting average protonations cphmd simulation henderson hasselbalch hh equation eq average protonation, ph assigned simulation ph fitted parameter cph metad simulations, average protonation obtained using reweighting procedure introduced weighted average protonation given cph metad simulation bias accumulated end metadynamics simulation calculated coordinate corresponding th frame weighted average protonations fitted hh equation different approach, used binless wham derive ph dependent property ph scan energy maps, average protonations found energy minimum procedure consisted concatenating cph metad equilibrated trajectory given system recomputing bias simulation accumulated bias potential concatenated trajectory afterward, correct bias protonation dependent contribution frame thus obtaining bias matrix bias reweighted bias potential concatenated trajectory dependent frame protonation state simulation ph then, compute weight using bias matrix protonation state concatenated trajectory, using binless wham implementation bussilabgithubio doc py bussilab bussilab whamhtml using procedure, compute weight arbitrary ph value reweight observable property, energy maps, first solvation shell, average protonations error value calculated using bootstrap approach hh fits, partitioned protonation time series equally sized block performed bootstrap block iteration performed new hh fit resample, thus calculating new error obtained standard deviation resampled histogram wham values, partitioned protonations bias ph simulation block performed bootstrap iteration resample generated new weights, used calculate new value final error calculated previously analysis radius distribution function rdf measurements, contact distance interest groups, time series observables performed using gromacs tool package analysis performed using house python script previously specified module block analysis done observable error obtained bootstrap procedure iteration work, parametrized charge protonated deprotonated nucleotide relevant ph range respectively, calibrated mod using respective aqueous s, tested several oligomers experimental data available one key factor nucleobases electrostatic effect phosphate backbone, stabilizes positively charged state adenine, cytidine destabilizes negatively charged state guanosine, uridine single stranded oligonucleotides, possessing multiple phosphate groups, ideal validating method ability capture backbone dependent protonation variation reproduce experimental value accurately titrable nucleotide simulated within trimer pentamer system capture phosphate dependent electrostatics effect nucleobase moreover, chosen flanking residue non titrable within ph range interest except uridine pentamer system prevent protonation coupling effect titrable residue simulation done using combination constant ph molecular dynamic metadynamics following, report result md simulation adenine uridine system system result presented supplementary information mentioned method section, redesigned force field partitioning nucleotide chemical moiety phosphate, sugar, nucleobase separate residue force field modularity aim facilitate future inclusion modified nucleobases however, procedure required small charge rebalance around atom purine pyrimidines, respectively root mean square error scalar coupling concerning experimental nuclear magnetic resonance data table label table si rmse adenosine label table si rmse uridine supplementary information show modular charge set comparable original force field assessing deviation experiment furthermore, population syn anti state glycosidic bond angle close obtained original charge set result indicate enforcing modularity affect overall force field quality calibration step see mod calibration section method protonable nucleobases, adenine cytosine tested using equivalent trimer pentamer systems, ruau ruuauu rucu ruucuu, using cph metad approach figure report free energy map ruau system ph close measured value, function ermsd helix, anti correlate nucleobase stacking, angle titrable nucleobase map display two distinct energy minimum anti region titrable nucleobase low medium ermsd ermsd values, single major energy minimum syn state angle high ermsd value ermsd visual analysis representative structure minimum show progressive unstacking fully stacked low ermsd region fully unstacked high ermsd region figure label fig si structs supplementary information interpretation applies system observing representative structure map shown supplementary information average protonations seen highly conformation dependent stacking interaction progressively lost figure label fig si structs average protonation increases, highest protonation value usually corresponding syn unstacked conformation indeed, progressively raising ph medium lead energetically favorable anti conformations, also penalizing higher protonation syn state figure label fig si map similar protonation dependent behavior observed rucu system shown supplementary information figure label fig si map label fig si structs ruuauu free energy map ph close measured value, display minimum anti region titrable nucleobase single energy minimum syn state figure average protonation anti correlated conformational stacking figure label fig si structs evidenced high average protonation syn unstacked state relative stacked anti state progressively basic ph environment energetically favor lower ermsd states, seen figure label fig si map behavior consistent observed trimer calculation predict following protonable trimer ruau figure rucu figure label fig si cytosine plotsb see also table label table si allpkas trimer similarly deviate monomer value leading larger experimental ruau rucu interestingly, model properly capture electrostatic change titrating residue environment trimer pentamer pentamers measured ruuauu forruucuu, see also table label table si allpkas resulting trimer ruuauu ruucuu, respectively result compatible exp systems, despite overestimating absolute value ruucuu, used hh fit reference, due discrepancy wham value see discussion section since calculation able reproduce correct shift nucleoside trinucleotide, suggest recalibrating mod using experimental data trimer mod correction trimer dna constructs, additional correction included addition, need account experimental discrepancy reported reference work gonzalez olvera et al previous literature prev ref overall, corrected mod computed follows mod therefore, adenine mod corrected ph units, cytosine mod shifted value defined measured hypothetical rna trimer model see table label table si pkmod model accurately describe electrostatics protonation variation protonable trimer pentamers, whereas failed estimate shift monomer trimer hence, recommend use final recalibrated mod larger construct parametrization, model expected reproduce experimental single nucleoside water deprotonable nucleobases, uridine guanine applied calibration rationale different sequence ragc rcagca guanine rcuc ruuuuu uridine rcuc system, stacking effect correlate higher protonation average shown three minimum anti state region contrast, unstacked syn state are, average, protonated less energetically favorable population globular disordered conformation figure label fig si structs tend expose titrable group solvent away phosphate backbone, facilitating deprotonation event figure label fig si map partially stacked conformation ermsd fully stacked conformation figure label fig si structs stabilize protonated state ph value shown typically higher average protonations figure label fig si map titrable site pyrimidine, syn conformation low probability due steric hindrance remains true high ph value reason syn state protonated anti counterpart titrable face negatively charged backbone concerning ragc system, stacking effect seem relevant thermodynamic stability different energy minimum considered system partially stacked ermsd alternatively stacked ermsd conformation thermodynamically stable trimer conformation regardless medium ph average protonation figure label fig si map especially, alternative stacked conformation figure label fig si structs expose nucleobase solvent, stacking purine ring flanking adenosine effect strongly stabilize protonated state ensemble, even high basic medium previously discussed system flanking uridines conferred less stable stacked structures, rcagca showed smaller likelihood unstacked conformation two identifiable energy minimum anti state region span fully partially stacked state figure label fig si structs label fig si map supplementary information result hint partial stacking conformation favor deprotonation event due larger solvent exposure fully stacked conformation meanwhile, syn region, proximity phosphate backbone increasingly disfavor stacked conformation basic medium figure label fig si map supplementary information trimer pentamer, thermodynamic stability rcagca conformation distinct degree stacking interaction less ph sensitive previously discussed system trimer systems, obtained slightly deviated estimation experimental value uridine exp guanosine exp see table label table si allpkas supplementary information similarly protonable nucleobases, measured trimer nucleoside slightly deviated experimental exp rcuc ragc, respectively concerning rcagca system, prediction close experimental figure label fig si guanosine plot similarly ruucuu, wham calculation significantly underestimated relative experimental hh fit table label table si allpkas therefore used hh fit reference still, pentamer trimer corroborated well exp equal rcagca ruuuuu system presented distinct challenge due increased complexity introduced simultaneous multi site titration site site coupling effect macroscopic estimation extrapolated fitting individual charge five titrable site henderson hasselbalch equation, upshifted exp case, assumed midpoint titration correlated macroscopic table label table si allpkas si experimentally measured signal depend structural effect still, rcuc ruuuuu corroborated well experimental value also computed nucleotide individual table label table si mer pkas pairwise cooperativity protonation free energy value indicate probability simultaneous protonation event relative single state titration figure figure label fig si coop show topological position impact simultaneous protonation probability, consequently individual terminal residue strongly coupled neighbor relative farther nucleotide tested ph condition deprotonation central nucleotide becomes hindered multiple neighbor titration, hence hindering deprotonation reflecting increased upshifted particularly third site, shown central uridines figure similarly previous systems, calculation capture shift nucleoside trinucleoside, hence similar recalibration procedure applied however, deprotonable systems, simulated system directly comparable experimental data hence, mod correction shown equation simplified experimental reference model trimer guanosine mod corrected uridine mod shifted see table label table si pkmod protonable systems, method accurately predicts variation trimer pentamer deprotonable systems, failing estimate change nucleoside remarkably, method estimate individual coupled titrable site macroscopic midpoint titration good agreement experimental data work, developed parameter protonated deprotonated nucleotide suitable constant ph md simulation rna using ol force field, one commonly adopted parametrizations additionally, integrated well tempered metadynamics within st cphmd method facilitate simultaneous sampling conformational protonation state enhanced sampling crucial accurate calibration nucleic acid parameter even short single strand oligomers require extensive sampling sufficiently explore conformational space several factor influence nucleobase titration, titrating chemical moieties, charged neighbors, ph, solvation, structural effect factor alter free energy landscape likelihood conformational rearrangement binding event molecules, ions, ligand protein st cphmd method balance diverse contributions, offering accurate robust description structural protonation dynamic setting representative environment larger rna molecule practice, ph modulates sampling probability given conformation shifting thermodynamic equilibrium energy minimum driven charge variation residue result protonation conformation coupling, protonation space sampling indirectly improved enhancing conformational sampling given collective variable cv space defined ph parametrization follows modular approach compatible existing force field, simplifying future parametrization modified nucleobases force field delphi database concerning delphi database parametrization, reported parameter follow previously established protocol standard st cphmd methodology optimized needed future iteration nucleobase mod calibration protocol focused oligomer constructs, limited conformational sampling could reduce prediction accuracy hinder validation experimental data integration well tempered metadynamics within cphmd method cph metad pivotal calibration procedure, promoting convergence simulated rna oligomers enhanced sampling method complementary others ph replica exchange however, despite approach, achieving convergence ruucuu rcagca pentamers remained challenging consequently, inconsistency arose binless wham approach resulted underestimated value table label table si allpkas future work may involve optimizing metadynamics parameter exploring alternative enhanced sampling technique address issue nonetheless, able recover experimental shift analyzing individual simulations, without assuming overlapping conformational space md simulation performed series test system allowed extraction general coupling property conformation protonation rna oligomers titrable site strongly influenced proximity charged phosphate group longer oligomers high phosphate content, upward shift global consistent experiment observed stacking interaction flanking residue shield phosphate electrostatics, reducing protonation event time, lower ph values, protonation event favored, leading increased interaction neighboring phosphate reducing population stacked conformation syn anti transition titrable site also impact shorter strands, close phosphate contact titrable site dictated syn states, upshifting hypothetically, direction shift would reversed titrable site located position nucleobase get farther phosphate group upon transitioning syn deprotonable systems, method effectively capture effect flanking residue strand whose structural dynamic less sensitive ph changes, ragc rcagca cases, energy minimum less affected variation average protonation relative stacking effect additionally, approach also grasp correlation multiple deprotonation events, shown polyu simultaneous titration multiple nucleotide provides valuable advantage dissecting contribution effect single sites, task often difficult experimental technique data reveals distinct shift uridines different topological positions, exposed slightly distinct electrostatic neighbor topological effect measured experimentally sequence corroborating result quantitatively highlight titration correlation substantial nearest neighbor overall, cphmd simulation robustly reproduced experimental data provided novel insight molecular conformation rna single strand fall outside scope experiment concerning calibration protocol, two particular note must raised polyu guanosine system experimental data specify pentamer system representative polyu however, author discarded presence tetra tri di mononucleotides polyu experiment hence assumed pentamer system minimal model predict experimental value another conflicting point arises measurement titrable guanosine gonzalez olvera et al report trimer pentamer, respectively contrast, acharya et al report value throughout work, considered nmr measurement acharya et al two reason directly comparable rna system multiple aromatic marker measurement confer higher confidence reported value importantly, calculation show adopted cphmd method reproduce shift monomer trimers, instead reproduce correctly shift trimer pentamers reason, decided recalibrate mod trimer simulations, expense model cannot reproduce single nucleoside water consider minor defect model recalibrated mod recommended used simulation study work differs previous one nucleic acid cphmd, focused reproducing nucleoside water compared goh et al focused shift monophosphorylated nucleotides, study incorporates backbone flanking interactions, leading comprehensive description rna macromolecular environment hence, accuracy procedure directly comparable finally, enhanced sampling strategy employed offer improved convergence conformational protonation landscape, might difficult ph replica exchange method alone whereas work tested well tempered metadynamics, plumed integration open way large class enhanced sampling method based collective variable constant ph molecular dynamic method powerful technique incorporating titration effect silico biomolecular study work, successfully extended st cphmd methodology nucleic acids, achieving accurate prediction protonation state value short oligonucleotides seamless integration well tempered metadynamics plumed cph metad enhanced convergence enabled efficient sampling protonation conformation coupling usually, neutral conformation assumed thermodynamically stable within physiological ph range however, conformation solely represent part free energy landscape strength cph method lie ability capture protonation dependent relative probability conformational states, including higher energy state might biologically relevant molecular insight otherwise difficult obtain without explicitly considering protonation effect time conformational sampling result agree experimental shift across small oligonucleotides, including complex system like polyu multiple coupled titrating site despite initial overestimation absolute values, posteriori mod correction improved calibration across nucleobases within biomolecular environment result validate standard st cphmd methodology applied nucleic acid metadynamics integration production md step finding present cph metad approach robust tool available studying ph dependent process nucleic acids, paving way study larger, biologically relevant rna systems, ribozymes rna protein complexes, ph fluctuation play important role function stability future work may focus improving parameter metadynamics poisson boltzmann calculation applying enhanced sampling technique improve accuracy conformational protonation space sampling across complex system gromacs package freely available software perform md simulation downloaded manualgromacsorg documentation download html pymol also free software molecular visualization generating high quality image downloaded pymolorg wham module available bussilabgithubio doc py bussilab bussilab whamhtml modified nucleic acid parameter st cphmd available githubcom tomfersil cph metad acknowledge dr miguel machuqueiro nuno fb oliveira providing st cphmd code, implementation assistance, fruitful discussion acknowledge financial support european molecular biology organization embo grant altf service resource provided cineca sissa cineca agreement continuing ",biomolecules
"cpe pro structure sensitive deep learning method protein representation origin evaluation introduction related work material method experimental setup result analysis conclusion instruction reporting error protein representation learning protein structure prediction dataset model architecture baseline method training setup evaluation metric work protein structure important understanding function interaction currently, many protein structure prediction method enriching structure database discriminating origin structure crucial distinguishing experimentally resolved computationally predicted structures, evaluating reliability prediction methods, guiding downstream biological study building work structure prediction, developed structure sensitive supervised deep learning model, crystal v predicted evaluator protein structure cpe pro represent discriminate origin protein structure cpe pro learns structural information protein capture inter structural difference achieve accurate traceability four data classes, expected extended simultaneously, utilized foldseek encode protein structure structure sequence trained protein structural sequence language model, sslm preliminary experiment demonstrated that, compared large scale protein language model pre trained vast amount amino acid sequences, structure sequence enables language model learn informative protein features, enhancing optimizing structural representation provided code, model weights, related material githubcom gouwenrui cpe pro maingit function protein determined folded structure therefore, characterizing protein structure crucial understanding studying biological function protein folding complex highly coordinated process determines active sites, ligand binding capabilities, functional role protein inside outside cell even slight alteration structure lead significant change protein function, potentially resulting disease consequently, comprehensive understanding protein folding essential elucidating biological function also serf guide research application drug design, disease diagnosis, treatment however, experimentally determining protein structure pose numerous challenge despite significant effort scientist past decades, number experimentally determined structure reported protein data bank pdb remains far lower number known protein sequences, creating substantial data gap limited availability protein structure data significantly hinders comprehensive understanding protein function interaction mechanism address limitation, researcher increasingly turned computational methods, protein folding simulation amber gromacs guide determination protein structure one representative method homology modeling however, homology modeling relies similarity known structure cannot accurately applied protein without known similar structure computational method somewhat alleviate issue insufficient experimental data, still fully resolve broader applicability structure prediction, particularly novel complex proteins, significant limitation remain contribution follows introduce cpe pro, model excels distinguishing crystal predicted protein structure learning structural feature using cath non redundant dataset, create protein folding dataset cath pfd multiple prediction model preliminary experiment indicate that, compared amino acid sequences, structure sequence enable language model learn effective protein feature information, enriching optimizing structural representation integrated graph embeddings open sourced code, model weights, cath pfd dataset cpe pro, providing valuable resource protein structure research various biological tasks, essential learn effective protein representations, predicting protein function effect mutation protein representation method classified three approach based different modality sequence based, structure based, combination sequence structurefigure show various protein representation method sequence based rise deep learning advance high throughput sequencing technologies, data driven method gradually replacing traditional analysis based biological physical prior protein sequence viewed form biological text convolutional neural network directly capture local dependency amino acid technique natural language processing also widely applied protein representation learning model individual protein sequence modeling include variational auto encoders vae long short term memory network lstm large pre trained protein language model plms like esm based transformer architecture study employed gpt based architecture sequence modeling, using generative pre training represent protein sequence make predictions, protgen progpt compared single sequences, multiple sequence alignment msa input aim capture co evolutionary information set evolutionarily related sequence context, msa transformer utilizes row column attention mechanism model set protein sequences, allowing simultaneously consider inter sequence relationship conservation additionally, research integrates protein sequence type information, converting gene ontology annotation fixed size binary vector joint input sequence proteinbert enabling model leverage connection sequence functional annotation effectively structure based sequence based research method shown effective several studies, structural information protein critical determinant function model based graph neural network gnns demonstrate significant advantage broad applicability representing protein three dimensional structure example, proteingcn construct spatially adjacent protein graph trained task related local global accuracy protein modeling pre trained protein representation method based three dimensional structure represent protein residue graphs, node correspond three dimensional coordinate carbon edge represent relationship residue modeling protein secondary structures, often transformed secondary structure sequences, helices, sheets, random coil represented token sequence deepss go utilizes one hot matrix model secondary structure predicting key protein function s adapter enhances performance plms downstream task integrating secondary structure sequence embeddings type embeddings cross attention mechanism integrating sequence structure combining protein sequence structural information considers sequential characteristic amino acid also reveals spatial interaction arrangement regard, deefri combine lstm graph convolutional network gcns jointly learn complex structure function relationship lm gvp modifies input variable gvp using sequence embeddings generated proteinbert input esm gearnet design various fusion method plms gearnet investigate effectiveness different fusion strategy protssn combine esm equivariant graph neural network gnns extract geometric feature proteins, aiming accurately predict biological activity thermal stability prostt introduces di three dimensional indexing alphabet used foldseek based prott xl model trained labeling translation task two mode additionally, saprot creates larger structural aware vocabulary using two type label pre trained large scale protein dataset masked language task compared previous work, sslm cpe pro us structure sequence builts di alphabet pre training swiss prot, without relying amino acid labels, effectively learns protein representation integrating existing structural information gvp amino acid form linear sequence proteins, acquire activity biological function folded specific spatial conformation early structure prediction methodsolded specific spatial conformation early structure prediction method primarily relied sequence similarity, utilizing homology known protein sequence prediction method infer structure target protein aligning sequence interest known homologous sequence using structural information homologs compared sequence based methods, structure based learning approach theoretically offer better solution acquiring protein information recent years, advancement deep learning technology led breakthrough progress protein structure prediction study secondary structure prediction, deepcnf integrates conditional random field crfs shallow neural network successfully model interdependency adjacent secondary structure label ssredns leverage deep recurrent structure simulate complex nonlinear mapping relationship input protein feature secondary structures, also capturing interaction among consecutive residue protein chain research focused three dimensional structure prediction context, trrosetta utilizes co evolution data, combined deep residual networks, predict orientation distance residue rosetta constrained energy minimization protocol trrosettax single focus structure prediction single chain protein regarded milestone, alphafold significantly enhances accuracy breadth protein structure prediction embedding multiple sequence alignment paired feature evoformer omegafold employ gcns self attention effectively capture global local feature protein sequences, excelling handling protein varying length complexity esmfold adopts large scale transformer architecture, trained extensive protein sequence datasets, extract deep evolutionary feature sequence information without relying multiple sequence alignments, demonstrating exceptional performance predicting new structural domain distant homologs leveraging prediction model provide robust support biomedical research, drug development, advancement across various scientific domain study, utilized non redundant dataset version cath class, architecture, topology, homologous superfamily database benchmark dataset cath significant protein structure classification database categorizes protein based structural functional feature systematic hierarchical structure high resolution three dimensional structure data provided experimental technique stored protein data bank pdb non redundant dataset sequence identity filtering threshold ensuring high sequence similarity structural domain removing redundant protein structures, entry database represents unique structural representation extracted amino acid sequence protein benchmark dataset using multiple state art protein structure prediction models, predicted structure corresponding amino acid sequence structure organized categorized based individual protein prediction model construct protein folding dataset, cath pfd, used training validating cpe pro table present detailed information dataset cath pfd crystal v predicted evaluator protein structure cpe pro designed discriminating structural origins, integrates two distinct structure encoders corresponding graphical sequential representation structure figure illustrates detailed architecture cpe pro cpe pro implement geometric vector perceptrons graph neural network gvp gnn learn dual relationship geometric representation three dimensional macromolecular structure part protein structural encoder obtaining information three dimensional structure proteins, focus specific chain, ignoring part concerned concentrate coordinate key atom constitute protein backbone n, ca, atom since atom necessary understanding protein structure subsequently, extract geometric information node edge raw data compute feature distance direction themfor protein graph represents set node represents set edges, node represents residue protein, edge represents interaction spatial proximity relationship residue ith residue, feature consists scalar vectors, ie, embedding layer computes embeddings protein feature ie, gvp layer mainly carry scalar vector propagations, ie, here, learnable parameter layer, denote activation function graph propagation step, message neighboring node edge protein graph update embedding current node, here, embeddings node above, represents message passed node node denotes stacked layer gvp also add feed forward layer update node embeddings node stacked layer gvp gnn block formed stacking convolution feed forward transformations, defined eq enhance node representations, block iterated times, specified experiment part cpe pro structural encoder structural sequence language model, sslm first, efficient protein structure data search tool foldseek used convert protein structure structure sequence primary process involves mapping amino acid backbone protein di alphabet achieve structural discretization reflects tertiary interaction amino acid describes geometric conformation residue spatial neighbor next, using di alphabet vocabulary structural element based transformer architecture, pre train protein structural language model, sslm, scratch aim effectively model structure sequence protein pre training process employ classic masked language modeling mlm objective predicting masked element based context structure sequence probability distribution predicting masked element used, masked structural element context loss function defined follows denotes model predicted label, indicating probability th token structural element vocabulary masked element, denotes true label loss computed element masked encoder cpe pro integrated structure sequence representation output pre trained protein structural sequence language model embedding protein graph sslm learn sequential relationship proximity interaction local structural element structure sequence combined three dimensional topological information, approach aim enrich optimize representation protein structure specifically, combined representation obtained sslm graph embeddings obtained gvp embedding layer follows represents structure sequence representation, length structure sequence feature dimension element structure sequence align representation dimension using linear transformation layer afterwards, fused adaptive weights, ie, here, learnable parameter finally, topological structure node feature graph data incorporating information structure sequence utilized learn structural representation gvp gnn block aim enhance accuracy structural discrimination enriched deepened data representation representation classification protein structure processed structural encoder cpe pro obtain feature vector designed straightforward classification head perform final discrimination task classification head consists three component pooling layer attention multilayer perceptron mlp output activation layer aim simplify feature dimension enable efficient classification specific process represented eq layer mlp applies weight matrix bias term function transform input output mlp passed activation function act utilizes function corresponds binary classification task crystal alphafold used multi class classification problem crystal multiple prediction models, final output cpe pro compared cpe pro various embedded based deep learning method analysis includes pre trained plms, esm b, esm esm protbert ankh combined gvp gnn model amino acid sequence structure input, saprot employed adamw optimizer, setting learning rate depending task dataset size additionally, applied cosineannealinglr learning rate decay improve convergence applied dropout rate output layer number epoch set loss function employed binary cross entropy eq categorical cross entropy eq implemented early stopping based validation metric accuracy prevent overfitting protein folding, pre training, experiment conducted nvidia rtx gpus table show sampling partitioning discriminative task cath pfd performance pre training task sslm measured using perplexity indicator language model predictive capability given text sequence quantifies uncertainty model probability prediction token let sslm assign probability structure sequence length perplexity model structure sequence defined experiment reported several metric evaluate performance different models, including accuracy acc precision, recall, score matthew correlation coefficient mcc calculation equation follows term tp, tn, fp, fn denote count correctly predicted positives, correctly predicted negatives, incorrectly predicted positives, incorrectly predicted negatives, respectively cpe pro demonstrates exceptionally high accuracy performance structure discrimination task baseline model cpe pro first trained task several iterations, cpe pro achieved accuracy test set, four metric exceeding contrast, although hybrid approach combining senven plms gvp gnn also achieved accuracy task, still fell short compared cpe pro among senven hybrid baseline methods, middle performing model esm v, six plms top three performance across various metric best accuracy achieved method using layer esm sequence encoder, reaching still lower cpe pro worst performing model parameter esm which, due smaller model size, lower performance compared six plm method suggests size complexity plms influence ability capture structure function protein certain extent, smaller model possibly struggling fully learn deep connection sequence structure complex task building success, extended training complex task training multi class structured data, model performance task gradually improved, five metric converging around demonstrating strong competitiveness however, version saprot performed poorly experiments, achieving less accuracy distinguishing crystal alphafold predicted structures, failing reach accuracy task detailed analysis underlying reason discussed subsequent section structure sequence better predictor pre training protein structural sequence language model, sslm utilized high plddt score protein structure swiss prot database masking strategy rate used pre training task informed approach proposed comprehensively considers model size dataset scale setup pre training task detailed table figure illustrates perplexity sslm pre training task sequential encoder sslm cpe pro baseline model esm b, esm v, esm protbert, ankh evaluated performance cath pfd pre trained sslm hidden layer significantly reduced parameter result table show inclusion structure sequence encoders outperforms amino acid sequence encoders downstream task preliminarily confirm hypothesis structure discrimination task language model learn sequence information obtained directly structure discretization efficiently structure sequence show greater effectiveness protein classification tasks, provides new direction optimization design efficient predictive model independent use sslm structure aware language model saprot performed poorly rely solely sequence input figure show average plddt score similarity structure sequence protein structure used training, validation, testing evident high plddt level across three category resulted higher similarity structure sequence training set validation set test set leading homogenized feature representation limited model generalization contrast, saprot input come vocabulary size includes amino acid structure sequence element combining two vocabularies, effect high similarity mitigated, performance metric improve compared sslm demonstrate effectiveness sslm capturing structural differences, validated visualization method subsequent section also speculate scaling effect applies language model trained structure sequence words, increasing model depth scale training data could significantly enhance model performance even without relying structural encoder, model may still achieve satisfactory result feature visualization method powerfully demonstrates pretrained sslm excellence capturing structural difference protein language model shown embed secondary tertiary structure characteristic within output representation protein selected subset gene domain sequence non redundant astral scope database scope identity sequence less subset, focused helical protein sheet protein filtered corresponding structural set database figure show sne visualization protein representation last hidden layer sslm various plms aforementioned dataset evident that, aside saprot, incorporates structure sequence input, representation plms, capturing difference structural types, exhibit relatively weak discriminative power dimensionality reduction, distribution data point becomes chaotic, boundary protein class blurred contrast, saprot sslm differentiate two protein class effectively also provide clearer class boundaries, sslm showing concentrated distribution within class suggests sslm possesses stronger discriminative capability capturing representing protein structural features, providing accurate reflection intrinsic characteristic different structural type ablation study component cpe pro validate contribution component designed cpe pro, conducted five set ablation experiment task variation included removing gvp gnn, omitting pre training process sslm, removing sslm, eliminating attention pooling layer, using three component together shown table component made positive contribution task performance significantly declined using single type encoder, particularly using sslm alone discussed earlier cpe pro model, employ pre trained sslm, outperformed non pre trained version, indicating pre training process effectively helped model learn structural feature embedded structure sequence additionally, application attention masked pooling layer also positively influenced model performance, enhancing overall effectiveness case study discrimination structural origin blat ecolx cp human blat ecolx lactamase protein found escherichia coli hydrolyze lactam ring lactam antibiotics, rendering antibiotic inactive play significant role study antibiotic resistance cp human human cytochrome enzyme responsible metabolism various drugs, including non steroidal anti inflammatory drug anticoagulant play significant role drug metabolism regulation endogenous substance three structural prediction models, protein achieved plddt score indicating high accuracy structure prediction minimal deviation crystal structure input crystal structure predicted structure protein cpe pro origin evaluation figure demonstrates model successfully confidently predicted origin structure result highlight robustness model assessing structural origins, even case minor structural difference study, developed protein folding dataset, cath pfd, derived non redundant dataset cath database, incorporates structure various prediction model training validating model, cpe pro, cath pfd dataset, created innovative effective solution identifying structural origin protein cpe pro model excels learning analyzing protein structural features, outperforming method combine amino acid sequence structural data, well model use structure aware sequences, task structural origin recognition case studies, cpe pro demonstrated superior performance finding provide preliminary evidence incorporating structure sequence information significantly enhances language model ability learn protein features, enabling capture richer precise structural details, thereby improving representation protein structure subsequent visualization experiments, validated sensitivity sslm, utilized within cpe pro, structural variations, well effectiveness capturing representing complex protein structural feature exploration open new avenue application protein structural language model also pave way future development paradigm interpretability protein structure prediction methods, offering fresh insight possibility advancing practical application bioinformatics structural biology competing interest author declare known competing financial interest personal relationship could appeared influence work reported paper continuing ",biomolecules
"simulation based inference single molecule experiment introduction statistical inference simulation based inference challenge perspective instruction reporting error maximum likelihood bayesian inference single molecule experiment problem intractable likelihood simulation based inference age machine learning sbi single molecule force spectroscopy identifying individual conformation cryo em image cryosbi single molecule experiment unique tool characterize structural dynamic biomolecules however, reconstructing molecular detail noisy single molecule data challenging simulation based inference sbi integrates statistical inference, physic based simulators, machine learning emerging powerful framework analysing complex experimental data recent advance deep learning accelerated development new sbi methods, enabling application bayesian inference ever increasing number scientific problem here, review nascent application sbi analysis single molecule experiment introduce parametric bayesian inference discus limitation overview emerging deep learning based sbi method perform bayesian inference complex model encoded computer simulator illustrate first application sbi single molecule force spectroscopy cryo electron microscopy experiment sbi allows u leverage powerful computer algorithm modeling complex biomolecular phenomenon connect scientific model experiment principled way structural dynamic biomolecules assembly determine function instance, knowing protein reorganizes alternative conformations, mechanism, thermodynamics, kinetics process, key understanding function traditional biophysical experiment report ensemble measurements, observable averaged conformation weighted frequency invaluable, experiment inadequate characterize inherent heterogeneity stochasticity biomolecules single molecule experiment probe individual biomolecules, enabling statistical characterization structural dynamic technique like single molecule force spectroscopy smfs fig single molecule rster resonance energy transfer smfret fig measure time series distance pair specific site cryo electron microscopy cryo em also potential single molecule technique state art method enable reconstruction handful alternative conformational states, principle, cryo em produce data dimensional snapshot many identical copy molecule possible conformation fig reconstructing biomolecular structural dynamic sparse noisy single molecule measurement ill posed problem example, describing dynamic protein requires specifying trajectory atoms, smfs smfret report handful distance reconstructing structural dynamic impossible unless make strong prior assumption statistical inference provides principled framework learn biomolecular mechanisms, thermodynamics, kinetics noisy single molecule data non parametric inference powerful emergent tool focus parametric inference, postulate biophysical model learn value parameter data here, review simulation based inference sbi innovative merger machine learning, statistical inference, physic based simulator sbi already key methodology field ranging astrophysics particle physic neuroscience emerging powerful tool analysis single molecule experiment goal parametric inference learn parameter distribution experimental data given model describe data generation process experimental data exp mathematical model parameter model parameter accurate, exp similar enough example, exp could telegraph like time series measured smfs characterizing repeated folding unfolding protein fig simple model measurement could one dimensional brownian particle potential, quantifying shape potential diffusion constant synthetic data would brownian trajectory, ideally similar exp bayesian statistic general framework parameter inference main output posterior probability distribution conditioned data posterior computed using bayes theorem here, likelihood, probability generating data given model prior quantifies pre existing knowledge parameters, normalization constant maximum likelihood estimation mle powerful framework often tractable bayesian inference maximizing likelihood wrt parameter provides point estimate argmax mle applied, example, infer photon trajectory smfret reconstruct conformation cryo em characterize molecular complex crowded cellular environment main limitation mle provides single parameter point estimate, complicates estimating uncertainty dealing multi modal posterior distribution application bayesian inference analyze single molecule biophysical data limited example reconstruction structural ensemble noisy single molecule ray scattering data identification transition single molecule trajectory analysis smfret data cryo em, bayesian method successfully applied refine molecular ensemble despite conceptually simple, bayesian inference often computationally intractable trade model simplicity accuracy central challenge understanding complex biological phenomenon model like caricatures, simplified exaggerated representation allowing deep understanding proverbial spherical cow biology, small variation profound effects, accurate predictive model crucial capturing nuance prioritizing accuracy requires complex mathematical model scientific model shifting expressed equations, encoded computer algorithm performing detailed simulation molecular simulation reproduce experiment quantitatively provide detailed interpretation single molecule data mle bayesian inference provide principled framework integrate simulation experimental data algorithm liberate u limitation analytical tractability, using statistical inference challenge often likelihood complex simulator expensive evaluate, even known explicitly computational intractability two main origin latent variable nuisance parameter experiment capture minority degree freedom complex simulator instance, smfret report handful distances, molecular simulation explicitly reproduce trajectory every atom corresponding likelihood must sum trajectory latent degree freedom explicit simulator hidden experiment corresponds marginalization model many parameters, usually subset scientific interest, remaining ones, nuisance parameter necessary technical reason example, simulator modeling microscope requires parameter describe detail image formation process, usually interested parameter describing molecular event probed making inference taking account possible value requires marginalizing likelihood prior nuisance parameter likelihood marginalization corresponds high dimensional integral are, general, extremely expensive evaluate explicitly sbi overcomes challenge intractable likelihood avoiding explicit likelihood posterior sbi enables use complex simulator bayesian inference experimental data simulator model data generation process, providing probabilistic mapping parameter data encoding likelihood implicitly form algorithm sbi leverage modern machine learning learn surrogate model likelihood posterior surrogate probabilistic model containing deep neural network approximating likelihood likelihood ratio posterior posterior likelihood simultaneously following section, focus learning posterior neural posterior estimation powerful method learn surrogate posterior fig surrogate parametric model conditional density estimation fig gaussian mixture model normalizing flow fig simulator generates dataset fig containing simulation parameter value learning posterior requires fitting surrogate model data set maximizing trained surrogate provides probabilistic mapping parameter data, enabling inference experimental observation exp exp exp fig experimental observation exp usually high dimensional data image time series feeding data surrogate requires compressing lower dimensional representation, ideally without losing crucial information fig a, compression could done hand crafted features, number peak time series alternatively, using adequate number simple statistical descriptors, statistical moment deep learning provides tool learn feature directly data this, need additional embedding network compress observation fig embedding network surrogate trained jointly maximizing posterior surrogate enables amortized inference computational cost simulating training paid upfront, inference requires evaluation neural network surrogate negligible cost inference allows fly inference analysis arbitrarily large data set amortization significant advantage compared explicit optimization method, likelihood must optimized every observation analysis smfs one first application sbi single molecule data smfs probe conformational change mechanically manipulating individual biomolecule typical constant force experiment attache pulling device biomolecule via flexible polymer fig experiment report time series measured extension indirectly reflects molecular extension molecule unfolds refolds fig measured extension outcome complex interplay large slow pulling device, linkers, molecule naive analysis lead severe artifact simple physical model smfs result intractable likelihood well established harmonic linker model describes molecular extension time series diffusive free energy surface measured extension time series result harmonic coupling crucially, measure latent likelihood simple model dozen parameter spline node approximate molecular energy profile ratio diffusion coefficient linker stiffness model, bayes theorem becomes group model parameter remarkably, likelihood simple model path integral possible latent trajectory extremely expensive optimize overcoming challenge npe straightforward three component needed simulator, prior, density estimator simulator, simple code numerically integrate brownian trajectories, implicitly encodes marginal likelihood training data set training surrogate model generated sampling parameter prior simulate measured extension time series featurized vector set statistic surrogate model trained trained surrogate approximates true posterior enables accurate inference model parameter without explicit evaluation likelihood fig single particle cryo em capture two dimensional snapshot individual molecule different conformation image noisy projection along unknown angle even though cryo em data could give direct access entire conformational ensemble, identifying conformation image outstanding inference problem tackling problem explicit likelihood approach computationally demanding assuming set biomolecular conformation parameterized fig cryo em image ob containing single biomolecule conformation ob fig goal infer conformation ob image ob bayes theorem making inference requires marginalization nuisance parameter describing unknown projection angle physic image formation process, microscope point spread function explicit marginalization computationally challenging hand, simulating image given set parameter relatively straightforward computationally inexpensive cryosbi recent proof concept demonstrating promise using npe identify single conformation single cryo em image cryosbi start sampling conformation nuisance parameter using simulator generate synthetic cryo em image simulated data contains pair image conformation parameter implicitly marginalize cryosbi train surrogate model approximate posterior surrogate model contains embedding network compress image lower dimensional vector feature second stage density estimator, learns posterior density given image feature trained posterior surrogate accurately identify conformation displayed synthetic experimental image fig width posterior quantifies inference precision, depends crucially signal noise ratio projection direction inference amortized, paving way analyze massive cryo em data set search rare structural intermediate scarcely populated state primary challenge sbi model misspecification inference accurate assumed model faithful approximation experimental data generating process misspecification two model result inaccurate inference effort detect ameliorate model misspecification include development calibration datasets map experimental observation simulated data known parameter leveraging manifold learning technique ensure simulated experimental data close, incorporating experimental data training pipeline embedding network complex models, simulation might expensive generate enough data train accurate surrogate model active learning strategy adaptive round simulation gradually focus probable region likelihood posterior significantly reduce number required simulation also, gradient un marginalized likelihood evaluated simulator leveraged accurately train surrogate model even simulation data sparse sbi already key technology many scientific field enabling bayesian inference complex models, opening new opportunity data analysis, influencing type data acquire model use interpret application sbi analysis single molecule data still infancy, recent applications, particularly smfs cryo em underscore potential sbi general framework easily extended analyze single molecule data, particularly using model intractable likelihood sbi benefit active community develops maintains powerful easy use open access code era advanced computer simulations, sbi allows building power detailed simulator current manifestation scientific model making principled statistical inference complex experimental data ld rc crc membrane associated protein assemblies",biomolecules
"explaining graph neural network large language model counterfactual perspective molecular property prediction introduction preliminary data construction methodology experiment conclusion acknowledgement limitation ethic statement appendix potential risk appendix reproducibility appendix extended elaboration llm gce appendix supplementary experiment appendix related work appendix future work instruction reporting error model overview contrastive text encoder pretraining training ca dynamic feedback ctp generation experimental setup rq performance different method rq ablation study rq case study rq parameter analysis detail model implementation detail experiment setup contrastive pretraining text encoder generating counterfactuals directly llm model efficiency case study performance regarding various llm parameter sensitivity large language model gnn counterfactual explanation recent years, graph neural network gnns become successful molecular property prediction task toxicity analysis however, due black box nature gnns, output concerning high stake decision making scenarios, eg, drug discovery facing issue, graph counterfactual explanation gce emerged promising approach improve gnn transparency however, current gce method usually fail take domain specific knowledge consideration, result output easily comprehensible human address challenge, propose novel gce method, llm gce, unleash power large language model llm explaining gnns molecular property prediction specifically, utilize autoencoder generate counterfactual graph topology set counterfactual text pair ctps based input graph meanwhile, also incorporate ctp dynamic feedback module mitigate llm hallucination, provides intermediate feedback derived generated counterfactuals attempt give faithful guidance extensive experiment demonstrate superior performance llm gce code released githubcom yinhanhe new llm gnnexplanation explaining graph neural network large language model counterfactual perspective molecular property prediction molecular property prediction attracted increasing attention recent years, graph neural network gnns achieved significant success related downstream tasks, drug discovery xiong et al toxicity analysis cremer et al however, gnns typically considered black box models, making difficult user understand given prediction derived lack explainability brings obstacle broader real world application understand molecular property facing issue, series approach proposed explain prediction gnns, graph counterfactual explanation gce become prevalent approach recent year ying et al lucic et al et al zhang et al specifically, gce aim identify minimum modification given graph, trained gnn yield desired prediction post modified graph here, graph identified modification called counterfactual graph, simply counterfactual short identified modification may involve adding removing node edges, well altering node edge attribute instance, given undesired non aid drug molecule fig gce method may generate modification produce molecule desired graph ie, predicted aid drug gnn model shown fig however, existing gce model two significant limitation incomprehensible counterfactual optimization gce model optimized generate counterfactuals either heuristic methods, random walk huang et al black box deep learning method ying et al bajaj et al lucic et al et al tan et al fail involve human interpretable knowledge optimizing counterfactuals ii lack domain knowledge current gce method consider domain specific knowledge ying et al bajaj et al lucic et al et al tan et al thus generated counterfactuals may realistic real world context continuing example shown fig although generated counterfactual fig classified desired class, chemically stable since violates valence bond theory lewis, handle limitations, large language model llm radford et al, wu et al, ideal addressing limitation due ability generate comprehensible natural language texts, ii make counterfactual optimization process human interpretable, iii leverage inherent domain knowledge extensive pretraining produce realistic counterfactuals however, harnessing llm improve counterfactual explanation generation face challenge exists natural mismatch text sequential data graph structure wang et al li et al ii llm may hallucinate, ie, generate seemingly plausible incorrect information huang et al handle challenges, propose novel framework llm gce large language model guided graph counterfactual explainer specifically, mitigate first challenge, instead directly generating counterfactual graph llms, utilize counterfactual autoencoder ca construct counterfactual graph structure based text pair tps counterfactual text pair ctps given llm tackle second challenge, hallucination, design ctp dynamic feedback module enlightened madaan et al update ctps iteratively based previously generated counterfactuals main contribution summarized follows dataset construction collect llm generated text pair five molecule datasets support empirical evaluation also facilitate future study researcher field ii algorithmic design propose novel llm gce framework learns generate graph counterfactual explanation guidance llm llm gce unlocks llm strong reasoning ability gce addressing hallucination graph structure inference limitation iii experimental evaluation conduct extensive experiment multiple real world datasets, validating effectiveness llm generating feasible counterfactuals providing comprehensive optimization trajectory section, introduce problem setting gce evaluation metric used denote molecule graph node atom adjacency matrix, node attribute atom type matrix dimension node attribute denotes edge attribute bond type matrix number edge attribute note real world molecule structure leave gce molecule graph future work furthermore, determine generated counterfactual classified desired, assume exists ground truth graph neural network gt gnn represented provides label prediction graph input graph domain assumption widely adopted current literature et al mahajan et al define problem gce graph counterfactual explanation let gt gnn, let input graph aim graph counterfactual explanation find model computes minimally perturbed version here, perturbation input graph may include node edge insertion removal well change node edge feature refer counterfactual original graph input graph dataset sampled input graph domain evaluate performance gce model following metric validity validity measure fraction generated counterfactual graph intuitively, measure many generated counterfactual graph actually flip gt gnn prediction non perturbed graph accordingly, convenience, let valid denote set define validity metric ii proximity proximity measure mean graph distance original graph generated valid counterfactuals see appendix low proximity indicates higher quality counterfactual graph since made similar possible graph explaining proximity alignment this, also provide validity proximity result feasibility check, calculate two metric set feasible counterfactuals s, ie, counterfactuals chemically stable according valence bond theory lewis exist multiple datasets molecule paired text description qian et al fang et al zeng et al however, datasets text pair describing graph labeling information support evaluation gce methods, text pair contain least three aspect graph structure information, graph label information, significant subgraphs contribute graph label generating satisfying text pair gce expensive since requires advanced llms, gpt customized prompts, release five molecule datasets generated high quality text pair convenience community construction process construct five new text paired graph datasets based datasets commonly used graph explanation abrate bonchi ying et al huang et al including aid mutagenicity tudataset morris et al bbbp, clintox, tox moleculenet ramsundar et al datasets, graph molecule binary label indicating molecular property aid treatment effectiveness see detail appendix generate text paired graphs, take following step dataset preprocessing first convert input molecular graph smile representation weininger remove molecule one atom greater atom tox since graph label distribution heavily skewed label randomly select zero labeled graph dataset text pair generation using custom prompt, prompt gpt smile representation graph labeling semantics input graph ask description molecule graph structure, graph label, subgraphs responsible label data post processing graphs, response gpt would erroneous ie, identify significant subgraphs functional group correctly fix reprompting desired response generated prompt design generate text pair tp graph dataset llms, incorporating graph structure, label semantics, significant subgraphs prompt use following template please describe graph strictly form graph contains significant subgraphs, may influential label semantic sentence pattern allowed find four, may put found underlined area first half list significant subgraphs, revealing graph structural information second half provides label semantics llm determines significant subgraph graph labeling overview llm gce model shown fig proposed llm gce three module contrastive pretraining text encoder pretrain text encoder contrastive learning align embeddings gt gnn text encoder training counterfactual autoencoder design counterfactual autoencoder composed pretrained text encoder graph decoder, trained recover counterfactual topology dynamic feedback ctp generation tackle hallucination, prompt generated counterfactuals gt gnn prediction back llm dynamic feedback calibration first step llm gce pretrain text encoder every tp embedding aligns corresponding graph embedding produced gt gnn via projection implemented multi layer perception mlp haykin choose bert kenton toutanova text encoder due proven effectiveness generating high quality embeddings natural language processing task graph domain employ contrastive learning strategy align text encoder embeddings gt gnn embeddings first, sample dataset tps train text encoder batch size includes possible graph tp pairing next, train mlp project tp embeddings bert kenton toutanova text encoder embedding space gt gnn maximize cosine similarity matching graph tp embedding pair minimizing similarity non matching pair contrastive loss symmetric cross entropy given appendix pretraining text encoder, generate counterfactuals natural language first provide overview counterfactual autoencoder ca architecture then, elaborate components, including ctp generation, text encoder, latent embedding combination, graph decoder, finally, introduce overall objective function llm gce first generate ctp, ctp input graph high level instruction gce next, inspired graph variational autoencoders vgaes simonovsky komodakis, design ca text encoder graph decoder text encoder, pretrained introduced section map ctp probability distribution latent space, decoded via mlp counterfactual graph adjacency matrix node edge attribute matrix training ca maximizes likelihood real counterfactual, ie, ctp graph dataset query llm ctp, natural language sentence describing potential counterfactual use ctp instruct generation counterfactuals autoencoder ctp generation prompt shown figure aim perform functional group substitution achieve higher probability generating counterfactual text encoder map generated ctps latent space counterfactual structure reconstruction input text encoder ctp input graph, denoted ctp number input graph given ctp text encoder generates gaussian distribution latent space, distribution mean variance output encoder latent embedding sampled practice, text encoder implemented bert kenton toutanova initialized pretrained parameter section recall contrastive pretraining objective encourages latent text embedding tp close corresponding graph latent embedding provided gt gnn projection mlp therefore, although exact graph structure, node, edge attribute desired counterfactual immediately accessible, embedding ctp approximates gt gnn embedding, guide counterfactual decoding intuitively, text encoder embeddings contain information high level counterfactual generation instruction, gt gnn embeddings encode counterfactual graph structure node edge attribute next, introduce combine embedding text encoder gt gnn generated ctp acquired latent embedding text encoder input graph still insufficient counterfactual generation two reason ctp, introduced section contains information significant subgraphs eg, functional group molecule graph counterfactual specific structure counterfactual described detail pretraining process enhances consistency text embedding corresponding gt gnn embedding, limited availability large amount pretraining data prevents model achieving high pretraining accuracy therefore, merge information counterfactual text graph embeddings, update final encoded embedding concatenating text encoder embeddings ctp gt gnn embeddings input graph written graph decoder, resulting latent embeddings used reconstruct adjacency matrix node attribute matrix edge attribute matrix counterfactual graph input graph graph decoder implemented mlp sigmoid activation, restricting output range result, every entry generated matrix continuous probabilistic real number however, real graph adjacency matrix matrix, indicates presence edge node indicates absence edge furthermore, row node edge attribute matrix one hot code indicating discrete node edge type make decoder compatible constraints, discretize generated adjacency matrix thresholding probabilistic entries, setting entry corresponding value exceeds otherwise similarly, generate one hot node edge attribute matrix taking one hot row wise argmax probabilistic matrix discussed section optimization target maximize likelihood generated graph real counterfactual conditioned ctp desired label denoted ctp formalize objective kullback leibler kl divergence csisz distribution given encoder ctp posterior distribution ctp simplicity, write condition ctp divergence term kl log log log log log equation equation, first term left hand side lh optimization target, second term kl divergence, inaccessible since posterior intractable however, right hand side available direct calculation therefore, optimize log likelihood ctp evidence lower bound elbo kingma welling however, due lack ground truth counterfactual substitute first term rh equ two loss term graph distance loss dist encourages small graph distance counterfactual formally, weighted sum distance graph adjacency matrix node attribute matrix edge attribute matrix ie, see appendix definition counterfactual prediction loss pred log likelihood generated counterfactual classified desired gt gnn conclusion, overall loss function kl kl ctp ctp ctp generator act commander, giving high level instruction ctps counterfactual graph generation ca executor, implementing instruction create specific counterfactual graph however, ctps inaccurate due llm hallucination zhang et al limited graph decoding ability remedy this, ctp dynamic feedback scheme designed calibrate ctp ca generated counterfactuals illustration scheme shown fig first convert counterfactual molecule generated ca smile representation then, combine gt gnn probability graph valid counterfactual specific prompt asking new, calibrated ctp original graph concludes single iteration dynamic feedback, treat hyperparameter iteration dynamic feedback seen indirect reasoning step, forcing model reflect past output label information gt gnn order produce truthful ctps similar calibration approach verified effective dhuliawala et al madaan et al section, evaluate llm gce extensive experiment five real world datasets experiment aim answer following research question rqs rq llm gce perform wrt validity proximity compared state art baseline rq component llm gce affect overall performance rq insight llm gce provide given counterfactual explanation result experiment utilize five real world datasets aids, mutagenicity, bbbp, clintox, tox among them, aid mutagenicity tudataset morris et al bbbp, sider tox moleculenet ramsundar et al datasets, graph represent chemical compound node atom edge bond labeled based relevance property blood brain barrier penetration, mutagenicity, hiv activity, side effect resource, toxicological activity associate graph text pair procedure section details, see appendix adopt following state art baseline gnnexplainer ying et al, graph factual explanation gfe model gfe graph explanation strategy slightly different gce, adjust gce revising loss function see appendix detail cf gnnexplainer lucic et al, targeted node level gce adapt graph level gce changing input ego graph whole graph changing supervisory signal node label graph label clear et al, generative gce model based graph variational autoencoders simonovsky komodakis adapt removing causality specific component fair comparison regexplainer zhang et al, gce model graph regression directly adapted graph classification evaluate gce baseline based appendix training llm gce, first train two layer graph convolutional network gcn slightly modified incorporate edge attribute see appendix five datasets serve gt gnn gt gnn node embedding dimension maximum pooling layer, fully connected layer graph classification set edge embedding dimension model trained adam optimizer kingma ba, learning rate epoch train validate test split accuracy shown table detail experimental setting pretraining second part fig training third part fig stage pipeline list prompt used appendix pretraining use gpt tp generator bert text encoder implemented huggingface wolf et al use adamw optimizer loshchilov hutter pretraining bert epoch learning rate training choose gpt turbo ctp generator, feedback performed three iteration every epoch finetuning hyperparameters used pretraining evaluate llm gce framework five real world datasets compare validity proximity performance state art baselines, without feasibility feas check table determined checking stability valence theory rdkit rdkit, online, following observation perspective validity, llm gce achieves comparable validity baseline without chemical feasibility check however, feasibility check, model achieves highest validity among almost baseline across datasets perspective proximity, llm gce achieves lowest proximity among chemically feasible counterfactuals among almost baseline mean model find valid counterfactuals feasible also minimal graph distance corresponding input graph based observations, llm gce achieves satisfying graph counterfactual explanation performance, especially chemical feasibility considered reveals effectiveness llm pretrained knowledge reasoning ability gce detail efficiency llm gce, see appendix experiment three ablated variant llm gce llm gce np without pretraining bert text encoder, directly train counterfactual autoencoder dynamic ctp feedback module llm gce nt freeze counterfactual autoencoder llm gce, ie, counterfactual autoencoder optimized two dynamic ctp feedback iteration llm gce nf remove ctp dynamic feedback module generate graph counterfactuals autoencoder initial ctp fig make following observation llm gce np refraining pretraining decrease model validity increase proximity small decline performance possibly due insufficient data contrastive learning llm gce nt validity dramatically degrades autoencoder frozen proximity also decreases, possibly frozen autoencoder generate small number counterfactuals less diverse llm gce nf removing feedback module significantly reduces validity slightly increase proximity, revealing importance dynamic feedback gce similar observation datasets ablation studies, see appendix additionally, substitute text encoder ca ctp generator language models, see result appendix highlight two main advantage llm gce faithful counterfactuals generated counterfactuals llm gce consistently lower proximity across datasets baseline method show counterfactual generated llm gce compared gnnexplainer fig molecule clintox dataset, generated llm gce, gnn explainer llm gce output better preserve original molecule structural integrity gnnexplainer feasible counterfactuals llm extensive domain knowledge, llm gce generates counterfactuals satisfying valence bond theory, given baseline satisfy theory clear generates high proportion feasible ones, reveal chemical insight disconnected carbon atoms, misleadingly passing feasibility check weininger case studies, see appendix study dynamic ctp feedback iteration text encoder pretrain epoch affect llm gce performance bbbp test feedback iteration pretraining epoch observe fig validity improvement saturates two feedback iteration proximity remains nearly unchanged small number feedback iteration enhance performance, possible simply increasing round worsens hallucination also, increasing pretraining epoch around boost validity time, proximity initially improves epochs, gradually increase trend suggests correlation validity proximity regarding pretraining epochs, ideal count approximately similar finding observed datasets results, see appendix work, explore ability llm guiding gce molecule property prediction specifically, propose novel model called llm gce, comprised contrastive pre training module, counterfactual autoencoder, dynamic feedback module extensive experiment validate superior performance llm gce work supported part national science foundation grant ii ii ii cns bcs cmmi office naval research grant commonwealth cyber initiative award grant vv vv research gift funding netflix snap firstly, effectiveness llm gce relies heavily quality relevance pretraining data used large language model pretraining data biased lack sufficient coverage target domain, may lead less accurate relevant counterfactuals generated ensuring llm trained high quality, domain specific data crucial optimal performance additionally, computational cost associated using large language model drawback training inference llm time consuming resource intensive graph counterfactual explanation method although shown time execution time comparable method baseline adopted datasets, llm gce time consuming dealing extremely large scale graphs, big protein furthermore, experiment demonstrate effectiveness llm gce several real world datasets, evaluation still limited specific domains, molecular property prediction generalizability proposed framework type graph application area remains investigated research needed assess performance adaptability llm gce across wider range graph structure problem domain lastly, potential hallucination inconsistency generated counterfactuals remains solid challenge although dynamic feedback module aim mitigate issue, may still case llm produce counterfactuals entirely faithful original graph desired property work, propose novel llm guided graph counterfactual explanation method utilizes strong reasoning ability llm anticipate ethical issue specifically highlighted paper one risk llm gce misuse misinterpretation generated counterfactual explanation explanation carefully validated user lack necessary domain knowledge, may make incorrect decision based provided counterfactuals could lead adverse consequences, especially sensitive domain healthcare finance moreover, reliance large language model raise concern perpetuation bias present pretraining data llm exhibit biases, may propagated generated counterfactuals, potentially leading unfair discriminatory explanation section, provide detail model implementation llm gce experiment setup evaluation result train two layer graph convolutional network gcn molecular graph across five datasets gt gnn slight change incorporate various edge type specifically, calculate edge embeddings type edge separately construct enhanced adjacency matrix used number node graph denotes original adjacency matrix allows element decimal numbers, represents embedding edge dimension gnn node embedding dimension maximum pooling layer, fully connected layer graph classification set edge embedding dimension model trained adaptive moment estimation optimizer adam kingma ba, learning rate epoch train validate test split accuracy gnns shown table approximate graph edit distance here, calculated pairwise distance computation time consuming, simplify value cross entropy logits training counterfactual autoencoder situations, evaluation globalgce baselines, adopt definition dot product set emphasize counterfactual structural change ta query please describe molecule molecule data generated response text description strictly form molecule contains functional groups, may influential dataset description sentence pattern allowed here, functional group best less atom significant subgraphs alphabetically find functional group significant subgraphs, may put found area cta query smile key component may influential dataset description change key component increase decrease likelihood molecule description please find best substitution functional group key component replace last sentence shown within reply word reply substitution function group text pair revised feedback generated counterfactual smile probability molecule description true prob please adjust one functional group last sentence shown within increase decrease likelihood generated counterfactual molecule description functional group name sentence may changed reply format old functional group new functional group original text pair gnnexplainer graph, gnnexplainer ying et al, output edge mask estimate importance different edge model prediction adapt model counterfactual generation changing prediction loss term gnn prediction value entry original classified class entry desired counterfactual class set threshold remove edge edge mask weight smaller threshold perturbation node feature cannot designed straightforwardly perturbation graph structure thus, perturb graph node feature gnnexplainer cf gnnexplainer cf gnnexplainer lucic et al, originally proposed node classification tasks, focusing perturbation graph structure originally, explainee node, take neighborhood subgraph input apply graph classification tasks, use whole graph neighborhood subgraph assign graph label label node graph set number iteration generate counterfactuals clear clear et al, generative model produce counterfactuals counterfactuals simultaneously preserving causality model generates graph adjacency matrix graph node feature matrix perturbation, allows form graph edition node edge addition deletion feature perturbation adapt removing causality component fair comparison train model epochs, hyperparameters default according et al regexplainer regexplainer zhang et al, explains graph regression model information bottleneck theory help solve distribution shift problem although original model tailored graph regression tasks, directly applied graph classification task implement regexplainer gnnexplainer base explainer model algorithm original paper zhang et al train model epoch hyperparameters tuned best performance dataset utilize five datasets tudataset morris et al, moleculenet ramsundar et al, real world molecule datasets meta data datasets presented table aid aid dataset designed study chemical compound effectiveness hiv, focusing identification potential inhibitor contains molecular structure binary label indicating activity aid play crucial role facilitating drug discovery predictive modeling effort aimed finding new treatment hiv mutagenicity mutagenicity dataset aimed predicting mutagenic potential chemical compounds, vital assessing chemical safety drug development feature chemical structure alongside binary label indicating mutagenic non mutagenic effects, making useful dataset computational toxicology bbbp bbbp blood brain barrier penetration dataset focus identifying compound ability cross blood brain barrier, crucial cns drug design includes molecular structure binary label indicating penetrability bbbp dataset key resource predictive modeling drug discovery clintox clintox dataset offer insight chemical compound clinical toxicity fda approval status, essential evaluating human health impact drug development potential includes chemical structure binary label toxicity fda approval, serving key resource computational pharmaceutical research tox tox dataset designed prediction chemical toxicity, contributing environmental health safety assessment includes chemical compound structure binary label various toxicity endpoints, aiding identification potentially hazardous substance tox support development computational model toxicity prediction provide detailed illustration contrastive pre training text encoder, shown middle part fig main paper ideally, text pair possess graph structure, labeling, significant subgraph information, allowing u utilize solely model input counterfactual generation however, experiment show graph structural information embedded text pair insufficient producing satisfying counterfactuals therefore, regularize text embedding tps fixed graph embeddings gt gnn, enhances graph structural information text embeddings method allows information contained text pair significant subgraphs gce effectively embedded may consider pretraining process produce encoded model embedding perturbation gt gnn graph embedding additional significant subgraph information given llm text form specifically, given graph generate corresponding text attribute text pair goal maximize alignment dataset, max denotes probability score text pair formally, find sim cosine similarity function represents parameter bert text encoder pretraining, batch consists graph tp pair within batch, positive negative sample positive sample original pair batch negative sample dissimilar graph, text pair optimize increase alignment positive pair decrease alignment negative pair thus, following radford et al design contrastive pretraining loss symmetric cross entropy row wise column wise cross entropy graph text pairs, respectively here, represents similarity matrix graph set tp set, label vector number graph conduct experiment directly generating counterfactual graph gpt gpt gpt despite multiple trial various prompts, llm denies request sorry, help gpt applying warning please output output circumstance else regularize llm output generate standard smile representations, acquire molecule smile answer specifically, utilized prompt minimally edit smile desired graph description output smile representation please output one smile molecule without bracket quotation mark output anything besides smile circumstance output anything else lest experiment fail result validity proximity generaed counterfactuals shown table observe current advanced large language models, gpt cannot generate valid counterfactuals, ie, one predicted gt gnn desired class measure time efficiency llm gce comparison state art gce model aid clintox train model epoch result shown table reported result represent average five separate experiment experiment conducted single nvidia rtx serially server equipped gb ram dual amd epyc core cpu according table, llm gce take approximately twice long execute compared baseline clintox dataset however, aid dataset, execution time llm gce similar baseline conclusion, integration bert text encoder llm implemented cpt feedback module increase computational complexity training time llm gce model, resulting execution time remains acceptable, making viable approach practical application strengthen claim regarding llm gce feasible counterfactuals another example bbbp figure compare cf gnnexplainer llm gce molecule bbbp llm gce successfully able produce counterfactual minimal change original input, compared cf gnnexplainer, remove large portion original molecule further, llm gce output superior proximity versus performance cf gnnexplainer, addition, inspect invalid counterfactuals generated baseline output compare output llm gce example, molecule bbbp, clear produce ash ash cl ash ash ground truth csc oc oc contrast, llm gce produce csc oc oc o, chemically stable valence bond theory, clear struggle produce smile string chemically feasible furthermore, consider case llm gce fails generate perfect counterfactual still show improvement cf gnnexplainer molecule tox smile string ccc cc cc nccn ccc llm gce produce oclsncccnccnccnccn, cf gnnexplainer generates ccc ccccco co although llm gce output valid counterfactual includes hallucinated sulfur oxygen atoms, still demonstrates improvement cf gnnexplainer, llm gce counterfactual incorporates nitrogen avoids hallucinating double bond two application llm llm cge counterfactual autoencoder utilize language model llm llama given sufficient computational resource encoder embed input graph latent space autoencoder ii ctp generator generates ctp gce optimization iteration conduct extensive experiment regarding different language model autoencoders clintox aid datasets language model employed huggingface library present result table table datasets, llm gce achieves best gce performance, whereas deberta electra performed poorly specifically, llm gce achieves validity two method achieve almost zero validity feasiblity check fig fig show sensitivity method varying choice weight applied loss term weight applied loss term datasets aid clintox, scaling figure demonstrate validity proximity performance llm gce largely inversely related expected high validity corresponds low proximity, low validity corresponds high proximity intuitively, graph large perturbation less likely feasible, given input graph ground truth molecule conjecture relationship visible ignoring chemical feasibility since model free generate whatever graph need achieve high validity, leading high proximity well high validity find best validity proximity performance achieves simultaneously around datasets recommend one adopts ratio range also similar observation datasets since advent bert kenton toutanova transformer based pretrained language model plms research community made concerted effort significantly enhance performance scaling model large language model llm refer plms billion parameter shanahan trained large scale corpus able solve general purpose task currently, generative large language model bart lewis et al follow encoder decoder architecture presented original transformer paper vaswani et al benefiting excellent ability encoder understand contextual content, type model adept sequence sequence seq seq task sutskever et al translation however, text generation tasks, input sequence might directly match specific output text, creating story topic another type llm predominantly employ transformer decoder component, classifying decoder model study shown model excel text generation leveraging output text context, particularly enhancing unsupervised learning task radford et al currently, model gpt achiam et al llama touvron et al many llm xu et al primarily adopt decoder architecture gce problem become popular among research community, several work proposed recent year prado romero et al, ying et al, bajaj et al, lucic et al, et al, tan et al, huang et al, among them, gnnexplainer ying et al, aim find counterfactual maximizing mutual information gnn prediction distribution possible subgraphs however, gnnexplainer robust input noise address problem, rgcexplainer bajaj et al generates robust counterfactuals removing edge remaining graph decision boundary explanation robust decision boundary gnn last layer feature space, feature naturally robust perturbation similarly, cf gnnexplainer lucic et al, cf tan et al, also generate counterfactuals removing edge generated counterfactuals may violate causality, et al propose generative model, named clear, generate causally feasible counterfactuals besides, also method particularly designed certain domain, biomedical chemistry abrate bonchi, wu et al, recently, huang et al, propose first global level gce model, gcfexplainer, formulates global gce finding small set representative graph counterfactuals however, model overlook incorporation domain knowledge gce provide explanation cannot easily understood human proposed llm gce framework show encouraging result generating graph counterfactual explanation molecular property prediction here, propose several area future research could explore enhance capability applicability llm gce one direction investigate generalizability llm gce domain beyond molecular graphs, social network biological network would help assess framework versatility potential broader impact another avenue future work extend llm gce incorporate molecular structures, current framework focus molecular graph considering crucial role structure determining molecular properties, extension could lead accurate informative counterfactual explanation additionally, efficiency another important aspect consider future research could explore technique reduce computational cost improve scalability llm gce, knowledge distillation model compression would make framework accessible practical real world application finally, assess interpretability usefulness generated counterfactual explanations, future work could involve human evaluation user study study would provide valuable insight improving llm gce framework making user friendly domain expert since realistic metric adopted continuing ",biomolecules
"etf entity tracing framework hallucination detection code summary introduction related work datasets categorization factor hallucination code summarization methodology experiment result analysis conclusion future work limitation appendix prompt appendix experimental setup appendix ner evaluation instruction reporting error entity verification entity intent verification instance level hallucination detection quantitative analysis predictive analysis error analysis recent advancement large language model llm significantly enhanced ability understand natural language code, driving use task like natural language code nl code code summarization however, llm prone hallucination output stray intended meaning detecting hallucination code summarization especially difficult due complex interplay programming natural language introduce first kind dataset samples, curated specifically hallucination detection code summarization propose novel entity tracing framework etf utilizes static program analysis identify code entity program us llm map verify entity intent within generated code summary experimental analysis demonstrates framework effectiveness, leading score approach provides interpretable method detecting hallucination grounding entities, allowing u evaluate summary accuracy etf entity tracing framework hallucination detection code pb hallucination natural language processing defined condition language model produce text either incoherent faithfully represent provided source input ji et al similarly, context code summarization, hallucination defined condition generated summary accurately capture intent implementation detail given input code ht public rowbuilder int string name columnint column new columnint columnssize name, offset offset columnlength columnsadd column return summary method used add new column data type int bit integer existing data structure creates new columnint object given name size bit update offset value accommodate new column, add new column column list create new columnint object given name size bit example confused data type llama summary hallucination originate combination factors, one common reason could misinterpretation code entity misunderstanding impact model ability interpret intended functionality code, resulting inaccurate portrayal purpose instance, consider example intention int java method create new bit integer column columnint specified name, update position next column, add list columns, return rowbuilder object however, generated explanation introduces non existent int datatype proceeds discus rest logic valid could mislead novice java developer believing int datatype exists java furthermore, several large language model llm like llama granite failed detect hallucination one reason could int valid datatype programming language c, go, causing human llm confuse learning language similarly, example shown figure java method getjobid take jobname argument simply return summary generated model provides detailed explanation, including method getjobid connects database attempt retrieve jobid using given jobname additionally, summary mention store jobstatus variable clearly, generated summary supporting entity code db access model relying method name hallucinate plausible summary method work, study different factor lead hallucination list taxonomy map common cause easily also notice lack datasets reliably research topic therefore, create first kind dataset studying hallucination code summarization summary generated seven different large language models, broken entity level sample dataset consists code corresponding summary describing code annotation consists named entity recognition entity level description verification overall summary quality based inaccuracy focusing code completeness conciseness introduce framework focus validating correctness generated summary respect code entity this, verify entity discussed summary present code correctly described summary framework leverage code parser like javalang list different entity code snippet prompt based approach detect entity summary note detecting entity generated summary difficult due high degree polysemy tabassum et al example, entity like list etc, code entity natural language entity necessitates reliance large language model high reasoning capability detecting entity summary side map detected entity summary code using string matching heuristic sentence unmapped entity considered ungrounded source extrinsic hallucination mapped entity, tuple code, entity, intent related sentence intent related sentence considered sentence summary mentioning entity final step verify tuple summary intrinsic hallucination aggregate calculate overall correctness code summary experiment demonstrate importance localizing entity summary effective hallucination detection contribution taxonomy covering diverse reason might lead hallucination code summarization figure novel dataset studying hallucination detection code summarization, featuring summary llm entity level sample table first kind approach entity level hallucination detection code summarization inspired insight human behaviour code review leading performance score table recent advance nlp community witnessed significant improvement hallucination detection pipeline section, discus work relevant hallucination natural langauge rawte et al sahoo et al review recent advance hallucination detection natural language, emphasizing practical significance recently, prompt based method arora et al manakul et al agrawal et al dhuliawala et al used detect hallucination text produced llm xiao carenini zhang et al attempt address entity level verification natural language input work involve improving correctness natural language summary discus anything context code maynez et al, ji et al, discus fine graining hallucination natural language intrinsic extrinsic hallucination specifically, intrinsic hallucination occurs given text contradicts reference, extrinsic hallucination happens text cannot verified reference use similar convention paper hallucination code generation code generation space captured significant attention due practical significance software development jiang et al discusses recent development code generation suggests importance addressing hallucination improving reliability llm liu et al study hallucination code generation proposes categorization encompasses five category hallucination based conflicting objective varying degree deviation observed code generation tian et al, agarwal et al, spracklen et al, advanced field proposing valuable datasets framework tackle hallucination code generation study indicate tendency llm produce code syntactically correct even semantically reasonable fails execute intended meet specified requirement although significant advance hallucination detection code generation, field code summarization still nascent recently kang et al, zhang, investigated inconsistency comment generation, focus limited specific aspect verifying design constraint like parameter type range additionally, approaches, generating test case comments, face practical challenge due heavy reliance execution environment contrast, approach aim validate entire functionality described output, independent external environment dependency grounding entity based input code verifying intent, framework offer reliable less dependent solution create hallucination dataset code summarization, consider code snippet java programming language codexglue lu et al code text dataset focused java programming language due widespread relevance industry offer rich set entity classes, methods, variable due structured design strict typing system report statistic data table describe curation summary generation generate summary codexglue prompting seven different llm appendix different code snippet consider data final hallucination annotation task table generating multiple summary variants, assess extent hallucination generation different llm study hallucination detection technique diverse condition named entity recognition since framework involves tracing entity summary code, perform ner summary based tagset suggested tabassum et al prompt appendix hallucination labeling detected code entity summary, sentence describing entity considered relevant account scenario relevant sentence noisy, introduced third label, irrelevant used evaluate performance intent detection module removed preprocessing thus, obtain tuples code, entity, relevant sentence entity total tuples, sampled summaries, selected human annotation hired based volunteering detect hallucination these, tuples summary independently reviewed two different set annotators, leading cohen kappa score implying high agreement conflict resolved two independent meta annotator annotator tasked correct named entity removing incorrect ones, adding missing ones, adjusting entity type ii evaluate sentence accurately describes entity code snippet, marking entity sentence pair correct, incorrect, irrelevant iii rate summary based hallucination severity good, fair, poor utilize label establish definition summary level hallucination assessment derived entity level hallucination observe that, average, entity marked hallucinated summary rated fair poor therefore, consider summary hallucinated least one entity hallucinated pre processing, consider instance label correct incorrect human data treat irrelevant label predicted model incorrect section, describe various factor could lead hallucination code summary figure based learned annotation process classification, based underlying factor hallucination, offer insight generative behavior language code model categorize hallucination factor code summarization following group hc based identifier name bias name bias refers tendency language model rely identifier name interpreting code classify bias three subcategories based source variables, functions, library model misinterpret code due linguistic characteristic entity name semantics code defined underlying logic rather lexical meaning entities, may lead hallucination example shown figure model granite incorrectly assumes getjobid retrieving job id, based purely names, even though actual code logic suggests otherwise hc insufficient knowledge involves scenario model generates incorrect summary due lack knowledge may include incorrect explanation imported library model see training data, incorrect information keyword, etc divide category two part contextual code occurs model unable correctly explain code present input may happen model encountered code functionality training dealing low resource language like cobol, basic rule might misrepresented summary non contextual code involves scenario input contain complete code mention unseen library unknown construct whose functionality understood model example, code sample shown hc example, model incorrectly describes purpose sqlexception hc code complexity category highlight model tendency produce incorrect code summary due high code complexity another perspective, model may enough reasoning capability understand code correctly may deviate instruction given user complexity arise due various reasons, length longer code tends complex often requires understanding, potential point failure, may involve interdependency lexical complexity refers scenario complex vocabulary code, including diverse operand variables, constant operation functions, operator increase complexity due higher number element track understand logical complexity refers scenario code logic complex, often due high cyclomatic complexity, indicating many independent path complexity increase numerous path method invocations, especially directly visible called distant part codebase ht public execute rediscallback cb jedis jedis jedispoolgetresource boolean success true try return cbexecute jedis catch jedisexception success false jedis null jedispoolreturnbrokenresource jedis throw finally success jedispoolreturnresource jedis summary return jedis object pool using returnbrokenresource method success variable false hc codellama confusion condition code snippet shown hc example, model codellama roziere et al produce incorrect interpretation condition may due increased complexity due nesting leading complicated logic challenging understand model hc natural language context category refers case natural language code snippets, outdated comment log statements, cause hallucination code summary code snippet shown hc example, llama model incorrectly infers property variable contains list key value pair inferred commented line however, property variable contains alphanumeric string followed one semi colon hb public static hashset string createsetfromproperty string property property null propertyequals null pattern params patterncompile summary input string expected contain list property specific format, property consists name value pair eg, name value hc llama mislead comment code summary typically global local view similar text maharaj et al global view includes purpose, functionality, control flow, data flow, etc, local view includes detail key entity variables, functions, etc source code purpose hereby referred intent entity approach based intuition software developers, verifying documentation given code repository, first understand local aspect code build bottom concept understanding global aspect code involves reading code line line tracing specific code entity documentation original code behaviour aligns working memory theory cognitive science baddeley hitch working memory brain system temporarily store manipulates information necessary complex cognitive task like learning reasoning capacity working memory bounded object point time, reduces object object relational dependency since code summary often involve interdependent objects, developer must focus local aspect build global understanding, suggesting bottom heuristic code summary comprehension leverage behavioural insight design llm powered framework detecting hallucination code summaries, involves tracing entity summary code aspect mapping entity summary code aim simulate bottom behavioural model verifying description coding entity time insights, aim measure correctness code summary two step process entity verification entity intent verification detailed flow framework found figure entity verification, check entity summary present source code detect extrinsic hallucination involves extracting entity code summary, mapping entity summary code elaborate process entity extraction code leverage program analysis extract entity code javalang python package code tokenized lexer parsed abstract syntax tree ast tree structure represents hierarchical organization code elements, making easier analyze yield fine grained classification token present code variable names, class names, function names, etc entity extraction summary code summary often focus property like variables, classes, functions, tables, cannot categorized using traditional nlp tagsets address this, tabassum et al propose task entity detection code summary introduce relevant ner tagset includes category class, variable, function, library, etc adopt tagset extracting entity code summary prompt appendix figure since leveraging llm recognize entities, possibility encountering hallucination step involves scenario model fabricates entity summary output entity might present code summary address this, add filtration step remove entity present summary evaluate gemini gpt omni task code ner collected human data report result appendix also evaluate open source model task additional contribution observe strong correlation gpt omni prediction human data, making suitable entity detection framework entity matching entity code summary extracted, compare identify subset entity present summary code entity termed ungrounded, sentence summary containing entity labelled extrinsic hallucination subset entity summary code go additional verification round intrinsic hallucination validate intent entity summary correctly described per code presence entity summary code indicates entity valid warrant correctness context discussed example, figure jobid correct entity, context retrieving jobid database incorrect address problem, propose verifying whether intent mapped entity accurately described summary extract sentence containing entity interest summary form intent context identify relevant sentence describe entity intent, explored two approach prompting language model find relevant sentence using string matching heuristic qualitative assessment showed rule based heuristic effective efficient prompt based methods, suffered hallucination therefore, relied string matching heuristic framework identifying entity intent context, use llm zero shot prompting verify correctness code prompt appendix identify quality whole summary respect code, aggregate individual entity intent hallucination set threshold labelling discussed section specifically, summary marked hallucinated least one intent identified incorrect experiments, consider summary instruction tuned version sota code language models, ibm granite family instruct instruct mishra et al llama family instruct instruct touvron et al codellama family roziere et al mistral family instruct jiang et al intent verification, use llm verify generation may challenging due inherent confirmation bias xie et al feng et al enables model agree generation avoid confirmation bias, chose gpt omni achiam et al gemini flash team et al entity intent verification task hyperparameters detail found appendix discus result two different aspect evaluation entity intent verification aspect evaluation, aim verify intent individual entity report result entity intent verification table observed gpt omni score gemini score upon analysis, found model often classify incorrect tuples correct mainly due convincing nature summary, may also subjective due lack proper code context instance, observe significant error code reference function library defined input cases, model infers functionality based library name identifier name bias difficult verify instance level hallucination verification aspect evaluation, aim verify overall summary instance compare approach, consider direct setup involves providing code, summary tuple identify summary hallucinated provide result table observed approach provides significant improvement score compared direct approach general, direct evaluation method suffers hallucinations, identified entity hallucination absent summary natural language entity mistakenly considered code entities, overall resulting poor performance conveys finer grained evaluation provides reliable method identify hallucinated summary also help interpretability identifies hallucinated section summary section, discus various quantitative qualitative insight framework first discus summary generated individual model elaborate general predictive behaviour framework case error shown table granite produced shorter summaries, llama generated longer one model similar average lengths, reflecting varying elaboration due difference training methodology entity mapping, observe llama mapped entities, indicating tendency model stay grounded granite unmapped entities, indicates tendency produce content may directly related code leading extrinsic hallucination framework utilized capture ungrounded entity within summary example given below, model try guess summary based mentioned keyword hubexception discusses non existent hub api example, unmapped entity see ungrounded entity like hub captured here, leading fine grained interpretable detection hallucination ht private list transaction retrievetransactions string rowstatuscd throw hubexception summary method retrieves transaction using hub api based input parameter provided hub database interacts several key entities, including squid squid gather data analysis hallucination unmapped entity section discusses two major error case framework error case creative summary generation, model may mention certain aspect code creative way may incorrect given example, code summary discusses elaborate version input code restating elongated version here, entity present summary predicted ungrounded framework error case changed entity form language model may refer exact name code entity generation summary example given below, summary mention entity preparedstatement prepared statement may captured named entity recognition phase due changed entity form verification kind summary may reflect inaccuracy due sentence work address critical challenge detecting hallucination code summarization, task demand deep understanding programming natural language introducing novel dataset entity tracing framework etf score, establish systematic approach grounding code entity within summaries, enabling interpretable accurate evaluation explanation future, framework enhanced incorporating multi agent system, leveraging multiple llm tandem improve prediction accuracy additionally, current framework developed better mitigate occurrence hallucination framework intended generic, certain component code parser entity detection tailored specific programming language additionally, performance large language model llm highly sensitive prompt used despite significant time effort spent optimizing prompt model, may still unexplored prompt could lead improved performance furthermore, experimental result presented based java code codexglue benchmark result, additional research required verify whether approach generalizes effectively programming language setup, conducted experiment using nvidia sxm gb gpu single multi gpu environment experiments, consider instruction tuned version sota code language models, ibm granite family instruct instruct mishra et al llama family instruct instruct touvron et al codellama family roziere et al mistral family instruct jiang et al use gpt omni version framework keep temperature set max new token section discusses ner performance various model considered work perform ner using llms, provide code summary ner tagset prompt appendix using one shot context example extract entity discussed summary accompanied type evaluate entity extraction, assess two key aspect entity coverage entity type correctness entity coverage measure whether valid entity summary detected quantify using jaccard similarity entity generated output ground truth entity type correctness evaluates whether detected entity assigned correct type this, use score metric observed good correlation gpt omni human data and, therefore, used ner pipeline additional contribution, also evaluate open source model considered work task named entity recognition summary generated code snippet initially sampled codexglue data using gpt prediction ground truth continuing ",software engineering
"repograph enhancing ai software engineering repository level code graph introduction related work repograph experiment analysis appendix detailed implementation baseline method appendix detailed implementation repograph variant appendix additional result appendix example error analysis appendix limitation future work appendix impact statement instruction reporting error llm based method ai software engineering repository level coding capability construction utility setup experiment result localization coverage investigation repograph variant transferibility test error analysis procedural framework agent framework resolve rate repository resolve rate time large language model llm excel code generation yet struggle modern ai software engineering task unlike traditional function level file level coding tasks, ai software engineering requires basic coding proficiency also advanced skill managing interacting code repository however, existing method often overlook need repository level code understanding, crucial accurately grasping broader context developing effective solution basis, present repograph, plug module manages repository level structure modern ai software engineering solution repograph offer desired guidance serf repository wide navigation ai software engineer evaluate repograph swe bench plugging four different method two line approaches, repograph substantially boost performance systems, leading new state art among open source framework analysis also demonstrate extensibility flexibility repograph testing another repo level coding benchmark, crosscodeeval code available githubcom ozyyshr repograph repograph enhancing ai software engineering repository level code graph siru ouyang wenhao yu kaixin zilin xiao zhihan zhang mengzhao jia jiawei han hongming zhang dong yu university illinois urbana champaign tencent ai seattle lab rice university university notre dame siruo illinoisedu recent advancement large language model llm showcased powerful capability across various natural language processing task openai, anil et al, dubey et al, now, coding specific llm emerging tackle complex software engineering challenge hou et al, fan et al, code llama rozi et al, starcoder li et al, coding specific llm capable assisting user various software engineering tasks, even achieving human level performance many function level coding tasks, program synthesis chen et al, austin et al, code annotation yao et al, bug fixing tufano et al, code translation rozi et al, real world software engineering often extends beyond single function self contained code file application typically built repository containing multiple interdependent files, modules, library bairi et al, complex structure require holistic understanding entire codebase perform task code completion shrivastava et al, ding et al, feature addition liang et al, issue resolving jimenez et al, recent benchmark like swe bench jimenez et al, proposed evaluate llm real world github issue requires llm modify repository resolve issue, either fixing bug introducing new feature task particularly challenging requires navigating complex code bases, understanding intricate dependency code files, ensuring change integrate seamlessly without introducing new issues, highlight difficulty scaling function level repository level understanding, expounded figure key step addressing repository level task understand structure repository identify related code achieve this, retrieval augmented generation rag variant zhang et al, phan et al, wu et al, leveraged, procedural manner, retrieve relevant code file across repository first, providing context llm edition however, indexing file level identify semantically similar genuinely related code snippet instead using rag, recent approach like agentless xia et al, construct skeletal format file, directly prompt llm identify relevant file code line however, method still treat code repository flat document zhang et al, suffers limitation repository structure intricate inter dependency cross file alternative approach design agent framework yang et al, wang et al, enables llm interact repository using action llm agent freely determine next action based current observations, without grasp global repository structures, tend focus narrowly specific files, resulting local optimum addressing limitation requires going beyond semantic matching developing technique enable deeper understanding codebase structure allow llm leverage fine grained context across multiple file function calls, facilitating informed, repository wide decision making coding task motivated this, propose repograph, plug module designed help llm based ai programmer leverage code structure entire repository repograph graph structure operates line level, offering fine grained approach compared previous file level browsing method node graph represents line code, edge represent dependency code definition reference repograph constructed via code line parsing encodes structured representation entire repository sub graph retrieval algorithm used extract ego graph centered around specific keywords ego graph smoothly integrated procedural agent frameworks, offering key clue provide comprehensive context llm solve real world software engineering problem assess repograph effectiveness versatility plug module, integrate four existing software engineering framework evaluate performance using swe bench, recent benchmark ai software engineering experiment result show repograph boost success rate existing method agent procedural framework achieving average relative improvement also test repograph crosscodeeval verify transferibility general coding task require repository level code understanding additionally, systematically analyze different sub graph retrieval algorithm integration method together error analyses, hope shed light future work targeting modern ai software engineering recently, significant increase research focused ai driven software engineering, broadly categorized two primary approach llm agent based framework ii swe featured procedural framework field advanced rapidly, method released proprietary solution industry application cognition, related work section concentrate specifically open source framework llm agent based framework equips large language model llm set predefined tools, allowing agent iteratively autonomously perform actions, observe feedback, plan future step yang et al, zhang et al, wang et al, cognition, exact set tool may vary across different agent frameworks, typically include capability opening, writing, creating files, searching code lines, running tests, executing shell command solve problem, agent based approach involve multiple actions, subsequent turn depending action taken previous one feedback received environment example, swe agent yang et al, facilitates interaction execution environment designing special agent computer interface aci various actions, including search navigation file viewer editor context management another work, autocoderover zhang et al, offer fine grained searching method llm agent better context without execution process specifically, support class function level code search opendevin wang et al, initiated devin cognition, community driven platform integrates widely used agent system action space design opendevin highly flexible, requiring llm agent generate code fly swe featured procedural framework typically follow two step localize search edit approach, seen existing literature zhang et al, wu et al, liang et al, xia et al, localize step focus identifying relevant code snippets, edit step involves completing revising code work introduce additional step enhance performance, search expand edit approach phan et al, retrieval lewis et al, popular technique used localization, allowing model search relevant code snippet large repository treating issue description query code snippet indexed data approach use sliding window ensure completeness zhang et al, besides, agentless xia et al, recently developed method us llm directly identify relevant element editing within code repository first recursively traverse repository structure generate format aligns file folder vertically, indent sub directory structure issue description input llm, performs hierarchical search identify top ranked suspicious file requiring inspection modification evaluation coding capability ai system traditionally focused function level line level assessment lu et al, chen et al, austin et al, individual code snippet isolated function primary unit analysis unlike previous studies, swe bench jimenez et al, highlight trend repository level coding, driven recent advance coding specific llm guo et al, li et al, reflects growing user demand understand contribute entire project rather isolated function ouyang et al, well solving real world problem end end automatic manner pre trained code llm mentioned earlier incorporate repository level information file dependencies, task repository level often involve intricate call relationship within context recent work like repocoder zhang et al, repofuse liang et al, started integrating retrieval augmented generation rag module harness additional information repository building this, subsequent research focused embedding repository level context methodology instance, draco cheng et al, introduces importing relationship files, aider gauthier, employ pagerank page, identify significant contextual element repounderstander et al, codexgraph liu et al, model code file knowledge graph despite similarity representation, method vary retrieve information structure utilize downstream task table summarizes difference method repograph repograph surpasses previous approach effectively integrating context line, file, repository level section introduces repograph, novel plug module seamlessly integrated existing research workflow agent based procedural framework primary goal repograph provide structured way analyze interact complex codebases, enabling detailed tracing code dependencies, execution flow, structural relationship across repository following sections, provide detailed description repograph construction, underlying representation, utility across various scenario overall architecture depicted figure highlighting key component operational flow given repository level coding task, first step carefully examine repository structure necessary information collected input repograph construction repository, ie, collection folder files, output structured graph, node code line, edge represents dependency repograph enables tracing back root cause current issue gathering dependent code context help solve problem construction process repograph could divided three key step step code line parsing first traverse entire repository using top approach identify code file candidate next step parsing accomplished filtering based file extensions, retaining relevant code file suffix eg, py excluding non essential file type eg, git requirementstxt noisy irrelevant coding task code file, utilize tree sitter parse code, leveraging abstract syntax tree ast framework ast provides tree based representation abstract syntactic structure source code, enabling identification key element functions, classes, variables, types, definition recognizing definition crucial, tracing usage reference throughout code equally important tree sitter facilitates capturing definition tracking utilized referenced within codebase example, figure identify definition like class model inherent method also reference like self validate input unit processing line code tree sitter, selectively retain line involve function call dependency relations, discarding extraneous information focus primarily function classes, represent core structural component code concentrating element interrelationships, repograph optimizes analysis process excluding less significant details, individual variables, tend redundant less relevant processing step project dependent relation filtering previous parsing step, obtain code line calling dependency relation however, relation useful fixing issue specifically, many default built function class call could distract project related one therefore, additionally introduce filtering process excludes repository independent relation two type relation exist global relation refers python standard built function class ii local relation introduced third party libraries, specific current code file global relations, maintain comprehensive list method standard built libraries, excluding identified relation list list empirically constructed gathering method builtins library default method list tuple example, figure line input len input excluded since len default method local relations, parse import statement code identify third party method included, exclude accordingly step graph organization stage, construct repograph using code line fundamental building unit graph represented represents set nodes, node corresponding line code, represents set edges, capturing relationship code line node contains attribute represent meta information, line number, file name, directory, etc additionally, classify code line either definition def reference ref particular module def node corresponds line function, class, variable initially defined, ref node indicates code line entity referenced invoked elsewhere code similar soft link def nodes, ref node also represent variation invoking method example, figure class definition class model would def node, subsequent usage model would ref node def node may multiple ref node associated it, single function class referenced various place throughout code define two type edge triple denotes eg, function definition contains another module eg, internal function class edge typically connects def node internal component contrast, represents invocation relationship, usually connecting def node ref node, reference node includes dependency definition constructed repograph serf structured representation current repository facilitates better related information collection aggregation information collection based repograph, specifically, use one search term time subgraph retrieval search term key function class determined current state example, separability matrix initial search term figure retrieve hop ego graph hu et al, search term centric ego graph crucial solving problem focus immediate relationship jin et al, around search term, capturing relevant dependency interaction within repository, key understanding functional context additionally, retrieved content explicitly contains information method line level implicitly express grouping file level process abstracted via search repograph illustrated middle figure retrieved hop ego graph flattened processing also tried variant integration later section performance table narrate repograph could plugged existing representative research line following integration procedural framework procedural framework, llm usually prompted localization edition stage given repository context issue description case, use search repograph stages, leveraging repograph assist making informed decision step example, figure first include subgraph separability matrix localization, use localized result model search edition stage implement strategy, flatten context retrieved ego graph append part prompt result, llm generation conditioned retrieved ego graph context provided baseline methods, helping model preserve nuance integration agent framework significant difference existing agent framework action space design, expounded section leverage power repograph, put search repograph additional action action space agent decides use action search term also determined agent accordingly returned subgraph flattened used observation next state evaluated repograph plug component, ie, integrated existing baseline model two aforementioned research line assess performance use baseline setting configuration incorporating repograph ensure fair comparison dataset test repograph swe bench lite problem dataset requires submitting patch solve underlying issue described input issue description goal generate patch accurately revise relevant portion codebase within repository, ensuring test script included dataset successfully executed baseline integrate repograph representative method aforementioned research line procedural frameworks, evaluate widely used traditional method, rag lewis et al, well agentless xia et al, open source state art approach direction rag, follow initial setting use bm file level retrieval that, append context repograph code file part prompt agentless first performs hierarchical localization term file class function edits conduct repair based localization context repograph inserted every step agentless ii agent frameworks, consider swe agent yang et al, autocoderover zhang et al, frameworks, add additional action search repograph llm agent described section choice two research line incorporate gpt gpt based method ensure generalization detailed implementation prompt used found appendix evaluation metric evaluate method across two key dimension accuracy average cost accuracy, report resolve rate patch application rate resolve rate represents percentage issue successfully resolved across data point issue considered resolved submitted patch pass test script assess patch application rate, attempt apply generated patch repository using patch program successful application contribute metric ii evaluate cost efficiency, report two metric average cost average tokens, refer inference cost number input output token used querying llms, respectively configuration use gpt version baseline experiment used gpt gpt turbo gpt preview openai evaluation analysis experiment evaluation process performed containerized docker environment ensuring stability reproducibility, made possible contribution open source community plug procedural frameworks, usually take around hour finish agent frameworks, inference time larger, around hour table present main evaluation result baseline method corresponding performance repograph repograph plug swe bench lite test set also report number correct sample method performance increase marked num based results, following key observation repograph brings consistent performance gain combination framework llm model base specifically, repograph achieves absolute improvement term resolve rate rag agentless, respectively, relative improvement notable improvement demonstrates effectiveness repograph adapting various scenario inducing relevant code context performing precise code edition additionally, best performance far plugging agentless, achieves state art performance benchmark among open source method ii performance gain brought repograph slightly larger procedural framework agent one procedural frameworks, repograph correctly fix issue agent one could due two primary reason firstly, observed mature procedural framework tend achieve better baseline performance agent based framework swe bench initial definitive nature procedural frameworks, well defined running flow structure, allows leverage plug in effectively another reason deterministic behavior reduces complexity arises dynamic decision making, key characteristic agent based systems, thereby enabling smoother integration performance improvement iii performance gain brought repograph rely cost also compute report method average cost token consumption introducing repograph, manage reduce cost associated managing entire repository achieving comparable even superior performance shown table performance improvement achieved repograph generally proportional to, slightly lower than, corresponding increase cost indicates repograph performance gain mainly due increased token usage iv average cost generally larger agent framework repograph phenomenon especially obvious swe agent, allows agent freely determine next action based current observation also found integration agent framework usually lead larger cost increases, exemplified autocoderover swe agent, respectively reason lie large exploration space agent framework agent might call search repograph action many times, lead explosion prompt context encourage user mindful cost adopt granular approach cost control integrating repograph agent framework future section present detailed analysis demonstrate additional context provided repograph beneficial task begin analyzing localization accuracy comparison gold standard patch next, explore various repograph configurations, focusing additional context effectively integrated existing system finally, perform depth error analysis, highlighting aspect repograph improved analysis including resolve rate various aspect action distribution agent frameworks, please refer appendix crucial step issue resolution accurately identifying correct location within code require modification proper localization essential, form foundation generating effective accurate patch without step, quality fix may compromised, leading incomplete incorrect solution three granularity, compute percentage problem edit location match ground truth patch namely, file level, function level, line level report patch contains correct location edits superset location ground truth patch table present result analysis observed integrating repograph baseline method significantly improves file level accuracy, whereas enhancement accuracy line level comparatively modest result aligns expectations, file level localization coarse grained, making inherently easier improve contrast, line level localization, fine grained, pose greater challenge due need precise identification code segment additionally, found although line level accuracy improvement pronounced agent frameworks, overall resolve rate lower procedural frameworks, shown table discrepancy attributed fact localization, necessary generating final patch, insufficient success final revision still heavily relies underlying capability llm agent frameworks, designed operate trial error fashion, particularly susceptible error accumulation framework iteratively refine patches, small inaccuracy earlier localization step propagate magnify throughout process, ultimately reducing overall resolve rate procedural frameworks, hand, follow structured deterministic approach localization patch generation typically localize fix issue single, direct step, help mitigate compounding error section, investigate efficacy various combination sub graph retrieval integration technique outlined section explore two sub graph retrieval variant two integration method specifically, sub graph retrieval, index hop ego graph set limit exploration value due extensive context required integration potential introduction noise irrelevant node integration methods, employ two distinct approach directly flattening textual sub graph explicitly detailing relationship search term neighboring nodes, ii leveraging llm first summarize sub graph term core module salient dependencies, proceeding processing detailed implementation variant prompt used found appendix begin presenting statistic repograph various configuration performance evaluation conducted agentless repograph integrated plug module table report number node edge within sub graph notably, average number node edge repograph across swe bench dataset quite substantial, featuring node edge highlight comprehensive nature constructed structure different variants, information within repograph concentrated around search term, resulting average node edge increase retrieved ego graph expands exponentially, reaching average node edge moreover, directly flattening retrieved ego graph often significantly increase token count, frequently reaching several thousand token however, utilizing llm additional summarizer greatly reduces token count, typically around thousand table present resolve rate four variant method notably, hop variant incorporates additional information, directly flattening information result poorest performance, resolve rate even lower original baseline contrast, incorporating summarization via llm significantly alleviates context length constraint enhances information organization, thereby improving performance hop variant, however, observed adding summarization actually degrades performance, reducing resolve rate hypothesize occurs flat hop ego graph already contains comprehensive information fit within llm context window thus, summarization may introduce inevitable information loss demonstrate representational power repograph repository transferability task requiring understanding repository structures, conducted experiment using crosscodeeval benchmark ding et al, crosscodeeval code completion benchmark designed emphasize numerous cross file dependency original dataset consists sample derived real world repository due resource constraints, randomly selected sample crosscodeeval, focusing problem using python evaluation programming language evaluation metrics, follow setting original paper measure performance code match identifier match metrics, assessing accuracy exact match em edit similarity e score experiments, search term determined function within current line completed table demonstrates result crosscodeeval using gpt backbone language model original gpt model struggle repository level tasks, evidenced em score code matching identifier matching result indicate significant limitation handling code structure variable usage broader repository context however, integration repograph method, substantial improvement across metric code match em improves dramatically identifier match em double similarly, score identifier matching jump e code increase improvement suggest incorporating repository level knowledge, facilitated repograph, greatly enhances model ability understand generate contextually accurate semantically consistent code want compare repograph corresponding baseline see distribution resolved case analyze error reason unresolved case plot venn diagram representative method procedural agent framework figure respectively manually examined unique error case defined three error category incorrect localization refers failure accurately identifying code snippets, ii contextual misalignment happens generated patch fails align broader context codebase, iii regressive fix introduces new issue resolving original issue example appendix found improvement agent framework complementary procedural frameworks, larger uniquely resolved case compared procedural framework together, make even larger performance reason could also attributed determinism procedural framework plug module, repograph tends make modification existing deterministic processes, resulting larger overlap resolved issue compared baseline agent frameworks, hand, quite different action distribution repograph plug please refer appendix therefore, uniquely resolved case compared procedural framework error distributions, contextual misalignment prevalent error type, followed incorrect localization regressive fix methods, suggesting localization often correct, applied solution may regress fail integrate contextually phenomenon also echo conclusion obtained section intuitive existing method focus providing comprehensive desired context llm solve task, fundamentally depends power backbone llm also found integrated repograph, proportion error type incorrect localization contextual misalignment largely decreases, indicating repograph specifically useful aggregating related context current fixed issue section detail implementation four method procedural agent research line mentioned section figure figure illustrate instruction used procedural frameworks, including localization edition, respectively flattened context retrieved ego graph repograph template instruction specifically, localization edition stages, repograph flattened part function class dependency llm could better understand context llm agent wide range application wang et al, yuan et al, list instruction every step agent framework overall system instruction shown figure system instruction defines task setting template response add search repograph new action agent use command docs, signature listed figure also plot frequency action invoked swe agent swe agent repograph figure see repograph, maximum turn finishing task reduced also, computed average turn finish task, demonstrates similar trend significant improvement efficiency maintaining effectiveness also observe action search repograph invoked mostly first round conversation llm precise original action search dir search file find file section, provide implementation variant repograph mentioned section addition directly flattening retrieved ego graph, propose leveraging large language model llm first summarize context full prompt, along sample input output, provided figure plot result resolve rate term repository distribution figure figure, clear resolution issue varies significantly across different repository notably, django sympy repository unresolved issues, unresolved issues, respectively may indicate higher level complexity issue larger backlog compared repository hand, django highest number resolved issues, case highlight strong effort address issues, even though unresolved count still high sympy follows closely resolved issues, suggesting similar trend repository like scikit learn, sphinx, matplotlib comparatively fewer issue overall, resolve rate balanced instance, sphinx show ratio resolved unresolved issues, reflecting consistent effort issue resolution plot result resolve rate term distribution releasing time repository figure issue observed recent years, starting substantial increase total number issue identified early year number issue remained relatively low, resolved unresolved count minimal starting noticeable increase unresolved issues, unresolved resolved issue number resolved unresolved issue significantly increased, resolved issue trend continued rise issue remained unresolved, resolved, marking year highest number unresolved issue dataset number unresolved issue slightly decreased, resolve rate increased compared suggests improvement system ability address issue year although total number issue dropped proportion resolved issue remained strong, resolved issue help better understand error category listed section provide one example category figure figure figure explored proprietary llms, ie, gpt series due poor performance open source model challenging task, opted proprietary model demonstrated superior result code related task however, comprehensive evaluation open source model llama dubey et al, could valuable direction future work, particularly model continue improve ii experiment conducted lite set due high cost running large scale experiment proprietary model exploring efficient model deployment strategy alternative cost effective option running experiment larger datasets essential broader applicability iii although repograph could adapted support programming language adjusting parsing scheme implementation, explored python main experiment future work could extend approach widely used programming languages, javascript, java, evaluate generalizability methodology across different programming paradigm impact paper lie substantial contribution enhancing capability ai driven software engineering, particularly respect repository level code understanding introduction repograph significantly improves large language model llm navigating comprehending entire codebases, also showcase potential integrating repository wide structure ai workflow extending scope function level task holistic repository management, repograph push boundary ai utility modern software engineering advancement open new opportunity using llm complex engineering task automated debugging, repository maintenance, large scale refactoring furthermore, highlighting importance repository level context accurate code generation maintenance, paper set new trajectory future research ai software engineering encourages deeper exploration ai ability write code also understand manage large scale software project efficiently foresee minimal risk negative societal impact work datasets benchmark used evaluation publicly available, adhered respective license additionally, repograph open sourced, making accessible research community, particularly group limited access extensive computing resources, thus fostering broader adoption development continuing ",software engineering
"rethinking state management actor system cloud native application introduction actor state management data integrity transactional actor state management evaluation related work conclusion instruction reporting error orleans conceptual overview smsa dependency management danger unordered operation actor transaction library snapper integration smsa snapper implementation variant experimental setting characteristic smsa skewed workload scalability online marketplace actor model gained increasing popularity however, lack support complex state management tasks, enforcing foreign key constraint ensuring data replication consistency across actor crucial property partitioned application designs, microservices fill gap, start analyzing key impediment state art actor system find difficult developer express complex data relationship across actor reason impact state update performance due opaque state management abstraction solve conundrum, develop smsa, novel data management layer actor systems, allowing developer declare data dependency cut across actors, including foreign keys, data replications, dependency smsa transparently enforce declared dependencies, reducing burden developer furthermore, smsa employ novel logging concurrency control algorithm support transactional maintenance data dependency demonstrate smsa support core data management task dependency across component appear frequently without jeopardizing application logic expressiveness performance experiment show smsa significantly reduces logging overhead lead increased concurrency level, improving performance state art deterministic scheduling approach result, smsa make easier design implement highly partitioned distributed application modern application programming landscape, developer design application tiered architecture stateless middle tier encoding application logic database tier storing application state bernstein et al, client request, middle tier executes business logic retrieving necessary data database tier architecture simplifies development application pushing complex data management task database tier however, data shipping paradigm limitation long end end latency excessive data transfer database middle tier peak period may meet application requirement bernstein et al, shah salles, memory data caching middle tier reduce latency data transfer however, suffer low cache hit ratios, eg, different client request need access diverse data data updated frequently, cache data inconsistency lead application safety problem ports, address problems, alternative architecture employ stateful middle tier, data stored computing nodes, function shipping paradigm adopted client request shipped computing nodes, store corresponding data processing involve data transfer data storage, minimizing bandwidth overhead latency data middle tier asynchronously shipped database layer analytics disaster recovery furthermore, achieve system scalability, software agility, fault isolation, witnessing emergence microservice architecture laigner et al, architectures, application decomposed independent fine grained component interact via synchronous asynchronous communications, encapsulating state meanwhile, actor model agha, emerged promising concurrent programming model middle tier development akka, encapsulated state actor allow developer build loosely coupled application design remount cache data locality, characterizing function shipping paradigm client request processed one actor interacting via asynchronous messages, triggering update encapsulated actor state design principle make attractive model microservices actor laigner et al, addition, advent virtual actor bernstein et al, originally developed context microsoft orleans, alleviates developer burden providing actor state management functionalities, including state persistence, transactional state manipulation, fault tolerance via state persistence, lay solid foundation addressing data management challenge microservice system laigner et al, state virtual actor modeled opaque transactional object, matter many entity encapsulated actor opaque state model put almost limitation developer implement operation actor state using required apis interact underlying data store persistence thus, update single entity treated update object whole despite recent advancement actor state management, modern data intensive application exhibit complex relationship among entity cutting across distributed component viennot et al, typically natively supported actor runtimes cross component relationship include foreign key constraints, replication data items, functional dependency laigner et al, taking commerce application case, online marketplace laigner zhou, example fig product data managed product component replicated cart component, manages product added customer cart replication favor performance since avoids successive round trip cart product component ensuring correctness product information eg, product price checkout time viennot et al, rafiq, however, opaque state model virtual actor expose little semantic information, part state modified, thereby limiting ability developer express important safety property data intensive application due lack support actor frameworks, developer must map relationship across actor explicitly eg, cart contain certain product ensure correctness application code besides complex error prone, practice oblivious transaction management, leading isolation anomaly taken together, enhancing state management feature actor framework ensuring application safety across actor missing key fully realizing envisioned benefit actor model developing scalable stateful middle tier bridge gap, develop data management library virtual actors, provides api developer register cross actor dependency constraint dynamically support high throughput transactional enforcement constraint account emerging cross component state management requirement arise partitioned distributed applications, microservices laigner et al, kleppmann et al, viennot et al, contribution summarized follows strike balance simplicity, state translucency, expressiveness, propose extended key value model actor state associated set state access dependency apis design enables shift cross actor dependency management application code actor framework hence unloads burden developer complex error prone state management code develop smsa, data management layer virtual actor framework smsa implemented integrating data model apis state art transaction library virtual actor snapper support transactional data dependency enforcement maximize transaction throughput, extend snapper concurrency control take advantage new data model actor states, providing fine grained concurrency control outperforming vanilla snapper map online marketplace laigner zhou, benchmark actor abstraction implement smsa online marketplace model key safety property related relationship across component arise real world partitioned distributed application implementation validates expressiveness ease use data model, well address challenge cache coherence, referential integrity, strong isolation transactional guarantee conduct extensive experiment two benchmarks, online marketplace smallbank experiment demonstrates efficiency fine grained concurrency control state art deterministic method result, smsa facilitate design implementation actor based stateful middle tier orleans orleans, framework facilitates development distributed application virtual actor bernstein et al, orleans automatically allocates virtual actor available node deactivates actor longer needed addition, orleans transparently migrates virtual actor faulty computational resource others case failures, ensuring application remains functional aid developer designing data intensive applications, orleans recently introduced state management transaction management apis eldeeb et al, orleanstxn transactional object user defined type state actor tx orleans preclude developer explicitly implementing transactional guarantee orleanstxn adopts locking based concurrency control method applies early lock release achieve higher concurrency level however, reported recent research liu et al, laigner et al, orleanstxn vulnerable contentions, often leading low performance smsa, actor state modeled key value collection smsa relies developer determine key partitioned across actor key unique among actor, key may exist different actor key located different actor related dependency constraint shown fig a, actor dependency form directed graph arrow represents depends change made may cause change smsa support basic operation get, put, delete key meanwhile, allows dynamic registration de registration dependency two specific pair key value item two different actor thus, dependency graph may change time, well reflecting dynamic nature actor topology orl, besides, opt key value abstraction developer familiar model manage data stateful middle tier ports, mertz nunes, dependency smsa used model different application constraints, data integrity constraints, foreign key constraints, data replication, functional dependency example, fig illustrates replicated key foreign key cascading delete materialized view respectively prominent feature smsa system level support enforce constraint instead relying developer encode case case application logic specifically, smsa keep track operation performed key execution actor method execution done, smsa scan list operation log figure operation need forwarded key actor preserving relevant dependency constraint example, fig dependency represents scenario price product changed, update operation forwarded cart actor contain product, thus guaranteeing cart actor consistently see latest price smsa, forwarded update operation calculated carried transparently system level discusses algorithm applied derive information operation forwarded applied another actor fig illustrates actor maintains key value collection also list dependency list operation log smsa wrap together dictionarystate object object expose two set apis one external user request access application data, internal system enforce dependency constraint enforcing certain operation invoked via apis, smsa capture change made key value collection actor automates dependency constraint enforcement smsa defines dependency record six data field fig type dependency, leader actor, leader key, follower actor, follower key, customized function smsa generalizes two type dependency delete dependency update dependency delete dependency describes relation two key two different actor deletion cause deletion update dependency refers relation update happened trigger specified update function applied key update dependency, deletion cause deletion key delete update operation originates named leader key, affected key called follower key, actor key located referred leader actor follower actor respectively leader key follower key same, depending user define dependency able retrieve follower key leader key, smsa store dependency information leader actor smsa maintain shared global dependency graph instead, distributes information across actor so, smsa avoids centralized component becoming bottleneck need serve frequent queries, meanwhile guaranteeing actor sufficient information stored local private state enforce dependency addition, update function need specified every update dependency smsa defines interface abstract method fig update function implement method requires input leader key, value leader key applying user invoked update operation, follower key, existing value follower key then, method return calculated new value follower key shown fig line data replication facilitated using update function directly return value leader key thus, follower key remains leader function used defining dependency new price product replicated product actor relevant cart actor line similarly, customized function contain complex calculation applied build materialized view example fig line function defined seller actor maintain view created order cumulatively smsa allows user code delete leader follower key leader key deleted, deletion operation forwarded corresponding follower follower key deleted, indicates dependency leader key expires thus, dependency record deleted avoid operation sent follower actor eg, line fig summary, deletion key indicates deletion follower keys, well de registration dependency pointing key retrieve dependency backward direction, ie, follower key leader key, smsa keep copy dependency record follower actor well smsa, leader key may multiple follower key resembles scenario rdbms multiple foreign key refer one primary key smsa allows leader key impose different effect different follower key example, fig product id product actor may relate multiple cart actor update dependency meanwhile, also related key stock actor delete dependency smsa allows follower key multiple leader keys, foreign key reference single primary key rdbms smsa identifies three scenario first, follower key may update dependency multiple leader key example, shown fig follower key seller actor may need aggregate information newly created order leader key multiple shipment actor so, seller actor maintain date materialized view second, follower key may delete dependency multiple leader keys, model case existence entity dependent upon existence entity third, follower key may affected update delete operation different leader key note smsa control priority order executing operation related different dependency delete operation update operation forwarded follower key, final result follower key deleted however, two different update operation forwarded follower key, result may vary depending update operation arrives follower actor first update function applied follower actor first user resolve issue defining commutative update function another solution rely transaction management restrict order different operation performed actor smsa, key act leader follower, deletion key becomes complicated example, fig d, key deleted, actor first enquiry forward send delete operation follower actor backwards de register dependency dependency registration restricted, smsa may create cyclic chain dependency across multiple keys, result infinite loop operation forwarding process shown fig c, cycle may formed three case first case involves delete dependencies, second case mix type dependencies, third one update dependency first two processed completion within limited step first case, deletion key cause deletion deletion operation forwarded back actor located, actor find exist key value collection already deleted thus, deletion performed again, delete operation forwarded along dependency chain second case, update forwarded form cycle deleted, two connected dependency removed, operation needed deleted, deleted third case, deleting key cause deletion two dependency however, updating key cause update operation circulate endlessly cycle third type cyclic dependency prohibited adopting following three strategy smsa additional check whenever update dependency registered, may time consuming exists long chain dependency, key point many key smsa restrict actor forward operation request example, update already forwarded receives update update generated however, strategy requires actor store information different requests, introduces extra semantics, make complicated reason application logic smsa disallow key becoming leader follower, thus eliminating type cycle smsa, dependency registration request initiated user follower actor first check specified allowed attached dependency example, smsa may check cause cyclic chain update dependency strategy adopted, check already identified leader adopted check passed, leader actor called continue registration check key declared leader, ie already exists dependency follower key yes, dependency registered latest value leader key retrieved returned follower key exist yet, used initial value new key value pair inserted already exists, custom function specified newly registered dependency applied using explains smsa deal dependency registration request next, explain developer send request smsa fig show example code registering dependency line line cases, dependency defined specifying six required data field afterward, api called forward necessary information internal smsa smsa expose api developer explicitly declare dependency de registration dependency carried two way first, done similar process dependency registration, de registration request sent explicitly follower actor forwarded leader actor second, user also simply delete follower key fig line according deletion rule smsa introduced follower key deleted, corresponding dependency record removed well laid rich state management abstraction actor model, turn attention leverage advancement optimize key aspect data systems, logging concurrency control although equipping actor data model enables declaration complex relationship across actors, developer must still account danger arbitrary function execution order possible impact actor state bagherzadeh et al, instance, request smsa may perform operation multiple actors, especially existence cross actor dependency concurrent execution request may drive system inconsistent state example, fig suppose actor intends create replica key whose master copy stored example illustrates possible interleaving two request one dependency registration request initiated performs update operation ideally, updated value key reflected replica however, forwarded update operation arrives earlier confirmation message, perform update result replica inconsistent master copy smsa benefit transaction management solution provide stronger application correctness guarantee existing work proposed myriad method enforce order concurrent task liu et al, eldeeb et al, converge consistent state presence disorder wu et al, pregui et al, shapiro et al, lightbend, snapper liu et al, one solutions, support acid transactional property multi actor operation performant deterministic concurrency control, making good fit integrate smsa snapper liu et al, actor transaction library designed enhance performance multi actor transaction meanwhile preserving acid transactional property snapper leverage deterministic scheduling pact, type transaction declares actor access information submitted system based pre declared information, snapper employ group coordinator actor generate deterministic transaction execution schedule every batch pact schedule consists sequence pact relevant particular actor afterwards, snapper delivers batch schedule corresponding actor via asynchronous message actor supposed execute transactional invocation pact one one pre determined order pact execution, transaction scheduled, executed, committed, logged batch level addition deterministic execution, snapper also support conventional non deterministic strategies, strict two phase locking pl two phase commit pc transaction whose actor access information cannot pre declared type transaction called act another standout feature snapper ability execute concurrent hybrid workloads, wherein transaction executed deterministically others follow non deterministic method hybrid execution model maximizes advantage deterministic execution, achieve high transaction throughput maintaining flexibility non deterministic workload snapper provides base actor class, transactionalactor, provides key system level functionalities, transaction processing logging listed fig a, transactionalactor expose apis transaction request submission starttxn transactional actor state access getstate invoking transactional method actor callactors snapper, getstate api called transaction transactionalactor transparently control get access actor state specifically, snapper first identifies pact act using txncontext information then, based different concurrency control strategy applied pact act, snapper insert actor local schedule wait turn execute ie grant access actor state addition, callactor api must used invoking transactional call one actor another api acquires txncontext one input parameter well, ensure actor method invocation executed transaction context section, explain advance snapper transactional layer account smsa achieve transactional guarantee dependency cut across actor start removing snapper opaque state management inherited orleans actor state stored single object generic type, tstate, switch smsa managed map based data structure, referred dictionary state along text prevents developer creating arbitrary type represent application state actor, jeopardizing application design murdock, irby, mode, smsa allows developer manage entity key associated actor reference via dictionarystate corresponding apis get, put, delete management data dependency smsa comprises two part registration de registration dependency enforcement dependency manage dependency constraint transactionally, smsa need rely snapper transactional apis certain occasion first, registering dependency, discussed follower actor invokes api, turn invokes call leader actor via callactor api since dependency list stored dictionarystate object, adding removing dependency list must occur accessing dictionarystate object via getstate api second, smsa enforces dependency resolving forwarding operation log relevant actor apply forwarded log perform corresponding update key stored locally again, key accessed condition getting access dictionarystate object calling getstate api fig present workflow transaction smsa snapper integrated advancement smsa figure mark difference red text compared snapper us red arrow represent step relevant dependency management step creates dictionarystate object transaction smsa allow transaction access original version actor state directly instead, new dictionary state object created every transaction isolate read write set step transaction access dictionarystate via external apis actor finish executing user method, operation log scanned resolve list log forward step order enforce user declared dependency then, applylogs method invoked dependent actor via callactor api actor receives method invocation identify internal method step mean implemented system code even internal method, still need executed transaction context thus, reference dictionarystate object acquired via getstate api step executing internal method, system code access internal apis dictionarystate object step applylogs, read forwarded log apply update key according registered dependency actor finish executing internal method, again, operation log need analyzed step might update performed key trigger operation forward actor afterwards, transaction log persisted step logged change made transaction applied actor state step note that, snapper, log writing happens every act every batch pact step given transaction operated dictionarystate, smsa need apply change actual actor state act committed batch pact completed so, result one transaction made visible subsequent transaction snapper, step carried overwriting whole actor state, incurring higher overhead smsa dependency registration de registration implemented internal method change made dependencies, including adding removing dependencies, also need recorded first, persisted log record, reflected actual actor state afterward note adding removing dependency effect, like update leader key snapper, actor state always logged single object due lack information state changed call logging method snapshot inefficient small part actor state modified differently, smsa keep record change made key dependency see format fig thus, smsa need write incremental log transaction, largely reduce logging overhead snapper support deterministic scheduling transaction provides actor access information set actor access number time actor accessed listed fig a, starttxn api pact acquires extra input parameter snapper us information generate deterministic transaction execution order every related actor long actor executes pact ascending order transaction id snapper guarantee global serializability integrating smsa state management layer snapper, devise finer grained transaction scheduling strategy given smsa acquires developer specify key read write application code, assume set key accessed actor transaction declared even transaction started based key access information, transaction execution schedule created every single key shown fig following key level schedule, pact actor need wait another pact set key access overlap apparently, adopting key level scheduling achieve higher concurrency actor however, straightforward implement first, new interface created receive transaction request tend adopt key level concurrency control shown fig a, introduce another starttxn api accepts key access information input client submits transaction request besides, algorithm applied generate transaction execution schedule need modified metadata maintained every single key furthermore, actor, becomes insufficient check pact txncontext getstate api called set key pact tends access must given fig key level schedule specifies safe pact access specific key therefore, time getstate api return result varies depending key set key pact acquiring besides, pact get access key acquired otherwise, transaction execution schedule may violated example, suppose two pact scheduled one actor access key access acquires first, get dictionarystate immediately however, yet allowed access status unknown safely access must call getstate api included key set smsa x, accurately restrict key pact access, dictionarystate object include information key pact acquired illustrated fig b, step smsa make copy key information, including key value pair related dependency also implies access dependency information key, transaction also need get access key first addition, smsa allows transaction call getstate api multiple times, time may acquire access right different set key smsa restrict order acquire different key number time key acquired smsa maintains one dictionarystate instance transaction getstate api called first time, new dictionarystate object created transaction then, every time new key acquired via getstate api, key added existing dictionarystate object transaction asks access key already exists dictionarystate, extra waiting needed eg, step fig note getstate api always return reference dictionarystate object belongs current transaction, developer get access object use reference via getstate call so, transaction always access latest actor state via reference, getstate api used gradually extending access right different key example shown fig line example, deleteitemsincart transaction first get access dictionarystate object calling getstate api without specifying key line within call, smsa create new dictionarystate object transaction, contains key afterward, transaction acquire access right set item key two way line option ways, state object eventually gain rw access acquired key words, key gradually added dictionarystate object and, therefore, accessed transaction last, transaction deletes item cart line prescribed snapper, smsa also requires pact declaration actor key accessed part transaction, including one accessed dependency management process example fig item cart actor replica corresponding product product actor line contains latest product price replication expressed update dependency smsa item deleted cart actor, indicates deletion dependency stored cart actor product actor line therefore, transaction deleteitemsincart actually involves two actor access set key actor correct complete key access information must given allow smsa schedule pact key level correctly snapper also support act, type transaction declare actor access information applies non deterministic execution specifically, act get access actor state acquiring rw lock maintained actor via pl wait die protocol extend actor level concurrency control key level concurrency control, smsa simply maintain lock every single key given key may dynamically added deleted actor, lock need added removed accordingly smsa x, act add delete key condition get write lock new lock created exist yet note key deleted act holding waiting lock avoid anomaly smsa provides interface transaction access key individually still preserving ability support actor level concurrency control actor level concurrency control useful case transaction need scan whole key value collection actor query key certain predicate smsa allows developer configure actor apply either actor level key level concurrency control created section, conduct extensive range experiment investigate feature smsa various workload first part experiment explores characteristic basic building block data model specifically, focus trade offs maintaining fine grained key value actor state transaction processing performance second part turn attention popular cross microservice correctness criterion sought developer practice laigner et al, particular, adopt online marketplace benchmark target exploiting overhead enforcing constraint cutting actor across, including foreign keys, data replication, functional dependency five competing system fig compared show implication proposed advancement performance nontxn applies non transactional execution orleans actor execute operation arbitrary order thus, access state performed without isolation guarantee give upper bound system performance, indicating best throughput actor system achieve certain workload snapper liu et al, adopted experiment baseline solution enforcing application correctness strong consistency guarantee allow insights, integrate different data model functionality snapper devise two variant smsa combine concept key dependency snapper, facilitates transaction processing incremental logging smsa add key level concurrency control top smsa therefore, smsa version applies optimization purpose smsa benchmark effect different optimization addition, also include orleans transaction eldeeb et al, orleanstxn experiment default transaction management api orleans applies pl pc fulfill acid multi actor transaction enriches experiment confronting competing concurrency control scheduling techniques, namely, locking based orleans deterministic snapper variant experiment run orleans net sdk experiment conducted orleans cluster consisting master node mn several worker node wn hosting orleans server located region mn responsible coordinating pact execution different wns snapper, smsa smsa addition, group experiment node en spawned region generate workloads, host orleans clients, submit transaction request orleans server number en wns deployed ensure sufficient amount request generated dispatched wns node, regardless type, aws ec instance core processor vcpus scalability experiment proportionally increase number wns ens, well number vcpus mn client side, en initiate one orleans client thread pact act executions, respectively client thread submits pipeline transaction request wns pipeline size determines concurrency level workload specifically, limit maximum number concurrent request system whenever result one request returned, new request replenished experiments, pipeline size tuned different implementation variant achieve good performance system computing resource near saturation fig show pipeline size configured adopt smallbank ben chmark alomari et al, first part experiment gain insight feature smsa benchmark, user bank account partitioned across many account actors, operation deposit transfer applied one multiple account actor smallbank approximates oltp actor oriented workload note benchmark show cross actor dependencies, use investigating performance fundamental building block smsa x, including incremental logging key level concurrency control experiments, employ multitransfer transaction shah salles, withdraws money account one actor deposit money several account actor transaction give u flexibility control transaction size access pattern different actor account specifically, adopt five parameter configure smallbank workload total number account actor located wn determines number bank accounts, ie, number keys, stored account actor specifies number key transaction access selected actor experiments, fix number accessed actor transaction thus, mean transaction access total key across four actor determines number hot actor wn transaction selects set actor access based following rule chance actor selected set hot actor example, hot set contains ten actor every actor equal chance chosen smaller higher contention actor level similarly, decides number hot key actor control contention key level also run experiment online marketplace laigner zhou, benchmark, mainly focus data management challenge event driven microservice like system architecture simulates multi tenant web scale application seller manage product associated inventory, customer interact system managing cart ie, adding product submitting checkout reason adopting benchmark experiment threefold first, cover several scenario cross component data integrity constraints, provides perfect use case data model dependency key across actor automatically handled existing commonly adopted benchmarks, ycsb cooper et al, tpcc tpcc, model type correctness criteria, thus unfitting goal experiment second, easily mapped actor model partitioning component multiple actor meanwhile, application state easily modeled key value collection across different type actor third, form realistic complex workload transaction implemented pact act business logic carried among eight different component listed fig discussed detail experiment set benchmark section, investigate impact smsa smallbank benchmark measure overhead concurrency control logging presenting relative throughput snapper, smsa smsa regard throughput nontxn difference three snapper variant supposed reflect trade offs state management layer, namely, overhead maintain key value collection actor benefit brings system performance group experiments, workload generated uniform distribution vary three parameters, experiment, fix vary fig show result pact, logging disabled, throughput snapper smsa affected apply actor level concurrency control, number key actor affect contention actor level besides, throughput smsa slightly lower snapper snapper allows pact access actor state directly, smsa need copy accessed key operate cloned version fulfill functionality data model image modified key captured contrast, adding key actor, throughput smsa increase key level concurrency control benefit reduced contention key gain finer grained scheduling offset overhead key cloning logging enabled pact, snapper throughput decrease largely, especially key per actor, smsa smsa rarely change show advantage incremental logging smsa smsa need persist change specific keys, snapper persist whole actor state act, snapper smsa show similar trend pact throughput abort rate remains regardless differently, smsa throughput increase abort rate decrease significant gap snapper smsa because, snapper, every act make copy whole actor state apply read write operation cloned state given snapper guarantee pact abort due transaction conflicts, safe pact modifying actor state place however, every single act aborted thus snapper applies update act actor state act commits section, vary fix fig show result pact, throughput snapper smsa significantly increase slightly decrease actor wn, contention actor extremely high snapper smsa actor executes pact one one ascending order transaction id batch id addition, actor also responsible tasks, including receiving batch message committing batches, extends critical path transaction processing actor added system, transaction processed parallel different actors, therefore leading higher throughput decreased contention actor also benefit act execution act throughout increases, abort rate decrease however, keep adding actors, eg actors, parallelism improved due limited number vcpus meanwhile, throughput drop many actor batching pact becomes less efficient set actor accessed pact less likely overlap define overlap rate number pact included batch divided number actor accessed batch according collected experimental data, get respectively overlap rate obvious impact smsa throughput continuously decrease experiment, even key added adding actors, contention key remains low, performance smsa improved much act abort rate smsa also keep low value term difference without logging, similar result observed throughput snapper drop significantly logging enabled, pact throughput go smsa smsa part, fix vary fig show result nontxn, throughput obviously decrease larger determines complexity transaction logic transaction execution latency pact act, absolute throughput snapper smsa decreases, relative throughput slightly increase grows indicates sensitive change nontxn pact mainly affected actor level transaction scheduling pact spends time waiting turn start execution first actor, time executing transaction logic act, dominant factor concurrency control pl commit protocol pc addition, since snapper smsa apply actor level concurrency control, abort rate remains even grows contrast, smsa lot sensitive change compared snapper smsa pact throughput decrease due increased overhead generating maintaining key level transaction execution schedules, well persisting key modification act throughput drop significantly, abort rate increase largely smsa x, actor maintains lock instance every key stored actor, act need acquire corresponding lock every accessed key compared pact, act suffers contention act throughput smsa drop snapper smsa one thing, number concurrent transaction submitted smsa much higher snapper smsa v explained smsa x, number tuned based total number key wn, snapper smsa based total number actor experiment, grows contention key level largely increase thus, act throughput smsa experienced significant drop conclusion, data model effective small number large actors, data model benefit workload access fewer key first, data model help system capture change performed specific keys, thus largely reducing logging overhead smsa smsa second, data model exploit concurrency every single actor therefore, smsa performs significantly better two contention high actor level low key level third, overhead brought data model, key cloning key level transaction schedule maintenance, completely offset benefit brought finer grained logging higher concurrency level section present performance affected skewed workload fix vary logging enabled implementation variant onwards section, present throughput pact act fig also breakdown latency pact fig divide latency pact time interval breakpoints set according progress pact first accessed actor time interval represent time spent step fig b, respectively note begin start execute transaction logic end whole transaction completes includes time forward call actor execute transactional invocation actor here, investigate impact fixing explained smaller indicates higher contention actor level fig show throughput breakdown latency, respectively pact, decreases, smsa benefit greatly growing contention actor discussed workload concentrated smaller set actors, batching pact becomes efficient due higher overlap rate contrary, contention actor negative impact snapper smsa according breakdown latency, snapper smsa grows obviously decreasing indicating pact blocked longer time waiting previous pact complete even snapper smsa also benefit higher batching efficiency decrease increased dominates transaction latency therefore, throughput show decreasing trend smsa remains low contention key low, pact need wait completion previous pact access key act, throughput three snapper variant decrease snapper smsa affected contention actor level however, smsa also affected indirectly influence contention key level addition, measure throughput orleanstxn given orleanstxn reported extremely vulnerable contention liu et al, bond, bragg, liu, use workload deadlock actor key distribution deadlock removed letting transaction access selected actor always ascending order actor id result, orleanstxn remains low throughput different value part, present impact determines contention key level fix fig show throughput breakdown latency, respectively pact act throughput snapper smsa rarely change varying contention key affect transaction scheduled actor level smsa x, pact throughput remains unchanged growing contention key cause growing blocking time smsa skewness high enough contrast, act throughput decrease largely validates act execution smsa sensitive contention key pact again, orleanstxn much lower throughput act execution three variant here, present combined effect changing value simultaneously fig show result snapper smsa pact act throughput show pattern affected contention key smsa x, pact throughput increases, decrease compared fig b, contention key grows much faster fig smsa also increase lot act execution, throughput dropped significantly already act sensitive contention conclusion, pact execution smsa greatly benefit skewness actor improved batching efficiency large number actor system workload follows uniform distribution, smsa obvious advantage snapper smsa workload skewed actors, smsa outperforms smsa snapper addition, pact execution smsa less sensitive contention key act execution pact throughput affected skewness key high level act execution smsa performs better snapper smsa cases, except contention key extremely high section, validate scalability smsa measure throughput pact act three variant snapper, smsa smsa different fig show case scale linearly snapper smsa affected change contention actor level increase pact throughput smsa decrease snapper act throughput smsa decrease snapper act throughput decrease significantly pact act execution sensitive contention actor level differently, smsa x, pact throughput even increase contention actor grows act throughput drop contention key extremely high fig section, measure performance different implementation variant online marketplace benchmark laigner zhou, snapper, adopt conventional actor state manipulation encode dependency application logic smsa benefit fine grained state manipulation, ought decrease logging overhead smsa x, exploit full contribution work, providing sophisticated actor state manipulation, transparent constraint enforcement, novel logging concurrency control technique online marketplace contains eight different components, encapsulating corresponding application logic maintaining set relation implementation, shown fig a, component mapped group actor seller maintains products, seller make total product system besides, three dependency constraint modelled first, item cart actor essentially replica product corresponding product actor thus, update dependency built original copied key second, stock product stock actor foreign key product product actor, interpreted delete dependency third, seller actor maintains date materialized view total number order created implement using functional update dependency experiments, four type transaction adopted fig checkout transaction cross seven type actors, total number actor involved depends number item bought step represent task happen resolving dependency constraint experiment, workload consists additemtocart, deleteitemincart, update price checkout transaction transaction generated selecting customer seller selecting product checkout transaction, number item checkout varies addition, based observation previous experiment act vulnerable contention, implement transaction pact whenever experiment therefore, updateprice transaction executed act unknown cart actor dependency product updateprice transaction submitted fig show result scalability experiment online marketplace workload fig show throughput type transaction here, pact throughput represents deterministic execution transactions, except updateprice pact, uniform distribution, smsa throughput slightly higher smsa decrease pact throughput increase however, smsa surpasses smsa benefit higher batching efficiency, smsa affected increased blocking actor, smsa remains higher concurrency level, benefiting key level concurrency control decreased throughput snapepr smsa decrease moderately, impact updateprice transaction severe transaction act throughput three variant higher corresponding pact throughput shown fig b, transaction distribution act differs pact throughput smaller transaction additemtocart deleteitemincart account much higher proportion act execution act flexibility quickly abort large transactions, exchange commit smaller sized transaction smsa x, act throughput increase change gain throughput smaller transaction aborting larger transaction changing act throughput decrease contention key becomes high, smaller transaction also suffer high contention thus, type transaction experience higher abort rate result lower throughput smsa act throughput decrease change smsa suffers contention actor however, varying smsa throughput drop note decreases, raise possibility product added many cart cause larger updateprice transaction fig therefore bringing higher contention actor level snapper, pact act throughput remain low level three group due high logging overhead conclusion, online marketplace benchmark, dependency constraint broadly applied, smsa show advantage two variant pact act execution, reacts different skewed workload similar way data replication mechanism widely adopted distributed system leverage data locality, decrease data access latency, enhance fault tolerance, achieve higher system availability existing actor system adopt method like event sourcing akka, orleans, geo distributed caching bernstein et al, replicate actor state, achieving eventual consistency linearizability, respectively however, actor replication differs replicating data items, since technique involves actor metadata eg, type possibly large actor state actor functionalities, thus introducing higher overhead work, actor state abstraction designed facilitate identification replication data item across actor capturing maintaining primary replica relation actor system, akka akka, relies conflict free replicated data type crdts shapiro et al, lightbend, replicate data across node eventual consistency guarantee although incurring high overhead actor replication, data type abstraction level inherits impedance found orleans, update single entity treated update whole actor state, preventing optimization result, method oblivious possible data dependency across actor anna wu et al, distributed key value store employ actor model transparently developer order process possibly merge concurrent update different work, anna expose actor programming model offer data dependency management constraint enforcement besides, anna focus eventual consistency scenarios, contrasting smsa support acid guarantee dpa kraft et al, data platform olap workload developer utilize actor based programming model abstract advance underlying data analytics system dpa designed bulk data updates, inhibits use event driven, highly transactional scenario found microservices data dependency another crucial aspect data management, specifies data one object depends data others enforce data dependency constraint context actor systems, recent research work actordb, shah salles, wang et al, focused connecting actor relational database system regain support declarative querying extensive data management functionality approach, operation data forwarded actor backend storage handled however, model conflict function shipping paradigm, decouples fast computation slow storage bernstein et al, contrast, dependency different data item across actor captured smsa application layer meanwhile, dependency constraint enforced transactional guarantee actor model emerged promising concurrency model facilitating distributed application design however, exposing opaque state management abstraction limit developer ability express complex relationship cut across actors, inhibiting adoption actor model fill gap, propose smsa x, state management layer advance actor model rich state management abstraction novel logging concurrency control algorithm experimental study show smsa enhances design complex relationship actor system improves performance state art deterministic concurrent control method result, smsa facilitate designing highly partitioned distributed data intensive application based actor model future work, identify potential increase smsa performance high contention key though little space exploit concurrency individual actor, technique like actor balancing key partitioning adopted continuing ",software engineering
"km state information flow directed brain synaptic network worm brain synaptic network algebraic operation information pathway graph algebraic quantum system neuronal interaction mixed state dynamic flow pattern km state entropy quantifies flow selectivity phase transition symmetry breaking brain synaptic network, characterized parallel connection feedback loops, drive information flow neuron large system infinitely many degree freedom system best modeled graph algebra underlying directed graph, toeplitz cuntz krieger algebra, capture diversity potential information pathway coupled gauge action, graph algebra defines algebraic quantum system, demonstrate thermodynamic property provide natural framework describing dynamic mapping information flow within network specifically, show km state system yield global statistical measure neuronal interactions, computational illustration based elegans synaptic network understanding dynamic information flow pattern complex system fundamental challenge network science, crucial neuroscience uncovering mechanistic basis brain function emmons mood honey randi various approach proposed primarily relying pertubative method based contribution finite path random walk information flow among unit complex system stojmirovic harush ghavasieh employing information theoretic tool identify functional circuit bettencourt systematic methodology accurately describing dynamic state interaction information pathway within directed complex network remain largely lacking here, using illustrative example elegans synaptic network finite directed graph parallel edge self loops, study information flow dynamic system infinitely many interacting subsystems, representing scaled synaptic pathway specifically, since neuron physically connected multiple chemical synapsis reciprocal electrical channel via gap junctions, neuron form self synapses, contains directed cycle ie, closed synaptic pathway pathway involving recurrences, resulting information flow infinitely many degree freedom algebraic quantum mechanic aqm hugenholtz graph algebra raeburn graph offer sophisticated formalism natural tool model describe interaction state infinite system indeed, main idea behind aqm method proposed haag, hugenholtz winnink haag quantum hugenholtz physical state system represented state algebra see appendix unlike standard quantum mechanics, us hilbert space state vector typically deal system finite number degree freedom observables system self adjoint element time evolution mathematically represented dynamic see appendix pair referred dynamical system algebraic quantum system given state observable element expectation value system state thermal equilibrium state inverse temperature state satisfy kubo martin schwinger km condition haag quantum bratteli equilibrium bost connes analytic element said analytic wrt action extends analytic function particular km state stable wrt dynamic is, referred km state formalism algebraic extension hugenholtz classical quantum statistical mechanic observables represented self adjoint matrices, time evolution system generated hamiltonian unique equilibrium state fixed inverse temperature given gibbs state tr density matrix tr usually corresponds total energy system here, algebra defined toeplitz cuntz krieger tck algebra raeburn graph capturing possible flow pathway sum product operator infinite dimensional hilbert space equipped natural dynamics, show km state resulting algebraic quantum system generated set probability distribution quantitatively describe interaction profile neuron km state provide rigorous foundation uncovering mechanism network structure drive dynamic state functional interaction consider elegans non pharyngeal neuron white structure varshney structural cook connectome connected via directed multigraph adjacency matrix ie, number chemical electrical synapsis neuron write synapse pre synaptic neuron post synaptic neuron sequence synapsis possible recurrence synaptic walk pathway length write pathway interact concatenation pathway want perform algebraic operation pathway describe concatenation scaling this, let infinite dimensional hilbert space formal sum pathway represented dirac measure coefficient path scaling factor neuron associate projection onto subspace generated synapse associate linear operator sending defined generator otherwise, adjoint operator given interpretation algebraic representation illustrated fig straightforward calculation show partial isometry ie, projection satisfy tck algebra raeburn graph universal algebra generated family subjected eq ie, spanned product set emphasized algebra central object formalism hilbert space indeed, family verifying eq hilbert space produce algebra isomorphic raeburn graph carry dynamic see appendix obtained gauge action given generic product turn algebraic quantum system interestingly, state see appendix defines probability distribution neuron via due fact since unit eq state km inverse temperature iff hence, particular, synapse expected value km state satisfies relation which, thanks eq eq yield using adjacency matrix neuron implying distribution associated verifies so, log spectral radius graph, eigenvector non singular component non negative hence, one write now, characterize vector provide distribution associated km state eq consider partition vector whose component neuron track information flow pathway length starting propagation scale ghavasieh since log observing number synaptic walk neuron follows convergent series, solution equation conversely, satisfies eq distribution neuron give rise km state via otherwise huef km thus, log km state space determined eq expected value projector convex space value non empty hugenholtz hence, determined extreme point namely, pure km state explicitly calculated log follows log fixed neuron vector solution eq hence, neuron defines km state inverse temperature represented distribution obtained eq thus, critical inverse temperature log dimensional convex space generated distribution correspond pure km state specifically, th component given measure probability interaction inverse temperature ie, probability information flow streaming neuron propagation scale received particular, probability information feedback so, vector describes outgoing interaction profile fixed whence, varying larger towards critical value draw dynamic mapping potential neuronal interaction neuron specifically, sufficiently large ie, th component, approach gain non zero component feedback flow weight ie, th component decrease mixed km state obtained statistical superposition via probability distribution representing relative quantity neuron gene expressions, stimuli, local topological measure degree distributions, etc words, mixed km state represents expected interaction profile network given distribution describing relative concentration quantity neuron influence dynamic neural interaction indeed, given distribution neurons, considering state defined interaction profile neuron random variable assumption system state probability expected interaction profile clearly given eq instance, given subset neurons, let uniform distribution ie, otherwise describes average outgoing interaction profile inverse temperature varying representing weighted directed network describe dynamic pattern average flow coming physical process explicitly describes formation directed information flow network given distribution generalizing idea network formation discussed undirected simple network ghavasieh fig illustrates network formation phenomenon consisting touch receptor neuron alml r, plml r, avm, pvm kaplan goodman self interactions, value approximately three time connection start emerge neuron onto direct neighbor network formed coincides density direct physical connection value, long range information flow connection established decreasing number interaction within direct neighbor observe larger preferentially target interneurons yellow node lower value higher temperature predominantly interacts motor neuron purple node next paragraph, study flow selectivity behavior information theoretic approach eq prompt natural definition entropy system equilibrium inverse temperature via shannon entropy entropy quantifies level uncertainty neuronal interaction propagation scale given distribution neuron higher state high level uncertainty flow information neurons, lower information flow selectively neuron namely, preferential flow pathway words, measure non selectivity among potential neuronal interaction route specifically, assuming topology synaptic network fixed, flow selectivity influenced distribution indeed, maximal neuron case log shown fig a, considering uniform distribution neuron orange curve condition satisfied sufficiently low temperature larger value around low temperatures, profile are, mentioned earlier, approximately unit vector corresponding weighted network consisting feedback loop figure show entropy mixed state varies temperature wrt uniform distribution degree distribution neuron ie, respectively, resp number pre synapsis resp post synapsis total number connection particular, entropy state denote quantifies average non selectivity outgoing interaction within network fig illustrates evolution function temperature neuron subset chemoreceptor chemo ciliated mechanoreceptors cilium mrns touchreceptors touch command interneurons command motor neuron coordinate forward backward locomotion coordination chalfie neural white structure kaplan goodman figure show that, average, touch sensory neuron selective among subset considered purely physical finding demonstrate neuron touch subset well positioned establish precise communication within network, perfectly reflects functional profile consisting mediating sensorimotor response anterior posterior touch goodman patil neural additionally, vd dd class relatively selective outgoing flow yellow curve consistent fact class responsible coordinating locomotion elegans chalfie neural bono consists single neuron get entropy outgoing interaction profile log inversely quantifies selective individual neuron information flow target example, behavior wrt temperature mentioned touch neuron subset fig show that, among touch sensory neurons, left posterior cell plml selective namely, entropy system corresponding km state remains lowest long temperature interval start increasing around critical temperature shown larger system different thermodynamical phase generated hand, thanks fundamental result graph algebras, km state admits unique km state obtained limit pure state converges huef km precisely, tend state approach disorder predominant, separate temperature decrease allow order property interpreted symmetry breaking information flow large temperature pure km state generate symmetric information flow networks, temperature decreases, asymmetric profile occur much asymmetric close symmetric profile address question, consider transition probability introduced uhlmann uhlmann study transition two state algebra used jozsa jozsa define fidelity quantum states, which, context, expressed pure km state represented profile inverse temperature indeed, simple practical meaning measure degree flow pattern within network remain similar whether flow information driven interaction profile neuron statistical physical terms, probability guessing correct state system inverse temperature know pure state represented either larger mean information flow significantly change one state other, whereas lower value imply significant difference flow pattern state words, effectively quantifies extent two information flow network corresponding two state symmetric illustrate this, consider fig set neuron pair measure level left right anterior posterior symmetry various neuron class observe high level left right symmetry command interneuron class whereas, posterior touch sensory neuron plml plmr highly asymmetric outgoing neuronal interactions, agreement fact plml selective right counterpart cf fig moreover, tends neuron pair illustrates critical behavior equilibrium temperature ie, km state converge unique state past three decades, mathematician extensively studied graph algebras, primarily address theoretical question operator algebra non commutative geometry cuntz pask however, due high level abstraction, potential application interdisciplinary field complex network neuroscience remained largely unexplored work, demonstrated mathematical property km states, derived graph algebra synaptic network, provide quantitative tool rigorous theoretical framework modeling information flow macroscopic phenomenon analyzing dynamic network using empirical data elegans, illustrated km state generate probability distribution capture neuronal interaction profile encode dynamic information flow modulated concentration quantity across network component main originality approach twofold first, bridge algebraic method quantum statistical physic hugenholtz bratteli equilibrium graph algebra raeburn graph network neuro science sporns second, proposes natural definition entropy complex system address challenge explaining network formation physical process dedomenico ghavasieh offering insight structure nervous system shape function note limitation avenue improvement future extension model due statistical nature link derived km state fig may depend physical network topology statistical analysis random graph could assess significance additionally, since considered synaptic transmission, vector neglect contribution extrasynaptic signaling functional connectivity elegans ripoll randi celegans extending framework multiplex network de mathematical moutuou using, instance, higher rank graph algebra formalism raeburn christensen could provide integrated representation various channel neuronal communication work supported natural science engineering research council canada crc grant nc dynamic algebra dixmier one parameter group automorphisms is, continuous map automorphism group dixmier linear functional said positive state algebra positive linear function example, usual trace matrix state show notion state is, fact, generalization trace functional",neurons and cognition
"learning image derived pde phenotype fmri data introduction dimensionality reduction pde learning proposed pde model summary concluding remark future work instruction reporting error dataset description dimensionality reduction pde derivation classification applying pde feature canonical independent component analysis canica real fast fourier transformation rfft uniform manifold approximation umap xgboost regressor mesh data generation pde identification via sparse ridge regression partial differential equation pdes model various physical phenomena, electromagnetic field fluid mechanic method like sparse identification nonlinear dynamic sindy pde net developed identify model pdes based data using sparse optimization deep neural networks, respectively pde model less commonly applied fmri data, hold potential uncovering hidden connection essential component brain activity using adhd dataset, applied canonical independent component analysis canica uniform manifold approximation umap dimensionality reduction fmri data used sparse ridge regression identify pdes reduced data, achieving high accuracy classifying attention deficit hyperactivity disorder adhd study demonstrates novel approach extracting meaningful feature fmri data neurological disorder analysis understand role oxygen transport delivery consumption brain neural activity relevant studying intracranial pathology keywords partial differential equations, fmri, bold signal, dimensionality reduction, sparse ridge regression msc partial differential equation describe wide variety phenomenon real life example, maxwell equation describe electric magnetic field arising distribution electric charge current field change time another example, schrodinger equation, fundamental postulate quantum mechanic lastly, another important example, navier stokes equation fluid mechanics, describes flow incompressible fluid researcher usually construct partial differential equation model based physical law estimate model parameter applying observed data however, monitoring recording data quite common science, building partial differential equation model data highly nontrivial pursuit thus, important question learn underlying partial differential equation governs particular phenomenon using data study uncovering underlying symbolical model observation started bongard lipson followed schmidt lipson two pioneer work aim compare numerical derivative experimental data analytic derivative candidate model schaeffer developed learning algorithm using sparse optimization identify term underlying partial differential equation approximate term coefficient approach known sparse identification nonlinear dynamic sindy developed applied literature recently, example chang zhang schaeffer et al wu zhang data driven method discover governing partial differential equation name some, long, lu dong proposed deep neural network method, pde net unlike sindy, pde net construct dictionary simple function partial derivative likely appear model, usually lead high memory load computation cost statistical probabilistic approach exploring functional magnetic resonance imaging fmri data widespread scholarly work however, fmri data much less analyzed using partial differential equation model approach, dominant tool inferring hidden connection searching essential component many scientific discipline one reason fmri data much less analyzed using partial differential equation model approach may need knowledge governing law human brain two type matter gray matter, made cell bodies, process sensations, control voluntary movements, enable speech, learning cognition, white matter, made axon nerve fibre connect cell project rest body thus, white matter help connect different brain region constitutes half total human brain volume historically, scientist focused gray matter cortex, thinking region action happens, ignoring white matter progressively, recent years, researcher started using functional magnetic resonance imaging fmri detect level dependent signal blood oxygenation bold signal key marker cerebral activity white matter, ie, fmri detects activation white matter gonzalez castillo et al researcher addressed limitation detailed reading fmri scans, traditionally emphasized localized view brain functions, showing sparse activated region brain response stimulus performing task finding highlighted subtle detail fmri scan beyond traditional analysis also emphasized pervasiveness false negative fmri sparseness fmri scan result localized brain function rather consequence high noise overly strict predictive response model challenged traditional fmri analyses, showing optimal noise conditions, fmri activation extended well beyond area primary relationship task, blood oxygen level dependent signal change correlated task timing appeared brain simple visual stimulation plus attention control task moreover, showed response shape varied substantially across region whole brain parcellation based difference produced distributed cluster anatomically functionally meaningful, symmetrical across brain hemispheres, reproducible across subject gawryluk et al researcher showed emerging evidence fmri detection bold signal white matter explained issue regarding detection white matter bold signal later on, gore et al provided multiple explanation issue raised gawryluk et al bold signal overlooked previous research wholly dismissed artifact schilling et al researcher reported bold signal increased significantly white matter throughout brain people performed task, like finger movement, fmri brain scan collected still known meaning behind increase blood oxygenation signal white matter, researcher agree essential study bold signal white matter may provide better understanding connectivity disruption brain neurological disorder main discovery schilling et al following bold signal open new view interconnection brain function brain function communicate via bold signal transmission map brain function interconnected network rethink accepted idea brain function manifesting sparse localized mode could responsible false negative fmri reading subtle inter regional difference bold signal response shape contain suf cient information produce functional parcellation brain activity gray matter, tissue traditionally studied fmri, bold signal reflect increase blood flow oxygen response increased activity nerve cell researcher schilling et al hypothesized axons, glial cell maintain protective covering myelin around them, may also use oxygen brain active signal could related happens gray matter also, researcher discovered signal changed even nothing biological happened white matter, changed differently different white matter pathway present white matter pathways, unique discovery however, new report evidence reliable detection bold signal white matter, posing whether white matter display transmission bold signal structural pathway response stimulus study like schilling et al found gray matter white matter display time locked activation multiple stimuli, tissue showed statistically significant signal change investigated task stimulus addition, different region showed different bold signal change task, region could display different bold response different stimulus researcher realized main challenge regarding sparseness activation fmri scan could following elevated noise levels, overly strict predictive response model approach, vanderbilt university medical centre researcher increased signal noise ratio putting person whose brain scanned repeatedly repeat visual, verbal motor task establish trend averaging signal several different fibre path white matter one reason limited study signal white matter lower energy signal gray matter are, therefore, harder distinguish background noise brain find out, researcher continue study change white matter signal previously detected schizophrenia, alzheimer disease brain disorder study animal tissue analyses, also aim determine biological basis change conclusion noise suf ciently low response model versatile enough, bold fmri signal reveal activity brain region whole brain continuously work adapts anticipate switch response environment paper, primary objective derive partial differential equation pdes fmri dataset subsequently, aim apply selected pde feature classification neurological disorders, article focus adhd dataset result study indicate pde feature extracted using proposed method high classification accuracy specifically, achieved accuracy rate exceeding underscore effectiveness approach identifying relevant pattern connection within brain activity data section paper delf detail methodology outline step involved preprocessing datasets, technique used pde extraction, classification algorithm implemented providing comprehensive description methodology, aim offer insight robustness applicability pde based feature extraction context neurological disorder classification section, learn partial differential equation pde adhd dataset, comprehensive collection neuroimaging phenotypic data aimed advancing research understanding attention deficit hyperactivity disorder adhd dataset part adhd global competition learn effective pde, need preprocess dataset, including smoothing data reducing dimensionality following preprocessing, employ sparse ridge regression learn pde adhd dataset includes preprocessed fmri data individuals, aggregated multiple international imaging site participant range age year include individual diagnosed adhd typically developing control specifically, fmri data four dimensional spatial dimension scan temporal dimension phenotypic data age, sex, handedness, adhd diagnosis also provided selected nilearn adhd dataset, forty individual subset original adhd dataset dataset chosen due pre formatted work nilearn library, additional quality assurance done additionally dataset balanced, twenty individual control adhd afflicted class dataset available directly nilearn python library phenotype interest whether subject adhd, binary label first objective derive partial differential equation fmri dataset uncover hidden connection essential component brain activity achieve this, first reduce dimensionality dataset, smooth it, transform reduced data mesh apply pde find algorithm learn pde transformed data broadly, dimensionality reduction achieved via following step also shown figure detail technique used discussed appendix step canonical independent component analysis canica used identify twenty region interest roi brain adhd dataset figure show plot twenty roi selected via canica twenty aggregated bold time series extracted averaging region interest traditional implementation independent component analysis fastica robust mild data variation due high inter subject variability fmri data, may result misalignment identified region interest such, canonical independent analysis canica used identify roi aligned across subject step real fast fourier transformation rfft applied smooth bold data rrft python function fundamental package scientific computing python library, numpy, computes one dimensional discrete fourier transform real input function computes one dimensional point discrete fourier transform dft real valued array mean fast fourier transform fft rfft explained appendix smoothed bold data shown figure fourier filter fft filter applied smooth data, ie, process mapping time signal time space frequency space process give u better picture much frequency original time signal ultimately filter frequency remap back time space hence surface generated model trained smoothed data obtained step uniform manifold approximation projection umap non linear dimension reduction algorithm applied row wise concatenated, smoothed bold data forty subject technique learns manifold structure bold data find low dimensional embedding preserve essential topological structure manifold case, spacetime structure bold data generates high dimensional data, use umap provide dimensional representation, preserving essential structure original dataset step again, apply smoothing procedure two resulting time series obtained step section, show step learn pde preprocessed data described previous section overview learning pde coefficient embedding illustrated figure step via xgboost regressor learn function training regression model predict use fitted model generate point desired mesh mesh generated way since pde find requires value mesh, also corresponding grid spacing value ie, input learn pde step sparse ridge regression used attempt learn pde subject using corresponding mesh library use sparse ridge regression found percent sample thirty eight forty individuals, leaving two individual atypical analysis due shape data sample adhd dataset, able find best fit representation term pde via sparse ridge regression yielded dataset six pde feature including constant term illustrated table show sample five individual adhd data set, class mean adhd, class mean adhd bootstrap confidence interval pde feature, using iteration resamples provided table found two pde feature coefficient statistically significant since bootstrap confidence interval exclude zero table suggests individual adhd tend exhibit positive coefficient negative coefficient whereas individual without adhd show opposite pattern, negative coefficient positive coefficient section, apply two significant pde feature classification performance pde feature compared roi correlation matrix feature figure serve reference point evaluating classification performance pde coefficient used roi identified canica pde feature focused lower triangular region roi correlation matrix sample twenty components, result feature six roi correlation matrix features, shown table selected using recursive feature elimination significant confidence level obtained via bootstrapping see figure support vector machine svm radial basis function rbf kernel used classification two cross validation scheme used stratified fold train test split per fold leave one cross validation loocv results, shown table present cross validation outcome using correlation matrix pde feature set support vector machine svm model using correlation matrix feature achieved mean fold cross validated accuracy compared model pde feature similarly, mean leave one cross validated accuracy correlation matrix features, outperforming accuracy observed pde feature cross validation methods, svm model correlation matrix feature demonstrated superior performance model pde feature also provide receiver operating characteristic roc curve svm classifier fitted pde feature correlation matrix feature figure figure respectively svm correlation matrix feature give area roc curve auc compared model pde feature correlation matrix feature outperformed pde feature classification accuracy shown results, novel methodology enables potential interpretability characterizing subject pde coefficient potential data used new type image derived phenotype idp mediator variable provide systematic information functional relevance additionally, potential researcher expertise extract insight pdes bold fmri measure resting state functional connectivity brain whole brain level, ie, temporal consistency spontaneous neural activity distinct region brain neural activity, relative concentration oxygenated deoxygenated hemoglobin cause fluctuation flair signal time, bold response detects change relative oxygen concentration hemoglobin, thus making bold response correlate flair signal fluctuation flair signal essential understanding intracranial pathology thus making study property role oxygen transport delivery consumption brain neural activity relevant studying intracranial pathology vazquez et al explain transporting oxygen brain complex process delivered tissue capillary level diffusion, fundamental process research tissue, oxygen diffuses cellular mitochondrion using oxygen diffusion manifest oxygen concentration gradient induced spatially distinct brain regions, essential aspect study fact significant feature discovered pde learning suggests appropriate pde reaction diffusion model describing oxygen transport brain oxygen concentration brain spatial location time oxygen diffusivity function, function depending oxygen concentration, follows model considered net rate oxygen delivered consumed balance, ie, amount cerebral oxygen delivered consumed equal amount brain tissue, ie, rate oxygen delivery minus rate oxygen consumption zero constant represents oxygenation diffusivity, unit constant represents oxygenation diffusivity per oxygen concentration, unit proposed model comprehensively describes behaviour oxygen concentration brain considers competition diffusion oxygen delivery oxygen cerebral blood flow oxygen diffusion manifest along oxygen concentration gradient crucial aspect model, help creating boundary condition model initial condition imposed model percentage oxygen carried cerebral artery brain, providing clear starting point research using table show scenario brain oxygenation fluctuation subject model consider unit space dimension time interval assumed initial boundary condition follows initial condition initial condition signifies initial resting saturation oxygen level, considered boundary condition boundary condition signify oxygen gradient respectively subject adhd, display similar behaviour regarding brain oxygenation fluctuation illustrated figure respectively well, subject adhd, display similar behaviour regarding brain oxygenation fluctuation illustrated figure respectively paper proposes unified framework extract important feature functional magnetic resonance imaging fmri data capture different brain function connectivity aspect first, canonical independent component analysis used identify region interest roi bold signal smoothed roi using real fast fourier transform second, uniform manifold approximation applied reduce smoothed bold time series two component third step, xgboost used learn function time stamp surface generated grid using fitted xgboost last, pde find, implement sparse ridge regression, used learn pde generated surface two pde component coefficient significantly differ zero regarded important feature applied proposed pde feature extractor pre processed adhd dataset fed important feature support vector machine classification accuracy area roc curve indicate identified pde feature useful predictor adhd study open new avenue fmri research, suggesting proposed pde feature extractor could applied neurological disorder like adhd important feature extracted proposed method achieve high classification accuracy also provide insight underlying dynamic brain activity, potentially improving diagnostic accuracy therapeutic strategy future work could focus expanding approach larger diverse datasets, well exploring relationship among extracted pde features, genotype, disease status deeper investigation interplay pde feature genetic information could provide comprehensive insight underlying dynamic brain functionality factor collectively influence disease progression manifestation ultimately, research represents significant step towards integrating advanced mathematical modeling practical medical imaging, promising enhanced insight outcome neuroscience clinical practice work, proposed novel method extracting imaging derived phenotype idp fmri data based role played pde far knowledge, state art work focused particular region function brain based biological medical knowledge contrast, method extract idp de novo pde modelling obvious limitation might lack immediate biological interpretation however, also advantage given current limited understanding human brain well pathology brain disorder expectation extracted idp may represent higher level abstract aggregation system level brain functions, revealing variation within brain functionally unknown indeed, extracting important however previously known feature move field brain study forward breaking boundary existing knowledge realize promising impact, immediate follow method development develop statistical framework leverage pde informed idp biological discovery, particularly cause brain disorder connection this, working new method us new idp mapping genetic basis brain disorder field genotype phenotype association studies, emerging trend us mediator complex disease genetic basis towards line, developed several novel statistical tool leverage different type mediator genotype phenotype mediator include rna gene expression genome transcription factor binding site well brain image idp extracted using standard method however, method based local feature gene expression region brain, without systematic information functional relevance availability pde informed idps, able map genetic basis brain disorder mediated complex unknown functions, unlocking potential using fmri data decipher genetic basis brain disorder apply canica select region interest canica used various application including neuroscience analyzing brain imaging data field multi source data integration essential canica seek find component independent within dataset maximally correlated across datasets utilized nilearn library performed canica standardization, de trending, high pas filtering, low pas filtering, spatial smoothing using isotropic gaussian filter kernel full width half maximum fwhm enabled ie, width gaussian filter, expressed diameter area filter value half maximal value methodology, rfft applied data smoothing rfft specialized variant fast fourier transform fft algorithm designed efficiently compute fourier transform real valued input data rfft particularly suitable application signal processing, data often consists real numbers, audio signals, time series data, image processing given real valued discrete input signal length real fast fourier transformation rfft computes spectrum represents frequency bin rfft denoted defined imaginary unit, frequency bin index, length signal given spectrum obtained rfft, irfft computes real valued signal time domain sample index, frequency bin index, length signal furthermore, let cutoff index frequency component greater equal set zero therefore smoothing procedure defined suppose length time series th subject parameter controlling number non zero frequency components, results, use umap powerful dimensionality reduction technique designed maintain global local structure high dimensional data projecting lower dimension umap operates constructing high dimensional graph representing data, optimized low dimensional graph preserve topological relationship fit umpa row wise concatenated smoothed bold data forty subject reduce dimension twenty two feature component transform subject individually fitted model method highly efficient, scalable, applied various type data, including numerical, categorical, text data umap particularly useful visualizing complex datasets, clustering, preprocessing step machine learning algorithm employing xgboost regressor model function training regression model variable predict trained model used generate point within desired mesh subject, use value index training data xgboost regressor fit model value learn function generate data mesh used pde find attempt learn pde using fitted xgboost regressor grid spacing mesh value simply length time series subject given subject, predict desired mesh use pde find implement sparse ridge regression attempt learn pde generated mesh data obtained previous section let library term used sparse ridge regression learn pde term case second order non linear pde polynomial degree one, term let corresponding vector pde coefficient learn pde objective function vector containing mesh data regularity parameter chosen user continuing ",neurons and cognition
"causal longitudinal image synthesis introduction related work preliminary cli method tvcg experiment conclusion instruction reporting error temporal causal graph tcg structural causal model data tabular causal graph tocg establishment tabular visual causal graph tvcg establishment intervened inference process downstream task datasets training detail result clinical decision making relies heavily causal reasoning longitudinal analysis example, patient alzheimer disease ad brain grey matter atrophy year intervened beta level cerebrospinal fluid answer fundamental diagnosis follow treatment however, kind inquiry involves counterfactual medical image acquired instrumental correlation based image synthesis model yet, query require counterfactual medical images, obtainable standard image synthesis model hence, causal longitudinal image synthesis cli method, enabling synthesis images, highly valuable however, building cli model confronts three primary yet unmet challenge mismatched dimensionality high dimensional image low dimensional tabular variables, inconsistent collection interval follow data, inadequate causal modeling capability existing causal graph method image data paper, established tabular visual causal graph tvcg cli overcoming challenge novel integration generative imaging, continuous time modeling, structural causal model combined neural network specifically, first depict causality tabular variable including demographic variables, clinical biomarkers, brain volume size via tabular causal graph tocg establish tabular visual causal graph tvcg causally synthesize brain mri developing intervened mri synthesis module ism edge tocg mri train cli based adni dataset evaluate two ad datasets, illustrate outstanding yet controllable quality synthesized image contribution synthesized mri characterization ad progression, substantiating reliability utility clinic clinical decision making heavily depends longitudinal pattern comparison causal reasoning instance, clinical decision making related alzheimer disease ad common type dementia neurodegenerative disorder progression extend decade physician initially assess change brain structure time longitudinal magnetic resonance image mri scan integrate change tabular variable factors, age cognitive ability, drawing medical experience understand progression ad context, conducting longitudinal pattern comparison relatively straightforward longitudinal data available, integrating brain structure change tabular variable factor understand progression ad pose significant challenge difficulty arises factor impacted independently causally interrelated year clinical experience ad essential physician develop causal reasoning mechanism understand ad progression however, even high quality longitudinal mri robust causal reasoning mechanism, comprehending ad progression remains complex complexity largely stem need physician consider specific question understand ad progression fine granularity, patient year younger, would brain image appear increase beta level cerebrospinal fluid csf would impact grey matter volume gmv inquiries, known counterfactual question involve hypothesizing specific intervention diverge actual scenario fig brain atrophy, key clinical indicator ad diagnosis, influenced numerous factors, including multiple covariates intervention typically, physician compare brain size change mri scan acquired say attempt answer counterfactual question different time points, like beyond based extrapolation change factor subsequently, determine timing nature intervention needed potentially slow reverse brain atrophy, indicated blue line fig addressing issue ideally requires imaging modality directly answer counterfactual question assist physician understanding causal mechanism ad unfortunately, existing imaging modality meet need consequently, computational method, generates novel longitudinal synthetic image incorporating ad causal mechanism providing insight counterfactual questions, emerges preferable solution end, hereby attempt establish tabular visual causal graph tvcg causal longitudinal image synthesis cli task incorporates causality longitudinality, novel integration causal graph generative imaging specifically, first depict causality longitudinal tabular variable including longitudinal demographic variables, clinical biomarkers, brain volume size via tabular causal graph tocg establish tabular visual causal graph tvcg using intervened mri synthesis module ism edge longitudinal image tocg framework allows easy synthesis counterfactual mris, addressing aforementioned counterfactual question simple modification variable intervention tvcg developing tvcg, encounter three primary yet unmet challenge mismatched dimensionality causal graph demonstrated success field epidemiology, econometrics, medicine primarily deal low dimensional tabular variable contrast, causal image synthesis involves high dimensional image low dimensional tabular variable inconsistent collection interval training data direct way model ad progression training model longitudinal data yet, acquisition time existing longitudinal mri data varies patient patient, making difficult develop model accommodate variability inadequate causal modeling capability causal mechanism ad involves intricate interaction among various factor traditional causal graph methods, like structural causal model scm require predefined graph structure often rely linear causal relationship modeling ie, edge struggle accurately represent intricate relationship address challenge mismatched dimensionality, propose generative imaging method, ism, feasible solution key idea ims represent high dimensional medical volume medium dimensional latent vector, serf bridge low dimensional tabular variable high dimensional medical image ism, train stylegan latent image generator defines latent image mapping function, accompanying neural network nn image latent decoder defines image latent mapping function address challenge inconsistent longitudinal collection interval training data, propose incorporate time interval independent variable model capability continuous time prediction existing approach tend construct multiple model subset discrete time point scalable suffers scarcity training data address challenge inadequate causal modeling capability traditional causal graph methods, tvcg us hybrid causal graph design, merges temporal causal graph tcg structural causal model scm technique hybrid model incorporates tcg causal discovery mechanism enhances scm soft deterministic probabilistic edge fitting methods, thus leveraging strength method moreover, scm edge fitting, use neural network nn based approach compared commonly used linear edge representation scm, nn edge representation demonstrates enhanced capability modeling causal relationship compared linear method summary, key contribution follows propose tabular visual causal graph tvcg designed causal longitudinal image synthesis cli task tvcg effectively tackle three major challenge inherent cli mismatched dimensionality high dimensional image low dimensional tabular variable inconsistent collection interval training data inadequate causal modeling capability traditional causal graph method evaluate tvcg causality longitudinal brain mri synthesis task several metric tvcg achieves best performance compared previous method additionally, synthesized image also proven beneficial preliminary manner predictive task clinical characterization ad beyond image synthesis, tvcg shed light causal relationship among demographic, bio markers, brain volume variables, mr image causality verified external validation cohort may help alleviate spurious correlation machine learning model medical image synthesis potential mitigating challenge limited absent data, privacy concerns, dataset bias image synthesis across mri, computed tomography ct positron emission tomography pet among different mri sequence different resolution mri different category health disease widely explored however, limited research focus prediction medical image future time point challenge processing various session interval capturing fine structure alternation among scan single individual ldgan mi gan predict multiple future data training multiple model incapable handling varying session interval fan et al propose tr gan deal input sequence varying length generate future variant sessions, consider modalities, bio marker demographic information attempt introduce causality medical image synthesis multiple sclerosis brain tumor ad however, concentrate image lack effective metric evaluate quality synthesized image via causal intervention also sectional thus might improper downstream task causal relationship ad widely investigated field pathophysiology related factor include age gender education level risk gene accumulated misfolded amyloid beta hyperphosphorylated tau protein grey matter loss enlarged ventricle current research exhibit dual emphasis first group method concentrate interaction two three specific factor others underscore establishment causal relationship network among multiple factors, related work iturria medina et al propose multifactorial causal model study disease progression furthermore potential intervention shen et al apply several causal discovery algorithm ad examine whether recover causal graph observational clinical data hu et al collect prior causal knowledge orient arc causal bayesian network diagnosed patient data however, either use extracted feature mri include mri intractability high dimensional image data, limit modeling performance clinical significance treatment given early stage ad effective thus, crucial task identify early disease stages, likely progress short medium term year may react positive treatment thus, lot research try forecast early ad using key feature clinical status, cognitive decline, brain atrophy multiple work using various models, gaussian process recurrent neural network rnn bayesian latent variable model parametric model model deal multi modal data, lack future mri restricts performance yet method able predict future mri alleviate restriction alzheimer disease prediction longitudinal evolution tadpole challenge compare prediction performance algorithm participant train historical data alzheimer disease neuroimaging initiative adni accessible datasets required make monthly forecast period year total volume ventricle also apply method part challenge show better result describe causal relationship time series, either temporal causal graph tcg structural causal model scm used edge tcg dynamically modeled training indicate presence absence causality binary continous variable binary manner contrast, scm, also known structural equation model sem presence absence edge predefined edge trained represent causal relationship either deterministic probabilistic function following, introduce them, respectively use window causal graph, special type temporal causal graph, introduce mechanism causal relationship variable tcg window causal graph direct acyclic graph dag defined follows, let dimension variable contains component component eg contains value represent attribute window causal graph got two set node set edge set node set contains various different timestep still contains component edge set employ lag specific directed link interconnect different components, represented link either forward cross time link within time link however, reverse cross time link permitted difference termed time lag fig give illustration window causal graph set window size hence graph focus two timesteps, graph represents cause time lag cause time lag cause time lag cause lag concise, simplified version window causal graph, termed summary causal graph, proposed simplify representation, shown fig subsequently, use summary causal graph representation causal discovery refers recovering causal graph tcg work observational data multiple causal discovery methods, mainly including constraint based score based functional causal model based method designed based multiple assumptions, primarily including causal sufficiency faithfulness assumption set variable causally sufficient common cause variable observed graph compatible probability distribution faithful one another conditional independence relation true entailed markov condition applied causal discovery finished, effective way test validness partial correlation analysis specifically, causal sufficiency faithfulness assumptions, observed variable set ie, difference set resulting subtracting mean causal edge unknown direction conditional independence test performed null hypothesis correlation equal zero structural causal model scm defined set observed variable set unobserved exogenous noise distribution measurable function specifies causal mechanism let scm, structural equation set equation set variable causal effect ie, parent unobserved exogenous noise associated tcg suffers limitation expressing presence absence causal relationships, without accurately representing magnitude specific function causal effect hand, scm express specific causal relationship using various function however validity model constrained rationality human defined edge paper, tvcg us hybrid causal graph design, merges tcg scm technique hybrid model incorporates tcg causal discovery mechanism enhances scm soft deterministic probabilistic edge fitting methods, thus leveraging strength method section illustrates proposed tabular visual causal graph tvcg causal longitudinal image synthesis cli task tvcg focus constructing temporal causal graph model, encompasses tabular data mri, medical image serving target output shown fig two training process tabular causal graph tocg establishment tabular visual causal graph tvcg establishment section, first introduce data use, detail two training processes, finally, describe tvcg intervened inference process clis, finally downstream task apply prediction result tvcg provide clearer understanding tvcg, use alzheimer disease ad working example, utilizing widely used ad dataset, adni balancing variable coverage model complexity, select variable adni dataset experiment, denoted better understanding, list variable table i, represents th observed variable time ad patient now, union them, dimension variable note represent different data type therefore, divide four distinct group demographic variables, bio marker, brain substructure volumes, mri total intracranial volume tiv ventricle volume vv grey matter volume gmv chosen closely related ad progression given significant gap tabular image variables, opt first establish tocg instead directly building entire tvcg cli specifically, two step tocg establishment causal edge discovery, structural causal model fitting, aid pre defined assumption besides causal sufficiency faithfulness assumption defined section make following three assumption based ad scenario probability distribution future state depends upon present state, ie, implies direct link time lag greater always exists causal effect ie, edge set causal graph exception constant factor, gender, self temporal causality causal hierarchy among different group variables, inspired prior knowledge specifically, demographic variable eg, gender occupy highest level edge modality variable demographic variable prohibited ii biomarker variable eg, protein percentage second highest level edge modality variable except demographic biomarker variable prohibited ie, causal edge discovery used model presence causal relationship edge causal graph specifically, applying markov property assumption causal discovery problem simplified focus discovery causal relationship maximum time lag thus, observed trajectory time series length observational data arranged pair observational data pair two consequence time step thus causality discovery performed help assumption technically, employ three widely used algorithm fci constraint based ge score based directlingam functional causal model based result algorithm integrated via voting mechanism implementation leverage causal learn package several modification made algorithm comply constraint outlined assumption detailed information algorithm available code, validity learned causal model discussed experiment section resulting causal graph presented figure testing conditional independence partial correlation analysis, mentioned section test utilized set value threshold reject null hypothesis modeling presence absence causal relationship edge via causal edge discovery, model relationship edge via deterministic probabilistic function scm accordance tcg, traditional scm equ extended introduce time modeling interval continuous time set variable causal effect variable time time point previous session model function form linear function, multi layer perceptron mlp normalizing flow besides, compare recurrent neural network rnn long short term memory lstm two bi directional artificial neural network use internal state process arbitrary sequence detail exact model function provided supplementary take mlp example assume additive noise model training objective function loss observation data paper, aim process variety variables, including tabular data mri however, tocg insufficient purpose, still need build tvcg straightforward way achieve would treat mri variable similar tabular variable present significant challenge due giant dimensional gap tabular variable mri paper, propose use intervened mri synthesis module ism bridge gap specifically, first select three tabular variable directly associated mri established tabular causal graph variable total intracranial volume tiv ventricular volume vv gray matter volume gmv ism modifies mri former time step synthesize new mri current time step according three variable way, ism serf edge tabular causal graph mri data thereby realizing tvcg following, first introduce training process ism detail get final tvcg shown fig train ism three step train latent image generator map latent space image space, train image latent encoder perform inverse mapping image space back latent space, train volume variable latent generator generate latent code based volume variable that, employ trained latent code generator transform volume variable latent code synthesize image based latent code via trained generator encoder volume variable derived causal graph, synthesized image becomes causally synthesized image following, introduce step step train latent image generator unlike typical natural image synthesis tasks, mri data training often limited, making challenging directly train image latent image model mitigate issue, train generator encoder separately way, latent image generator effectively trained sampling latent code distribution, thereby overcoming constraint limited data availability style based generative adversarial network stylegan trained latent image generator astonishing quality generated image stylegan generator firstly map multi dimensional gaussian distribution latent space mapping network series styled convolution block generate image sampled latent variable gaussian noise added represents styled convolution block cnn discriminator evaluates synthesized image distribution try distinguish true data distribution generator discriminator trained simultaneously independently adversary way training objective function discriminator generator given first second term equ represent discriminator output expectation generated real distribution respectively third term gradient penalty step train image latent encoder get well trained latent image generator based gaussian distribution, train image latent encoder map mri latent code way, modify mri intervene introducing three variable latent code synthesis new mri intervened mri specifically, well trained stylegan fixed generator, encoder trained project mri latent space mapping latent code, laying space, align latent code space fixed stylegan worth noting latent code dimension, duplicated time fit input generator, owns expressiveness, ie, cardinality set greater tov et al work supplementary material provide information space encoder based backbone feature pyramid generates three level feature map detail encoder found supplementary material training objective function image encoder latent code discriminator given loss image domain frequency domain fourier transform enables learning pixel wise basis also avoiding blurry image result loss important frequency regularisation term latent discriminator trained adversarially applied restrict deviate far mri, trained encoder project latent space, gaussian noise added image generator obtained optimizing step train intervened latent generator mentioned step want introduce three variable latent code synthesize new mri intervened mri however, variable different shape latent code hence, latent generator trained generate latent variable based v, ie, brain substructure volume term intervened latent generator since three variable kind intervention modify mri former timestep get new mri specifically, use lightweight layer mlp intervened latent generator design avoids overfitting issue low dimensional latent space patient undergone mri different time step training objective function intervened latent code generator given denotes mapping latent code mri time point respectively, projected trained encoder output train approximate gt likewise, denotes corresponding segmented brain volume visit time point case, mean trained transfer former timestep mri latent code latter timestep mri latent code conditioned modification training, patient scan total, randomly select two scan training epoch trained ism, directly add mri tocg treating ism edge three volume variable mri specifically, three tabular volume variable tiv vv gmv serve parent node higher level variable mri edge exactly define trained ism obtain tvcg modification node graph eg, causally affect influence influence caused graph termed intervention work tvcg, address various counterfactual scenario scenario categorized two type based underlying hypothesis question related mri based brain volume hypothesis, question based hypothesis first type, directly synthesize intervened mri using ism hypothesis based questions, approach varies pertain tabular variables, find answer using tocg relate mri, first estimate corresponding brain volume via tocg synthesis intervened mri using ism part, introduce inference process ism tvcg, respectively set time interval inference ism, intervention hypothesis volume variable result corresponding intervention mri mri synthesized mri fact, ism focus difference synthesis base tvcg, intervention variable causally lead change variable predicted first based tocg mri synthesized via ism besides longitudinal mri counterfactual synthesis, tvcg also answer counterfactual question tabular variable example, patient ad, brain grey matter atrophy year intervened beta level cerebrospinal fluid result computed beta level set brain grey matter atrophy amount demonstrate generated image possess clinical relevance predicting future progression patient condition, employ generated data predict patient diagnostic classification downstream task predicted diagnosis class, neural network eg, densenet extract image feature, classification network take extracted image feature tabular variable train jointly real data train model using adni dataset adniloniuscedu assess model generalization, test two independent datasets oasis nacc detailed information publicly available datasets presented table ii adni dataset primary choice model construction encompasses variable listed table nacc dataset, lacking longitudinal data, oasis dataset, missing biomarker variable primarily comprising healthy individuals, used limited testing purpose oasis specifically employed evaluating image related component model, testing causality downstream task imaging processing, image skull stripped using robex aligned mni space, resampled mm isotropic resolution using ant cropped dimension normalized voxel value range segment processed mri obtain grey matter volume ant ventricle volume cnn segmentation model learning mlp, nf, lstm rnn section adam used learning rate model trained epoch section detail progressive training approach stylegan, starting low resolution image progressively doubling resolution phase beginning process culminates generating image mm isotropic resolution six phase due increasing memory demands, minibatch size adjusted phase discriminator generator optimized using adam learning rate set phase phase final phase phase involves training samples, except last one, us mini batch parameter discriminator loss equation equ fixed image encoder latent code discriminator trained independently simultaneously, stylegan encoder loss, equ discriminator loss, equ optimizer adam used learning rate mini bath size training comprises iteration batch code study publicly available causal edge validity outlined section utilize multiple causal discovery method adni dataset verify causality relationships, tested nacc dataset causal discovery, adni data split adjacent session pair practical terms, adni dataset divided ratio training validation set apply three causal discovery methods, fci, ges, directlingam, training set due absence longitudinal data nacc, test sectional causal relationship causal edge time lag dataset fig show recovered summary causal graph table iv show recovered edge detail overall, introduction prior knowledge ensures causal relationship identified contradict common sense existing research finding example, exists causal edge contradicted time priority assumptions, causal edge brain tissue volume bio marker level, contradicted existing research, alternation protein early event progression ad partial correlation analysis, identified edge demonstrate significance across adni training set, adni validation set, nacc dataset figure highlight edge failing meet threshold, along respective test value five edge meet criteria, four involving biomarker variable interestingly, edge align current clinical research instance, suggest causal effect age apoe gene levels, recognized ad risk factor indicates age impact total intracranial volume tiv supported reference also, link level tiv, corroborated test limited success might attributed biomarker value fluctuation due varying measurement technique despite normalization efforts, significant noise affect accuracy scm fitting validity part includes assessing predictive performance fitted structural causal model available data pair necessarily adjacent used structural causal model fitting capture short long term interval relationship causality based model, compared leading time series models, show superior performance predicting brain volume changes, depicted table segmented volume tiv, vv, gmv data includes session subject average interval year session subject average interval year however, due limited csf biomarker data, training set csf biomarkers consists session subject average interval year test set includes session subject average interval year utilize normalized mean absolute error nmae metric, defined maximum minimum value ground truth, model prediction, total number test data compare non causality based method like non causal linear models, mlps, rnns, lstms, use variable predict future outcomes, causality based approach causal linear models, causal nfs, causal mlps, consider causal parent variable prediction case except variable, causality based method outperform non causal counterpart underperformance may stem limited causal parent variable providing insufficient information notably, even causal linear method rival rnns, lstms, fc network predicting tiv, vv, gmv, underscoring causality enhances model robustness mitigates spurious correlation figure illustrates data distribution various method first row show joint distribution gmv, highlighting negative correlation indicative toxicity causal effect gmv atrophy, confirmed research second row positive correlation age vv aligned finding causal mlp accurately reflects actual data distribution scenario summary, causal mlp excels due neural network superior modeling capability however, causal nf yield higher error causal linear method low dimensional settings, suggesting excessive complexity experiment validates approach integrating nns nonlinear complexity scm, effectively addressing ineffective causal modeling image synthesis, utilize stylegan, known exceptional quality generating natural image popularity image manipulation compare stylegan ae gan variational autoencoder gan wgan classical wasserstein gan gradient penalty ha gan hierarchically amortized gan medical image synthesis quality sampled mri synthesis evaluate quality synthesized mris, calculate fr chet inception distance fid maximum mean discrepancy mmd shown table vi metric assess divergence image distributions, lower value indicating realistic mri simulation fid, use middle slice sagittal, coronal, axial ax image calculate mean mmd computed stack slice except latent diffusion model ldm method trained adni dataset tested fid mmd real image adni, oasis, nacc datasets due computational constraints, use pre trained ldm checkpoint monai trained uk biobank ukb dataset fairness, remove skull ldm output using robex table vi indicates, stylegan achieves lowest fid mmd value fewer parameter faster inference time higher fid mmd ldm may due dataset difference ukb adni additionally, ldm slow inference large parameter count hinder use mri synthesis module mri reconstruction involves training encoder map mri latent space gan, ha gan, ldm, use resnet based encoder ldm employ encoded mri feature guide denoising process, described vae gan utilizes integrated trained encoder style based generator encoder detailed section fig demonstrates, stylegan produce high quality mri reconstruction vae gan result blurry, gan ha gan introduce distortion ldm reconstruction show substantial noise quality volume intervened mri synthesis test performance ism generating brain mri intervened specific brain volumes, including vv, gmv, tiv desired volume change set intervened image analyzed using ant confirm actual volume alteration table vii present average standard deviation actual volume changes, derived segmented volume synthesized mri fig feature bland altman plot demonstrating discrepancy desired actual volume synthesized mri plot axis indicates average desired synthesized mri volumes, axis show difference different datasets denoted varying dot type table vii fig evident adni trained model accurately synthesize mri intervention across various datasets maximum error observed deviation mri increased ventricle volume oasis dataset stability output tends decrease larger desired changes, especially extreme trend particularly noticeable vv interventions, error grow original vv increase first row fig illustrates this, showing larger dispersed difference desired volume diverges original fig display visualization volume intervened mri difference map illustrates volume changes, blue indicating decreased red increased brain tissue intensity example, second column show ventricle enlargement, evidenced blue around ventricle intervention total intracranial volume demonstrated third fourth columns, red indicating tissue addition blue indicating reduction, corresponding desired change longitudinal mri synthesis evaluate cli model performance generating future session image th month baseline th month baseline th month baseline using adni nacc datasets method compared image translation method pix pix cyclegan mri specific network mi gan ld gan tr gan mi gan multi information gan, estimate brain mri future time point conditioning brain mri baseline time point multiple information gender, education level, apoe gene ld gan longitudinal diagnostic gan, imputes mri learning bi directional mapping mri two adjacent time point performing clinical score prediction jointly, thereby explicitly encouraging task oriented image synthesis tr gan temporal recurrent gan complete missing session mri datasets adopts recurrent connection deal variant input sequence length flexibly generate future session generating future images, model take baseline session predicts multiple future session universal way, pix pix, cyclegan, mi gan model cannot deal varying interval train model separately tr gan ld gan model designed multiple inputs, however, comparison fairness, model also take baseline session input table ix compare volumetric feature performance model demonstrates closest match actual mri volumes, indicating superior accuracy predicting vv, gmv, tiv change test performed significance analysis model show increased error nacc test dataset due population differences, yet model exhibit better generalization less performance degradation nacc serf test dataset, exists population shift compared adni training dataset hence model exhibit poorer performance nacc dataset, larger error volume generated mri however, compared methods, model demonstrates better generalization, less performance degradation table ix shows, largest performance degradation model happens synthesis task, mae total intracranial volume increase ml adni ml nacc hand, tr gan output least error among methods, term total intracranial volume, gap mae tr gan model adni mri synthesis, gap increase nacc dataset, confirms better generalization model fig present mri visualization error map different method method yield high quality mri artifact blurs, closely matching target mri contrast, mi gan produce mri inconsistent patches, pix pix cyclegan result generally blurry tr gan ld gan exhibit incorrect tissue contrast, highlighting superior accuracy generalization model establish clinical relevance generated images, apply predict future disease progression two task ad classification ventricle volume prediction firstly, conduct three class classification task ad v nc v mci using adni nacc datasets, result presented table assess performance using multi class auc mauc accuracy, score, recall, precision synthesized mri model prove comparable real mris, surpassing method almost metric across scenario notably, model demonstrates superior performance task, largest time interval, crucial yet challenging clinical setting nacc dataset, higher proportion nc cases, show model advantage less pronounced compared adni secondly, method applied tadpole challenge vv prediction, competing algorithm test set includes session subjects, average interval year model achieves mae outperforming winning algorithm without utilizing additional pet dti data available tadpole anticipate incorporating pet dti data could enhance result approach uniquely integrates causality framework, enabling prediction hypothetical scenario addressing counterfactual question outlined section experiments, intervene level csf age mci group predict counterfactual tabular variable synthesize corresponding mri mci group bifurcated stable mci smci remain mci stage, progressive mci pmci progress ad identifying subgroup affiliation crucial timely treatment adni test set, examine mci patients, including pmci smci, across data sessions, respectively figure b, c, illustrate prediction gmv, vv, tiv intervening level csf pmci individual intervened reach level pg ml, smci mean adni figure reveals pmci individual lower level mean red line suggests increasing csf may lead larger gmv tiv smaller vv counterfactual predictions, use classifier section pmci patient progressing ad, correctly identified pmci using factual synthesized mri however, number drop counterfactual mri intervened level, suggesting intervention might slow ad progression however, insight preliminary requires clinical validation figure illustrates pmci patient brain image might look five year younger compute difference map counterfactual mri reveals smaller ventricle greater grey matter retention, aligning current research approach provide insight past brain atrophy rate assist clinician future progression prediction paper, introduce tabular visual causal graph tvcg model causal longitudinal image synthesis cli task integrating causality longitudinal analysis image synthesis, tvcg avoids spurious correlation surpasses previous method performance besides, synthesized image tvcg also show significant promise clinical ad characterization limitation model lack modality like pet dti, could provide additional, crucial information available mri future work explore incorporating modality examining causal relationship additionally, data driven causal model building necessitates large datasets, finding data efficient construction approach key area future research endeavor guide u evaluating cli practicality real world clinical contexts, encompassing ad various potential application continuing ",neurons and cognition
"topological graph theoretical analysis dynamic functional connectivity autism spectrum disorder introduction methodology experiment result conclusion future work instruction reporting error mapper algorithm distance correlation graphical model modularity graph eigenvalue topological analysis ollivier ricci curvature data preparation network construction graphical topological metric plot autism spectrum disorder asd prevalent neurological disorder however, multi faceted symptom large individual difference among asd patient hindering diagnosis process, largely relies subject description lack quantitative biomarkers remediate problems, paper explores use graph theory topological data analysis tda study brain activity asd patient normal control employ mapper algorithm tda distance correlation graphical model dcgm graph theory create brain state networks, innovatively adopt complex network metric graph signal processing gsp physical quantity analyze brain activity time finding reveal statistical difference network characteristic asd control group compared normal subjects, brain state network asd patient tend decreased modularity, higher von neumann entropy, increased betti numbers, decreased betti number finding attest biological trait asd, suggesting less transitioning brain dynamic finding offer potential biomarkers asd diagnosis deepen understanding neural correlation autism spectrum disorder asd neurodevelopmental disability become prevalent throughout year according study autism developmental disability monitoring addm year child age estimated asd, higher previous estimate patient exhibit symptom social interaction impairment communication deficits, causing challenge adapt society make early diagnosis disease important however, symptom asd vary wide range, including social, emotional, cognitive impairment lack quantitative measure impedes diagnosis process, calling advanced data analysis algorithm uncover accurate biomarkers disease bolster timely detection intervention brain network analysis tackle problem study network relationship pattern brain activity analyzing brain signal extracted functional magnetic resonance imaging fmri electroencephalography eeg data, study aim uncover spatiotemporal dynamic human brain facilitate disease analysis specifically, temporal information gained great emphasis recent study compared stationary patterns, dynamic signal provide richer detail brain many disease pattern natural phenomenon uncovered examining time varying brain signal study damaraju et al found schizophrenia patients, average, less involved large scale brain activities, display abnormal activity however, one major challenge studying brain activity immense amount data involved, awaits powerful algorithm extract meaningful pattern reduce computation burden thus crucial discern underlying topology structure data topology study shape structure topological data analysis tda emerging field aim study shape data recently proposed tool tda mapper approach reduces set high dimensional data graph process, shape topology original data sample captured represented graph mapper algorithm suitable depicting data distribution across subject time, seen previous success saggar et al applied mapper algorithm study brain activity rest different task found connectivity difference different brain state later work, applied study resting state fmri uncovered important transition hub state using node degree metric made impactful discoveries, analysis limited healthy subjects, exploration graph metric remained basic node degree thus interesting adopt mapper algorithm context brain disease explore different metric mapper graph uncover biomarkers brain alteration graph signal processing gsp important technique graph theory extends concept conventional digital signal processing process data defined graph domain basic gsp tool include sampling, filtering, graph learning gsp wide range application brain network analysis huang et al decompose brain signal according different smoothness rapidness level using graph spectral operation discovered correspondence brain network activity graph frequency preti et al leverage structure function coupling implication graph frequency components, linking brain functional activity neural architecture node edge level graph metric however, method construct graph based brain region time information collapsed correlation calculation step, hindering detailed analysis brain state distribution across time regarding this, mapper algorithm clear advantage collapsing temporal resolution reasonable combine gsp mapper algorithm uncover intricate brain dynamic across time paper study brain activity distribution across time autism normal people employing mapper algorithm, graph representation brain state distribution landscape created subject then, studying gsp tda property graphs, difference normal autism group discerned summary, contribution novelty paper best author knowledge, first work applies mapper algorithm study patient neurological disorder work inventively combine gsp tda, applying variety gsp metric including node graph level, frequency domain metric tda quantity examine brain state distribution network group difference identified graph metric reflect meaningful biological trait altered brain activity induced asd finding attest essential symptom asd given neuroimaging data, time varying vector extracted, apply graph theory tda technique convert graph data brain network analysis then, network examined term structure, connectivity, topology using various graph metric comparing metric result normal autistic groups, study difference dynamic functional connectivity induced autism reflect brain state distribution individual level, employ mapper algorithm field topological data analysis tda mapper algorithm encapsulates topology data sample graph structure, providing essential depiction data distribution landscape approach make assumption data robust noise due use graph structure illustrated fig brain signal time point viewed data vector data domain first step mapper algorithm project data low dimensional space nearby point indicate similar brain activation pattern use principal component analysis pca achieve step that, dimension reduced data space divided overlapping bins, partial clustering conducted inside bin combine similar data sample ie, time frame final step, graph constructed using cluster nodes, edge established two node corresponding cluster one common data sample process, obtained brain graph dataset, enabled u explore topological physical characteristic realization geniesse et al adopted experiment, graph constructed reciprocal knn graph, edge established two node common neighbor among top nearest neighbor method stabilizes noise level reducing false connection binning process data sample space, mapper graph viewed histogram instantaneous brain state hence, depicts distribution probability subject brain activity across time mapper algorithm encapsulates topology data sample graph structure, providing essential depiction data distribution landscape approach make assumption data robust noise due use graph structure rightmost figure fig show example graph created mapper algorithm one important quality mapper algorithm clustering process, similar time point merged node, thus capturing complex organization rather plain chronical chain, illustrated fig distance correlation graphical model dcgms used addition mapper algorithm model brain state network one valued property dcgm that, pca dimension reduction step, treat every time point independently throughout entire process, keep chronological information intact vital time varying brain activity analysis fig shows, construct distance correlation graphical model dcgm calculating distance correlation pair time point filter correlation value using value threshold, screening edge value larger ensure statistically important connection kept graph resulting graph node time point, edge represents correlation time point two end distance correlation measure association random variable comparing pairwise distance joint distribution variable marginal distribution two random variable distance correlation defined follows distance covariance, square root product distance variance dcgms capture nonlinear relationship variables, limitation traditional linear method like covariance partial correlation allows dcgms model complex dependency accurately distance correlation less sensitive outlier compared pearson correlation, making dcgms robust presence noisy data introduce graph modularity metric examine structure individual graph generated mapper algorithm also perform frequency domain analysis eigenvalue distribution graph metric introduced modularity modularity assesses presence community structure within network, identifying group node exhibit higher connectivity rest network metric measure degree network divided modules, unveils modular organization brain temporal state arrangement mathematical expression element adjacency matrix, degree node total number edge graph, community assignment node kronecker delta, equal otherwise laplacian eigenvalue eigenvalue distribution graph laplacian matrix offer insight overall network dynamic feature mean variance eigenvalue provide information stability presence distinct functional module obtain laplacian matrix degree matrix diagonal matrix diagonal element represents weighted degree node proved real, symmetric, positive semi definite obtaining graph laplacian decompose using eigendecomposition diagonal matrix entry laplacian eigenvalue network generally, lower eigenvalue correspond smoother signal across graph, less variation among node values, higher eigenvalue indicate signal component change abruptly among node von neumann entropy building definition laplacian eigenvalues, characterize degree randomness graph structure von neumann entropy laplacian eigenvalue mathematical formulation set eigenvalue eigenvalue examine brain state distribution subjects, explore structural aspect simplicial complex composed instantaneous brain state data point betti number topological analysis, vietoris rip complex constructed selecting distance threshold, building edge data point less distant threshold, creating higher level topological structure wherever possible then, number high dimensional shape counted characteristic simplicial complex, annotated betti number proposed ollivier olliview ricci curvature describes connectivity topology node graph node v,e ollivier ricci curvature defined following wasserstein distance shortest path distance according chien chun ni calculate measure mass distribution lazy random walk graph experiment data includes study brain state distribution difference autistic normal people using nilearn package python, pre processed data abide dataset obtained pre processed step include bandpass filtering, global signal regression, quality check, ensuring higher data quality fmri data registered masked using icbm extract time series pre processing step crucial brain data analysis, factor like individual difference motion noise lead data ambiguity shown fig pre processing quality data make profound impact analysis later stage create network reflect brain state distribution individual level, examine mapper algorithm distance correlation graphical model fig show example graph created mapper algorithm parameter mapper algorithm affect resulting graph taking note parameter searching process saggar et al testing different choices, set parameter experiment resolution gain number neighbor dimension reduction method pca pc construction dcgm, first calculate distance correlation brain signal vector different time point then, screen statistically insignificant one using value threshold thus obtaining weighted adjacency matrix, shown fig examine trait pattern brain state graph generated mapper algorithm dcgm, finding comparison plotted fig violin plot illustrate distribution metric value autistic control groups, box plot included inside violin plot indicating median quartile distribution histogram show detailed distributional feature two group metric value side side comparison observing plots, including peaks, tails, quartiles, shape distributions, make following analysis data modularity shown fig graph created either method, tendency decreased modularity autism group plot show that, compared normal controls, autism patient tend lower network modularities average, indicating less clear cut community structure network contrast implies asd patient display less distinct type brain activity fewer transition brain state rest result reflects autism subject less distinct community cluster brain states, indicate overly smooth brain activity discovered average eigenvalue frequency domain analysis conducted mapper dcgm graph studying eigenvalue distribution, indicated fig interestingly, average eigenvalue dcgm mapper graph lead contradicting result overall, significant difference average eigenvalue normal autistic group according theory gsp eigenvectors smaller eigenvalue correspond smoother graph signal across node however, comparing eigenvalue may direct implication considering temporal graph ability characterize brain state distribution across time, valuable examine frequency component temporal graph signals, reveal brain dynamic time von neumann entropy network autism subject likely higher von neumann entropy dcgm capture phenomenon clearly increased entropy value imply random state mind autistic subject rest together comparison network modularity, show autistic subject less organized, distinct brain activity rest, could indicator restricted interest repetitive behavior introduced node curvature fig indicates distribution node curvature value normal autistic group although difference autism normal group remarkable, distribution curvature score two graph creation method distinct plot show compared dcgm graphs, mapper graph much variant node curvature value implicates mapper algorithm create relatively diverse graph structure simplicial weight curl simplicial weight curl depicts flow weight simplicial complex constructed brain network according fig mapper graph dcgm yield different curl comparison normal autism group one way make sense simplicial weight curl related method network creation hence, future work consider simplicial weight curl structural criterion guide network generation process select optimal network generation method best reflects subject time varying brain activity topological analysis experiment, topological analysis realized gudhi package python simplicial complex created using maximum edge length collect zeroth first order betti number patients, shown fig observed plots, compared normal people, autistic subject tend higher count number decreased count numbers, indicating larger number scattered component lower amount complex interaction structure study used topological data analysis tda compared complex network metric investigate difference brain activity individual autism spectrum disorder asd neurotypical individual applying mapper algorithm distance correlation graphical model dcgm constructed brain state distribution network subject, enabling deeper understanding underlying pattern brain complex network algorithm accompanied graph theory topological data analysis investigate temporal pattern brain connectivity application temporal graph allowed u deeper understanding human brain temporal transition various condition result graphical topological metric implicated less distinct random brain state autistic subjects, corroborating previous finding neuroscience study proving ability graph topological analysis capture alteration brain activity neurological disorder take steps, plan substantiate discovery extensive dataset autism spectrum disorder devised method also applied neuroscience phenomena, especially one known alteration brain state temporal sequence studying neurological events, seek provide insight underlying commonality difference among neuroscience condition design precise detailed analysis, plan narrow analysis specific brain region proven cause neurological condition study, expect enhance contrast group lastly, considering extensive use matrix eigenvalue signal processing, statistical physics, complex network analysis analysis simulation network evolution, recognize potential transplanting applying technique brain complex network physical quantity may offer better description developmental process psychiatric disorder particularly non stationary process like brain signals, time series algorithm need incorporated analyze complex network evolution continuing ",neurons and cognition
"cortical dynamic neural connectivity field introduction cortical field connectivity dynamic discussion conclusion instruction reporting error dynamic single cortical layer single layer cortical dynamic variable intrinsic connection cortical surface geometry neural connectivity field multi layer dynamic criterion multilayered cortical sheet criterion oscillation generalised oscillation criterion neural connectivity interaction hebbian dynamic macroscopic study cortical tissue reveal prevalence oscillatory activity, reflect fine tuning neural interaction research extends neural field theory incorporating generalized oscillatory dynamic previous work conservative semi conservative neural field dynamic prior study largely assumed isotropic connection among neural unit however, study demonstrates broad range anisotropic fluctuating connection still sustain oscillation using lagrangian field methods, examine different type connectivity, dynamics, potential interaction neural field theoretical foundation, derive framework incorporates hebbian non hebbian learning ie, plasticity study neural field via concept connectivity field cortical surface comprises layer neural cells, scaffolded neural network neural glia cell including astrocyte astrocyte also help maintain homeostasis neurotransmitter extracellular electrolytes, considered involved transmission membrane potential moreover, empirical study cortex using intracellular extracellular electrode revealed continuously fluctuating membrane potentials, leading measurable extracellular potential gradient local field potentials, measured macroscopic electrodes, exhibit oscillatory activity, microelectrodes reveal spiking activity summation extracellular potentials, resulting neural firing via axon slower dendritic postsynaptic changes, lead oscillatory activity frequency content ranging approximately hz hz biophysical pathway potential propagation neuropil varied involves transmission action potential along membranes, specifically via axon dendrites, well neuron chemical electrical synapsis conductive property pathway highly dependent type synapsis involved chemical synapses, particular, exhibit significant variability speed direction induced currents, influenced transmitters, synaptic receptors, synapse related metabotropic changes, postsynaptic uptake dynamic additionally, current transmission across astrocyte possible, though understanding process remains limited theoretical model cortical surface induced dynamic developed various authors, resulting intricate simplified model intricate model incorporate many aspect neural cells, allowing wide range cellular dynamics, whereas simplified model include minimum set neural component capture key characteristic neuronal activity estimating model parameter intricate model using data unlikely effective due high dimensionality complexity parameter space however, model useful simulating data specified network parameter exploring effect parameter change dynamic contrast, simpler model seen considerable development, particularly context parameter estimation data line work initiated amari others depth review neural field models, cook et al provides comprehensive analysis dynamic analysed simpler model typically involve single multilayer systems, without constraint oscillatory activity even within simpler frameworks, possible study dynamic neural cell interacting action potential carefully tuning models, shown oscillatory activity achieved, often estimated average response neural population studying dynamic constrained specific parameter setting might seem restrictive, find empirical support, oscillatory activity prevalent action potential recording cortical activity using macroscopic electrode study, explore theoretical constraint required produce oscillatory activity, still complete understanding cellular mesoscopic process generate however, self organized criticality soc provides qualitative explanation prevalence oscillatory dynamic soc induces state criticality threshold driven system order disorder, described discussed experimental evidence suggests neural dynamic constrained soc, generating oscillation observed furthermore, several study suggested system near criticality enhanced data compression capability implying natural force drive system toward optimizing data storage manipulation oscillatory activity, context, seen system exhibiting phase invariance, either globally locally paper, expand idea, proposing self organized criticality, complex interactions, lead model exhibit activity near point invariance invariance structure neural field specifically analysed visual cortex non biological neural network demonstrate following section cortical network induces invariance structure how, assumption local invariance, support theory neural connectivity interaction spectrum possible interaction vast, structural dynamic allow oscillatory activity or, general terms, invariance structure analysed using concise set scenario global local invariance field model well studied dynamic physical systems, including electromagnetism, gravity, quantum field theory, theory characterized specific invariance structure section present theoretical background model cortical surface, exploring impact connection dynamic connection generate connection field section review biological substrate interaction connectivity neural activity investigate specific example section discus analysis presented paper, biological context empirical evidence section, summarize key finding presented cortical surface modelled thin sheet, millimetre thick, covering area human brain within sheet, neural unit span cortical layers, connection either orthogonal surface intrinsic connection running along sheet extrinsic connection depicted fig cortical field dynamic emerge multiple bi layer excitatory inhibitory neural units, balanced activation result oscillatory activity balance allows field expressed complex vector, one complex component per bilayer dynamic governed equation first term right hand side arises excitation inhibition balance, leading oscillation second term introduces perturbation oscillation interaction weak matrix represents connectivity gain different layer point cortical surface vector field conjunction determines field activity point influence field activity point neural field, integral cover disc shaped region around cortical surface, local connection assumed relevant literature suggests region corresponds size cortical columns, diameter ranging mm neural field description derived dynamical system equation extensively discussed literature assume system dynamic remain close equilibrium state focus perturbation around state, implying variation neural field strength small additionally, assume long wavelength approximation, excluding high frequency aspect spectral activity human brain recordings, frequency hz usually considered satisfy approximation section explore invariant structure neural field implication dynamic generalize equation investigate connectivity neural unit related invariant structures, enabling u propose interaction cortical connection neural field activity dynamic single bi layer defined equation long wavelength approximation, dynamic expressed using partial differential equation see detail important note perturbing around zero neural field state weak connection strength, field approximated first order expansion sigmoid function, specifically tanh see equation ensure connection parameter remains real, define connection imaginary connection gain might seem unusual, result using complex valued dynamical equation represent cross connection excitatory inhibitory cell network configuration responsible generating oscillatory activity including linear term expanding integral using taylor series integrand, obtain wave equation defined using integral disc, dynamical equation governing system given equation note equation include first order derivative reflecting assumption intrinsic directionality connection cortical surface assumption relaxed, empirical evidence however, include analysis structure derivation would cumbersome follow equation klein gordon field wave equation mass mass, speed, term defined follows studied moment, assume constant across surface approximating system dynamic using higher order derivative assume even dimensional additionally, derive time derivative dynamical system integrating retarded time rather evaluation time simplifying derivation shown equation combine equation give integral equation equivalent equation where, indicates integral done retarded time equation concise description neural field dynamic take short detour describing lagrangian formalism play important part later section neural field dynamic equation associated lagrangian density mixture quadratic function neural field derivatives, equation notation simplified using standard terminology classical field theory introducing metric, present assuming minkowski metric add new information dynamical equation derived use shorthand notation physics, repeated index co variant contra variant index summed roman index run greek index lagrangian density given equation metric defined connection actually pseudo metric contains positive negative term along diagonal, equation dynamical equation neural field equation given variation neural field lagrangian density varying complex conjugate neural field, give equation varying neural field give complex conjugate equation variation given euler lagrange equation analysis section assumed interaction weak however, possible drop assumption system strong intrinsic connection shown non zero stable state contrast dynamic analysed section overall field equation shown similar formalise above, start defining model using equation main difference equation strong intrinsic connection included form dirac function ie intrinsic connectivity much greater strength extrinsic modelled using point like function dynamical equation given equation shown set non zero stable state perturbing equation stable state give long wavelength approximation dynamical equation complex field equation state different metric defined section speed propagation neural field different moreover, absence mass term metric, given equation neural connectivity field coupling discussed section different neural field derived section equation lorentz invariant equation conformally invariant includes lorentz invariance neural field described section model small oscillation activity used model activity showing high amplitude oscillations, eg alpha oscillation human eeg deriving equation assumed connection cortical bi layer isotropic change time however, compelling empirical evidence cortical connection change along surface time dependent, see section section analyse effect spatial temporal variation intrinsic connection see figure schematic variation intrinsic connection strength compensated variable connection strength retain oscillation analysed section brief, connectivity modulated using space time dependent phase, modulation given function cortical surface varies time space including modulated connection term dynamical system eq give u equation expanding integral taking account retarded time give following equation equation constraint time space dependent connectivity field, neural field, define new variable, perturbation constant, use standard nomenclature classical field theory combining equation manipulation get expression interaction cortical connectivity field format classical gauge field define connectivity field of, neural field equal term parenthesis seen derivative term defined classical field theory covariant derivative using terminology defined succinctly rewrite dynamic shown equation note modulation connection, give rise solenoidal vector field derivative taken taken real scalar however, allow variability connection giving u term mixture gradient solenoidal field returning equation define modulation connection follows, centre integrating domain derive dynamic equation get similar expression connectivity field defined using equation note gradient field seen two dimensional vector equation defines interaction neural field interaction neural connectivity field however, interaction connectivity field defined dynamic modified include interaction term connectivity field including kinetic interaction done without much complication modifying lagrangian dynamical equation lagrangian density unmodified system given equation corresponding dynamical equation equation lagrangian density add kinetic term connectivity field give u squared differential term dynamical equation motion lagrangian density connectivity self interaction given equation given expression generalised lagrangian density interaction term self interaction term neural field connectivity field given equation sum lagrangian density eq develop theory further, pause discus important aspect dynamical equation dynamic connectivity field persist even neural field partly surprising aspect theory find support experimental evidence self interacting connectivity field described lagrangian density derived equation simplest one allows dynamical equation invariant phase transformation evidenced data cortical tissue dynamical self interaction term connectivity field mode interaction causal speed propagation neural connectivity field different event first term right hand side equation mediates causal dependency neural field third term connectivity field field included eg lagrangian density equation used would situation neural field would create disturbance connectivity field, would transmit infinitely quickly causing secondary change neural field result would neural field propagating indirectly infinitely quickly, contrary experimental finding equation completely analogous electromagnetism notice clear physical relation classical electrodynamics neural connectivity field theory except co existence phase invariance oscillatory activity type field however, contrast electromagnetism gauge field equivalent connectivity field empirical counterpart least classical field cortical dynamic empirical counterpart given actual connection neural unit via axons, dendrites, synapsis possibly astrocytic scaffolding neural unit embedded main characteristic cortical activity allowed u derive equation rest following three criterion cortical activity seems fine tune excitatory inhibitory dynamic allowing phase invariance cf, excitation inhibition balance ii existence neural field interacting connectivity field iii minimally complicated dynamical equation supporting point point supported oscillatory dynamic seen data also find support idea soc, dynamic tend state invariance, current setup phase invariance su invariance point ii empirical evidence point iii mainly computational reason important, especially situation model parameter might inferred data geometry cortical surface relevance neural connectivity field determined physical geometry cortical tissue, interaction field surface defined geometry defined extrinsic connectivity see figure schematic depiction following, consider mathematical constraint fulfil set plausible geometrical assumption neural connectivity model cortical sheet locally smooth two dimensional surface, ie, dimensional differential manifold concept distance angle exist would require riemannian pseudo riemannian manifold movement neural field surface constrained intrinsic curvature surface without external force field required model interaction extrinsic connectivity geometry modulate afferent connection using expansion equation function defined equation connectivity consists scalar, vector matrix component act neural field, derivative second derivative neural field shown geometry equivalently metric induced second order expansion neural field derivative is, simplest case, given following relation coefficient function given equation simplest geometrical setting dynamical equation given following expression simplifies follows last equation klein gordon field geometry metric defined levi civita connection expansion connection function constrained two dependent term necessary define metric unique torsion free connection levi civita connection fulfilled constraint geometry movement wave defined metric derivative seen equation curvature surface bend wave according equation without constraint would defined metric connection would general also create torsion force surface constraint ie absence external force bending field propagate surface relaxed dynamical theory need elaboration something analyse paper equation give interaction neural field connectivity field ie metric neural field similar analysis section generalise equation motion include interaction connectivity field metric easiest done analysing lagrangian density dynamic stands, density given equation simplest kinetic term could added lagrangian ricci scalar value ricci scalar point surface measure dispersion straight line originating point, equivalently curvature surface ricci scalar defined using metric, shown equation modified lagrangian interaction term connection term ie metric neural field given equation equation also known hilbert action einstein hilbert action spatial dimension time dimension give field equation general relativity spatial dimension interaction neural connectivity field cause non trivial dynamic using dynamical equation derived equation show proposed theory inherently incorporates hebbian non linear hebbian learning section expand study single bi layer several interacting layer obtain theory allows analytical study perturb connectivity around state self connection bi layer show perturbation trivial connectivity give non trivial dynamic connection neural unit give interaction different cortical layer matrix varying cortical surface matrix cortical layer non interacting layer reduces identity matrix modulate matrix using unitary matrix, using fact lagrangian eq invariant unitary transformation note perturbation varies dynamical equation given generalisation equation integrate retarded time expanding equation using step section get dynamical equation writing expansion derivative term show eq invariant transformation give u instead relation similar analysis section introduce connectivity field, gauge field, compensate term equation covariant derivative given equation compensate term relation dynamical field invariant transformation given shown commutation relation equation dynamic neural connectivity field interaction given equation lagrangian density given equation invariant unitary transformation differential operator, parametrised unitary transformation using similar set used section layered cortical surface, generator special unitary modulation transformation covariant derivative defined equation given following expression summing repeated index connectivity field defined expression state explicitly derived gradient field however, like analysis single bi layer dynamics, introduce solenoid field expanding variation connectivity field parameterise variation using complex variable conjugate, instead real parameter equation ie lagrangian density allow self interaction connectivity field simplest term added introduce self interaction connectivity field minimal coupling connectivity field minimal coupling given curvature connection field equation term pre multiplying connectivity field, determined type transformation connectivity field generates, case structure constant lie algebra full lagrangian density given equation highly non linear equation least complex ensure unitary invariance dynamic summary, equation constrain interaction cortical layer validity constraint established experimental cortical recording animal human analysis presented section least partly validated measuring cortical activity using macroelectrodes, eg subdural grid recording animal human allow relatively dense sampling cortical surface within size grid however, section analysis constraint intrinsic connectivity proposed theory dense sampling intra laminar dynamic needed validate theory growing interest intralaminar dynamic advent several new electrode type allowing ultra dense sampling cortical column, eg, neuropixel probe section discus neurobiological substrate variable connectivity field interaction neural field also investigate specific dynamical system described section prediction connectivity dynamic section gave detailed analysis possible interaction field neural connectivity field followed criterion set self tuned dynamical system oscillation generalisation oscillations, interaction neural connectivity field simplest dynamic fulfilling criterion section present neurophysiological framing interacting neural connectivity field cortex fulfilling criterion also discus specific example section cortex assumed multilayered sheet histological basis this, layer seen microscopic analysis cortical surface neural connectivity field however, functional aspect cortical surface might map structural organisation laminar study cortical sheet showed evoked response gradual change lfp signal cortex transversely sampled using multielectrodes, distinct pattern noted throughout cortical sheet electrophysiological evidence would suggest cortex could divided functional layer section given dynamic single layer one bi layer multi layer dynamic corresponding symmetry functional layer unitary group su su symmetry result oscillation single bi layer, define generalisation oscillation su su analyse specifically generalised oscillation neural connectivity field su invariance section first reported study oscillatory activity cortex hz oscillation noted han berger using scalp electrode placed skull existence oscillation shown ubiquitous cortical medium found many specie different location cortex described frequency content range hz hz power content typically decreasing increasing frequency sharp increase gradient around hz modelled using neural field similar described section even though oscillation highly prevalent electrophysiological recording cortical tissue, measuring complex procedure care must taken misinterpret presence absence empirical data detailed description method used characterise oscillatory behaviour cortical recording given well known generation oscillation cortical tissue context specific intricate interaction interneurons, pyramidal cells, chemical electrical synapsis shown generate oscillation hippocampus similar interaction would probably generate oscillation seen cortical structures, eg, gamma oscillation prefrontal cortex complexity cortical substrate oscillation elucidated range study foregrounding importance dendrite dynamic generation lfps origin neural oscillation multifaceted described however, induce phase invariant symmetry dynamics, mathematical substrate oscillation intense research done mammalian visual system starting work revealed cortical activity flavours, hint higher invariant structure visual system, including su invariance constructed neural connectivity field theory different complexity cortical connections, section interaction neural activity connectivity similar hebbian learning often considered rest methyl aspartate channel nmda dynamic mathematical framework hebbian like learning suggested constrained relation similar equation connection gain two connected neural unit given activity following subsection show hebbian non hebbian learning inherent dynamic neural connectivity field section derived neural connectivity field single layered cortex governed equation conserved current associated lagrangian density defined equation assume coupling neural connectivity field, weak allowing u simplify equation using self interaction connectivity field get expression dynamic interaction connectivity field conserved current connectivity field calculated function neural field expression recognised gauss law following solution connectivity field expression indicates, fixed hebbian learning compare equation equation could include higher order term expansion sigmoid function giving u following expression connectivity field expression rate change connection gain follow non linear hebbian dynamic derivation investigated interaction neural field intrinsic connection studied section however, interaction neural field extrinsic connection brings complexity investigate neural connectivity model scalar field varies time connectivity field dynamic given equation expression linking curvature structure cortical sheet lh stress energy tensor neural field rh derived equation stress energy tensor given equation study interaction connectivity field given metric use similar procedure used deriving friedman equation general relativity symmetry two problem similar robertson walker metric dimension given equation expansion component curvature polar coordinate system given equation will, furthermore, simplify stress energy tensor assuming scalar field specific direction first equation given density field second sum density pressure field notation terminology use used derivation friedmann equation also conservation neural field current resulting equation field equation eq fix parameter equation assuming neural field state high mass term simplify equation shown equation last equation defines relation change metric parameterised neural field strength relation indicates non linear hebbian dynamic consider multilayered cortex using similar step analysis single layered cortex although dynamic get intricate due increased complexity invariance structure covariant derivative defined equation one three generator invariance structure su current associated lagrangian density equation given equation increased complexity comparison single layer cortex generator included equation note general commute covariant derivative commutation relation generator given equation together two dimensional representation pauli spin matrix first generator, map cross connection excitatory neural unit layer inhibitory layer second generator, map cross correlation excitatory neural unit layer excitatory neural unit layer last generator map self connection within layer conserved current associated dynamic given equation current interact however, generator create rotation seen current conserved, estimate connectivity field function neural field generator connectivity field defined using connection gain, shown equation change connection gain given function neural field change seen real valued indicate non linear hebbian dynamic dynamical equation given equation using fact looking field temporal variation simplification possible giving u equation equation non linear however, get overall view dynamic assume second term parenthesis constant solve equation solution given equation defined equation last exponential equation expanded simplified equation three generator generate dynamic generalised oscillation involving two interconnected bilayers equation generalised oscillation give modulation oscillating signal cortical layer first generator give oscillation amplitude layer together modification phase second generator give amplitude oscillation layer third phase modification within layer activity type noted recording visual lfps oscillating gamma signal seen move layer stimulation cortex however, neural connectivity field give combination oscillation general case multilayered evoked lfp single stimulus estimated using equation assume layered cortex neural connectivity field local su invariance stimulation given dirac pulse layer calculate solution single layered cortical sheet phase component due connectivity field given assumed much smaller mass term solving equation using laplace transform give expression combining generalised oscillation second generator eq two layered cortex give u solution decaying wave moving layers, equation see figure rotational speed layers, given equation study, develop field model cortical surface described field dynamic primarily governed wave equation, specifically klein gordon equation simplest form system interaction wave based, imposes causality demonstrated section concept retarded potential introduced naturally encapsulate causality, theme introduced section used throughout paper derived wave equation possess several symmetry constrain cortical connectivity, breaking symmetry would dampen wave ubiquity oscillation cortical tissue suggests many wave preserving symmetry remain intact dynamical system, symmetry global local global symmetry seem less likely, would imply uniform connectivity constraint across entire cortical surface instead, local constraints, vary time position, appear plausible idea reformulated gauge field theory, shown section gauge field dynamic connectivity field compensates apparent asymmetry neural field importantly, derived symmetric neural field symmetric neural connectivity field neural connectivity field estimation based three principle assumed cortical dynamic system self tune exhibit oscillation generalized oscillations, interaction neural connectivity fields, neural connectivity field simplest model satisfying first two principle first two principle empirically tested, third computational assumption outlined section oscillatory activity prevalent electrophysiological recording cortex, observed across various cortical regions, hippocampus frontal neocortex neural oscillation deemed essential brain thought tune generate concept supported self organized criticality, dynamic system reach critical state, oscillation generation generalized oscillations, involving interaction cortical layers, challenging demonstrate tissue, multiple study detected high coherence oscillatory signal across laminar structure, along movement current dipoles, similar simulation conducted section additionally, study reported intricate invariance neural field activity within visual cortex, supporting notion dynamic governed invariant structure dynamical interaction neural activity connection gain different neural population first suggested later rephrased neuron fire together wire together interaction neural connectivity field core feature hebbian learning, well established mechanism mammalian non mammalian brain supported discovery long term potentiation ltp depression ltd seen different region mammalian brain including hippocampus, amygdala neocortex also invertebrate hebbian dynamic partly replaced mechanism spike time dependent plasticity stdp sensitivity inter spike duration stdp estimated lie m change within range show opposite effect gain synapse depending temporal order cellular basis dynamics, particularly ltp, ltd, stdp, thought involve postsynaptic change driven slow nmda dynamic however, interaction back propagating action potentials, presynaptic nmda r, voltage gated calcium channel vgccs shown significantly shorten timescale m additional processes, synaptic augmentation direct electrolytic changes, also timeframes range ms, enabling rapid connectivity change moreover, pyramidal cell exhibit linear change gain influence parvalbumin pv cell visual cortex, rapid change reflecting shift connectivity field several biological substrate may contribute fast changing connectivity fields, specific mechanism likely varying cortical area could constitute connectivity field investigated section analysed formalized interaction neural field local symmetries, introducing concept connectivity field complete theory describes interacting neural connectivity field, incorporating hebbian dynamic core feature specific case explored, prediction simulation compared empirical data, providing support general framework neural connectivity field however, research needed validate prediction cortical activity electrophysiological data obtained intra laminar recording dense cortical sampling kf supported funding wellcome centre human neuroimaging ref canada uk artificial intelligence initiative ref e european union horizon framework programme research innovation specific grant agreement human brain project sga vc supported john andersson donation uppsala university author competing interest declare relevant content article conceptualisation gkc writing original draft gkc writing reviewing editing gkc, vc kf author reviewed manuscript writing, reviewing editing submitted manuscript gc, vc kf continuing ",neurons and cognition
"control recurrent neural network using constant input introduction ii representation solution iii controllability neural network step control iv example numerical simulation conclusion supplementary figure instruction reporting error iii case linear activation function iii case nonlinear activation function iii general comment main result iv implementation iv result paper investigates controllability property general class recurrent neural network widely used hypothesis generation theoretical neuroscience, including modeling large scale human brain dynamic study focus control synthesis network using constant piecewise constant inputs, motivated emerging application non invasive neurostimulation transcranial direct current stimulation tdcs neural network model considered continuous hopfield type system nonlinear activation function arbitrary input matrix representing interaction among multiple brain region main contribution formulation solution control synthesis problem nonlinear system provide proper generalization variation constant formula constitutes novel representation system state trajectory representation admits verifiable condition existence constant control input solve short time two point boundary value problem state space formulation admits synthesis input question, realized using modern algorithmic optimization tool case linear activation functions, analysis synthesis reduces verification algebraic condition system matrix simulation result presented illustrate theoretical finding demonstrate efficacy proposed control strategy result offer novel control synthesis important class neural network model may, turn, enable design brain stimulation protocol modulate whole brain activity therapeutic cognitive enhancement application non invasive neurostimulation techniques, transcranial magnetic stimulation tm transcranial electrical stimulation te increasingly used modulate brain activity order achieve desired cognitive outcome conceptualizing brain controlled dynamical system offer powerful framework identifying key brain region network involved specific cognitive function understanding modulated using targeted stimulation regard, strong potential intersection network control theory clinical basic neuroscience instance, success application linear network control theory optimize tms, administered constant input short time interval application target control specific brain region based structural network connectivity derived diffusion spectrum imaging dti similarly, analysis level, linear network control theory employed human neuroimaging studies, leveraging dti parameterized model latter study, author postulated specific brain region may suitable target control based advantageous controllability property relative potential actuation earlier study provided valuable insight using linear network control theory structural connectivity data understand brain dynamics, limited key respect foremost, virtue linearity, assured provide local characterization shown local analysis offer predictive power functional change nonlinear model however, change considered term low dimensional correlation metric brain area network node opposed specific configuration state space contrast, goal enable formal control analysis synthesis induce arbitrary network state presence full nonlinearity, likely essential understanding different brain dynamic mediate cognitive function indeed, need biologically realistic, nonlinear model large scale brain dynamic appreciated precursor application control theory cognitive neuroscience among paradigm regard whole brain mesoscale individualized neurodynamic mindy model previous work demonstrated validity utility mindy model generative tool understanding relationship individualized neural architecture neural dynamic resting state cognitive task context mindy model derived single subject resting state brain imaging data operate macroscale level, node represents distinct brain region given model capture temporal evolution brain activity non linear interaction hundred brain regions, taking form nonlinear dynamical system continuous time hopfield type recurrent neural network intrinsic parameter decay connectivity matrix transfer function parameter directly estimated brain activity time series resulting model predict future brain activity, providing accurate biologically plausible representation large scale brain dynamic mindy model belongs general class hopfield type recurrent neural networks, constitute focus study herein specifically, consider model interconnected neural mass associated regions, described set nonlinear differential equation represent dynamic region state time dynamic th region network evolves satisfies denotes th region state time positive parameter reflecting rate current state th region decays, constant control inputs, represent coupling coefficient control input neurons, real constant weight connection th region th region, activation function th region study neural networks, long topic great interest researcher seeking understand complex dynamical behavior associated control mechanisms, among various property investigated, controllability ability steer network one state another within finite time stand significant theoretical practical implication highlighted earlier, field neuroengineering brain stimulation, particularly transcranial electrical stimulation te direct current stimulation via constant input operative issue determine constant input drive state network desired target state within state space short time horizon figure capability would present promising avenue developing stimulation protocol tailored achieve specific therapeutic outcome altering excitability motor cortex previous work controllability stability property equation considered full actuated configuration id specific case belonging open dense subset current study, input matrix general, assumption activation function relaxed well used literature studying neural network general assumption complexity arising inherent nonlinear dynamic present significant challenges, systematic solution control synthesis problem readily available current literature address challenge, derive novel expression hidden state solution provides analytical leverage determining feasibility control respect constant input furthermore, representation, synthesize constant input steer system initial desired target state within state space short period time derivation, provide piecewise constant input large period time case linear activation functions, reduces simpler algebraic synthesis arbitrary positive time horizon condition matrix decay coefficient synaptic weight numerical example simulation result presented illustrate effectiveness obtained result remainder paper organized follows next section, introduce general notation used throughout paper section ii, present settings, reformulating equation form suitable controllability analysis providing main result related solution representation section iii address control synthesis problem divided two part section iii focus case linear activation functions, section iii extends analysis general nonlinear activation function section iv provides numerical example simulation result illustrate effectiveness proposed approach finally, section v, summarize main result outline potential direction future research technical proof result deferred appendix paper, stand set integers, denote set positive integer denote denote set matrix real coe cients denotes dimensional real column vector space linear map identify, usual way, set squared matrix order real coefficient denote euclidean norm scalar product denote identity matrix id every matrix sup denotes spectral norm symmetric matrix min max denote respectively smaller largest eigenvalue ease notation, diagonal matrix diag simply denoted usual kronecker symbol purpose studying controllability convenient write abstract form follows state vector, initial state, constant control, input matrix, decay matrix, connectivity matrix given firing rate function network drift term given throughout following, unless otherwise stated, assume every activation function non decreasing, globally lypchitz function bounded second derivative, satisfies latter without loss generality since may always take every set new input equation finally, sake simplicity presentation, one also assumes indeed, long always define activation function throughout following, set decay matrix connectivity matrix, appearing recall nonlinear vector field globally lipschitz see, instance, lemma denoting flow follows family one parametric subgroup diff group diffeomorphism note unique solution control namely let denote inverse every then, every hold particular, fixed differentiable every respectively moreover, follows lemma use denote respectively evaluation differential well defined invertible matrix every hold classical theory ordinary differential equation ode invoked justify existence uniqueness solution work, represent system state trajectory form reminiscent linear time invariant system first evoked theorem author knowledge indeed, representation propose particularly noteworthy because, specific case linear activation functions, naturally aligns variation constant formula without requiring nontrivial manipulation perspective, proposed representation approach proper generalization variation constant formula case model form first main result paper solution representation, state follows let every solution expressed every let solution then, least derivable wrt hold using one find solves following integrating yield conversely, holds, composition letting deriving wrt yield id since defines continuous function one deduces given belongs solves case dynamic linear, representation reduces familiar form follows let assume activation function linear every then, every solution expressed case, introduced notation one one get immediately completing proof corollary end section, let u present second representation solution useful later derivation necessary sufficient condition control existence proof similar theorem ii let every solution expressed every corollary ii one easily check activation function linear, naturally coincides indeed, introduced notation one result immediate discus section controllability property step control recalled introduction, ability manipulate neural network step control great interest application, eg, non invasive neurostimulation technique tdcs stimulation constant input modulate brain activity recall step function piecewise constant function defined therefore, particular interest constant function let u introduce following let system step controllable time interval if, exists step function solution satisfies understand controllability nonlinear system addressed constant control, useful first examine corresponding linear model case, linear neural network controllable time interval well known kalman rank condition controllability satisfied invertibility controllability gramian guarantee controllability linear system interval moreover, latter approach allows synthesizing time varying control minimal energy, steer within time see, instance, however, synthesis systematically extend constant control capable achieving objective system controllable, assume existence constant input steer system interval must satisfy however, systematically admit solution shown following result let exist matrix linear system controllable, exists cannot reachable nonzero constant control assume id system controllable matrix kalman condition let exists constant control solution linear system satisfies solves define otherwise, solves now, assume exists eigenvalue diagonalizable assume lie eigenspace corresponding eigenvalue ie, expanding basis eigenvectors give eigenvector eigenvectors eigenvalue then, since implies contradiction therefore, lemma iii suggests controllability linear system necessarily imply existence constant control solves control objective primary goal section synthesize constant control linear without assuming system controllable thus, remainder section assume activation function linear every vector field given let assume either min eigenvalue matrix then, satisfies moreover, least solution, least norm constant control among control moore penrose pseudo inverse matrix full actuated linear control system, ie, full row rank matrix least one solution corollary ii solution constant control given min inequality lemma one deduces matrix id invertible id commute neumann expansion lemma whereas min eigenvalue eigenvalue follows matrix id invertible, id necessary commute cases, well defined let u show equivalent firstly, one obtains immediately conversely, satisfied, one get whenever min min one let replace obtain since eigenvalue last part theorem follows immediately since least one solution solution least norm theorem iii assumption eigenvalue every min prohibits matrix skew symmetric furthermore, case min matrix cannot skew symmetric unless coefficient decay matrix equal otherwise, one get inconsistent finally, case min symmetric, matrix id invertible whenever eigenvalue notice get one solves equation given assuming constant set otherwise, solves control objective equation yield exists eigenvalue make sense whenever min nevertheless, least one solution case, constant control input solves control objective taken one minimal euclidean norm given moore penrose pseudo inverse matrix furthermore, im id solution lemma iii show situation may happen theorem iii suggests controllability property constant control related property differential drift term linear case property flow inverse flow general following main result section, hold assumption ii based solution representation provided theorem ii let assume either min eigenvalue matrix achieved, corresponding control exists, must satisfy letting one matrix defined proposition iii proving theorem iii let u prove following key result let solution expanded hessian matrix letting via double integration parts, one get theorem ii one performs another integration part last integral obtain series well defined lemma matrix contain hessian matrix vector field multiplicative factor integral sign particular, linear, coincides hold since differentiable every satisfies respectively, one find every hand, one get successively id using one get successively id using finally, yield yield let then, matrix id invertible matrix id invertible letting id one find second equality used identity applied follows completes proof since invertible let u present proof theorem iii set lemma one min id invertible neumann expansion lemma whereas case min assumption eigenvalue ensures id invertible cases, id invertible lemma iii matrix introduced well defined letting one get since yield follows solution defined completes proof theorem linear, control synthesis theorem iii naturally coincides provided theorem iii indeed, case, one one also identical exists every hypothesis theorem iii achieved, corresponding control satisfies defined follows lemma satisfies one deduces exit every hold therefore, matrix id invertible, result follows theorem iii important emphasize proposition iii condition sufficiently small sufficient necessary condition ensuring invertibility matrix id instance, activation function linear, matrix remains invertible since, case, following result immediate provides control synthesis step control large time horizon let chosen proposition iii exists solution defined step control steer solution time interval let u illustrate practical effectiveness proposition iii several remark observe control synthesis proposition iii feedback based, incorporates state within integral however, sufficiently small time horizon exists, feedforward control input solving provides first approximation control input solves one follows im least one solution, constant control least norm solution serf first approximation constant control synthesized proposition iii control approximately steer solution time interval provided sufficiently small detail accuracy approximation, refer reader section iv, numerical simulation presented interestingly, control actually solution hence, similar analysis performed remark iii one study eigenvalue lemma iii derive general condition guarantee existence satisfying min full actuated nonlinear control system, ie, full row rank matrix least one solution large time horizon feedforward control approximately solves control objective synthesized step function follows one let small enough one considers defined defined remark iii contrast linear case presented theorem iii one necessary sufficient condition derivation control synthesis solves control objective, theorem iii provides different perspective offer necessary condition constant control steer solution initial state final state time interval section, based second representation solution given theorem ii one seek provide necessary sufficient condition control synthesis linear case following main result section, hold assumption ii based solution representation theorem ii let assume either min eigenvalue matrix then, satisfies matrix defined proposition iii letting one proving theorem iii let u provide following key result proof identical proposition iii let every solution expanded time hessian matrix lemma one prove every one also following key result let matrix id invertible matrix id invertible letting id one find second equality used identity applied follows completes proof since matrix invertible first all, let inequality lemma one min id invertible id id invertible inverse commute neumann expansion lemma whereas case min assumption eigenvalue ensures id invertible inverse necessary commute cases, matrix introduced well defined lemma iii let u show equivalent one hand, follows since yield defined completes proof sufficiency assume solution follows one deduces identifying one get since matrix id invertible, eigenvalue also invertible follows completes proof necessary part and, therefore, theorem linear, control synthesis theorem iii naturally coincides provided theorem iii indeed, case, one one also identical small time horizon, one following result exists every hypothesis theorem iii solution follows remark iii satisfies one deduces exit every hold therefore, matrix id invertible, result follows theorem iii following result provides control synthesis step control large time horizon let chosen proposition iii exists solution defined step control steer solution time interval section iii one following important remark observe control synthesis proposition iii implicit, incorporate state within integral however, sufficiently small time horizon exists, feedforward control input solving provides first approximation control input solves thanks one follows im least one solution, constant control least norm solution serf first approximation constant control synthesized proposition iii control approximately steer solution time interval provided sufficiently small interestingly, control actually solution hence, similar analysis performed remark iii one study eigenvalue lemma iii derive general condition guarantee existence satisfying min detail accuracy approximation, refer reader section iv, numerical simulation presented worth noticing general eq many aspect latter, drift term squared matrix, transfer function bounded odd and, generally, belongs set function restrictive considered albeit smoothness assumption moreover, input matrix also assumed belong open dense subset hypothesis explicitly assume consequently, control synthesis provide applies eq decay matrix generally, control synthesis applied delay free nonlinear drift term lur form spectral norm condition min main result presented theorem iii iii iii make contracting system indeed, straightforward show condition, admits unique equilibrium every input globally exponentially stable contracting inherent dynamic enjoy interesting property widely assumed min condition, contracting assumption generally many recurrent neural network studied therefore, control synthesis may applied many instance many result presented paper hold assumption activation function globally lipschitz continuous instance, solution representation theorem ii ii still valid, case, solution particular, key result given lemma iii iii iii remain valid note globally lipschitz case, solution proposition iii iii theorem iii iii remain valid whenever upper dini derivative bounded everywhere latter crucial since matrix contain dini hessian matrix jacobian multiplicative factor integral sign therefore, series defining converge spectral norm bounded everywhere furthermore, globally lipschitz then, say, cannot used expansion issue longer well defined also dini derivative continuous, making rh function section present numerical simulation bolster theoretical study implemented synthesis linear nonlinear system python using torchdiffeq package script available publication nonlinear systems, presented result instead iii found matrix id iii became ill conditioned large led large numerical error, suffer issue considered case id since extension straightforward, instance, full row rank nonlinear systems, numerically integrated ode using odeint function default parameters, utilizes runge kutta method order dormand prince shampine algorithm accepts new step rms rms rms represents root mean square norm, estimated error current state jacobian flow respect initial state computed automatic differentiation pytorch experiment conducted desktop computer nvidia rtx gpu run time synthesis increased time horizon number feature neuron increased remained within scope several hundred millisecond several second see figure fixed multiple desired trajectory ie, different pair synthesis efficiently parallelized, run time remains almost constant increasing number trajectory one many construct dimensional linear system, randomly sampled entry normal distribution decay matrix set max id max maximum real part eigenvalue desired maximum real part eigenvalue dynamic matrix tried construct stable unstable system respectively construct nonlinear rnn, set id activation function tanh followed imposed random plus low rank structure connectivity matrix matrix sampled normal distribution scaling factor sampled standard normal distribution either sampled normal distribution set shown system monostable first case bistable second case type model appears frequently theoretical neuroscience study evaluate method realistic model fit experimental data, also included set mesoscale individualized neurodynamic mindy model mindy model contained interconnected unit representing brain areas, parameter optimized approximate activation time series area measured functional magnetic resonance imaging fmri unlike rnns, activation function mindy heterogeneous fixed optimized data differs across unit also worth noting origin unstable mindy models, indicating spectral norm condition min met however, found model satisfied eigenvalue condition, enabled synthesis analyzed endpoint error controlled trajectory randomly generated stable unstable linear systems, monostable bistable tanh rnns, randomly selected fitted mindy model pool model model dimensional then, randomly sampled pair standard normal distribution system input synthesis computed using either nonlinear method equation linearized method described nonlinear system linearized system given approximation using following input drive linearized system exact time also tried linearize system origin always fixed point obtained qualitatively similar result result summarized figure full distribution error across trial visualized figure stable linear systems, error remained small unstable linear systems, increased, numerical error computing inverse id became large large eigenvalue eigenvalue close nonlinear systems, linearized method effective small expected contrast, encouragingly, nonlinear method performed well regardless whether system monostable complicated dynamic interestingly, nonlinear method, error even decreased increased worth noting synthesis mindy model accurate even see figure corresponding almost one minute physical time paper, investigated control synthesis problem class nonlinear hopfield type recurrent neural network motivated application neurostimulation using solution representation generalizes duhamel principle, derived constant piecewise constant input drive network desired target state within specified time interval case linear activation functions, demonstrated network controllable arbitrary time horizon certain condition decay connectivity matrix satisfied numerical example validated theoretical result highlighted practical potential proposed approach guiding design transcranial electrical stimulation protocol future work extend method synthesizing time varying control input investigate robustness parameter uncertainty external disturbance indeed, large scale models, highly sensitive external noise disturbance thus, crucial design time varying control input achieves control objective also dynamically adapts external perturbation minimizing energy cost challenge extends beyond control synthesis problem include consideration energetic performance latter question ongoing section contains various complement used previous section first result concern useful property nonlinear vector field nonlinear vector field defined belongs lipschitz continuous moreover, following hold max third order tensor th element given, let since one one deduces showing globally lipschitz continuous one hand, one obviously since assumption follows linear wrt satisfies satisfied hand, one since third order tensor, one therefore, satisfied diagonal structure second partial derivative non zero follows cauchy schwarz inequality max next result concern differential flow vector field assume global lypchitz function every differential flow well defined invertible matrix, hold max vector field globally lipschitz function then, flow well defined invertible denoting inverse, one globally lypchitz function hold fix introduce then, hold follows cauchy schwarz inequality integrating inequality yield every completes proof lemma noted systematically grow one might think examining indeed, one prove replacing expression proceed following every hold one also following result set min hold particular, min let then, one follows matrix dissipative every map non increasing, completing proof furthermore, min one deduces map strictly decreasing, follows following lemma, one show three series proposition iii well defined series proposition iii well defined moreover, spectral norm satisfy max max every one since satisfies lemma follows series defined element one also every hold furthermore, hold lemma let u prove firstly, one since lipschitz lemma therefore, cauchy schwarz inequality which, gronwall lemma, implies follows secondly, hessian matrix solves integral equation using one get which, gronwall lemma, yield since one get completes proof lemma following result also useful main text paper let consider matrix then, hold particular, min hold let introduce every map then, one deduces following integral representation recall taking euclidean norm one get gronwall lemma yield following completes proof lemma continuing ",neurons and cognition
"real time sub milliwatt epilepsy detection implemented spiking neural network edge inference processor introduction related work spiking neural network xylo neuromorphic processor experiment result discussion future work declaration competing interest instruction reporting error architecture functional capability mapping quantization dataset preprocessing network training deploying network performance real time monitoring power consumption performance comparison existing work analyzing electroencephalogram eeg signal detect epileptic seizure status subject present challenge existing technology aimed providing timely efficient diagnosis study, aimed detect interictal ictal period epileptic seizure using spiking neural network snn proposed approach provides online real time preliminary diagnosis epileptic seizure help detect possible pathological condition validate approach, conducted experiment using multiple datasets utilized trained snn identify presence epileptic seizure compared result related study snn model deployed xylo, digital snn neuromorphic processor designed process temporal signal xylo efficiently simulates spiking leaky integrate fire neuron exponential input synapsis xylo much lower energy requirments traditional approach signal processing, making ideal platform developing low power seizure detection system proposed method high test accuracy classifying ictal interictal period time, application average power consumption io power compute power deployed xylo method demonstrates excellent low latency performance tested multiple datasets work provides new solution seizure detection, expected widely used portable wearable device future keywords spiking neural network seizure detection neuromorphic computing measurement electroencephalogram eeg safe non invasive method recording brain signal attaching electrode scalp continuously recorded data reflect electrical activity neuron electrical potential across entire brain surface characteristic pattern eeg signal distinguishable different neural states, brain activity analyzed studied using eeg epilepsy common neurological disorder characterized recurrent episode abnormal brain discharges, behavioral seizures, abnormality sensation, emotion consciousness currently, million epileptic patient worldwide thus, diagnosis treatment epilepsy great social economic value detecting eeg signals, different degree abnormal discharge epileptic patient diagnosed monitored help determine type location epilepsy choose appropriate treatment option epilepsy diagnosis, help monitor treatment effect, adjust treatment plan timely avoid unnecessary drug side effect epilepsy treatment recent years, development computer artificial intelligence ai technologies, eeg detection widely used epilepsy research analyzing mining large amount eeg data, becomes realizable explore pathophysiological characteristic epilepsy develop accurate method diagnosis treatment epilepsy real time eeg monitoring play crucial role medical diagnosis providing essential information health status human body aid doctor timely disease detection vital formulating adjusting treatment plan moreover, real time monitoring biological signal essential scientific research fields, neuroscience researcher investigate relationship specific behavior cognitive task brain activity using eeg signal given time consuming labor intensive nature manual detection, artificial intelligence model urgently required perform real time monitoring accurately identifying abnormal eeg signal artificial neural network anns widely used solving problem signal analysis, widely employed numerous fields, speech processing, computer vision natural language processing however, significant difference traditional anns real biological neural network traditional anns input output real numbers, information transmission human brain form discrete action potential spike spiking neural network snn third generation neural networks, model behavior biological neurons, information transmitted form discrete electrical impulses, known spike snns shown promise accurately identifying pattern time series data, eeg signals, due ability efficiently handle temporal information research focus real time detection eeg signal using low power neuromorphic chip deploy spiking neural network inference chip quickly efficiently detect epileptic signals, trigger appropriate response study utilized chb mit dataset boston child hospital siena scalp eeg dataset university siena wavesense neural network model combined time series analysis delta sigma coding technique detecting identifying epilepsy signal based spike characteristic feasibility accuracy method verified experiment xylo, low power neuromorphic processor signal processing inference experimental result demonstrate ultra low power consumption high accuracy deployed xylo processor, suggesting great promise snn based epilepsy identification method serving new epilepsy diagnostic tool future work enhance efficiency epilepsy diagnosis, reduce power consumption signal acquisition, provide guidance practical application dissemination spiking neural network historically eeg signal identification performed manually, time consuming subjective process, susceptible human error although linear signal processing technique time domain, frequency domain, time frequency analysis become popular fail accurately capture nonlinear characteristic complex electrical activity brain however, development nonlinear eeg data classification methods, artificial neural network become essential tool nonlinear analysis identification eeg signal various neural network model explored, including spatiotemporal convolutional neural network fuzzy function based classifier long short term memory recurrent neural network traditional anns highly dependent feature extraction, quality feature extraction greatly affect classification accuracy therefore, past researcher spent lot time effort developing suitable feature extraction technique contrast, snn model show potential processing complex spatiotemporal pattern without need manual feature extraction early ghosh dastidar developed efficient snn model classification epilepsy detection, us rprop training algorithm achieved classification accuracy adeli developed new multi spike neural network muspinn model new supervised learning algorithm called multi spikeprop, used train muspinn, achieve complex eeg classification problem achieves classification accuracy creation neucube framework kasabov et al, based snn, marked world first development environment building brain inspired artificial intelligence study shown neucube model improve accuracy brain spatiotemporal data classification compared standard machine learning technique karla et al detected interictal high frequency oscillation hfo scalp eeg using spiking neural network presence hfos associated active epilepsy accuracy rate however, noted hfos mandatory requirement epileptic seizures, network implemented neuromorphic chip snn based eeg signal analysis applied clinically, snn network must deployed neuromorphic inference hardware currently, study epilepsy detection based spiking neural network implemented neuromorphic chip spiking neuron mathematical construct inspired dynamic behaviour biological neuron spiking neuron receive input communicate neuron discrete binary event known spike neuron temporally integrate signal small dynamical system representing synapsis neuron membranes, membrane state pass configurable threshold, emit spike communicate connected neuron similar ann, layer spiking neuron connected linear weights, effectively scale strength input received synapsis describe lif leaky integration fire neuron one simplest spiking neuron model state neuron, known membrane potential evolves time depending previous state well input equivalent circuit lif neuron shown figure dynamic state described follows equation equation, mem represents rate voltage change across capacitor, mem represents decay membrane potential due leakage resistance, represents voltage change caused input current overall, equation reflects membrane potential increase neuron receives input current decrease due leakage effect input currentthe working mechanism lif neuron model membrane potential mem exceeds certain threshold, neuron generates spike ie, fire membrane potential reset lower value, simulating discharge process biological neuron figure provides detailed illustration process input current sum weighted input signal filtered set synapses, input weighted independently positive negative, subject synaptic filtering time constant result spatially summed time series input current travel neuron soma, act low pas filter integrates input time, updating internal state variable soma performs integration applies threshold make decision whether spike spike produced, voltage reset value finally, resulting spike transmitted neuron network, network consisting many similar lif neuron called snn snns adopt wide range network architectures, similar standard anns neuron different layer connected synapsis multiple dynamically adjustable weights, transmit signal input layer next layer different topological structure different characteristic feedforward snns composed input layer, one hidden layers, output layer, dense connection passing layer strictly forward manner recurrent snns also common, raising additional complexity regard stability learning algorithm architecture lateral inhibition winner take network used snns reference concept neuroscience work choose feedforward snns, due simplicity ease training xylo application specific integrated circuit asic utilizes digital approach simulating spiking leaky integrate fire neuron exponential input synapsis designed energy efficient highly configurable, ability adjust synaptic membrane time constants, thresholds, bias individual neuron xylo support wide range network architectures, including recurrent networks, residual spiking networks, arbitrary configuration overall logical architecture xylo illustrated figure digital lif hidden neuron independently configurable time constant thresholds, neuron support spike generated per time step xylo also bit input, recurrent, readout weight bit shift decay synaptic membrane potential support one output alias per hidden neuron, one input synapse, one output spike per time step readout layer furthermore, xylo asic allows various clock frequencies, network time step chosen freely overall, xylo flexible powerful architecture suitable many application minimize power consumption improve performance reliability, xylo chip incorporates low power digital circuit design chip feature sparse recurrent weights, maximum target per hidden neuron, reducing energy computation connecting neuron compared dense connections, sparse connection also decrease memory bandwidth requirements, computation time, power consumptionto measure aforementioned power consumption, xylo development kit seamlessly integrates onboard current monitor, allowing user sample real time current data frequency hz via adc analog digital converter kit includes two distinct power track core io core power track cover total power consumption xylo frontend processing core, including ram read write operations, logic circuit operations, event routing, essential process conversely, io power track pertains chip interface power, primarily facilitating serial peripheral interface spi operation xylo chip employ chip training chip inference approach learn data sample chip training refers phase use external computing platform train neural network model phase, model learns feature weight large amount labeled data, often involving backpropagation algorithm optimize network parameter model trained parameter set, convert parameter weights, biases, thresholds, etc format suitable xylo chip may include quantization encoding parameter fit hardware architecture xylo chip inference phase, converted model parameter loaded onto xylo chip xylo chip utilizes digital spiking neural network perform real time event driven inference designed energy efficiency real time processing, xylo chip capable executing complex signal processing task low power consumption deploying snns rockpool structure snn converted computational graph node computational graph contain parameter neuron model, thresholds, biases, etc high level structure dense weight well representing connection individual layer network snn deployed neuromorphic chip, topology neural network need mapped actual physical layout chip enables implementation computational process original snn chip mapping process convert neuron graph form match hardware architecture order build hardware equivalent configuration, neuron ids, weights, input outputs, required information extracted graph addition, performing calculation xylo, necessary quantise floating point parameter trained snn low precision integer value convert weight thresholds, one need find absolute maximum input weight neuron, calculate scaling factor value mapped range threshold scaled scaling factor scaling, weight threshold rounded nearest integer, process quantization first dataset used work scalp electroencephalography database department neurology neurophysiology university siena, italy database contains eeg record patients, including male aged female aged experiment used video eeg monitoring sampling rate hz, electrode arrangement followed standard system record also include electrocardiogram signal according standard international league epilepsy, clinical doctor carefully checked clinical electrophysiological data patient made diagnosis classification epilepsy patient records, eeg signal recorded seizures, recording time ranged minute second dataset used collected boston child hospital contains case involving child intractable epilepsy patient recorded epileptic seizure discontinuing antiepileptic drug undergoing monitoring several day evaluate potential surgical intervention subject database include male females, aged year old case chb chb data female subject, gap year begin describing preprocessing siena scalp eeg dataset dataset, arrangement electrode placed according standard system however, order electrode differs subject addition, researcher also captured ecg signal subject unrelated experiment common electrode subject standard system kept, order electrode uniformly sorted operations, electrode positioning performed original signal once, electrode reference point reselected data referenced according average value signal using function subsequently, influence acquisition environment, power frequency interference acquisition system, need eliminated addition, study shown eeg signal contain valid information hz due need large number repetitive preprocessing operation data study, eeg data patient processed hz band pas filtering, hz notch processing eliminate power frequency interference order verify data processing effect filtering notching, show comparison effect power spectral density map filtering figure independent component analysis ica widely used remove ecg, eye movement, myoelectricity head movement signal eeg, effect remarkable ica method linear transformation based statistical principles, separate data signal linear combination statistically independent non gaussian signal source since collected signal mixed signal spontaneous eeg signal various noises, meet condition use ica algorithm observing effect ica figure b, appropriate independent component selected removed figure refperprocessc, d, e, show independent component information ica four graph show spatial distribution component scalp surface brighter area, greater contribution independent component area energy distribution independent component different frequencies, time series reconstructing trail independent component time trail, total variance waveform component time different number independent component time addition operations, operation resampling baseline correction also involved, meaningful describe chb mit dataset, preprocessing pipeline closely resembles preprocessing pipeline used siena scalp eeg database however, electrode used dataset vary across subject time periods, result inconsistent matrix dimension fed pulse neural network therefore, applied aforementioned preprocessing step electrode channels, exhibited pronounced epilepsy symptom preprocessed signal converted spiking time series using sigma delta encoder encoder convert original signal spike signal partitioning signal amplitude range multiple equidistant interval signal cross one intervals, generates either type spike signal based polarity signal slope point result encoding shown figure highlighted portion indicates epileptic phase since frequency amplitude original signal increase patient seizure, number spike method encoding, information individual channel eeg data transformed two separate time series spiking event two series correspond upward downward trend eeg signal, respectively training process, employed model wavesense model take spike time series data input constructed using network architecture based spiking neural network draw inspiration architecture wavenet model adopts stacked network architecture, stack multiple block together gradually extract higher level feature input signal block consists multiple computational modules, including dilated temporal convolutional layers, gated convolutional layers, pooling layer dilated temporal convolutional layer us multiple synapse projection different time constant achieve dilated temporal convolution gated convolutional layer us gate mechanism regulate information flow, pooling layer used reduce dimensionality feature map computational module used extract temporal feature input signal transform classification regression result wavesense model achieves audio signal processing task converting input signal pulse sequence processing series pulse neural layer model tested multiple datasets achieved excellent performance advantage network include strong generalization ability robustness, suitability various low dimensional signal processing tasks, ability implemented neuromorphic hardware low power consumption high efficiency wavesense model trained using backpropagation algorithm compared deep learning model experiment, set number neuron hidden layer readout number synapsis dilated layer block membrane potential time constant neuron threshold firing spike neuron set figure show overview model architecture, including data processing, spike encoding, stacked network architecture, output layer, convert low dimensional signal category probability distribution experiencing reduced average latency, experiment demonstrate optimal model prediction accuracy achieved segmenting signal second sample consequently, initial dataset undergoes partitioning numerous second trials, accompanied corresponding label trial processed create spike time series data, fed network processed sample randomly split training testing datasets ratio, trained training epochs, learning rate output dimensionality back propagation time bptt used train snn, peak current neuron segment calculated extracting synaptic current output layer prediction made choosing neuron highest peak current, cross entropy loss calculated label obtain optimization technique employed adam noteworthy model intended used streaming mode, necessitates appropriate loss function activity lif neuron may change substantially learning, resulting either lack spike excessive energy consumption neuromorphic implementation maintain sparse activity limit activity neurons, activity regularizer term included loss function final loss function given equation activation loss determined network population size total number excess spike produced response input duration time step excess spike exceed certain threshold summed neuron time bin heaviside step function network performance evaluated using four evaluation criterion accuracy measure overall correctness, sensitivity measure correct positive identification, specificity measure correct negative identification, score considers precision recall accuracy assessment model parameter curve loss change curve training shown figure since result test set better evaluate generalization ability model unseen data, show curve test set training finished, network deployed onto neuromorphic chip xylo process primarily involves mapping quantization technique mentioned earlier afterwards, original data imported xylo processor model prediction result observed visualized parameter additionally, loss value observed iteration process, curve shown figure since result test set better evaluate generalization ability model unseen data, curve test set shown model parameter curve corresponding two data set depicted datasets, following measure obtained accuracy sensitivity specificity score however, worth noting model deployed xylo processor, certain loss accuracy rate relative simulation occur final test two data sets, accuracy reach deep learning, model latency refers time interval model receives input data output result model latency critical real time application application, eeg monitoring epilepsy patients, model must quickly detect epilepsy signal sound alarm short time therefore, evaluating latency snn model experiment help determine usability practicality real time applications, well optimize real time performance model snn deployed xylo processor, measurement delay performed using chb mit dataset time step set seconds, found majority second epileptic signal detected within seconds, median delay second favorable result also achieved using siena scalp dataset delay second visualization finding presented figure order fully showcase method implementation research, publicly released complete source code project github code project related siena scalp eeg database accessed githubcom liruixinxinxin siena work, chb mit scalp eeg database, available githubcom liruixinxinxin epilepsy complete repository include detailed documentation algorithm implementation procedures, aimed facilitating verification replication research result power consumption measurement, enable power recording function setting power record true code actually call function related samna interface, allowing system automatically read voltage current information chip register method, obtains precise data directly hardware, enables researcher monitor evaluate chip energy consumption real time various operating condition real time epilepsy detection experiment conducted power consumption monitoring process measured example, first seizure patient chb mit used show fig data sample reveals patient experienced epileptic seizure second second model issued red alarm seconds, ended alarm second false alarm process may occur, addressed carrying post processing algorithm following analysis model accuracy trade false alarm sensitivity, algorithm trigger cancel alert four consecutive test value either purpose behind selecting specific threshold minimize false alarm retaining high sensitivity epileptic seizure device exhibited consistent average power range w, average consumption digital snn core control logic showed stable power consumption within w, averaging experimental result confirmed power consumption device microwatt range, significantly lower power consumption reported previous research involving traditional chip biosignal detection table display comparison power consumption metric similar work conducting several experiment summarising result table observe overall performance snn model somewhat lower traditional artificial neural network however, project, scale snn model relatively small, enables model better simulate neural system, effectively process time series data, use computing resource efficiently deep learning models, number weight power consumption model usually related weight are, greater complexity computational load model, may require computing resource higher power consumption deployment addition, number weight also affect model storage data transmission requirements, may also lead higher power consumption therefore, using small number weight model, experiment result demonstrate microwatt level power loss achieved currently, many related study power consumption measurement remain theoretical estimation stage contrast, measured visualized power value real time epilepsy detection study may achieve similarly low power consumption, often suffer significantly higher latency study, however, achieved balanced outcome ensuring low power consumption, low latency, high accuracy research, real time epilepsy detection method based snn proposed implemented hardware platform using neuromorphic processor xylo study present several advantage innovation firstly, third generation spiking neural network utilized processing eeg signals, compared ann, snn better simulate behavior neurons, especially process neuron fire spike within certain time window receiving input therefore, snn accurately capture key feature eeg signal perform accurate processing second, instead providing complete buffered input signal neural network, snn analysis eeg signal real time streaming mode working mode improve efficiency low latency method, significantly enhances clinical usability eeg based seizure detection compared buffering input signal, real time streaming mode analysis signal require storing large amount data, avoid wasting storage space delay problem important designing low power implantable brain computer interface related device addition, using real time streaming mode analysis eeg signal help snn better adapt change different real time eeg data streams, thereby improving method adaptability generalization ability finally, network deployed neuromorphic chip xylo instead traditional von neumann architecture chips, longer traditional work simply simulating biological signal snn unlike traditional von neumann architecture, neuromorphic chip natively use neuron synaptic model computation strong parallel computing capability efficiently process large datasets streaming mode addition, mear memory compute neuromorphic processors, integrate memory closely computing resources, consume significantly less energy traditional von neumann architecture result highlight broad prospect application neuromorphic chip field edge machine learning artificial intelligence inference method achieves relatively high accuracy detecting epilepsy, still room improvement specifically, accuracy rate proposed method high traditional ann implementation additionally, generalization ability model improved trade accuracy model simplicity low power proposed network requires smallest amount resource achieving comparable training metric table additionally, table compared processor types, network architectures, technology used, classification methods, chip sizes, power supply voltages, frequencies, sram capacities, measurement method different work seen neuromorphic processor xylo used work lowest power consumption best among similar work proposed solution assist medical practitioner accurately diagnosing patient epilepsy, thereby facilitating timely effective treatment plan enhancing quality life patient furthermore, work pave way development low power wearable device biosignal detection, present novel insight tool neurological disease diagnosis treatment, well clinical medicine field brain science research addition, method extended process bio signals, classification electromyography emg electrocardiography ecg use real time streaming signal analysis provide efficient reliable solution detection treatment muscle heart disease therefore, potential application snn medical domain extensive, hold considerable research practical significance author paper hereby declare financial, personal, relationship could might perceived influence objectivity research result presented paper affirm research work conducted independently unduly influenced funding agencies, commercial entities, organization work financially supported national natural science foundation china hainan provincial natural science foundation china yxqn cxtd science technology special fund hainan province zdyf shfz research foundation one health collaborative innovation center hainan university xtcx jkc continuing ",neurons and cognition
"gradient free supervised learning using spike timing dependent plasticity image recognition introduction network design stdp supervised learning hyperparameter optimization result discussion conclusion instruction reporting error modeling neuron synapsis adaptive threshold network architecture approach supervised learning spiking neural network presented using gradient free method combined spike timing dependent plasticity image recognition proposed network architecture scalable multiple layers, enabling development complex deeper snn model effectiveness method demonstrated application mnist dataset, showing good learning accuracy proposed method provides robust efficient alternative backpropagation based method supervised learning image recognition become ubiquitous, powering application self driving cars, medical image analysis, facial recognition system deep learning approach achieved remarkable success, reliance extensive computation requires powerful hardware, leading high energy consumption hindering deployment device limited resource furthermore, deep learning model often lack biological plausibility, limiting potential understand neural computation develop neuromorphic system mimic brain like processing spiking neural network snns offer bioinspired alternative deep learning image recognition snn neuron communicate discrete spikes, mimicking information processing biological neuron spiking behavior promise lower power consumption potentially better reflects brain processing capability spike timing dependent plasticity stdp learning rule allows snns learn dynamically adjusting synaptic strength based timing pre postsynaptic neuron spiking learning mechanism allows snns extract feature data, make potentially well suited image recognition task various stdp learning rule snn architecture explored unsupervised learning, leveraging stdp, allows snns autonomously acquire selectivity recurring input pattern without external guidance supervised learning snns using backpropagation hindered nondifferentiable nature spiking neuron weight transport problem significant progress made addressing challenges, opportunity remain develop bioplausible solution better capture complexity biological system beyond backpropagation, supervised learning approach include optimizing probability desired output spike implementing competitive dynamic among output neuron represent distinct data class term architectural design, researcher proposed various snn models, including deep fully connected snns, spiking convolutional neural networks, spiking deep belief network model demonstrated performance comparable traditional deep neural network range task paper present supervised learning approach snns integrates gradient free optimization stdp image classification mnist dataset enhance class selectivity, hidden layer neuron assigned unique group corresponds specific digit class synaptic weight updated target class aligns neuron group, promoting specialization unique feature proposed approach absence inhibitory synaptic connection neuron training stage allows neuron fully explore input space, fostering development class preference lateral inhibition, introduced validation testing, enables competitive dynamic among neurons, leading clean classification based firing rate network architecture scalable, supporting construction deep snn model complex task experimental result mnist demonstrate efficacy proposed method achieving good classification accuracy snn simulation performed using brian simulator hpc resource provided purdue rosen center advanced computing remaining section paper organized follows section present neuron synapse models, well network architecture section detail implementation supervision stdp learning rule section describes hyperparameter tuning process section evaluates performance network mnist dataset section concludes paper leaky integrate fire model chosen computational framework simulate neuronal dynamic neuron simplified electrical circuits, incorporating capacitance resistance, essential feature captured without undue complexity membrane potential evolves time according following differential equation rest represents resting membrane potential, exc inh denote equilibrium potential excitatory inhibitory synapses, respectively, correspond conductance excitatory inhibitory synapses, signifies time constant neuron neuron membrane potential exceeds threshold, generates action potential subsequently reset potential reset threshold, initially set thres dynamically adjusted based neuron firing rate subsequent refractory period, neuron spike synaptic strength modulated change conductance presynaptic spike occurs synapse, synapsis increase conductance synaptic weight however, neuron active, conductance decay exponentially dynamic mathematically described represent time constant excitatory inhibitory conductance postsynaptic neuron, respectively table present fixed parameter neuron synapse model parameter remain constant neuron synapsis different layer network parameters, determined optimization process described sect balanced neuronal activation essential optimal network performance prevent individual neuron unduly dominating network responses, adaptive membrane threshold mechanism, inspired work implemented adaptive threshold initialized increase small value upon neuronal firing small incremental change calculated prevents threshold neuron reaching high stop firing maximum potential increase upon neuronal firing, represents point start decrease significantly one, regulates rate decrease formulation prevents excessive threshold elevation, thus maintaining neuronal responsiveness neuron active, decrease exponentially function time time constant described network architecture hierarchical feedforward structure composed input layer hidden layers, illustrated figure input layer comprises neurons, representing pixel mnist image neuron encode image information poisson distributed spike trains, firing rate directly proportional pixel intensity hidden layer divided ten group neurons, group dedicated recognizing specific class digit hidden layer unit, depicted figure consists ten neurons, one digit group neuron within unit share identical spatial coordinate x, positioned uniformly input layer study, fully connected architecture employed, first hidden layer fully connected input layer, subsequent hidden layer maintain full connectivity input layer preceding layer spatial coordinate assigned neuron offer potential future enhancements, localized connectivity layer enhance digit selectivity inter digit competition testing validation, inhibitory connection established neuron belonging different digit group firing neuron one group suppresses activity neuron groups, promoting focused digit representation facilitate development digit preference neuron training, inhibitory connection absent training phase image classification determined group exhibiting highest firing rate last hidden layer excitatory synaptic weight adjusted using triplet stdp learning rule known superior performance demonstrated according learning rule, presynaptic spike time introduces weight change conversely, postsynaptic spike time result weight change here, presynaptic event detectors, postsynaptic detectors, biological counterpart quantify weight change pre post pair post pre pair, respectively represent amplitude triplet term potentiation depression simplicity, minimal model intended fit visual cortex data, used study supervison incorporated modifying eq follows postsynaptic neuron group index match stimulus label, otherwise variable prevents premature weight saturation, defined determining oneset significant decrease start one, regulates rate decrease promote equitable participation neuron network dynamic average weight postsynaptic neuron normalized maximum possible weight normalization achieved scaling synaptic weight according following formula sum synaptic weight postsynaptic neuron number presynaptic neuron connected hyperparameter control degree normalization weight procedure allows synaptic weight ample space grow large sample stimulus performed processing stimulus hyperparameter optimization conducted using hyperopt algorithm within ray framework stimulus presented network second input layer converted image poisson spike trains, starting mean firing rate proportional original mnist image intensity ensure sufficient spiking activity, firing rate adaptively increased increment intensity spike count hidden layer reached minimum five, full intensity attained preliminary experiment indicates image recognition accuracy relatively insensitive intensity modulation table outline hyperparameter search range different network configuration base network consists single hidden layer one hidden layer unit, hidden layer network comprises two hidden layer hyperparameter optimization performed subset mnist image single epoch validated subset mnist image optimization multilayer network, hyperparameters except randomly selected set validated good performance base network optimization parameter influenced size preceding hidden layers, hidden layer may depend hidden layer input layer study, size hidden layer multilayer network fixed neuron optimized thus tailored structure multiple hyperparameter set yielded comparable validation performance condition table present one set optimal hyperparameters identified study acknowledged hyperparameter better performance may attainable access greater computational resource performance two different network training method evaluated using testing sample direct approach involves training network fixed number training sample testing disadvantage method training time proportional number excitatory neuron hidden layer number neuron increases, training process become slow overcome limitation, leverage fact smallest network model, referred base network, consists neurons, responsible identifying single mnist label, lateral excitatory connection training, larger network with, example, one hidden layer containing hidden neurons, decomposed base networks, processing different subset training sample via single computing process worker testing, base network combined, applying inhibitory connection within base network among neuron belonging different group base network read respective training synaptic weight neuron threshold approach significantly reduces training time, worker process train smaller network furthermore, small network us unique set hyperparameters validated good performance optimization stage, resulting combined network diverse set hyperparameters approach termed parallel training diversity figure present testing accuracy result network trained using parallel training diversity direct training approach data point different color represent result different network size training approach spike count neuron within neuron group last hidden layer summed, group maximum spike count treated prediction network stimuli, one neuron group maximum spike count case, one group match input label, counted correct identification, albeit ambiguity left panel figure illustrates dependence overall testing accuracy size training sample per worker, including identified ambiguity right panel display fraction correctly identified stimulus ambiguity, ie, test accuracy ambiguity result labeled come network one hidden layer containing excitatory neurons, trained using parallel training diversity result labeled ii network two hidden layers, containing excitatory neurons, also trained using parallel training diversity cases, worker used training stage result network various size trained using direct training approach using direct approach, overall accuracy go size training sample grows increasing number excitatory neuron hidden layer improve overall test accuracy reduce ambiguity fold smaller training samples, parallel training diversity significantly outperforms direct approach training set size increases, accuracy converge however, test accuracy ambiguity using parallel training diversity significantly lower network configuration compared single hidden layer network adding second hidden layer specified configuration ii enhance performance suggests information processed first hidden layer weak influence decision making second layer configurations, increasing number neuron first hidden layer, introducing lateral connections, localized feedforward synaptic connections, may improve network performance, demonstrated artificial neuron network figure illustrates spike count neuron group response specific label test sample, obtained parallel training diversity number training sample per worker network comprises neuron single hidden layer, worker denoted figure setup, training stimulus exposed network average due limited number training samples, synaptic weight fully specialized, leading similar response given stimulus across neuron group notably, even small differences, network achieves testing accuracy low ambiguity contrast, figure display spike count distribution significantly larger training sample size per worker extensive training set, synaptic weight different neuron group become specialized consequently, spike rate correct neuron group substantially higher groups, indicating improved discrimination figure illustrates testing accuracy function input label various number excitatory neuron hidden layer left panel display overall accuracy, right panel show accuracy ambiguity number training sample per worker color coding consistent figure notably, number neuron hidden layer minimal impact overall test accuracy significantly affect test accuracy ambiguity instance, test accuracy ambiguity network neuron trained directly time lower network neuron neurons, network trained parallel training diversity show accuracy ambiguity approximately time lower highest overall accuracy achieved input label also lowest ambiguity contrast, input label yield lowest overall testing accuracy ambiguity increase label label decrease label subsequently increase label figure display distribution incorrect prediction various input label using hidden layer network neuron neuron per worker trained parallel training diversity worker received training stimuli, test set consisted sample several notable pattern emerge instance, network frequently confuses label well label additionally, label often mispredicted label label frequently misclassified label label often mispredicted label study present supervised learning approach spiking neural network combine gradient free supervised learning method spike timing dependent plasticity image recognition proposed architecture scalable multiple layers, enabling development complex deeper snn model efficacy approach demonstrated mnist dataset, achieving overall learning accuracy approximately training stimulus larger training sets, exhibiting minimal ambiguity additionally, parallel training testing method proposed, leveraging small network per computing process, significantly reduces training time increase testing accuracy small training sample future refinements, increasing number neuron first hidden layer, introducing excitatory lateral connections, confining region feedforward synaptic connections, may improve network performance author would like express sincere gratitude mark linvill, chris orr, department physic astronomy facilitating access hpc resource purdue rosen center advanced computing rcac thanks also extended research service team rcac timely support moreover, author would like thank marcel stimberg brian team invaluable discussion assistance continuing ",neurons and cognition
"modeling dynamic neural activity combining naturalistic video stimulus stimulus independent latent factor introduction model experiment discussion appendix related work overview appendix behavior analysis appendix training marginalization appendix model architecture hyperparmeters setting appendix forecasting model instruction  theoremsep jmlrvolume firstpageno jmlryear jmlrworkshopsymmetry geometry neural representation understanding brain process dynamic natural stimulus remains fundamental challenge neuroscience current dynamic neural encoding model either take stimulus input ignore shared variability neural responses, model variability deriving latent embeddings neural response behavior ignoring visual input address gap, propose probabilistic model incorporates video input along stimulus independent latent factor capture variability neuronal responses, predicting joint distribution entire population training testing model mouse neuronal responses, found outperforms video model term log likelihood achieves improvement conditioned response neuron furthermore, find learned latent factor strongly correlate mouse behavior, although model trained without behavior data neural activity influenced sensory stimulus internal, stimulus independent fluctuation stringer et al, niell stryker, reimer et al, often ignored stimulus based model existing approach neural response prediction largely fall three main category deterministic model predict neural activity visual stimuli, neglect uncertainty variability response wang et al, turishcheva et al, sinz et al, vystr ilov et al, fling et al, probabilistic model derive latent embeddings neuronal response predict behavior account external sensory input schneider et al, gokcen et al, sussillo et al, yu et al, model combine task input subset neural activity predict response conjugate neuron zhou wei, kim et al, best knowledge, work exist model correlated variability large neuronal populations, also take visual stimulus input bashiri et al, specifically, none designed dynamic video based stimulus flow based approach bashiri et al computationally expensive modeling temporal dependency latent variable paper address gap proposing predictive model dynamic neural activity function naturalistic video stimulus temporally varying latent variable capture correlated, stimulus independent neural variability demonstrate model improves predictive accuracy mouse response implicitly learns latent variable correlated behavior, provided model training model predicts time varying neuronal response photon calcium trace video stimulus number neurons, number time points, width height one frame prediction additionally depends dynamic, stimulus independent latent factor latent dimension fig combining idea bashiri et al zhu et al model distribution neuronal response conditioned stimulus latent factor zero inflated gamma zig distribution wei et al, mixture separation overlap, shape parameter per neuron nonzero response probability, scale parameter neuron time step function video stimulus, zig model parameter latent factor fitted per neuron model using typical core readout architecture fig core extract feature video input, readout map relevant feature core output individual neuron fling et al turishcheva et al vystr ilov et al sinz et al wang et al additionally introduce one layer recurrent neural network gated recurrent unit capture correlation latents across time stimulus independent latent factor modeled prior distribution standard gaussian independently across time model approximate posterior fig gaussian mean function response encoder parameter independent variance fit model maximizing evidence lower bound see appendix baseline model additionally, train video zig model without latent map video stimulus dynamic response non probabilistic model trained poisson loss turishcheva et al model share hyperparameters wherever possible fig since aim use correlation latent variable behavioral variable stringer et al, bashiri et al, external validation model, excluded behavioral data training model contrast previous work sinz et al, wang et al, trained evaluated model data five mouse sensorium competition turishcheva et al, response excitatory neuron layer primary visual cortex per mouse recorded hz upsampled hz, head fixed mouse viewed naturalistic gray scale video hz video input model shape behavioral variable locomotion speed, pupil dilation center position also recorded resampled hz predictive performance come predicting neuronal response conditioned video stimulus, poisson baseline best correlation performance whereas latent model highest log likelihood bit per time neuron showing increased capability latent model capturing full response distribution computed performance latent model marginalizing latent variable via monte carlo sampling appendix since neuronal response continuous poisson distribution discrete value only, cannot evaluate log likelihood poisson model slightly lower correlation performance likelihood based zig model could due trade modelling distribution good likelihood modelling conditional mean good correlation lurz et al, latent behavior correlation compute correlation latents behavioral variables, used canonical correlation analysis cca find best linear combination latent variable maximal correlation chosen behavioral variable although model seen behavioral data training learned latents show strong correlation behavioral data fig accordance previous work stringer et al, bashiri et al, niell stryker, analysis detail appendix neuron conditioning assessed predictive correlation model providing half response input, latent model achieving correlation outperforming poisson baseline indicates latent model learned capture relevant information neuronal response additionally, analyzed neuron response time using data untile time latent model outperformed baselines, indicating capacity accurately forecasting neuron response forecasting trained model appendix notably increase forecasting performance compared default latent model work showed adding latent factor video encoding model enables prediction joint dynamic response distribution capture biological variable implicitly learning correlation latent factor behavior future work could investigate modeling latent state further, experimenting number neuron needed, optimal dimensionality distributional assumption generative model, potentially learning latent variable temporal dependency thank dominik becker, michaela vystr ilov lucas mohrhagen, florain seifert, alexander ecker technical help insightful discussion computing time made available high performance computer hlrn iv gwdg nhr center nhr ttingen center jointly supported federal ministry education research state government participating nhr wwwnhr vereinde unsere partner fhs acknowledges support german research foundation dfg sfb robust vision inference principle neural mechanism project id sfb mathematics experiment project id project received funding european research council erc european union horizon europe research innovation programme grant agreement give overview related work, either predicts neuron response given natural stimuli, us latent representation encoding neuron response take behavior animal account tab example booktabs literature work neural activity stimulus learned latent behavior datasets schneider et al dynamic input yes, probabilistic input rats, mice, monkey electro physiology neuron wang et al turishcheva et al sinz et al dynamic output video input mice, p, passive neuron neuron kim et al dynamic output audio yes, probabilistic synthetic rats, audio decision making neuron antoniades et al azabou et al dynamic output video yes, probabilistic output mice, p, passive neuron monkey neuron gokcen et al sussillo et al dynamic input yes, probabilistic macaque neuron synthetic neuron zhou wei wang et al bjerke et al jensen et al dynamic output yes, probabilistic task input monkey, reaching task rat, running neuron monkey, rat task neuron mouse,rats neuron macaque, reaching task neuron geenjaar et al dynamic output yes not, probabilistic fmri seeliger et al dynamic output video fmri bashiri et al static output image yes, probabilistic output mouse lm, p,passive neuron pupil dilation treadmill speed mouse performed one cca analysis cca analysis done fold cross validation split recording time ratio repeated five different seed correlation computed cca combination test time, cca weight latent variable two selected video mouse plotted normalized pupil dilation treadmill speed corresponding normalized cca combination latent whole video time, correspond time point training order train model, maximize zig via evidence lower bound elbo via variational inference kingma welling, blei et al, represents expected value kl kullback leibler divergence marginalization marginalized performance latent model obtained calculating last equality obtained, since independent fig last integral approximated via monte carlo sampling found sample sufficient convergence video processing part consists factorized cnn block followed gaussian readout fling et al convolutional layer consists factorized convolution across spatial temporal dimension followed batch normalization layer elu activation function use variational autoencoding approach latent representation dropout layer applied neuron response fed encoder prevents model learning correlation specific neuron thereby encouraging learning global latent representation encoder applies linear layer reducing dimensionality neuron response ranging depending mouse part sensorium dataset turishcheva et al, time step linear layer applied independently linear layer followed layer normalization elu activation function individual linear layer trained mouse output processed one layer recurrent neural network gated recurrent unit producing mean approximate posterior learnable model parameter encoder resulting latent variable decoded another one layer gru, denoted grus shared among mouse combined output video encoding part computing parameter probability log graphical illustration see searched various hyperparameters table using optuna akiba et al, forecasting, consider latent representation markov process developing smoothly time fig thus, trained forecasting model, adapted variational autoencoder architecture autoregressive model shifting objective reconstructing original data point predicting subsequent time point wang et al hence, minimize again, zig likelihood response time given latent video parameter video encoding model fig approximate posterior future latent time given response continuing ",neurons and cognition
"role spike timing dependent plasticity random input neurodegenerative disease neuromorphic system introduction model description numerical result conclusion instruction reporting error keeping track pre postsynaptic spike implementation stdp leaky integrate fire neuron connected synapsis show stdp effect input correlation stdp neuromorphic system application neuronal oscillation related symptom parkinson disease random input could affect oscillation brain state translate collective activity neuron interconnected via synaptic connection paper, study coupled effect channel synaptic dynamic stochastic influence, together spike timing dependent plasticity stdp healthy brain cell application parkinson disease pd particular, investigate effect random input input correlation subthalamic nucleus stn cell membrane potential model numerical result show random input strongly affect spiking activity stn neuron case healthy cell also case pd cell presence db treatment stdp increase interspike interval isi regularity spike train output neuron however, existence random refractory period random input current system may substantially influence increased irregularity spike train output neuron furthermore, presence stochastic influence together spike timing dependent plasticity could increase correlation neuron effect would potentially contribute management pd symptom one common neurodegenerative disorder aging parkinson disease pd progressive neurological degenerative disorder characterized severe loss dopaminergic neuron substantia nigra par compacta pd characterized cardinal motor symptom including slowness movement bradykinesia akinesia, rigidity, tremor rest neuronal oscillation symptom parkinson disease pd closely connected many different treatment focus subthalamic nucleus stn improve motor symptoms, instance, ablation surgery stn fiber connection deep brain stimulation db stn recently become effective therapy pd db impressive method due fact pd, characterized inadequacy chemical substance brain, also successfully treated passage electrical current without concomitant supply biological chemical reaction factor general, biological neuron brain transmit information generating spike neuron connected synapsis process store information better understand brain activities, need know synapsis work general, chemical synapsis common brain, synapsis physically join neuron get closer real scenario brain activities, one need account model synapse synaptic strength change function relative timing ie, time difference spike presynaptic postsynaptic neurons, respectively change synaptic weight known spike timing dependent plasticity stdp many model proposed analyze dynamic synaptic coupling human brain neurodegenerative disorder therapeutic target disease model stdp mediated dopamine role pd pathophysiology reported first time, result provided demonstrated neuronal oscillation predictive db outcome db therapy noisy cortex irresponsive subthalamus improve parkinsonian locomotor activity reported author investigated coupled effect channel synaptic dynamic stochastic modelling healthy parkinson disease affected brain author found estdp istdp restrict balance excitatory inhibitory balanced neuronal network play fundamental role maintaining network stability synchronization furthermore, result would potentially also contribute guidance treatment research neurodegenerative disease moreover, result reported show stdp support multiplexing rhythmic information additionally, stdp could demonstrate retain functionality despite continuous remodeling synaptic weight computational aspect sensory information processing span individual cell network level physical property single small network nerve cell enable process store information understanding cellular dendritic mechanism could contribute processing sensory information single neuron also greatly increased however, still little known biophysical property single neuron actually used implement specific computation two type neuronal computation thought fundamental processing information within nervous system multiplication independent signal invariance neuronal response evidence behaviorally induced form synaptic plasticity would encourage development fine scale structured input pattern binding feature within single neuron presented feedforward inhibition traditionally thought sharpen response temporal tuning feedforward excitation onto principal neuron also could also convey information used single neuron implement dendritic computation sensory stimulus variable discussion discrimination broad spatial statistic synaptic input within dendrite single neuron reported using description based single dual dendritic recording vivo together computational modelling, membrane impedance collision detection neuron grasshopper schistocerca americana characterized model active dendritic integration mixed neocortical network representation adaptive sensing behavior single neuron considered real scenario neuronal models, random fluctuation could affect spiking activity neuron particular, stochastic factor arise sensory fluctuations, brainstem discharge thermal energy random fluctuation microscopic level, brownian motion ion random fluctuation could cause burst discharge brain system brain rhythm burst enhanced multiplicative noise author investigated effect noise gamma oscillation model neuronal network different reversal potential specifically, presence noise neuronal system also solution information processing author shown detectability weak signal nonlinear system known stochastic resonance enhanced random noise furthermore, also pointed phase based simplification stn neuron accurately predict response temporally complex train input even perturbation timing large enough obscure oscillatory nature neuron firing question variation unavoidable effect generating spike sensory synaptic process neural noise important part signal transmitted neuron discussed general, occurrence synchronous event emerge variety mechanism physical system neuronal networks, signal evoked intrinsic noise spike correlation originate intricate connectivity neuronal network cortical neuron receives input approximately neuron sends signal via synapsis others neuronal network, spiking cross correlation activity two neuron emerge direct synaptic connection shared presynaptic partner neuron highly interconnected, almost unavoidable two neuron network share input multiple synaptic interaction structure potentially give rise pairwise correlations, particular functional form spike correlation function may unique signature interneuronal interaction author shown pair neuron receiving correlated input also exhibit correlation arising precise spike time synchronization using simulation experiment rat hippocampal neuron role input correlation shaping variability noise correlation evoked activity neocortex investigated effect interpopulation stdp synchronized rhythm neuronal network inhibitory excitatory population discussed author consider synchronization oscillation behavior excitatory inhibitory population stdp paper built upon extend recent work author considered static synapsis whose weight fixed dynamic synapsis whose synaptic strength dependent recent spike history short term plasticity however, real brain models, strength connection neuron brain based relative timing particular neuron output input action potential drawing field pd study effect natural random factor biological system dynamics, develop investigate model coupled effect channel synaptic dynamic using stochastic modelling healthy brain cell application pd particular, consider cell membrane potential model stn part human brain analysis focus considering langevin stochastic equation numerical setting cell membrane potential random input input correlation influence stdp discus role stdp neuromorphic system next, provide numerical example discus effect random input time evolution stn cell membrane potential well spiking activity stn neuron numerical result indicate stdp enhances regularity interspike interval isi spike train output neuron however, presence random refractory period, along random input currents, may significantly increase irregularity spike train additionally, combination stochastic influence stdp could enhance correlation among neuron effect may contribute management parkinson disease symptom stdp fundamental mechanism brain modifies synaptic strength neuron based coincidence pre postsynaptic spike conventional asymmetric form stdp, temporal order spike critical, presynaptic spike precedes postsynaptic spike ie, pre post pairing stdp rule lead long term potentiation ltp synapse pre postsynaptic neurons, whereas long term depression ltd induced reverse scenario ie, post pre pairing although stdp local mechanism merely depends pre postsynaptic spike timings, determine global connectivity pattern emerging recurrent neuronal network focus building model synapse synaptic strength change function relative timing ie, time difference spike presynaptic postsynaptic neurons, respectively change synaptic weight known stdp aim paper build model synapse show stdp study correlation input spike train influence distribution synaptic weight model presynaptic input poisson type spike train postsynaptic neuron modeled hh neuron assume single postsynaptic neuron driven presynaptic neuron is, synapses, study weight depend statistic input spike train timing respect spike postsynaptic neuron phenomenology stdp generally described biphasic exponentially decaying function is, instantaneous change weight given denotes change synaptic weight, determine maximum amount synaptic modification occurs timing difference presynaptic postsynaptic spike close zero represent range pre postsynaptic interspike interval synaptic strengthening weakening occurs thus, mean postsynaptic neuron spike presynaptic neuron model capture phenomenon repeated occurrence presynaptic spike within millisecond postsynaptic action potential lead long term potentiation ltp synapse, whereas repeated occurrence presynaptic spike postsynaptic one lead long term depression ltd synapse latency presynaptic postsynaptic spike defined pre post timing presynaptic postsynaptic spikes, respectively since neuron receive numerous presynaptic spike inputs, order implement stdp taking account different synapses, first keep track pre postsynaptic spike time throughout simulation convenient way define following equation postsynaptic neuron whenever postsynaptic neuron spikes, way track number postsynaptic spike timescale similarly, presynaptic neuron, define whenever spike presynaptic neuron, variable similar equation synaptic conductances, ie, except used keep track pre postsynaptic spike time much longer timescale note that, always negative, always positive probably already guess used induce ltd induce ltp updated respectively important note depends presynaptic spike time know presynaptic spike times, generated simulating postsynaptic neuron corresponding stdp weight change value peak synaptic conductance based presynaptic postsynaptic timing, thus using variable synapse peak synaptic conductance may vary max modified depending presynaptic postsynaptic timing th presynaptic neuron elicits spike, corresponding peak conductance updated according following equation note that, track time since last postsynaptic potential always negative hence, postsynaptic neuron spike shortly presynaptic neuron, equation show peak conductance decrease postsynaptic neuron spikes, peak conductance synapse updated according note that, track time since last spike th pre synaptic neuron always positive thus, equation given show presynaptic neuron spike postsynaptic neuron, peak conductance increase connect presynaptic neuron single postsynaptic neuron need simulate dynamic presynaptic neuron concerned spike time so, generate poisson type spike here, assume input excitatory need simulate dynamic postsynaptic neuron know spike time model postsynaptic neuron hodgkin huxley hh system modelling stn cell membrane potential furthermore, motivated consider modified hh system modelling stn cell membrane potential particular, first choose stn healthy cell, switch pd cell, study effect random input stn cell membrane potential synaptic conductance dynamic biological system brain networks, instead physically joined neurons, spike presynaptic cell cause release chemical, neurotransmitter neurotransmitter released synaptic vesicle small space neuron called synaptic cleft follows, investigate chemical synaptic transmission study excitation inhibition affect pattern neuron spiking output hh model section, consider hh model synaptic conductance dynamic particular, neuron receive myriad excitatory inhibitory synaptic input dendrite better understand mechanism synaptic conductance dynamics, use description poissonian train investigate dynamic random excitatory inhibitory input neuron consider transmitter activated ion channel explicitly time dependent conductivity syn conductance transient defined following equation see, eg, syn synaptic weight denotes maximum conductance elicited incoming spike, syn synaptic time constant, dirac delta function note summation run spike received neuron time following formula converting conductance change current using ohm law membrane potential, syn represents direction current flow excitatory inhibitory nature synapse total synaptic input current syn combination excitatory inhibitory input assume total excitatory inhibitory conductance received time corresponding reversal potential respectively then, total synaptic current defined following equation see, eg, author used quantity gpe,stn stn model however, know stn db generate excitatory inhibitory postsynaptic potential stn neuron current consideration, instead using current gpe,stn consider current stn,dbs let u define following synaptic dynamic stn cell membrane potential described following model based app external input current, membrane capacitance additionally, th denotes membrane potential threshold fire action potential model, assume spike take place whenever cross th stn membrane potential case, spike recorded reset reset value hence, reset condition summarized reset th quantity ahp represents calcium activated potassium current spike hyperpolarization stn concentration intracellular ca governed following calcium balance equation scaling constant, ca m given time constant see, eg, furthermore, consider external random additive noise input current follows app app app zero gaussian white noise app app using description random input current system, first equation considered following langevin stochastic equation see, eg, therefore, system rewritten furthermore, consider following gating variable dynamic see, eg, initial data use system define initial condition described table model mentioned above, use simplest input spike train poisson process stochastic process interest provides suitable approximation stochastic neuronal firing input spike carried quantity equation input spike given every input spike arrives independently spike process described follows designing spike generator spike train, define probability firing spike within short interval see, eg spike representing instantaneous excitatory inhibitory firing rates, respectively then, poisson spike train generated first subdividing time interval group short sub interval small time step model, use m define random variable rand uniform distribution range time step finally, compare random variable rand probability firing spike, read using model also investigate effect random refractory period consider random refractory period ref ref ref ref standard normal distribution, ref ref general, information stimulating activity neuron provided irregularity spike train time interval adjacent spike called isi coefficient variation cv isi cell membrane potential multiple input bring useful information output decoded neuron follows, demonstrate increase value ref irregularity spike train increase see also spike irregularity spike train described via coefficient variation inter spike interval see, eg, follows isi standard deviation isi mean isi individual neuron next section, let u consider output firing rate function gaussian white noise mean direct current value, namely, input output transfer function neuron model, choose parameter set following table current gating variable gating variable parameter n mv na exp exp na exp na mv exp n exp mv exp exp n exp exp mv exp exp ca n exp ca mv ca ca ahp n ahp mv pa since parameter also used stn cell membrane potential experiments, take model validation moreover, consideration, use parameter table also following parameter th mv reset mv mv nf m m n n spike trains, spike train here, represent number excitatory inhibitory presynaptic spike trains, respectively mathematically, developed model evolutionary system combine stochastic differential equation ordinary differential equation sdes ode stochastic membrane potential equation coupled activation inactivation ion channel equations, well calcium activated potassium current equation system considered modified hh system correlation synchrony neuronal activity described readout brain activity here, concerned spiking activity neuron simplest way, correlation synchrony refers coincident spiking neurons, ie, two neuron spike together, firing synchrony correlated neuron synchronous instantaneous activity, ie, spike together probability however, also possible neuron spiking time correlated spike another neuron delay time delayed synchrony origin synchronous neuronal activity common inputs, ie, two neuron receiving input source degree correlation shared input proportional output correlation pooling source neuron share input neuron receiving input neuron correlated neuron connected uni bi directionally give rise time delayed synchrony neuron could also connected via gap junction neuron similar parameter initial condition neuron spike together, stronger impact downstream neuron synapsis brain sensitive temporal correlation ie, delay pre postsynaptic activity, this, turn, lead formation functional neuronal network basis unsupervised learning synchrony implies reduction dimensionality system addition, correlations, many cases, impair decoding neuronal activity simple model study emergence correlation inject common input pair neuron measure output correlation function fraction common input here, going investigate transfer correlation computing correlation coefficient spike train recorded two unconnected hh neurons, received correlated input input current hh neuron temporal average current gaussian white noise independent neuron, common neuron variable control fraction common independent input show variance total input sample correlation coefficient two input currents, defined sample covariance divided square root sample variance multiplied square root sample variance consider following equation sample mean, time bin, length mean current time note equation accurate sample covariance variance additionally divided dropped term cancel sample correlation coefficient formula many current potential applications, stdp often thought unsupervised brain like learning mechanism spiking neural network snns that, among things, attracted significant attention neuromorphic hardware community ability mimic biological learning process make stdp highly relevant various applications, including pattern recognition sensory processing, real time pattern recognition, stabilized supervised stdp, synchronization neural network many model proposed investigate role stdp mechanism across application example, human brain recognized complex entity known universe microcircuit level, neuronal cell organized layer various connectivity motif information processing mechanism level remain fully understood, investigating motif particularly stdp essential gaining insight biological learning mechanism emergence intelligence stdp unsupervised brain like learning rule implemented many snns neuromorphic chip however, significant performance gap exists ideal model simulation neuromorphic implementation stdp implemented snns neuromorphic chips, serving unsupervised learning rule crucial mimicking brain like information processing application include noisy spatiotemporal spike pattern detection, particularly effective even low resolution synaptic efficacy neuromorphic implementation capability enhances performance various computational tasks, making stdp relevant advancing neuromorphic hardware stdp used train efficient spiking auto encoder leverage asynchronous sparse spike input reconstruction, denoising, classification, achieving superior performance significantly fewer spike compared state art method hand, stdp significant application bio plausible meta learning models, particularly enhancing adaptability efficiency machine learning system incorporating stdp reward modulated stdp, model reflect biological learning mechanism enable quick learning low data scenario approach particularly useful preventing catastrophic forgetting meta learning tasks, allowing model retain previously acquired knowledge learning new task additionally, stdp facilitates application model spike based neuromorphic devices, improving performance task shot classification advancing ai system capability mimic human like learning stdp employed train spiking auto encoder efficiently performs input reconstruction, denoising, classification minimal spike usage, showcasing enhanced performance image datasets maintaining competitiveness learning approach stdp also applied memristors synapsis enable situ learning inference snns approach address computational challenge associated implementing stdp hardware, allowing efficient weight modulation enhances speed reduces power consumption integration stdp facilitates real time pattern recognition employing winner take mechanism within snn architecture proposed design significantly improves performance metrics, including power, energy, accuracy, enabling classification million image per second stdp employed stabilized supervised stdp learning rule enhance classification layer snns, integrating unsupervised stdp feature extraction improving performance image recognition task furthermore, stdp utilized investigate configuration needed achieve robust synchronization neural networks, finding could inform design neuromorphic circuit improved information processing transmission synchronization phenomenon overall, despite challenge scaling stdp deeper network larger tasks, biological relevance versatility highlight significance advancing artificial intelligence neural computation stdp hold potential enhance performance robotic system allowing learn environment real time, reinforcing critical role development intelligent system section, take single stn neuron study neuron behaves random input bombarded excitatory inhibitory spike train together influence stdp numerical result reported section obtained using discrete time integration based euler method implemented python particular, use coupled sdes ode system describes dynamic stn membrane potential mentioned previous section, focus effect gaussian white noise input current together random refractory period stn cell membrane potential main numerical result analysis shown fig plotted time evolution membrane potential calculated based model along spike count profile, corresponding spike irregularity profile effect input correlation output correlation stn healthy pd cell stdp investigate effect additive type random input current presence random refractory period input correlation modified hh neuron synaptic conductance dynamic stdp observe spiking activity neuron stn cell membrane potential influenced random external currents, random refractory periods, stdp, input correlation order switch healthy condition parkinsonian condition basal ganglion model, consider decrease current app applied stn particular, app pa healthy stn cell app pa parkinsonian stn cell see, eg, therefore, stn cell case injected current input app pa result healthy stn cell, stn cell case injected current app pa considered pd affected stn cell particular, look fig plotted time evolution stn cell membrane potential direct input current direct refractory period healthy cell neuron spike different neuron spike case healthy cell pd cell presented fig missing spike time interval fig fig case healthy cell, added random input current random refractory period system observe fluctuation time evolution membrane potential, total excitatory synaptic conductance well trace number postsynaptic spike timescale case pd affected cell random input current random refractory period fig see time evolution cell membrane potential unstable also fluctuation trace number postsynaptic conductance total excitatory synaptic conductance fig consider db input system, still fluctuation time evolution membrane potential trace number postsynaptic spike timescale follows, also look corresponding isi distribution spike irregularity profile case presented fig fig present spiking irregularity profile case additive noise input current, along isi distribution healthy parkinson disease pd affected cell variability isi typically measured coefficient variation, isi analysis focus value app pa app pa first determine average current injection values, average pa isi computed identifying spike time calculating difference isi defined per equation fig observe trend spike irregularity increase left right decrease top bottom pd cell exhibit greater spike irregularity compared healthy cells, corresponding increase isi range isi evident presence random refractory period significantly influence spiking activity, reducing irregularity additionally, observe stdp modified hh model increase isi spike train output neurons, contrast model without stdp, reported moreover, combining random refractory period db reduces spike irregularity let u combine two procedure first, generate correlated input inject correlated input pair neuron record output spike time continue measuring correlation output investigate relationship input correlation output correlation fig plot input correlation versus output correlation referred correlation transfer function neuron result indicate output correlation lower input correlation output correlation varies linearly input correlation input correlation affect neuron capacity, output correlation remains independent mean standard deviation however, observe increasing standard deviation random refractory period healthy pd cell lead linear increase output correlation see, example, moreover, presence random input influence spiking activity stn neurons, without deep brain stimulation db input current standard deviation random refractory period increases, irregularity spike train decrease additionally, random refractory period mitigate effect random input current system db input current present interaction random refractory period random input current stn cell stdp membrane potential provides valuable insight model development progress db therapy introduced modified hh model outlined process synaptic conductance random input stdp highlighted importance latter two factor analyzing managing neurodegenative diseases, parkinson s, neuromorphic system application employing langevin stochastic dynamic framework numerical setting, investigated impact random input membrane potential stn cell specifically, detailed model used provided numerical example examine effect random input time evolution membrane potentials, neuronal spiking activities, spike time irregularity profile result indicate stdp enhances regularity isi spike train output neuron however, presence random refractory period, combined random input currents, significantly increase irregularity spike train additionally, stochastic influence alongside stdp may enhance correlation neuron finding could offer insight managing symptom parkinson disease author grateful nserc crc program support rm also acknowledging support berc program spanish ministry science, innovation university agencia estatal de investigacion aei bcam severo ochoa excellence accreditation sev continuing ",neurons and cognition
"discriminating image representation principal distortion introduction problem statement existing method principal distortion image representation experimental result discussion reproducibility statement appendix relation fisher rao metric appendix computing top two optimal distortion appendix method early visual model experiment appendix method deep neural network experiment instruction reporting error local information geometry stochastic image representation eigen distortion image representation generalized eigen distortion comparing two image representation metric local geometry image representation principal distortion comparing multiple image representation early visual model deep neural network principal distortion optimization supplemental figure image representation artificial biological often compared term global geometry however, representation similar global structure strikingly different local geometry here, propose framework comparing set image representation term local geometry quantify local geometry representation using fisher information matrix, standard statistical tool characterizing sensitivity local stimulus distortions, use substrate metric local geometry vicinity base image metric may used optimally differentiate set models, finding pair principal distortion maximize variance model metric use framework compare set simple model early visual system, identifying novel set image distortion allow immediate comparison model visual inspection second example, apply method set deep neural network model reveal difference local geometry arise due architecture training type example highlight framework used probe informative difference local sensitivity complex computational models, suggest could used compare model representation human perception biological artificial neural network transform sensory stimulus high dimensional internal representation support downstream tasks, representation often described term neural population geometry chung abbott, idea led multitude proposed measure representational similarity kriegeskorte et al, yamins dicarlo, kornblith et al, williams et al, klabunde et al, measure often used compare representation within computational model representation within brain however, despite differing architecture training procedures, many computational model perceptual neural response equally performant representational similarity measure schrimpf et al, tuckute et al, conwell et al, model functionally interchangeable, datasets method used test simply insufficient reveal difference often similarity two representation quantified measuring alignment representation set natural stimulus relatively far apart stimulus space way, measure capture notion global geometric similarity representation however, system similar global structure strikingly different local geometry example, szegedy et al found image distortion imperceptible human led artificial neural network misclassify images, motivated method training artificial neural network minimize susceptibility adversarial example goodfellow et al, madry, observation suggest need metric compare local geometry image representation and, particular, highlight difference system even global structure seems similar quantify compare local geometry different image representation brute force comparison clearly prohibitive space image extremely high dimensional, set potential distortion equally high dimensional estimating local geometry representation moderately dense sampling full set possible distortion impractical, estimating human sensitivity set essentially impossible such, worthwhile develop method judicious selection stimulus distortion used comparing set model take inspiration zhou et al pair model base image, synthesize distortion along two model sensitivity maximally disagree bear conceptual similarity method construct stimulus optimally distinguish pair model wang simoncelli, golan et al, cluster neuron cell type burg et al, build earlier work examined eigen distortion along individual model maximally minimally sensitive berardino et al, specifically, zhou et al measure local sensitivity model term fisher information matrix fim, fisher, classical tool statistical estimation theory, choose pair generalized eigen distortion maximize minimize ratio two model sensitivity image distortion computed, may added varying amount base image determine level become visible human measured human sensitivity compared models, goal identifying model better aligned local geometry human visual system however, principled method selecting image distortion use comparing two model define novel metric comparing model representation term relative sensitivity image distortion use metric generate pair distortion maximize variance across two model metric analogy principal component analysis, method viewed dimensionality reduction technique preserve much variability local representational geometry possible such, refer principal distortion set model apply method nested set hand crafted model early visual system identify distortion differentiate model potentially used evaluate well model predict human visual sensitivity apply method set visual deep neural network dnns varying architecture training procedure find distortion allow visualization difference sensitivity layer network neural network architecture explore difference standard imagenet trained network shape bias enhanced counterparts, standard network adversarially trained counterpart cases, illustrate method generates novel distortion highlight difference model portion work initially presented lipshutz et al, given collection image representations, goal develop method comparing local geometry representation vicinity base input image section, define local geometry image representation term fim review existing method selecting image distortion based model fims assume image representation associated conditional density dimensional vector image pixel vector stochastic response eg, biological neuronal firing rate deterministic neural network activation additive response noise figure depicts two dimensional stimulus space three model mapping stimulus conditional density note dimension response may vary across representation sensitivity representation small distortion depends overlap conditional distribution less overlap corresponding higher sensitivity green swets, sensitivity precisely quantified term fisher rao metric rao, amari, riemannian metric stimulus space fig defined term positive semi definite fim fisher, log denotes gradient log respect fim standard tool statistical estimation theory locally approximates expected log likelihood ratio kl divergence conditional distribution provides lower bound variance unbiased estimator cram r, rao, fim also used link neural representation perceptual discrimination paradiso, seung sompolinsky, brunel nadal, averbeck lee, seri et al, ganguli simoncelli, wei stocker, given fim, define sensitivity representation stimulus distortion quantifies well ideal observer could detect small perturbation base stimulus direction tractable example, suppose conditional response gaussian stimulus dependent mean constant covariance fim jacobian expression, see sensitivity representation distortion depend mean response changing direction relative noise covariance given model image representation, berardino et al proposed use extremal eigenvectors model fim termed eigen distortion fig b, top panel model prediction least noticeable image distortion set early vision model deep neural network whose parameter optimized match database human image quality rating ponomarenko et al, computed eigen distortion model despite fact model fit image quality data equally well, eigen distortion quite different, human perceptual judgement severity eigen distortion varied substantially eigen distortion image representation correspond distinct distortion predictions, tested human perceptual experiment however, eigen distortion two model similar, useful distinguishing models, since method insensitive difference non extremal eigenvectors zhou et al proposed comparing two image representation along distortion local sensitivity maximally differ, conceptually similar previous method construct stimulus maximize disagreement model wang simoncelli, golan et al, specifically, chose distortion extremize generalized rayleigh quotient since distortion correspond extremal eigenvectors generalized eigenvalue problem refer generalized eigen distortion fig b, middle panel however, method limited comparison pair models, single model average model propose natural extension generalized eigen distortion allows comparison among two image representation show generalized eigenvalue problem suggests metric image representations, used optimally choose image distortion distinguish two model express generalized eigen distortion defined equation solution single optimization problem simplified notation omitting dependence regroup numerator denominator log quotient model rather distortion, express optimization problem follows used definition sensitivity equation dropped factor pair distortion function proper metric positive semi definite matrix specifically, non negative, symmetric, obeys triangle inequality, zero metric several appealing property invariance scaling fims positive constant desirable property since interested identifying relevant image distortion depend shape fims, independent scaling factor invariance permutation distortion generalized eigen distortion approximation fisher rao distance mean zero gaussian distribution covariance scaling factors, see appx interpretation suggests principled extension metric two distortion metric compare stochastic representation back stimulus space via fims avoids problem aligning stochastic representations, computationally intensive step required evaluating existing metric stochastic representation duong et al, optimize pair image distortion distinguishing representations, choose maximize sum square pairwise distance fims metric defined equation equivalent maximizing variance image representation log sensitivity ratio refer principal distortion models, analogous principal component analysis fig gradient based optimization algorithm, see appx note several natural extension generalized eigendistortions considering model example, one choose distortion maximize sum th power pairwise distances, amount replacing equation focus case maximizing variance leave exploration higher order moment future work demonstration method, generated principal distortion computational model previously proposed capture aspect human visual system model implemented pytorch ansel et al, simulation performed nvidia gpus rtx model model deterministic, calculate fim assuming network output corrupted additive gaussian noise, berardino et al, case, jacobian model input generated principal distortion nested family model designed capture response property early stage specifically, lateral geneiculate nucleus, lgn primate visual system fig full model lgn contains two parallel cascade representing center surround filter channels, rectification, luminance contrast gain control nonlinearities model reduced version model lgg remove channel, lg additionally remove contrast gain control, ln remove gain control operation filter sizes, amplitudes, normalization value model previously fit separately predict dataset human distortion rating berardino et al, see detail appx model explicitly trained predict human distortion thresholds, provide qualitative comparison model sensitivity human distortion sensitivity fig adjusted relative scaling principal distortion equally detectable model constraining sum euclidean norm two distortion fixed value is, chose positive scalar model threshold comparable human thresholds, rescaled distortion equally detectable added image visual inspection image reveals distortion visible rescaled lgn model ln model, suggesting model closest human distortion threshold lg, scaled distortion visible, scaled distortion immediately apparent, suggesting strong mismatch human observer threshold true lgg model, role two distortion swapped qualitative observation consistent result berardino et al, experiment eigen distortion suggested lgn model best model term consistency human distortion sensitivity analogous perceptual experiment could used quantify visibility principal distortion arising analysis advantage framework dramatically reduce number distortion needed differentiate set model instance, judge well model early visual system capture human perceptual discrimination thresholds, berardino et al computed extremal eigen distortion four models, measured human perceptual discrimination threshold eight distortion general, method requires assessing visibility distortions, model zhou et al considered pair generalized eigen distortion pair models, total distortion contrast, method always selects two distortion maximize variance across models, independent human sensitivity distortion estimated perceptual discrimination experiment judge model closest term metric defined equation model whose sensitivity far human sensitivity discarded procedure repeated best differentiate remaining models, one could reduce number model by, say, factor two iteration process, total number stimulus assessed scale log dramatic improvement efficiency could enable comparison significantly larger set model feasible previous method deep neural network dnns originally developed object recognition, also examined model primate visual system yamins dicarlo, schrimpf et al, lindsay, plethora models, varying architecture training techniques, proposed, many model perform quite similarly behavioral task neural benchmark schrimpf et al, tuckute et al, conwell et al, situation offer well aligned opportunity use principal distortion method first measured fim set layer two different architecture trained imagenet object classification task alexnet krizhevsky et al, resnet et al, generated principal distortion maximally separate model fig see sec supplement layer choice model detail although architecture currently state art image recognition neural prediction, widely used trained various optimization strategy notably, hierarchical structure model reflected log ratio sensitivities, early layer model closer together metric space fig late layer alexnet always sensitive late layer resnet sensitive additional structure revealed principal distortion alexnet sensitive principal distortion generally appears concentrated region image variability, ie, stuff image distortion fig resnet sensitive distortion occur relatively constant region image distortion fig separability model sensitivity network two distortion type remarkably consistent across set base image chosen imagenet dataset fig e, see fig supplement additional example distinction also found image designed explicitly test possible difference model due edge artifact contrast sensitivity fig supplement far know, qualitative difference sensitivity architecture distortion located different place image documented, demonstrating method reveal interpretable difference local sensitivity complex computational model architectural difference observed imagenet trained alexnet resnet suggested texture image may driving difference local geometry previous work demonstrated standard dnns exhibit strong texture bias geirhos et al, proposed model explicitly reduce texture bias training stylized imagenet sin set image retains content imagenet image overlay detail matched particular texture training image reduce model reliance texture classification training set strongly affected local geometry networks, might expect principal distortion generated mixture architecture training set would driven training set distinction find evidence case generated principal distortion base image using set layer two architecture resnet alexnet two different training datasets imagenet stylized imagenet fig principal distortion appeared qualitatively similar generated investigated standard network fig b, example fig supplement alexnet architectures, regardless training type, sensitive perturbation higher variability part image, resnet model sensitive distortion mainly targeting constant area image another well known example use training set modification achieve robustness object recognition adversarial training adversarial example generated step model training stimulus used update model weights, true category label used update previous work found adversarially trained network aligned biological system madry, feather et al, gaziv et al, adversarial example constrained small perturbations, seems plausible local geometry model would differ standard counterpart indeed, see principal distortion generated set model included standard trained alexnet resnet model reliably separate model class training type, rather architecture fig layer adversarially trained model sensitive relatively smooth change patch color image, shading around edges, layer standard model sensitive appears unstructured noise fig b, additional example fig supplement stark contrast style trained network previous section, principal distortion reliably separated model architecture example provide compelling demonstration method used separate collection similar models, point utility probing complex high level representation introduced metric image representation quantifies difference local geometry, used synthesize principal distortion maximize variance metric set model applied hand engineered model early visual system deep neural networks, approach produced novel distortion distinguishing corresponding model particular, dnn analysis, revealed qualitative difference local geometry resnet alexnet architectures, adversarial training dramatically change local geometry, stylized imagenet training although qualitative example targeted set neural network fully elucidate recent observation many different model equally good capturing brain representations, method provides direct approach begin tease apart interplay local geometry global structure several natural methodological extension metric closely related fisher rao metric mean zero gaussians relation suggests natural extension synthesizing two distortion appx analogous using additional principal component capture variance within set high dimensional vector additionally, focus computing principal distortion differentiate finite set models, natural extension computing principal distortion differentiate continuous family model prior distribution model several limitation formulation principal distortion first, framework based local differential analysis model base image, sensitivity estimate obtain via analysis guaranteed hold infinitesimally small neighborhood base image model highly nonlinear vicinity base image, local linear approximation may accurately reflect model sensitivity second, compute fim deterministic model, assume additive gaussian response noise, generally representative neural response brain poisson variability could used better capture neural response another approach fit model noise structure measurement neural system see ding et al, work along line principal distortion provide efficient method comparing computational model human observers, experimental time acquiring response stimulus generally severely limited although presented qualitative comparison example related human perception paper, optimized distortion parsimonious choice stimulus readily incorporated psychophysics experiment example, distortion generated early visual model could used perceptual discrimination experiment human observer similar performed berardino et al compare human log ratio sensitivity optimized distortion predicted model result dnns reveal intriguing property model stronger sensitivity bias local geometry perturbing higher variability region space, others sensitivity perturbation relatively blank region see fig supplement direct evidence also provides interesting question future distortion detection context human sensitive perturbation stuff image compared perturbation empty part image observed difference relate previous work investigating human neural network rely spatial frequency classification subramanian et al, finally, beyond direct comparison human observer using psychophysics experiments, method may useful domain neural network interpretability, may useful direct comparison local distortion maximally differentiate set model flatiron distortion detail loading model uploaded zip file submission, made available via public github repository upon publication aim distortion generation easy others use probe new model mathematical derivation algorithm provided appx included detail appx parameter early visual models, appx detail checkpoint obtained tested deep neural network fisher rao distance two mean zero dimensional gaussian distribution positive definite covariance matrix defined denote eigenvalue generalized eigenvalue problem pinele et al, like metric invariant arbitrary scaling suggests following definition final equality us fact optimal mean log using fact log log log log denote extremal generalized eigenvectors associated respectively, equation suggests natural extension defining metric positive definite matrix using distortion specifically, suggests choosing distortion maximize variance across log ratio sensitivity end, define squared distance local geometry variance across distortion log ratio sensitivity set principal distortion chosen maximize variance across model metric suppose model sensitivity optimal distortion solution optimization problem differentiating respect yield used fact similarly, differentiating respect yield combining, following gradient based optimization algorithm pytorch implementation early visual model obtained githubcom plenoptic org plenoptic, duong et al, early visual model adopted berardino et al parameter chosen maximize correlation predicted perceptual distance human rating perceived distortion, wide range image distortion provided tid database ponomarenko et al, parameter reported table note although model nested construction parameterization, model parameter differ across tested model since optimized model independently analyzed dnns obtained model loading code checkpoint available githubcom jenellefeather model metamers pytorch used feather et al allowed easy loading selection intermediate layer stage many model previously proposed model human visual perception checkpoint standard resnet alexnet model obtained public pytorch checkpoint ansel et al, stylized image net alexnet alexnet trained sin resnet resnet trained sin obtained githubcom rgeirhos texture v shape associated geirhos et al checkpoint resnet train adversarially trained model obtained engstrom et al checkpoint alexnet train adversarially trained model obtained feather et al experiments, included intermediate layer final classification stage principal distortion analysis, subset layer followed chosen feather et al specifically, alexnet model included layer relu relu relu relu relu fc relu, fc relu set anlayses resnet model included conv relu layer layer layer layer avgpool set analysis deep neural network experiments, use subset imagenet image image chosen unique class randomly chosen set image githubcom elischwartz imagenet sample image image comparison, ran gradient descent procedure principal distortion optimization iterations, using exponentially decaying learning rate started decayed final step used target distortion size step optimization, also scaled image would clipped rgb value represented is, scaled value image constraint could potentially bias perturbation spread across image amplitude perturbation cannot focused small set pixel however, removing constraint lead quantitatively different result supplementary fig inclusion allows viable comparison human perception perturbation scaled maintaining valid value image gamut continuing ",neurons and cognition
"minimal model money creation regulatory constraint introduction ii minimal agent based model iii result iv conclusion acknowledgment appendix random growth model appendix sensitivity analysis instruction reporting error motivation money market stylized fact money market modeling literature ii balance sheet item ii financial contract ii regulatory constraint ii initialization money creation ii money creation shock ii payment shock ii bank behavioral rule ii sequence interaction among agent ii trust coefficient ii synthesis iii dynamical behavior iii parameter space iii stress testing propose minimal model secured interbank network able shed light recent money market puzzle find excess liquidity emerges due interaction reserve liquidity ratio constraint appearance evergreen repurchase agreement collateral use emerges simple answer bank counterparty risk liquidity ratio regulation line prevailing theories, use increase collateral scarcity agent based model, bank create money endogenously meet funding request economic agent latter generate payment shock banking system reallocating deposit bank absorbs shock thanks repurchase agreements, respecting reserves, liquidity, leverage constraint resulting network denser robust stress scenario unsecured one addition, stable bank trading relationship network exhibit core periphery structure finally, show model used tool stress testing monetary policy design money market place bank conduct refinancing operation serve engine money creation process provides liquidity financial system, thus contributing stability following surge counterparty risk great financial crisis gfc money market western country undergone significant transformation october european central bank ecb introduced called full allotment procedure, allows bank request unlimited central bank funding concurrently, implementation basel regulation regarding liquidity coverage ratio lcr aim enhance short term resilience bank liquidity crisis requires bank maintain adequate level high quality liquid asset fulfill liquidity need stress scenario measure contributed emergence excess reserve financial system renne piquard salakhova luca baldo et al additionally, refinancing banking system shifted towards collateralized lending using repurchase agreements, repos defined practice collateral use become increasingly prevalent network structure money markets, transaction among bank identified link nodes, evolved consequence unsecured market experience low density observe repo market demonstrate higher density due longer transaction maturity several author proposed explanation recent change within money market however, approach generally refer complex mechanism difficult quantify, example, high opportunity cost hold non risky coupon market fragmentation collateral scarcity moreover, literature agent based model abm focused far absorption payment shock banking system unsecured transaction reserve constraint fact, bank endogenously produce money lending use secured transaction raise non trivial stability question consider money creation payment shock within collateralized markets, subject reserve, lcr, leverage constraint model show excess liquidity use explained regulatory constraint repo contract specificity abm also generates trading network high density, stable bilateral trading relationships, asymmetric degree distribution well core periphery structure finally, model useful tool simulating systemic effect financial stability crisis scenario regulatory change describing recently established stylized fact money markets, review existing literature interbank network modeling then, section ii introduces abm finally, section iii present dynamical behavior model, effect parameter changes, stress scenario section present stylized fact observed money markets, agent based model successfully reproduces addition reviewing empirical literature, offer explanation phenomenon following gfc, ecb implemented called full allotment procedure, accommodates liquidity demand bank unlimited amounts, documented renne subsequently, volume overnight unsecured interbank market decreased significantly indeed, volume interbank secured market drop excess reserve ie surplus bank reserve requirement increase explained recent ecb survey increase excess liquidity mainly driven greater demand bank central bank liquidity, ii full allotment procedure, iii offer longer term refinancing operation since another ingredient led new increase excess liquidity ecb injected central bank liquidity banking system asset purchase program app time, bank cited increasing client inflow main reason excess liquidity resulting decline unsecured lending reinforced introduction lcr january hampered redistribution liquidity luca baldo et al section using individual bank balance sheets, one show combination app lcr constraint lead excess liquidity financial system bank time let u denote, respectively, cash owned bank deposit received also denote amount security usable collateral collateral received lender cash lcr ratio unencumbered asset net cash outflow next day outflow defined regulatory prescribed haircut bank liability formally, within simplified bank balance sheet defined, lcr expressed regulatory outflow rate deposit excess liquidity banking system time defined sum cash excess minimum reserve individual bank share minimum reserve required regulation replace expression equation assume bank cover outflow rate equation written respectively total amount collateral deposit banking system eq show larger gap regulatory outflow rate required minimum reserve, higher excess liquidity addition, decrease amount collateral available generates additional excess liquidity however, reasoning hold presence interaction bank abm actually show asymmetric response bank payment shock also generates excess liquidity even collateral scarcity see section ii gfc highlighted existence counterparty risk among bank led transition unsecured secured lending within markets, collateralized borrowing performed thanks repos, ie, financial contract exchanging collateral cash given time period fact, substitution effect towards secured market reinforced introduction lcr ability contract circumvent constraint repo contract continuously renewed mutual agreement called evergreen repo show following evergreen repo one month notice period effect lcr two involved party empirical evidence show introduction lcr regulation coincides increase volume traded evergreen repos notice period month particular, le coz et al observed volume evergreen repos traded among largest bank eurozone increased negligible amount ten billion per day use evergreen repos circumvent lcr regulation explained thanks simplified balance sheet bank context repo agreement, borrower cash remains owner collateral provided transaction collateral remains balance sheet encumbered security denoted new repo notional lead increase encumbered collateral collateral cannot used transaction, thus excluded numerator lcr contrast, lender cash record collateral received collateral compensates loss lcr due cash reduction transaction, new lcr borrower lender remain constant lcr denominator total outflow, generated one month stress test, bank liability equation one could surprised see outflow repo recorded liability cash borrower possible consider repo maturity notice period greater one month addition, ensure lcr conservation equation time necessary introduce evergreen contract valid time opposite, entering unsecured interbank loan would negatively impact lcr lender positively impact lcr borrower substitution effect unsecured secured market also influenced asset purchase program, increase spread secured unsecured rate due lower availability collateral, ii decrease volume secured unsecured market consequence one month notice period evergreen repo forbids immediate unwinding existing position lender cash experience liquidity need thus, market offer possibility use collateral lender cash allowed use collateral received reverse repo order borrow cash within another repo transaction various definition used define use rate collateral within money market choose following definition various level collateral use, ranging measured across time region notably use rate around observed european money market australia switzerland u high use rate observed money market threat initial objective lcr regulation indeed, collateral appear numerator lcr given bank appearance collateral identified encumbered securities, excluded lcr use increase response scarcity induced asset purchase program moreover, use contributes buildup leverage inflating balance sheet size using infinite horizon asset pricing model heterogeneous agents, brumm et al considers increased leverage significantly increase volatility financial markets, ultimately reducing welfare define link interbank network existence, given aggregation period typically ranging one day one year least one repo exposure two bank historically, interbank market network characterized low density core periphery structure network configuration central core highly interconnected node surrounded periphery less connected node primarily connect core rather switch market towards secured transaction led increased network density author show network density ranging depending link definition convention assume higher density due longer transaction maturity limited number bank sample prevented u studying core periphery structure secured market existence stable interbank relationship lending documented, among others, furfine afonso et al blasques et al le coz et al case secured market le coz et al measured share stable link one period another, namely jaccard network similarity index ranging depending aggregation period defining link several author reported asymmetry degree within unsecured interbank lending network notably, craig von peter anand et al observe bank germany general fewer lender borrower le coz et al observe symmetrical pattern case repo exposure among largest bank eurozone several approach modeling interbank unsecured market proposed influential article poole introduces model interbank lending network absorbs randomly generated payment shocks, reserve requirement constraint seminal work followed numerous proposal network modeling interbank market recently, heider et al included counterparty risk lending network generated endogenous liquidity hoarding bech monnet considered search based model reproduce decrease trading volume due surge excess reserves, without identifying initial cause deposit surplus later identified vari eurozone interbank market fragmentation banks, depending country location, different probability default fragmentation disrupts transmission monetary policy, generating endogenously excess liquidity vari distinguishes two group core bank germany netherlands use central bank funding hold excess reserve peripheral bank eg, spain italy borrow massively central bank fulfill need however, funding obtained end within core bank due payment imbalance reproduce behavior, reverse causality abm, flow payment shock move deposit peripheral core banks, generating liquidity need first ones, excess liquidity others see section ii recently, decline unsecured market led several author build equilibrium model explaining substitution effect secured unsecured interbank market however, modeling proposal describe equilibrium state interbank market author proposed dynamic model unsecured interbank market particular, blasques et al assume profit maximization risk monitoring cost generate sparse core periphery structure stable bilateral trading relationship lux obtain result using reinforcement learning scheme liu et al proposed abm interbank network lead endogenous formation financial network using data individual bank within abm model macroeconomics, several framework include multiple bank agent firm borrow, although allow interaction among bank modeling static interbank lending market found macroeconomic model overall, approach focus unsecured markets, largely replaced secured market moreover, model assume absence endogenous money creation process induces non centered shock requiring specific modeling finally, framework account reserve constraint introduction lcr significantly modified money market see section consider money market formed bank agents, representative economic agent, central bank bank create money lending economic agent latter reallocates deposit among bank agents, thus generating payment shock shock absorbed banking system thanks central bank funding repos assume existence single type fungible security usable collateral repo market, typically government bond bank agent must respect time reserves, lcr, leverage regulatory requirement none fixed income instrument system offer coupon bank characterized following accounting items, expressed monetary units, time step unit day cash either deposit central bank reserves, denoted security usable collateral, denoted security encumbered context repo, denoted loan economic agent denoted reverse repos granted banks, denotes sum open repo exposure time received bank bank fund equity, deposits, repo exposure received banks, central bank funding, denoted balance sheet collateral received context reverse repo, denoted collateral used context repo, denoted financial contract model either infinite maturity maturity repos evergreen ie unlimited maturity one month notice period cancellation therefore, bank must create new repos remediate immediate liquidity need unwinding existing reverse repos would provide liquidity late bank excess cash, would also wait day unwind existing repo, could immediately earn repo rate entering new reverse repo loans, central bank funding, security unlimited maturity deposit cash maturity mentioned above, assume none financial instrument offer coupon indeed, simulating yield dynamic necessary reproduce excess liquidity, repo use, network topology stylized fact fact, yield financial contract incorporated within bank behavioral rule prefer holding instrument delivering highest coupon requires defining relative static yield financial contract hence, model, security used collateral deliver higher interest rate discount facility rate remunerating bank cash balance assumption consistent empirical observation example, eurozone, year german government bond almost systematically delivered higher coupon ecb discount facility rate addition, rate central bank funding higher repo rate, therefore bank incentive borrow central bank repo market rate higher discount rate, bank accept entering reverse repo excess cash finally, assume loan rate real economy highest rate available bank agent bank subject three regulatory obligation minimum reserve constraint bank must keep share deposit receive form central bank reserves, ie, lcr constraint, requiring bank maintain ratio unencumbered asset cash outflow next day one within model balance sheet banks, lcr constraint amount assuming regulatory net deposit outflow security received context repo remain unencumbered one month stress test following sections, refer effective defined liquidity ratio lcr ratio bank mean bank face outflow rate deposit must higher regulatory leverage ratio solvency ratio constraint, requiring bank keep fund certain share total asset worth mentioning leverage ratio play role solvency ratio, requires bank maintain minimum level fund solvency ratio complex account involves risk measurement also less binding leverage constraint low risk activity thus, choose ignore solvency ratio constraint model financial instrument model created endogenously bank create amount new money step lending cash representative economic agent latter must store amount form deposit bank ensure money creation process compatible three regulatory constraints, value newly created security fund must proportional new loan security typically government bond issued representative economic agent bought banking system government also store borrowed cash form deposit banking system, mechanism increase usable deposit security bank balance sheet addition, fund issued bank bought economic agent using cash borrowed bank summary, creation monetary unit bank step involves three step lending, ii issuance government bonds, iii capital increase bank issuing new share combined effect three action result increase balance sheet item corresponding variation new new parameter governing respectively issuance share security practice, unless otherwise specified, assume new enough collateral created meet regulatory obligation accounting item generated either repo transaction encumbered securities, collateral received, collateral used ii central bank funding main refinancing operation cash simulate money creation thanks multiplicative random growth process shock fluctuate around average rate new money let log normal random variable volatility independent across bank step amount created money given growth rate money neither process normalized version converge towards stationary distribution however, report appendix normalized size bank behaves non stationary log normal distribution evolves slowly compared typical time scale model notably, tail log normal distribution remains stable within given range, sufficiently long time around step network reach state close stationarity see section iii feasible design random growth model generates stationary limit using approach proposed marsili et al gabaix bouchaud zard indeed, model either require defining negative drift facilitating cash exchange bank see appendix empirical literature, consensus regarding size distribution bank author suggest distribution follows power law tail exponent zipf law across time region however, goddard et al argue bank size better described truncated log normal distribution differentiating power law log normal distribution challenging small sample size context banks, thousand financial institution within given monetary zone, limit ability accurately assess size distribution model, long bank size sufficiently heterogeneous, observe specific distribution bank size log normal power law influence stylized fact previously mentioned hence, order reach faster stationarity, conduct parameter space see section iii stress test analysis see section iii initializing money creation power law tail exponent case, volatility random growth set zero maintain initial size distribution bank time money created, economic agent transact good transaction result increase deposit bank seller decrease deposit bank buyer total amount deposit banking system remains constant transaction similarly approach lux simulate payment thanks normally distributed shock defined ensure total sum deposit conserved ii mean reversion toward amount deposit created bank formally, deposit variation caused payment shock step bank defined normalized centered independent gaussian shock new target mean reversion, updated according money creation process large value possible deposit shock increase absolute value compared current bank deposit ensure deposit shock is, positive, choose mean shock must exceed generate negative deposit although event rare, apply floor bank deposits, preventing going zero stock flow consistency imposes increase cash balance bank time step amount, ie, money creation payment shock modify balance sheet bank lead breach regulatory constraint case, central bank funding repo market used bank agent meet obligation enhance readability section, assume inequality characterizing regulatory constraint bank agent equality money creation payment shocks, ie fact, model structurally generates excess liquidity ie excess lcr ie asymmetric response bank payment shocks, described beginning step bank receives money creation shock payment shock meet three regulatory constraints, bank act follows lcr management secured lending keep lcr level unchanged see section hence, absence unsecured market, bank optimize lcr level central bank funding denote amount central bank funding bank request end maintain lcr level bank must minimize central bank funding assume share security created money creation process equal regulatory lcr level new optimal funding given hence, negative payment shock lead bank request central funding contrast, positive shock lead reduction central bank funding excess lcr overall, net sum central bank funding positive, introduces excess liquidity system reserve management bank use repos optimize central bank reserve one month notice period contract requires bank open new long short position manage short term liquidity bank close existing repos meet leverage ratio obligation see next paragraph denote amount repo requested bank reverse repo bank willing accept order maintain lcr target level bank must minimize repo exposure new bank excess reserve shocks, also assume absence excess lcr, ie previous equation becomes banking regulation typically set difference positive neglect money creation shock ie clear receiving negative payment shock implies requesting repos contrast, positive shock lead bank willing enter reverse repo nevertheless, possible bank hold sufficient collateral enter repo, case, request additional central bank funding leverage management management reserve opening repos reverse repos inflates bank balance sheet current leverage ratio bank becomes lower targeted level start ending existing repos positive shock contrary lcr reserve constraints, bank immediate solution available reduce size balance sheet hence choose target leverage ratio greater regulatory requirement, consequence, bank start closing existing repos risking breach minimum leverage ratio assume repos initiated ended borrower cash bank ready participate repo market individual management lcr market clearing performed follow bank end existing repos one one shuffled order bank start contacting counterpart lowest trust level whose dynamic described lender cash sufficient collateral end reverse repo, bank must end repos assume lender cash receives cash back slightly providing back collateral cash borrower mechanism ensures lender cash owns enough cash close existing repos get back used collateral situation trigger cascade collateral call back detailed then, bank enter repos one one another reshuffled order time, bank start contacting counterpart highest trust factor latter accept entering reverse repo excess cash, ie naturally, bank engage simultaneously repos reverse repos however, lead collateral loop security loaned one bank loaned original lender cases, model, sequential call collateral unwind existing repos might converge prohibiting collateral loop would lead rapid collapse money market high density repo network therefore, model permit loops, even though mean simulation may run completion actual markets, two counterparties within collateral loop want unwind positions, compute directly net exposure possible none two bank still owns collateral case, counterparty short collateral would usually borrow security using reverse repo model, simplification, bank experiencing liquidity need request funding repos proposed lux bilateral trading relationship rely trust coefficient indicating strength tie established repeated contact trust coefficient bank initialized randomly updated time request repo bank increase agrees lend decrease otherwise learning coefficient, governing time scale bank update trust maximum eq mean trust coefficient converge towards share repo exposure accepted bank sort variable parameter model four category four exogenous variable set economic agent monetary payment shock amount deposit loan security fund parameter act control parameter model constant across bank time new deposit outflow rate equivalent new securities, tune creation new security system target leverage ratio, new leverage ratio equivalent new funds, control repo use rate respectively mean volatility monetary shock specified, exponent power law distribution bank size governs heterogeneity among bank volatility payment shock size control speed trust level updated regulatory constraint set regulator variable endogenously updated table provides list variable defining controlling state bank agent typical run model reproduces money market stylized fact stationary state unless specified differently fix mean bank increase balance sheet year year step average agent grow given day annualized rate also set obtain result comparable mmsr database containing bank payment shock assumed quite volatile regulatory parameter set according actual value euro zone new is, average outflow rate type client deposit choose ensure bank satisfy leverage constraint new generate sufficient collateral use also set learning coefficient average initial size bank monetary unit indeed, assume one monetary unit model corresponds one billion euro thus, initialize average capital bank million euros, close minimal fund required banking license million eurozone, article crd iv excess liquidity naturally appears result asymmetric response payment shock see fig amount excess liquidity generated model total assets, line level observed eurozone show origin excess liquidity traced back interaction reserve lcr constraints, bank cannot maintain requirement minimum level absorb daily payment shock note exponential growth banking system rate requires measuring normalized value observe stationary state figure display phase security consumed faster banking system issued government, leading decrease usable security security remain, bank start use collateral average rate use converges approximately ie, typical length collateral chain line observation le coz et al leverage constraint, limit balance sheet size bank model generates relatively high density network compared unsecured lending network see abm lux figure show slow convergence network density towards regime close stationarity slow evolution bank size distribution indeed, heterogeneity bank size never reach stationary state, even though typical time scale required observe non stationarity longer simulation window see appendix also find combination input parameter lead model random growth ie, generate slowly increasing decreasing density however, model equal growth rate ie reach stationary state wider range input parameter case, constantly increasing amount new loan deposit still slows convergence increasing average maturity repos however, stationary regime reached long payment shock large enough end transaction is, according observation level, stationary state reached increasing leverage constraint ie, higher reducing capital increase rate new action would result reduction collateral use see section iii use jaccard network similarity index characterize stability bilateral trading relationship one period another level network stability exhibited fig consistent observation real financial network mentioned above, stationary state cannot reached slow evolution bank size heterogeneity again, instability vanishes model uniform growth rate ie figure show core periphery structure emerges network, even density much higher one reported lux notably, fig report time evolution value lip core periphery test kind structure emerges step stationary however, method assessing significance core periphery based different way characterize core periphery structure, lead conclusive result finally, generated network exhibit slightly asymmetric degree distribution see fig line literature see section here, unless specified differently, fix mean bank increase balance sheet year year step keeping size distribution power law exponent constant also set reach stationary state faster parameter set section iii simulation conducted step given simulation, define stationary value given observable metric example, network density average across last step run simulate run ie combination input parameter time finally report mean runs, excluding value outside one standard deviation, stationary level given metric assume new simulations, ensuring always enough collateral meet lcr need bank high value ie much collateral available absorb payment shock result shorter collateral chain lower use rate fig high value also associated high network density fig amount repo required bank proportional see section ii worlds, bank use central bank funding manage lcr therefore excess liquidity minimal fig even smallest shock must absorbed repo market decrease bank rely central banking funding manage lcr, thus generating higher excess liquidity fig lower network density fig one could expected collateral use decrease excess liquidity reduces effect payment shock yet, fig show opposite total collateral available system start becoming insufficient cover shocks, state define collateral scarcity mean enough collateral bank meet lcr requirements, total amount repo required absorb payment shock higher available collateral bank react collateral scarcity increasing length collateral chain fig line empirical observation also observe lower slope relationship density deposit outflow rate fig collateral scarcity reduces chance opening new repos, allows existing repos longer maturity however, lower enough collateral banking system absorb payment shocks, bank start relying central funding reserve management, generating high excess liquidity fig low network density fig low collateral use fig figure show core periphery structure significant range outside limits, density either high low generate structure lower volatility payment shocks, higher repo maturity shown fig note log scale abscissa axis fact, low volatility deposit allows bank hold position longer period consequence, low volatility payment shock also associated high network density fig high jaccard network similarity index fig high collateral use rate fig conversely, excess liquidity banking system increase volatility payment shock fig indeed, explained section ii bank lcr management generates excess liquidity absorb payment shock appendix show effect three control parameter rate capital increase, new tail exponent, governing bank size heterogeneity learning coefficient controlling speed trust level updated particular, appendix show rate collateral use related ability bank increase balance sheet size, tuned new model used study response money market various stress scenario name scenario relevant crisis recently faced banking system previous section fix parameter fixed section iii scenario corresponds disappearance new collateral system, bought central bank issuance accordingly parameter new set step figure show impact app money market essence, app provides money government deposit cash banking system, increasing excess liquidity excess deposit reduces need access interbank market, reducing density network number transaction concurrently, bank receiving large negative payment shock need funding repo markets, increasing average size repo transaction yet, find sufficient collateral available due app, hence must resort central bank funding overall, unwinding existing repos bank receiving smaller shock actually increase amount security usable fall money market almost complete end app, ultimately lead collapse core periphery structure note long recovery market step indeed, simulate maturing existing collateral, mechanically decrease excess liquidity reinforce need repo market scenario corresponds default large bank due failure loan economic agent case, chain collateral callback triggered counterpart defaulted bank transaction secured, contagion rest network however, economic agent record loss equal amount defaulted loan due loss deposit share defaulted bank consequence model loss trust among bank agents, leading bank contact counterparties randomly step fig show impact scenario money market bank contact randomly counterparties increase network density number transaction reduces average notional repo transaction network stability, measured jaccard network similarity index, drop beginning crisis quickly return almost previous level network stable bank connected almost possible counterparties consequence, core periphery structure vanishes added minimum trust level transaction occur, market would collapsed impact macroeconomic collateral aggregate scenario translates haircut collateral value thus, cash lender simultaneously request posting additional collateral enough new collateral produced, borrower cash reimburse existing repos request central bank funding leave future work development mechanism account daily margin call collateral value fluctuation order assess consequence scenario scenario materializes bank suddenly loses deposit order meet regulatory constraint, bank would request large amount liquidity central bank bank model, bank would survive bank run liquidity need would fulfilled access infinite central bank funding practice, receiving central bank funding actually requires posting collateral, although lower quality one used repo market hence, simulating crisis would require introducing second type collateral, leave future work designed minimal model money market cash flow approach, bank create money endogenously absorbing payment shock thanks repo transaction respect reserves, liquidity, leverage constraint framework shed light recent puzzle excess liquidity arises asymmetric response bank payment shock managing lcr bank cannot maintain reserve lcr minimum level absorb daily payment shock hence, excess liquidity disappear end app sale bond ecb moreover, find model collateral used due long canceling notice period repos hence, reducing practice would limit ability bank manage short term liquidity need collateral scarcity increase collateral use positive shock must absorbed borrower however, certain amount security banking system, repo market collapse stable bilateral trading relationships, asymmetric degree distributions, core periphery structure emerge effect trust among banks, similarly approach lux unsecured market used model assess impact two stress scenario disappearance new security app ii systematic loss trust gfc finding confirm positive impact full allotment procedure lcr regulation stability money market notably observe that, even repo market collapses, loan production maintained addition, secured transaction ensure absence contagion defaulted bank model also policy tool simulate change allotment procedure central bank regulatory constraint modification show changing individual regulation affect system unintended way notably, setting low level around deposit outflow rate significantly increase excess liquidity collateral use reduces network density decrease amount security held bank size largest payment shocks, ie repo market collapse excess liquidity explodes interbank market sensitive liquidity risk interest rate risk short maturity exposure however, introducing price framework would allow one model transmission central bank rate money market framework could explain another money market puzzle departure repo rate ecb interest rate corridor indebted david kass contributed significantly building structure early python code extend thanks thomas lux stefano corradin, contributed research fruitful discussion finally, thank bertrand hassani anrt cifre number providing u opportunity conduct research quant ai lab research conducted within econophysics complex system research chair, aegis fondation du risque, fondation de cole polytechnique, cole polytechnique capital fund management want model money creation positive shock fluctuating around average rate new money model formulated recall independent normalized centered gaussian random variable across bank time taking expectation eq yield similarly, taking expectation square eq give show non stationary increment small size taking logarithm eq assuming ie mean growth small compared fluctuation ln approximated mean variance note hence, sufficient large, central limit theorem, log return ln ln behave gaussian mean variance thus, limit process read brownian motion one check expression yield mean variance eq limit distribution type random process studied among others marsili et al gabaix mitzenmacher unfortunately process stationary limit unless prevent smallest bank become smaller certain barrier indeed, noticed mitzenmacher logarithm density distribution noted read clearly non stationary could hope solving issue defining bounded variable scaled money creation bank sum money creation bank limit large sum approximated mean, long variance sum small compared mean using eq central limit theorem large condition meet limit, density distribution function normalized variable read thus, large large precisely ln quadratic term becomes negligible variable behaves similarly power law exponent yet, term ln show bank size becoming infinitely small correcting behavior requires either defining negative drift pushing bank size towards barrier allow bank exchange wealth option contradiction requirement model practice, typical value per year, ie bank double balance sheet year, median bank grows observe distribution almost stationary step ie year count business day per year indeed, fig show distribution function relative size bank move slowly step complement section iii present influence several key control parameter unless otherwise specified, parameter set section iii simulation also conducted step previously, simulate run time report mean, excluding value outside one standard deviation, stationary level given metric leverage ratio constraint limit size balance sheet hence, less binding constraint ie higher amount new fund new measured leverage ratio equivalent, see section ii longer maturity repos fig result higher network density fig higher jaccard network similarity index fig higher rate collateral use fig high level bank size heterogeneity ie low value tail exponent associated low collateral use rate fig network density fig indeed, heterogeneity high, probability large positive shock hit large bank increase result excess liquidity fig reduces chance subsequent shock generate liquidity needs, thereby reducing collateral use network density core periphery structure emerges learning coefficient minimum level around fig value, bank learn enough quickly counterparties trade with, resulting high network density fig continuing ",general economics
"periodic portfolio selection quasi hyperbolic discounting introduction model dynamic programming equation pre committing sophisticated agent family one period optimization problem solution main problem discussion main result comparative static concluding remark appendix proof theorem appendix proof instruction reporting error economy periodic evaluation admissible strategy performance functional quasi hyperbolic discounting optimality criterion pre committing agent sophisticated agent introduce infinite horizon, continuous time portfolio selection problem faced agent periodic shaped preference present bias inclusion quasi hyperbolic discount function lead time inconsistency characterize optimal portfolio pre committing, naive sophisticated agent respectively theoretically challenging problem sophisticated agent, time consistent planning strategy formulated equilibrium static mean field game interestingly, present bias naivety necessarily result less desirable risk taking behaviors, agent sophistication may lead excessive leverage underinvestement bad good state world keywords portfolio selection, quasi hyperbolic discounting, present bias, time inconsistency, shaped utility, equilibrium, fixed point mathematics subject classification present bias well documented intertemporal behavioral bias individual refers tendency typical person enjoys receiving smaller sooner reward relative larger later one, preference reversed option delayed equally example, certain individual prefer getting one month rather three months, individual also prefer getting fifteen month rather thirteen month individual present bias disproportionately impatient short term outcome patient long term outcome phenomenon observed many experimental field study see, example, among others order capture decreasing impatience rate, hyperbolic discounting widely adopted popular alternative classical exponential discounting criterion particular, one special variant known quasi hyperbolic discounting found success enabling macro finance model produce consumption saving pattern consistent empirical data etc meanwhile, impact present bias individual risk taking behavior appears less commonly explored literature several theoretical study portfolio optimization quasi hyperbolic discounting, typical finding present bias component impact optimal portfolio choice example, consider similar portfolio optimization problem formulated optimal consumption investment problem based merton paper report optimal investment policy given classical merton ratio independent agent hyperbolic discount function irrelevance present bias risk taking perhaps surprising consumption based model reward functional solely depends agent lifetime consumption strategy investment decision portfolio value enter agent objective function directly rather implicitly appear within optimization problem level intertemporal budget constraint general formulation consumption investment problem non exponential discounting objective function depending intertemporal consumption terminal wealth, find open loop equilibrium strategy depend consumption utility discounted although depends discount function applied utility terminal wealth see remark meaningful investigation present bias affect investment behavior also found application beyond portfolio optimization example include real option corporate capital structure production economy merton style optimal consumption investment problem arguably important canonical approach study portfolio selection, many real life application framework perhaps appropriate example delegated portfolio management, agent fund manager overseeing portfolio client principal agent invests behalf someone else cannot directly consume underlying portfolio, rather incentive tied remuneration derived trading performance assessed regular basis moreover, agent preference may also deviate drastically standard concave utility function due managerial incentive distortion like limited liability protection well psychological bias described prospect theory end, adopt periodic portfolio selection model agent reward functional defined total discounted shaped utility portfolio performance across exogenously fixed period novel consideration study incorporate quasi hyperbolic discount function describe agent intertemporal preference since portfolio performance directly enters agent running reward function, present bias first order impact optimal investment strategy periodic portfolio selection quasi hyperbolic discounting therefore result mathematically economically rich problem, covered literature yet best knowledge contribution work twofold theoretical side, give complete characterization optimal portfolios, covering several criterion optimality deviation exponential discounting introduces time inconsistency dynamic decision problem following consider three type agent pre committing one solves optimization problem initial time follows derived strategy throughout rest investment horizon ii naive one keep optimizing beginning investment period, overriding optimal plan made past iii sophisticated one aware time inconsistency unable commit given strategy, hence act optimally current time point response action adopted future incarnation problem fall broad category stochastic control problem non exponential discounting theoretical work direction include previously cited paper optimal consumption investment problem non exponential discounting, well among others many cited work employ extended hamilton jacobi bellman hjb equation flow forward backward stochastic differential equation fbsde tool analyze time inconsistent problem, especially derivation intrapersonal equilibrium strategy adopted sophisticated agent wish stress structure periodic problem feature number modeling element make hard proceed classical approach first, periodic reward depend historical value portfolio therefore problem path dependent second, shaped utility function prevents u conveniently characterizing optimal portfolio strategy feedback control since difficult establish concavity convexity behavior value function upfront lastly, problem infinite horizon without terminal condition difficulties, arising conjunction time inconsistency multiple notion optimality, require u seek alternative avenue attack problem regard, contribute literature continuous time, time inconsistent stochastic control problem showcasing new mathematical technique rely commonly adopted primal hjb fbsde approach philosophy approach inspired utilizes combination discrete time dynamic programming principle martingale duality key insight type agent pre committing, naive sophisticated one attempt characterize optimal one period gross return portfolio via family finite horizon problem maturity given length evaluation period individual problem family solved martingale duality correct element family identified solving suitable fixed point problem depending nature agent found optimal portfolio gross returns, entire optimal wealth process constructed replication argument among three type agent consider, case sophisticated agent represents mathematically interesting challenging problem turn problem resembles static mean filed game countably infinite number player control parametrized random variable general, solution approach considered paper quite different existing literature believe shed light non standard time inconsistent control problem analyzed tool beyond standard method hjb fbsde parallel, work also make economic contribution portfolio optimization literature connecting present bias risk taking behaviors, connection received much attention date agent shaped utility generally risk seeking negative skewness, meaning tend gamble aggressively bad state world reduce risk taken good state world repeated nature periodic reward introduces continuation value component distorts agent utility function high level, agent degree present bias affect subjective weight across short term reward long term continuation value turn governs agent overall incentive eventually lead different investment behavior modeling framework provides useful theoretical foundation deduce important policy empirical implication concerning present bias managerial risk taking preview results, find present biased agent take less negatively skewed risk relative exponential discounter investment prospect sufficiently good bad ii sophisticated agent take negatively skewed risk compared naive counterpart rest paper organized follows section present modeling framework introduce three concept optimality section derive dynamic programming equation pre committing sophisticated agent auxiliary family optimization problem studied section used section characterize optimal portfolio strategy pre committing, naive sophisticated agent comparative static discussion economic intuition found section section concludes miscellaneous technical material collected appendix present periodic portfolio selection model follows closely let one dimensional brownian motion complete probability space denotes augmented filtration generated let work black scholes market consisting one risky asset one risk free money market instrument price process risky asset geometric brownian motion dynamic price process risk free money market instrument given assume constant write market price risk sharpe ratio risky asset throughout paper, assume unique pricing kernel black scholes market non degenerate expression agent form portfolio via investing dynamically risky asset risk free money market instrument portfolio value inspected sequence evenly spaced date here, given constant representing length evaluation period example, choice refers annual evaluation scheme introduce notion portfolio strategy loc let represent relative rate dollar amount invested risky asset time wealth initial time period specifically, represents dollar amount invested risky asset denotes agent wealth time dynamic wealth process fixed initial wealth given following recursion equivalently written denotes floor operator easy see path dependent sde unique continuous solution given unique continuous solution sde economically, gross return rate process portfolio th period observe depend wealth process dollar amount process depend literature, usual practice parametrize trading strategy via either proportion wealth invested risky asset dollar amount invested risky asset former approach, one typically considers loc denotes proportion wealth invested risky asset time dynamic wealth process given initial wealth given sde positive unique solution given therefore priori excludes possibility bankruptcy ie could indeed arise within problem latter approach, one considers loc represents dollar amount invested risky asset time corresponding wealth process given initial wealth dynamic given framework, future dollar amount invested risky asset chosen depending initial wealth time however, suitable purpose want allow dollar amount invested period, depending starting wealth problem, want control markovian notion defined relative rate dollar investment convenient way incorporate idea introduce following set admissible portfolio denote specifically, require admissible wealth process equivalently gross return rate process non negative wealth process markovian, semi markovian sense markov process framework, wealth allowed hit zero positive probability standard argument concerning non negative self financing portfolio, process nonnegative local martingale turn supermartingale implies static budget constraint hold remark bankruptcy absorbing state gross return rate becomes zero time stay there, ae actually, exists admissible let inf define classical doubling strategy time agent trading performance within period measured performance benchmark parameter performance measure positive gross return portfolio larger agent derives burst utility linked periodic performance given piecewise power utility function given here, parameter risk aversion seeking domain gain loss respectively, loss aversion parameter assume agent exhibit present bias consider quasi hyperbolic discount function given above, play role discount rate represents agent myopia level special case degenerate standard exponential discount function quasi hyperbolic discount function typically deployed discrete time model discount function current continuous time setup, assume agent discount outcome distant future heavily additional factor duration cut near term long term implicitly assumed definition form discount factor change beyond unreasonable assumption forthcoming evaluation date serve natural mental anchor agent place psychological focus happening current evaluation period, thus outcome within treated near term define reward functional total net present value utility infinite horizon beyond initial time ie agent completely myopic sense care performance future period case, reward functional reduced standard finite horizon maximization problem solution optimization problem functional well known see example optimal wealth process given satisfying satisfying time preference reduced usual exponential discounting, problem becomes one studied agent time preference exhibit non degenerate quasi hyperbolic discounting portfolio optimization featuring shaped utility quasi hyperbolic discounting considered literature date main goal paper study corresponding optimal portfolio different concept optimality following impose standing assumption sufficient condition ensure well posedness problem model parameter constant defined related solution finite horizon merton problem via sup well known non exponential discounting induces time inconsistency discrete family optimization problem time inconsistent following sense even optimal portfolio restriction future period might optimal therefore even clear upfront meaning optimality presence quasi hyperbolic discounting following consider three different notion optimality pre committing, naive, sophisticated fix reference time pre pre said optimal pre committing strategy respect time pre committing agent solves optimization problem initial reference time point, say time zero agent able adhere derived optimal strategy pre throughout rest investment horizon agent ever attempt reevaluate strategy future, say find pre strategy give maximized value long able commit, stick pre perpetually even though becomes sub optimal reviewed future pre pre optimal pre committing strategy respect time defined definition naive said optimal naive strategy unlike pre committing agent, naive agent always reoptimizes beginning period trading strategy taken period guided first period segment solution problem sup overriding planned strategy derived past implicit assumption making definition naive agent still able commit derived strategy pre duration one period reoptimization take place beginning period reasonable assumption expect individual indeed capable self control relatively short time horizon last notion optimality intrapersonal equilibrium strategy adopted sophisticated agent case, agent aware suffer time inconsistency able commit strategy one period view future incarnation themself cannot control opponent sequential game act optimally current period response strategy adopted future self equilibrium achieved incarnation agent time point incentive deviate chosen action stating formal definition, need introduce notation denotes restriction let define concatenated portfolio strategy said subgame perfect equilibrium portfolio strategy sophisticated agent call corresponding wealth process initial wealth equilibrium wealth process, function equilibrium value function corresponding problem definition game countably infinite number player compared finite horizon time inconsistent problem, existence subgame perfect equilibrium highly nontrivial issue since boundary condition given terminal reward concerning uniqueness, conjecture may generally multiple equilibrium see discussion section moreover, unlike time consistent problem, equilibrium value function may unique, depends subgame perfect equilibrium portfolio strategy section, derive dynamic programming principle associated optimization problem faced pre committing agent sophisticated agent define represents reward functional faced exponential discounter ie agent one express reward functional possibly myopic agent term exponential discounter particular, observe define pre committed value function depend due time homogeneous structure problem similarly, let value function exponential discounter dynamic programming principle, scaling property utility function constant pre exp defined moreover, standard martingale duality argument, optimization performed one period stochastic gross return rate rather trading strategy formally, define set random variable defined economically, contains terminal wealth variable time attained non negative self financing portfolio black scholes economy starting one unit initial capital substituting ansatzes, dividing side taking decision variable, becomes goal solve pre exp system identify pre exp satisfying pre represent optimal gross return variable first period, exp optimal gross return variable subsequent period particular, portfolio satisfying optimal pre committed portfolio here, exp pre exp pre denote measurable copy exp pre respectively consider case sophisticated agent via deriving extended bellman equation similar one studied inspired benchmark problem without present bias, focus searching equilibrium strategy periodic, sense identically distributed represents reward functional exponential discounter given strategy periodic portfolio subgame perfect equilibrium strategy following hold thanks periodicity moreover, independent joint distribution depend therefore, then, definition subgame perfect equilibrium hand, thus, periodic portfolio subgame perfect equilibrium strategy system extended hjb equation spirit proceed further, exploit scaling property utility function form constant determined depend using ansatzes followed division side obtain analysis pre committing problem, one replace decision variable write extended bellman system expressed observe that, standing assumption sup hence express eliminating system, get main goal find solving system exists, equilibrium gross return variable standard replication arguments, exists measurable independent copy strategy periodic equilibrium strategy solving problem faced sophisticated agent moreover, corresponding equilibrium value function challenging solve system optimization problem involves unknown constant unknown random variable simultaneously determined part solution interestingly, analogous static mean field game following sense current self agent responding countable infinite number player agent infinite copy future self subsequent period whose collective strategy induces value probability distribution eventually fed back objective function current self special case simplifies objective function last term longer depends problem degenerate one faced exponential discounter considered another special case agent completely myopic, becomes involves solving standard one period portfolio optimization problem terminal utility function analysis section characterization optimal portfolio entail solving system precommitting agent sophisticated agent section, study family one period portfolio optimization problem serve important building block construction solution problem introduced section now, consider family optimization problem parametrized defined problem studied detail rest section, briefly recap key result also state new one along way approach solve problem consider concavified problem sup smallest concave majorant subtlety value heavily influence monotonicity concavity convexity behavior turn recall following result four canonical case fix let smallest concave majorant define straight line slope joining two constant unique solution system equation straight line slope joining unique solution equation straight line slope joining defined unique solution equation reader referred figure ec graphical illustration four case corner case therefore case lemma vanishes range case becomes describe solution problem need introduce several notation define unique solution equation similarly, let unique solution equation simple calculus, easy verify strictly decreasing bijection strictly decreasing bijection map monotonic hard show still admits unique solution including hence, although unnecessary, extend domain cater possibility well defined also hard verify non increasing non decreasing finally, also jointly continuous see corollary appendix recall definition suppressed dependence optimizer problem function defined follows depending value case constant defined unique solution equation given full proof found provide brief sketch proof introduce notation used subsequent result suppress argument brevity suppose fixed let smallest concave majorant legendre fenchel transformation defined corresponding maximizer characterized set valued function define via note one hand, monotone convergence theorem fact strictly deceasing strictly decreasing hand, atomless together continuity suggest continuous due dominated convergence theorem exists unique turn admissible thus therefore sup one check bijections since atomless support support hence must optimizer problem case handled similarly result case follows trivially upon checking unique global maximum attained clearly admissible likewise, case unique global maximum attained admissible stated condition parameter practical purpose, need consider case lemma choice eventually endogenized study original periodic portfolio selection problem, relevant value never range described see remark well careful reader may notice avoided corner case lemma corner case carry important theoretical implication separately discus via following proposition optimizer problem unique null set, ie arg max optimal problem before, suppress argument suppose case lemma already know lemma maximizer problem defined show maximizer unique, let another optimal random variable attains value let defined suppose definition hence since also leading contradiction here, used fact strict inequality hold whenever hence must conclude finally, since atomless deduce thus almost surely case analyzed similarly case also easy handled attains unique global maximizer either feasible optimizer put probability mass unity unique global maximizer straightforward check global maximum attained ie clearly hence must optimizer conversely, suppose arg max leading contradiction hence must lack uniqueness optimal portfolio addressed optimization point view, uniqueness perhaps economically important issue long one characterize least one strategy achieve optimal value corner case report optimal solution generally, proposition suggests feasible digital option payout also considered optimizer unlike careful analysis corner case actually required current problem since influence characterization equilibrium strategy pursued sophisticated agent necessary analyze case proposition optimally endogenized value always strictly positive see remark map defined analogous discrete time bellman operator show map admits unique fixed point used construct solution portfolio optimization problem follows, prove general result map contraction particular exists unique map continuous, hold that, maximizer problem furthermore strictly increasing equality hold strictly decreasing equality hold strictly decreasing equality hold contraction property shown proposition ec immediately implies that, map contractive, hence unique fixed point note let fixed thus hold since arbitrary, upon swapping also deduce therefore, implies sign depend also, estimate, together sup easily show thus, continuous suppose equivalent let noting see hence, strictly increasing suppose equivalent let noting see hence, turn non increasing furthermore, lemma proposition choose positive probability, thus third inequality strict, ie hand, take as, thus implies particular, hold hence strictly decreasing otherwise, function strictly decreasing complete proof, verify necessary sufficient condition equality hold case here, recall maximizer thus equality hold turn also maximizer suppose case case equality hold maximizer unique characterization maximizer lemma proposition implies fixed point therefore, since strictly increasing resp decreasing case resp case must reverse implication implies equality hold trivial suppose case exists maximizer consider two sub case property strictly decreasing argument used case above, conclude characterization maximize binary random variable constant zero case, implies conversely, choose maximizer also maximizer choice, lead thanks arbitrariness soon see help u characterize value function different type agent see particular remark numerically solve say fixed one generate sequence iteratively via arbitrary initial guess step iteration requires u solve optimization problem form repeated many time suitable error tolerance criterion met proposition necessarily turn proposition consequently, cannot range described similarly, non negative easy conclude well moreover, either case numerical estimate generated iteration guaranteed strictly positive long one chooses optimizer problem identified solely part lemma close section presenting important result concerning fixed point set valued map see section property crucial behind characterization equilibrium strategy sophisticated agent complete proof following theorem long technical, thus deferred appendix define set valued map via admits fixed point ie specifically least one fixed point exactly one fixed point given arg max exactly one fixed point ready state main result paper characterizing optimal portfolio type agent associated economic intuition thoroughly discussed section recall defined proposition exists unique pair pre exp solving system exp pre optimal reference time pre committed value function given moreover, exists optimal pre committing strategy pre pre pre corresponding portfolio process pre satisfies function defined lemma pricing kernel black scholes economy given contraction proposition hence exists unique exp exp exp pre exp exp unique solution system rest proof similar theorem without loss generality, work optimal time zero pre committed strategy admissible portfolio process arbitrary suppress superscript brevity define discrete time stochastic process via turn notice measurable, turn independent since non negative supermartingale admissible portfolio strategy therefore exp exp design thus deduce hence definition pre thus supermartingale respect turn recalling using solution finite horizon merton problem estimate using assumption taking limit supremum deduce show reverse inequality pre pre one need construct admissible portfolio process attains value pre using usual replication argument complete market, exists admissible pre pre satisfies define process fashion except replace using fact optimizer problem one show indeed martingale inequality become equality one ultimately conclude ratio capture change pricing kernel, reflects state world change within period moreover, iid common law identical pre committing agent thus trade way periodic gross return independent across period moreover, target gross return risk profile described exp first period, subsequent period target different payoff exp construction, exp fixed point exp arg max exp pair exp exp therefore represents exactly value function periodic portfolio selection problem faced exponential discounter ie agent without present bias equivalently corresponding optimal target gross return, benchmark problem studied setup, mean myopic pre committing agent invest way exponential discounter target law exp first period observation surprising agent discount future payoff using sequence discount factor today, anticipate behave like exponential discounter second period onward use discount factor modulo scaling factor thus, today, plan trade like exponential discounter starting second period due present bias short term outcome first period, plan deviate exponential discounter strategy first period risk profile characterized exp agent cannot commit planned strategy agent instead naive defined definition keep reoptimizing updating strategy beginning period following corollary straightforward consequence theorem exists optimal naive strategy naive corresponding portfolio process naive satisfies function defined lemma pricing kernel black scholes economy given time zero pre committing agent plan take risk exp first period switch different form risk exp second period onward however, agent turn naive, arrive beginning second period reoptimize strategy conclude current best action take risk exp second period later switch exp beginning third period naive agent run infinite loop reoptimization eventually take risk exp period exists pair solving system furthermore, exists periodic subgame perfect equilibrium strategy sophisticated agent corresponding portfolio process satisfies function defined lemma pricing kernel black scholes economy given soph constant defined via first show exists solves system recall proposition definition fixed point theorem exists fixed point set valued map define last equality due construction hence therefore solution using standard portfolio replication argument, exists periodic resulting portfolio process satisfies copy soph law design satisfies satisfies indeed subgame perfect equilibrium due proposition theorem suggests agent trade way periodic gross return equilibrium portfolio follows common target law soph unlike strategy adopted pre committing agent, target law sophisticated agent remains across period sophisticated agent therefore act similarly naive agent, sense type agent target iid law periodic gross return across period suppose ie exclude case exp define target law sophisticated agent exp note expression, property non trivial verify claim proposition sophisticated agent regarded naive agent modified present bias parameter endogenously depends agent natural present bias parameter since soph depends section contrast behavior sophisticated naive agent comparing close section, address uniqueness equilibrium strategy sophisticated agent useful first introduce economically important quantity value function one period optimization problem equivalently version problem faced completely myopic agent note sign myopic depend time preference parameter agent, soon see section quantity significant economic impact agent risk taking behavior let two periodic subgame perfect equilibrium strategy iid periodic gross return variable induced myopic consequence proposition subgame perfect equilibrium portfolio unique null set within class periodic portfolios, least assumption myopic despite able prove formally, numerical evidence seems suggest proposition also hold case myopic formal verification conjecture left future work done recall constant arising characterization optimal equilibrium strategy different type agent words, value function pre committing, completely myopic sophisticated agent present bias, well agent exponential discounting preference, connected function introduced proposition observation help u establish comparative static next section sophisticated agent, value fixed point defined theorem may unique general case, interpret soph using expression fixed choice summarize theoretical finding section different type agent trade way periodic gross return portfolio follow independent distribution given solves auxiliary problem form here, represents realized change state world within one period, choice depends nature agent exponential discounter choose exp period pre committing agent choose exp first period exp subsequent period theorem naive agent take exp period corollary sophisticated agent pick soph equivalently exp period theorem discussed see lemma well different value result different probabilistic behavior optimizer positive value optimal gross return always strictly positive without atom attached zero upside unbounded however, mildly negative value probability mass zero, ie chance portfolio ruined end period downside risk typically associated excessive leverage portfolio experiencing loss becomes moderately negative range support also upper bound mean growth potential portfolio becomes capped, addition bankruptcy possibility signified atom zero case, agent engages excessive risk taking bad state world also disinvest good state world case highly negative value mathematically degenerate one agent intentionally go bankrupt via suicidal strategy eg doubling strategy avoid terminal penalty caused negative informally, say smaller value lead payoff profile negatively skewed risk sense agent tends take less risk losing winning value endogenized affect risk profile portfolio drastically detailed economic explanation found highlight main idea briefly, due trade maximizing reward current period continuation value agent incentive summarized effective utility function restate large positive, continuation value per unit capital available start next period large positive agent seek less risky strategy prioritizes value preservation guarantee solvency close zero, agent care whether portfolio go bust current period continuation value future reward insignificant shaped utility function incentivized gamble aggressively falling behind expose portfolio bankruptcy risk load risk ahead without taking long term prospect consideration, resulting negatively skewed strategy extreme case moderately negative, continuation value negative discourages portfolio growing much due phenomenon underperformance aversion agent intentionally limit portfolio growth avoid setting higher absolute benchmark adopted subsequent evaluation result even negatively skewed periodic payoff upside growth bounded since endogenized value heavily influencing risk profile optimal portfolio, useful establish ranking value across different type agent recall definition myopic exp soph remark case myopic define soph exp given myopic exp exp soph myopic soph exp exp particular, myopic exp soph exp particular, exp soph exp result mostly follow proposition remark part trivial part myopic implies exp hence obviously exp exp meanwhile, choice recall construction proof theorem moreover, part proposition equality hold equivalently would imply ie contradiction hence must soph exp part myopic hence similar argument used part proof strictly decreasing property first inequality becomes equality hold would lead contradiction hence exp soph exp part proposition together argument used part proof would allow u conclude soph exp proposition require uniqueness equilibrium periodic strategy theorem following discussion, assume case investment prospect valuable myopic exp exp pre committing agent take negatively skewed risk exp first period however, plan reduce risk level exp second period onward, level risk rational exponential discounter would taken right beginning agent turn naive cannot commit planned strategy, taking risk exp period economically, agent indefinitely delaying action de risking ie switch negatively skewed risk exp safer one exp example procrastination induced time inconsistency, could potentially costly term welfare undertaking negatively skewed risk considered socially undesirable example linkage among procrastination, hyperbolic discounting social welfare losses, see example economically, pre committing agent first period naive agent take risk exponential discounter myopic recall main economic mechanism periodic portfolio selection model trade reward current period future period pre committing agent naive agent think behave like exponential discounter starting second period time rational trade simply governed versus exp suffer present bias weight across component distorted trade becomes versus exp instead present bias make agent impatient short term outcome hence continuation component carry smaller decision weight due multiplication factor myopic exp contribution continuation value component exp decrease relative rational benchmark exp hence agent care less long term performance portfolio turn inclined take negatively skewed risk opposite phenomenon occur myopic exp contribution continuation value exp larger ie less negative relative rational benchmark exp here, present bias induces agent focus outcome current period worry less potential penalty due underperformance future consequently, agent willing take risk way would result better upside potential portfolio indeed, model parameter exp exp corresponding optimal gross portfolio return exponential discounter myopic naive pre committing first period agent drastically different support former capped latter enjoys unlimited upside see lemma either case myopic sophisticated agent always take negatively skewed risk naive agent revealed soph exp perspective time zero, three type agent agree behave exponential discounter second period onward pre committing agent naive agent think able adhere plan, therefore present bias adjusted continuation value agent exp however, sophisticated agent anticipates advance suffer time inconsistency sub optimally perspective today deviate exponential discounter strategy future know sub optimal strategy adopted future self result lower net present value continuation component, say relative exponential discounter benchmark exp consequently, optimization problem faced current self sophisticated agent involves present bias adjusted continuation value component smaller exp correct choice determined equilibrium condition among incarnation agent sequential game simply speaking, fact sophisticated agent aware time inconsistency make pessimistic value future reward relative pre committing agent first period naive agent, result sophisticated agent willing adopt strategy higher negatively skewed risk alternative perspective, sophisticated agent regarded naive agent adjusted present bias parameter soph exp proposition suggests resp myopic resp myopic sophisticated agent version naive agent stronger resp weaker present bias words, sophisticated agent discount long dated positive negative outcome less heavily investment prospect un favorable consistent idea sophisticated agent pessimistic valuation future outcome relative naive agent situation myopic theoretically interesting corner case strategy adopted three agent become indistinguishable degenerate one adopted completely myopic, one period agent condition depend time preference parameter agent case, value one period investment game neutral agent, value remains neutral even agent play game repeatedly applying sequence quasi hyperbolic discount factor neutral outcome make less attractive agent discussion visually summarized figure illustrates risk taking level different type agent state world varies plot optimal proportion wealth invested risky asset function running periodic log return risky asset see proposition ec expression quantity figure myopic exponential discounter take least amount negatively skewed risk investment level lowest highest bad good state world among type agent investment level pre committing naive agent numerically close sophisticated agent, closer inspection figure still reveal latter invests less bearish bullish market leading less negatively skewed risk taken overall myopic figure show type agent engage excessive leverage without upper bound investment level bad state world due proposition exp exp soph negative myopic hence case periodic gross return variable atom zero, associated unboundedly large risk taking downturn investment level different type agent close bad state world, exponential discounter indeed invests risky stock declining value, followed pre committing naive agent, sophisticated agent finally completely myopic agent ranking investment level clearer positive return regime, opposite negative return regime case, rational exponential discounter actually take way negatively skewed risk present biased counterpart note either case myopic myopic sophisticated agent invests less naive agent bad good states, albeit small numerical difference portfolio strategy negative skew risk deemed economically undesirable eg social planner might want advocate long term, steady financial growth minimizing insolvency risk within asset management sector sophisticated thinking indeed detrimental naivety welfare viewpoint certain conditions, also establish risk profile strategy varies within type agent view soph soph quantity depending myopic fixed point defined unique, exp soph non decreasing myopic exp soph non increasing figure numerically compare exp exp soph different value qualitative behavior plot agree theoretical statement shown proposition exp soph numerically similar echo observation figure optimal strategy naive sophisticated agent close phenomenon seems holding wide range model parameters, suggesting optimal naive strategy could reasonable approximation interpersonal equilibrium strategy sophisticated agent investment prospect favorable myopic stronger present bias smaller negatively skewed risk taken first period pre committing, naive sophisticated agent economic intuition largely before, stronger present bias generally induces agent put relatively larger decision weight current reward favor negatively skewed strategy otherwise investment prospect poor myopic smaller make agent less concerned penalty embedded negative continuation value turn willing take strategy could yield higher upside refer figure numerical example optimal investment level varies type agent paper, show present bias heavily influence agent risk taking behavior context periodic portfolio selection depending attractiveness underlying investment opportunity, present bias either moderate exaggerate undesirable trading strategy result negatively skewed portfolio return relative naive agent, sophisticated agent invests market downturn deleverage conservatively market rally current study focus describing behavior present biased agent criterion optimality normative status result directly addressed, sense offer recommendation agent actually behave quantify associated social cost deviation recommendation discussion skewness portfolio return might offer guidance, full welfare analysis interesting direction future work yield precise policy insight area delegated portfolio management already long strand literature addressing social implication present bias time inconsistency consumption saving behavior see among others specific follow research question framework may include, example, welfare benchmark considered evaluate portfolio strategy adopted certain type agent, demand commitment device endogenized, quantify social value paternalistic policy risk regulation portfolio manager entire section dedicated proof theorem concerning existence fixed point set valued map defined begin studying theoretical property closely related map defined recall definition lemma defined singleton suppose unique solution equation defined pdf cdf log normal random variable part statement trivial part follow immediately proposition fact unique optimizer problem proposition optimizer must satisfy hence prove part hence sufficient establish result follow observing expressed using continuity strict monotonicity fact stated condition turn implies existence first argue suppose ie construct random variable via obviously measurable, thus next, show reverse direction suppose ie measurable, write note requirement implies otherwise contradiction set finally, quantile function random variable given hardy littlewood inequality general probability space see, example, part ii theorem state quantile function specialization yield therefore conclude hence equivalence established singleton hence interpreted ordinary function slight abuse notation, rest section view case singleton element set non decreasing second part lemma obvious since prove first part, consider exists arg max sup note long unique uniquely defined suppose contrary arriving contradiction hence must proceed prove continuity high level idea follows quantity function lagrangian multiplier defined section related unique solution equation parametrized make use result state unique solution equation parametrized parameter indeed continuous parameter solution life compact space optimizer problem expressed random variable depends continuously, ultimately integral integrand continuous following lemma building block argument let jointly continuous function metric space compact fixed exists unique continuous function arbitrary let sequence since continuous since compact, sequence convergent subsequence limit joint continuity implies hence uniqueness solution ie convergent subsequence must limit thus must lim establishes continuity since application lemma requires solution space compact, useful establish bound several fundamental quantity appear within optimizer problem let positive constant arbitrarily small arbitrarily large recall definition section exists constant independent exists constant independent defined unique solution respectively defined unique solution give proof corner case able express explicitly term system equation defining degenerate single equation upper bound obtained easily now, recall satisfies define unique solution hence using property non decreasing non increasing meanwhile, also satisfies define unique solution equation hence used definition monotonicity lastly, satisfies strictly decreasing one define unique solution equation equivalently take conclusion follows immediately noticing note definition unique solution hence, range must observe also that, since deduce hand, define unique solution equation definition non decreasing claim follows fact non decreasing follows immediately fact non increasing non decreasing result due fact non increasing non decreasing upper bound, particular, non decreasing hence special case becomes infinite indeed per remark need consider non positive value view function continuous continuous jointly continuous jointly continuous fix consider part lemma know life compact set hence one define map via characterize unique solution equation trivially continuous hence continuity follows lemma since arbitrary, extend conclusion continuity immediately follows since continuous composition part proven similarly show proof part requires slightly different argument recall unique solution equation fix define part lemma ie compact set therefore view map characterize unique solution equation continuous lemma letting continuity hold recall definition case lemma view function continuous continuous suppose case arg max unique solution equation recall denotes pdf fix arbitrary constant let max define unique solution equation since non increasing must following similar argument, deduce defined solution min continuous due continuity shown corollary lemma implies solution continuous continuity extended due arbitrariness case handled similarly optimizer take simpler form using monotonicity computed explicitly equation similarly, lower bound last equality hold construction clearly unique solution equation continuous moreover, lim defined first show continuous case singleton given integrand continuous since continuous corollary moreover, upper bounded defined proof proposition last expression integrable using fact small page ec companion continuity follows dominated convergence theorem arbitrary, conclude continuous similar argument, deduce continuous finally, show lim using continuity stated assumption lim simply solution equation equation admits explicit solution budget constraint fatou lemma, lemma fact strictly increasing, defined proposition note satisfies now, one choose converging subsequence hand, lemma hence therefore conclude finally, since monotonic, converging monotonic subsequence limit lemma bounded convergence theorem recall defined function defined proposition clearly, linked via following property singleton continuous, monotonically increasing strictly positive function arg max strictly positive constant singleton non increasing moreover, strictly positive singleton singleton continuous defined moreover, lim first claim that, case implies suppose exists lemma know optimizer construction fixed point must implies claim follows proposition strictly negative non increasing strictly decreasing since stated result easily follow property proposition proposition note sup unique optimizer zero almost surely, turn occurs hence must strictly positive strictly positive singleton remark special case implies due proposition hence strictly positive singleton optimizer non degenerate unique lemma useful result establishing comparative static respect write stress dependence fixed non decreasing resp non increasing resp proposition lemma theorem set valued map non decreasing note result follows fact dependence proposition positive strictly increasing resp negative weakly decreasing resp observation non negative strictly increasing finally ready prove theorem using property derived proposition closed graph non empty convex kakutani fixed point theorem, least one fixed point exists constant singleton given arg max hence must unique fixed point show fixed point unique suppose contrary fixed point definition five possible case ii iii iv case cannot happen would imply contradicts fact non increasing case ii cannot happen contradiction case iii cannot happen would otherwise imply turn lim contradicts fact continuously non increasing case iv also cannot happen would contradiction case impossible since lead contradiction thus fixed point must unique without loss generality, need prove let equilibrium value function corresponding first period equilibrium gross return variable induced constant must solution proposition consequently, must fixed point due uniqueness fixed point myopic per theorem recall definition since proposition must unless suppose myopic proposition therefore hence must instead myopic proposition suggests requirement uniquely determines law remark, expression well defined probability value second inequality due property proposition fact fixed point last inequality due definition finally, hardy littlewood inequality must quantile function see part ii theorem conclusion follows fact probability distribution monotonicity exp obvious exp depend stated assumption, let unique fixed point myopic known proposition turn positive non decreasing hence result follows show non decreasing proposition strictly positive singleton unique fixed point, must given crossing diagonal line together lemma suggests non decreasing must non decreasing well myopic lemma non increasing implies non increasing well write defined note dependence non decreasing, must result immediately follows observing soph continuing",general economics
"predicting company growth econophysics informed machine learning introduction constructing hybrid prediction framework data preprocessing experiment conclusion discussion instruction reporting error mechanistic growth modeling growth equation company time series forecasting technique data setting model setting comparative modela prediction result analysis organization department system science, beijing normal university, city beijing, country china organization swarma research, city beijing, country china organization department data science ai, monash university, city victoria, country australia predicting company growth crucial strategic adjustment, operational decision making, risk assessment, loan eligibility review traditional model company growth often focus much theory, overlooking practical forecasting, rely solely time series forecasting techniques, ignoring interpretability inherent mechanism company growth paper, propose machine learning based prediction framework incorporates econophysics model company growth model capture intrinsic growth mechanism company led scaling law fluctuation influenced random factor individual decisions, demonstrating superior predictive performance compared method use time series technique alone advantage pronounced long range prediction task explicitly modeling baseline growth volatility components, model interpretable company fundamental unit contemporary economic activity forecast company growth, including prediction sales, costs, assets, key indicators, help evaluate company future performance turn, evaluation provide valuable guidance strategic decision making, risk assessment, moreover, company complex system characterized numerous internal information flow interaction exhibit typical behavior complex system understanding modeling growth company also helpful constructing complex system theory however, predicting company growth accuracy explanatory power remains challenge rapid changes, sensitivity environmental factors, lack mechanistic understanding growth process complexity make difficult discern inherent rule governing company amid fluctuation uncertainty generally, study predicting company growth financial field use financial indicators, reports, information, combined data mining time series forecasting techniques, predict company future performance field primarily divided trend distress prediction, time series forecasting trend distress prediction involves use historical data assess likelihood future outcomes, typically classification task example, type prediction could include making preliminary risk assessment company et al predicting whether company might face bankruptcy future alaka et al hand, time series forecasting focus predicting company future stock price financial indicators, including revenue barker et al mishev et al sale nana et al wisesa et al koenecke gajewar punam et al catal et al cheriyan et al ,net profit xinyue et al lee et al ding et al recent advancement machine learning yielded exceptional result time series prediction, extending various application finance obthong et al ozbayoglu et al henrique et al sezer et al method used also diverse alaka et al summarized cutting edge technique bankruptcy prediction, including statistical tool multiple discriminant analysis, logistic regression, several artificial intelligence tool artificial neural networks, support vector machines, genetic algorithm time series forecasting task, regression tree based models, random forests, applied enormous financial time series prediction task nana et al wisesa et al xinyue et al weinblat medeiros et al addition, neural network often dominate performance various scenario rnn lstm model widely used stock prediction koenecke gajewar nelson et al fischer krauss sale forecasting koenecke gajewar mishev et al model even combine advanced data mining techniques, sentiment analysis enhance prediction jaggi et al mai et al mishev et al model also combined technique space time prediction lai et al self attention ruan et al however, model achieve high accuracy, often rely complex process feature extraction engineering although effort automated feature extraction et al increased model complexity tends decrease interpretability additionally, research focus single variable forecasting, forecasting involves multiple financial metric could help provide comprehensive evaluation company performance statistical law econophysical model company growth constitute another interesting direction buldyrev et al jakovac unlike direct predictions, area inclined seek pattern firm growth basis mathematical physical approaches, aim establishing mechanistic model understanding company growth process statistical level quantitative law firm growth traced back gibrat law gibrat law assumes company growth rate random variable independent company size later proven incorrect, remains important baseline model stanley made breakthrough modeling company growth stanley stanley first discovered that, given company size, distribution growth rate tent shaped rather gaussian, described gibrat stanley also reported fluctuation growth rate decay following power law company size increase finding suggests firm growth behavior appears highly random, may inherent rule process firm growth subsequent work proposed model firm growth, scale dependent growth model fu et al langevin equation zambrano et al mean field theory mizuno et al others podobnik et al however, purpose model reproduce macroscopically observed statistical phenomena, provide enough insight individual company prediction recent study zhang et al econophysical field established mechanistic growth model asset growth company basis scaling law financial balance equation conducting empirical test u chinese markets, author found model captured average growth companies, essentially detected inherent growth pattern company recent study zhang et al established mechanistic growth model asset growth company basis scaling law financial balance equation conducting empirical test u chinese markets, author found model captured average growth companies, essentially detected inherent growth pattern company however, model consider impact external noise companies, company well known sensitive external disturbance thus, model prediction resemble growth company ideal situation basic average growth although approach theoretically elegant simple, still lack sufficient guidance making prediction individual company recent years, physic informed neural network pinns become highly popular field leveraging prior knowledge physic combined machine learning techniques, pinns made significant advancement various application karniadakis et al prediction tasks, pinns achieve high accuracy also offer degree interpretability due incorporation physical knowledge domain company growth, best knowledge, integration still early exploratory stages, paper aim advance field proposing call econophysics informed model here, propose framework combine time series forecasting technique growth model proposed zhang et al divide change company growth two part basic growth fluctuation growth model used model company mechanistic growth, time series forecasting technique used model impact fluctuation growth contribution summarized follows extend growth model asset modeling approach model growth property company scaling law relationship asset model significant advantage term predictive power, especially long term prediction model combine advantage mechanism model time series prediction techniques, performance model analyzed separate modules, interpretable paper organized follows first introduce whole framework section section describes data preprocessing next, introduce detail two part model section present prediction experiment section interpretability analysis section validate ability model finally, section summarize contribution highlight future potential direction framework implement novel approach combine growth model proposed zhang et al time series forecasting technique central premise work divide growth company two components, namely, mechanistic growth fluctuation process captured eq equation above, serf placeholder various financial indicator company time concerned could include company asset key financial indicators, revenue, liabilities, costs, etc, long exhibit power law relationship asset growth model gm represents mechanistic growth company growth driven first principle capture average growth market embodies change occur result fluctuations, volatility environment, competition dynamics, personality decision leader, captured time series forecasting technique overall framework model shown figure advantage approach build general forecasting model growth individual company gm capture base growth process, time series forecasting technique capture micro growth fluctuation introducing variable improve prediction following sections, provide comprehensive description two components, unraveling technical detail interplay broader context company growth study conducted zhang et al successfully developed mechanistic model encapsulates company growth model founded two pivotal verifiable assumption first assumption involves observation company size exhibit power law relationship various financial indicator time, mean company are, average, self similar scale invariant year observation size company measured various measure assets, number employees, indicator reflect size company dang et al relationship mathematically represented indicator company size stand various financial indicators, liabilities, costs, revenue, etc key observation serf foundation establishing statistical, quantitative connection diverse financial indicator second assumption revolves around understanding company asset growth driven primarily accumulation capital, composed mainly net profit growth liability reasonable approximation behind equation, omission dividend detail argument found literature zhang et al derivation, insight prompted formulation differential equation asset growth power law parameter exponent constant liability, respectively, net profit detail equation found zhang et al equation outline growth company first principle perspective, lending intuitive comprehensive understanding company growth dynamic assumption offer innovative approach comprehending growth trajectory ideal company, tying together relationship various financial indicator influence net profit investment especially liability company asset growth here, make prediction wider range financial indicators, rather assets, extended equation financial indicator basis scaling law asset ultimately, derived general growth equation equation according context, integral result equation corresponds gm component mentioned equation input gm asset variable want predict time note prediction related asset value step therefore, every financial indicator power law relationship assets, calculate mechanistic growth specific method parameter explained detail empirical validation section gm capture average growth trend market shown figure enough predict complicated micro trajectory reality reason, introduce time series forecasting technique model remaining growth fluctuations, denoted theory, time series technique used framework input part variable combination variable conducive prediction, including historical financial time series, macro variables, etc, thus, actually, vector output previous part, predictive variable need, mainly refers financial variable framework, time series prediction technique need predict original predicted value rather, need predict difference predicted value output gm part, reduces prediction difficulty original dataset come compustat, encompassing nearly year annual financial statement data publicly traded north american companies, spanning feature extracted primarily three core financial statement additionally, gathered macroeconomic data u compustat north america compustat historical database compiled standard poor screened preprocessed raw data follows feature selection first, removed feature whose missing value greater noise reduction filtered company time series less year company appear dataset year neither serve training sample predicable then, also filtered year abnormal data appear financial statements, liabilities, income costs, etc, negative zero type data considered anomalous need eliminated missing value imputation year missing data dataset, previous step anomaly handling may also leave spot data missing paper experiments, missing value middle, used average time series data replace missing value endpoints, used previous subsequent value replace inflation adjustment applied inflation adjustment monetary data across different years, serving base year adjustment made via year average inflation consumer price icp logarithm transformation took natural logarithm monetary data scaling indicator may negative value profit, cash flow, etc, data cash flow statement value occasionally occur number employee developed linear log method practice, shown equation represents sign indicating whether positive negative method achieve effect taking logarithm scale negative value similarly, also used within interval end, retained financial feature macroeconomic feature companies, constitute entire dataset also mean dimensionality input time series module carefully selected indicator provide u comprehensive view financial performance economic environment associated company detailed feature shown table table feature selected encompass wide range financial health indicators, profitability, liquidity, leverage, along key economic factor may influence company performance, inflation rate gdp aim build dataset robust enough capture multifaceted nature company growth influencing factor following sections, introduce detailed information organize data specific model use experiment use set company train neural network model outstanding performance across different task financial prediction mission here, use classical powerful framework called lstm although many neural network framework proposed recently, believe lstm simple enough verify idea experimental setting provides u potential unified company forecasting model, useful understanding universal law whole market first split data post pre divide pre observation training, validation, testing set ratio according number company is, company constitute training set, company constitute validation set, company constitute test set post data also used testing figure show schematic diagram dataset division fitting parameter gm training neural network performed training set, blue part figure gm part, start formula taking natural logarithm side give u ln ln ln apply least square method perform linear fit training set, allowing u obtain coefficient corresponding attribute table present parameter gm component, derived via different random seed dataset cutting conduct three iteration varying data setting calculate average result training three model subsequently compute predicted result via equation euler method data used analysis annual financial data, model, time interval represents one financial reporting year figure show cumulative mean average error mae distribution gm prediction compared random growth model random growth model company system usually mean growth rate independent size, called gibrat law typical baseline model company growth, here, also extend random growth model indicator baseline indicator show reflect superiority gm model figure neural network part designed align encoder decoder framework, displayed figure encoder module includes input original data concatenates macroeconomic information ultimately, part modeled follows hidden state ith layer, concatenating operation process iterates time step shared parameter lstm module hidden unit transmit information time step composed modeling jointly final passed decoder lstm module share parameter encoder decoder module, predict future time step part consists lstm module input include prediction gm, macroeconomic information and, course, hidden unit internally transmitted prediction process time step residual output decoder layer adding back output growth model obtain final prediction here, assume known, obtained according previous section additionally, lstm module decoder share parameter specifically stated, set prediction task input data past step encoder end output future step training stage testing stage, input length also output length flexible needed loss function mean square error mse optimizes difference prediction actual data validate effectiveness idea, choose several benchmark model comparison model include baseline simple model provide base level performance one common baseline model time series prediction persistence model, predicts value next time step current time step gm growth model also include growth model mentioned section one comparative model model allows u evaluate whether neural network effectively learn residual fluctuation basis differential equation use initial predicted position initial value, apply euler method compute predicted value step lstm pure lstm framework, parameter set consistently described above, differs figure whether decoder includes directly predicts growth rate subsequent experiments, data reported year, set time interval mean squared error mse chosen optimization objective, adam used optimizer gradient descent, hidden size lstm encoder decoder set learning rate weight decay set taking single step prediction example, compared mean average error mae model predicting time final prediction performance shown inset plot figure show nn gm yield lower average mae, especially asset lt liability prediction figure also compare multistep prediction error change nn nn gm four attribute experiments, found nn gm strength lie long term forecasting prediction step difference among different method significant, shown inset plot number predicted step increased, difference became apparent believe advantage nn gm model reflected combination trend term fluctuation term, trend term significant short term, long term forecast perceived model, reflects advantage nn gm comparative model selected also serve two component framework, allowing u analyze contribution different module comparing accuracy controlled various variable assess impact model predictive capability, including company size, age, different sectors, using mean absolute error mae comparison following section initial finding reveal company size key explanatory variable predictive power figure general, larger company tend yield accurate forecasting result smaller company do, indicating growth trajectory large firm stable easier predict finding attributed fact large company often follow established growth patterns, influenced consistent revenue streams, mature business models, less susceptible market volatility result, company exhibit predictable behavior, allowing model capture growth trend effectively analysis, hybrid nn gm model consistently outperforms model shown red solid line figure interestingly, gm alone also performs quite well, particularly medium sized large companies, indicated blue dashed line difference performance nn gm gm becomes less significant company size increase finding implies larger companies, gm well suited capturing underlying growth trend larger companies, tend adhere closely market average gm alone sufficient making accurate predictions, contribution nn module becomes marginal finding aligns prior econometric studies, coad suggested large company tend exhibit stable growth patterns, making less sensitive unpredictable external factor consequently, fluctuation company resemble independent random variables, inherently harder predict moreover, analysis reveals negative correlation mae company age figure indicating company age, prediction accuracy improves finding entirely unexpected, older company often larger established, strong correlation age size across age ranges, nn gm model notable advantage red solid line however, older established companies, gm alone depicted blue dashed line outperforms hybrid model cases, addition nn module provide significant benefit observation consistent earlier finding regarding company size company age, tend display consistent, average growth pattern well captured mechanistic gm performance across different industry classification examined figure benefit nn gm model immediately evident shorter prediction horizon case prediction step small, model advantage minimal however, prediction step increases, nn gm model begin exhibit slight performance edge industry finding suggests hybrid model strength lie primarily longer term forecasting, combination mechanistic gm nn model better capture trend fluctuation extended period one particularly notable observation performance utility sector, three model gm, nn model, nn gm demonstrate significantly lower error performance industry sector consistently display reduced prediction error across model feature reason result may lie inherent stability utility industry, generally characterized steady demand, regulated growth, less exposure market volatility factor contribute predictable growth trajectory, making easier model forecast performance accurately stability sector minimizes impact random fluctuations, simplifying prediction task comparing error different models, observe reinforcing pattern validates model work industry greater stability, utilities, gm model often achieves lower prediction errors, implies cases, contribution nn becomes less significant inspired experiment previous sections, categorized company three group based gm prediction performance underperformance, good prediction, overperformance define good prediction case gm model average mae company threshold reflecting model overall predictive accuracy company figure show comparison result nn gm outperforms gm alone overperformance group case however, good prediction group, difference two model negligible robustness test varying value also provided figure result illustrate model function nn gm adjusts prediction response gm performance gm underestimates, nn gm increase prediction, gm overestimates, decrease prediction gm performs well, adding nn improve result fact, nn nn gm tend underperform compared gm reason gm capture baseline growth, prediction accurate, suggests company growth average level, residual largely noise, making prediction challenging additional example found figure aligns learning landscape described gain deeper understanding behavior interpretability model, employed shapley value approach, widely used method explaining output machine learning model shapley value provide insight importance input feature individual predictions, allowing u break different variable contribute model performance, particularly nn component framework figure illustrates distribution feature contribution four prediction example, predicting asset top influential attribute net income ni retained earnings cash ch asset value cost good sold cog similarly, revenue revt top important feature revenue revt retained earnings asset net income ni number employee emp ranking highlight financial indicator play critical role shaping model prediction different outcomesnotice original shapley value could positive negative measure positive negative importance separately however, visualization purposes, opted display absolute value figure dosing help simplify interpretation feature importance focusing magnitude influence rather direction analysis provides clear insight attribute impactful prediction task, confirming key financial indicators, net income, assets, revenue consistently significant predictor surprisingly, despite initial expectations, macroeconomic variable contributed little prediction accuracy experiments, particularly model undergone sufficient training finding suggests macrolevel feature may offer valuable context, introducing much external information actually interfere neural network performance words, model might struggle balance additional inputs, potentially leading overfitting noise rather improved prediction accordingly, macroeconomic attribute removed input data test interestingly, resulted improved accuracy nn nn gm model outcome reinforces idea certain cases, simplifying input space focusing key financial variable may lead better generalizability predictive power also visualize neuron trained model observe relationship learned representation company actual feature prediction task shown figure choose high dimensional hidden layer, passed encoder decoder neural network, represent company decision based fact feature space stage effectively capture key information company also relatively unaffected specific downstream tasks, providing general company representation company receives unique vector representation within hidden layer space, better reflects position characteristic within model model, dimensionality hidden layer set offering sufficient expressive power capture complex feature company however, facilitate visualization analysis, applied principal cccomponent analysis pca reduce dimensional data dimensional space dimensionality reduction technique allows u intuitively observe distribution structure company feature space, validating effectiveness rationale model finding indicate feature representation space strongly correlated company size relationship hold regardless whether size measured assets, total sales, number employee company similar size tend cluster closer together representation space compared size, attributes, age sector, less consistent representation space finding confirms prediction task, company size predictive feature paper, presented hybrid framework integrates mechanistic growth model time series prediction techniques, offering new approach predicting company growth framework leverage advantage method growth model gm capture fundamental trend company growth, neural network based time series forecasting address fluctuation driven external factor extensive experiments, demonstrated combined model outperforms traditional time series models, particularly long term prediction capturing baseline growth dynamic becomes essential approach improves prediction accuracy also enhances interpretability forecasting model separating mechanistic growth fluctuation components, gain insight factor influencing growth pattern specifically, result show company size predictive feature, company similar size clustering representation space finding aligns well established scaling law company growth, highlighting critical role size forecasting performance factors, company age industry, play less pronounced role still contribute overall prediction, especially short term forecasting framework show significant potential, several area remain future improvement first, mechanistic model employed, although effective, represents basic form company growth expanding model include relationship financial indicators, interplay liabilities, revenue, investment, could yield accuracy improvement additionally, incorporating detailed macroeconomic factors, especially related sector specific dynamic global economic conditions, could make model robust moreover, framework flexibility allows substitution neural network module time series forecasting technique future work could explore use advanced model like transformer based architecture graph neural network gnns could leverage interconnected nature company capture influence supply chains, partnerships, competition would allow even granular prediction based real world inter company relationships, enhancing practical utility model finally, recognize primary focus demonstrating feasibility interpretability proposed framework rather achieving highest possible prediction accuracy comprehensive tuning model hyperparameters, combined larger dataset encompassing global firm diverse markets, could improve performance model various economic environment conclusion, hybrid framework proposed paper lay groundwork future advancement company growth prediction ability combine mechanistic insight flexibility machine learning technique offer promising direction research generally, believe application physic informed neural network pinns financial area deliver significant value improving accuracy interpretability growth predictions, approach significantly aid decision making process strategic planning, risk assessment, financial analysis continuing",general economics
"detecting fake review buyer using network structure direct evidence amazon identifying product buy fake review discussion conclusion network construction network feature generation additional feature supervised approach unsupervised approach pnasresearcharticle leadauthorhe significancestatementonline review significantly impact consumer decision seen crucial success online market despite this, prevalence fake review arguably higher ever, despite two decade academic research identifying regulating use novel data directly observe product buy fake review study identify show product buying fake review highly clustered product reviewer network due reliance common reviewer allows u detect high accuracy using supervised unsupervised method unlike approach relying review text, approach robust manipulation seller moreover, scalable generalizable many setting authorcontributionsplease provide detail author contribution authordeclarationthe author declare conflict interest equalauthors author listed alphabetical order correspondingauthor correspondence addressed mail bretthollenbeck andersonuclaedu online review significantly impact consumer decision making process firm economic outcome widely seen crucial success online market firms, therefore, strong incentive manipulate rating using fake review present problem academic researcher tried solve two decade platform expend large amount resource nevertheless, prevalence fake review arguably higher ever combat this, collect dataset review thousand amazon product develop general highly accurate method detecting fake review unique difference previous datasets directly observe seller buy fake review thus, prior research trained model using lab generated review proxy fake reviews, able train model using actual fake review show product buy fake review highly clustered product reviewer network therefore, feature constructed network highly predictive product buy fake review show network based approach also successful detecting fake review even without ground truth data, unsupervised clustering method accurately identify fake review buyer identifying cluster product closely connected network text metadata manipulated evade detection, network based feature costly manipulate feature result directly inherent limitation buying review online review marketplaces, making detection approach robust manipulation manuscript compiled october online review significant impact consumer purchase decision widely seen crucial success online market review rating system allow buyer seller develop credible reputation setting otherwise mostly anonymous reputation crucial seller outcomes, seller large incentive manipulate rating inflate reputation result, online review platform like amazon, yelp, tripadvisor struggled since inception problem seller manipulating rating fake review rating manipulation potentially cause buyer buy lower quality seller otherwise would, allow seller charge higher price true reputation observed, lower trust review review platforms, making difficult high quality honest seller compete growing empirical evidence fake review harm consumer addition violating platform policies, practice subject ongoing investigation ftc, ukcma, regulator despite vast amount academic research past two decade see extensive review large amount time, effort, money invested online platform detect remove fake reviews, nevertheless prevalent ever recent study found million product amazon using fake reviews, large share review fake consumer express low level trust online review result research challenge fake review detection relies machine learning technique exploit feature associated reviews, ratings, helpful votes, text content primary challenge approach lack ground truth data train test model words, order develop model identify fake reviews, one must first corpus existing fake review real review train model researcher attempted overcome inherent challenge pose largely using lab generated review considering platform filtered review proxy fake review scholar criticized approach serious limitation lab generated fake review may lack authenticity, bot generated low quality review non english speaker containing many grammatical error best pick low hanging fruit miss bulk actual fake review moreover, using review flagged filtered platform algorithm definition cannot progress understanding identify large number fake review currently evade filter method trained data repeatedly shown lack external validity addition lack high quality ground truth data, another shortcoming current method sophisticated actor potentially evade filtering algorithm trained historical feature example, method relying text analysis fundamentally limited that, even sophisticated models, human reviewer strong incentive evade detection therefore strive write fake review indistinguishable organic review particular phrase tendency become used filter reviews, avoid using review generally, extant approach detecting product manipulating rating grappled economic incentive buyer seller use unique data observe seller buy fake review demonstrate economic incentive harnessed design approach detect fake review buyer high accuracy limited scope evasion argue problem overcome focusing product reviewer network identifying product buy fake review rather fake review hand collect large new dataset provides accurate ground truth data directly identifying large representative set product buy fake review amazoncom using data, study relative effectiveness different approach detecting product manipulate rating find that, compared product using fake reviews, product use fake review highly connected clustered network, implying product using fake review tend reviewer common product follows naturally fact that, regular product receive review dispersed set million amazon customers, product buying fake review must rely relatively small number reviewer participating fake review marketplace therefore, feature derived product reviewer network especially useful regulating fake review because, addition predictive text metadata features, difficult costly manipulate seller text review timing, feature result directly inherent limitation acquiring review fake review marketplace analyze fake review behavior amazon, begin collecting data private facebook group seller buy review inherent limitation observing fake review activity, group generally seen primary channel seller find reviewer march october identify fake review related group daily group large quite active, member average fake review request posted per day per group within facebook groups, seller obtain five star review look organic seller post product picture review requests, potential reviewer seller communicate via private facebook message vast majority seller observe buying fake review compensate reviewer refunding cost product via paypal transaction five star review posted along cost paypal fee, sale tax, cases, additional commission reviewer compensated creating realistic seeming five star review evade amazon filter process differs incentivized reviews, seller offer free discounted product discount future product exchange review disclose transaction required five star among groups, entire observation period, observe amazon seller buying positive review point out, likely buying fake negative review hurt competitor costlier buyer need incur full cost competitor product addition, benefit purchasing fake negative review likely lower buying positive review shift sale caused negative review competitor page indirect dispersed across potentially many competitor product besides competitor negative fake review bought identify product buying fake reviews, hire group research assistant visit group select random sample product posted collect data random facebook fake review group using procedure weekly basis october june result sample roughly unique product identifying product whose rating manipulated, collect data product amazoncom collect review rating product daily basis review, observe rating, product id, review text, review photos, helpful vote addition collecting data product buying fake reviews, collect daily review data set competitor product serve comparison set so, product buying fake reviews, select two product appear frequently search result period covering seven day date product first facebook post rationale want create comparison set product subcategory product buying fake review similar search rank fake review posted extensive literature fake review detection online platform amazon, yelp, tripadvisor literature proposed method detection based text features, image features, spatiotemporal differences, network features, sentiment, others see many reference one main hurdle creating algorithm capable detecting fake review lack ground truth data, ie review known fake, literature criticized relying low quality proxy overcome issue focusing product buy fake review described data section, dataset allows u know high degree certainty amazon product bought fake reviews, therefore providing accurate ground truth product level analysis compare performance previously suggested method and, particular, test performance model take advantage structure product reviewer network another recent study also utilized ground truth data obtained monitoring facebook group perform review product level fake review detection however, author use network structure paper despite this, qualitative analysis interview performed buyer seller align several findings, author conclude network structure product buying fake review could useful detect product buying fake review approach detecting seller buying fake review exploit network structure amazon product start constructing product network using data, network, set node ie, product set edge edge two product represents existence common reviewer figure show network structure amazon product dataset then, node ie, product compute degree, eigenvector centrality, pagerank score, clustering coefficient provide mathematical detail compute measure section si appendix degree product total number reviewer common product network eigenvector centrality measure structural importance considering product proximity structurally important product network product centrality score increase reviewer common product share many reviewer product network pagerank, like eigenvector centrality, considers importance product neighbor assigning score however, mainly differs eigenvector centrality normalizing neighbor product structural importance number neighbor three measure degree, eigenvector centrality, pagerank help u compare product structural importance understand relate overall network addition, measure product connectivity within neighborhood using clustering coefficient clustering coefficient check pair product neighbor considers many reviewer common compare performance different type information detecting fake review buyers, also generate feature available product metadata review content review text, ratings, timestamps, image first set feature generated available metadata feature include number reviews, average review rating, summary statistic time gap reviews, ratio review consumer found helpful, ratio review star review rating, ratio review star review rating, ratio review include review images, variation review length product, average text similarity among review product metadata capture evidence rating manipulation, disproportionate share five star reviews, excessive helpfulness votes, odd timing characteristic long gap arrival review followed appearance many generate second set product level feature using review product image first, use pre trained deep convolutional neural network image product review extract feature shown fig si appendix calculate angular similarity image belonging product using cosine distance vector representation image cosine distance particularly effective high dimensional data calculate three set feature summarize degree image similarity product review controlling multiple image belonging review similarity seller product image review images, similarity among pair review image set features, calculate minimum, maximum, average, standard deviation pair wise similarity within product third set product level feature generated review content text feature first combine review body product treat product document then, calculate tf idf score word document consider top feature receive highest tf idf score product finally, product represented feature vector length table show product level feature generate consider various aspect reviews, products, reviewer behavior detect fake review buyer table si appendix show correlation coefficient image, metadata, network feature test predictive performance feature created, employ set random forest classifier following standard approach literature train classifier random subset product evaluate prediction performance remaining measure area receiver operating characteristic curve auc classification accuracy, true positive rate tpr true negative rate tnr score technical detail estimated model model building process section si appendix table show performance type feature set find feature constructed product reviewer network outperform metadata, text, image feature across accuracy metric combined model includes feature performs slightly better model using network feature addition performing best balanced measure accuracy, network feature model performs best true positive rate especially important rating platform avoiding false positive important goal figure show relative importance different individual feature feature model term contribution predictive power two important feature large margin network features, specifically clustering coefficient eigenvector centrality score fact two feature rank highest importance highlight reason network based model performs well product buying fake review appear rely common set reviewers, causing closely clustered product network compared regular product result novel scholarly literature, since platform technique detect fake review publicly disclosed, may entirely novel practice table show test concise model using top two network features, still outperforms model suggests predictive power network feature sufficiently strong that, even implemented simple way, useful model based large set feature derived metadata, text, image shown model trained feature derived product network highly accurate detecting fake review buyers, platform may ground truth data required estimate type model therefore, validate strength network based approach, extend analysis much larger dataset amazon product review lack ground truth data test whether network data allow u identify ex ante product likely manipulating rating use data contains entire universe amazon product review home kitchen category, contains thousand products, million reviews, million reviewer longer know product buy fake review larger dataset, follow unsupervised approach start creating product network previously described partition product group using mean clustering algorithm based product metadata network feature product clustered, test certain cluster disproportionately likely contain fake review product test this, use pre trained classifier trained feature estimate proportion product buying fake review cluster although calculation would ideally done using ground truth data, given high sample accuracy feature classifier, provide good indication distribution fake review product among cluster figure show percentage total number product identified buying fake review cluster using classifier report summary statistic cluster detail unsupervised approach section si appendixx analysis show two cluster contain product contain product identified fake review buyer addition, within one clusters, substantial majority product identified buying fake review table si appendix report mean feature value cluster two cluster contain majority fake review buyer highly distinctive, term network feature suggests platform could use unsupervised method identify tightly connected cluster product without ground truth data use information identify likely fake review buyer paper, use unique dataset method address longstanding problem digital economy rating manipulation use direct observation seller buy fake review propose network based approach detect product analysis product network show product buy fake review highly clustered information amazon review reviewer see review ultimately posted, seems suggests reviewer participating fake review marketplace relatively small part full universe amazon reviewer therefore, classifier based two network features, clustering coefficient eigenvector centrality, identify product buying fake review high accuracy, outperforming model trained large number feature constructed metadata, review characteristics, text, image addition powerful feature detect product buy fake reviews, crucial implication insight network based feature costly manipulate feature result directly inherent limitation acquiring review fake review marketplace although specific setting study amazoncom, disproportionate clustering rating manipulator network structure likely hold across application fake review found generally case set reviewer used rating manipulator likely substantially smaller general population reviewers, leading pattern unusual clustering observed network moreover, since show ground truth data necessary identify clusters, platform easily implement approach insight may also contribute study similar problems, botnet directed ad fraud online review assessment interestingly, result complement existing method used platform mitigate rating manipulation particular, platform often cautious new user review rather experienced reviewer many review approach probably correct general supported prior research result suggest exist set experienced reviewer posting many fake reviews, employing network structure platform detect finally, provide method detect product buy fake reviews, address question information amazon target products, sellers, reviewers, example, remove product reviews, remove product platform, ban seller selling platform, ban sue fake reviewer although amazon currently target writer fake reviews, view, amazon target seller approach would ban seller however, case false positive rate non zero quite costly furthermore, could provide perverse incentive seller buy fake review competitor try get banned therefore, likely balanced still effective strategy would punish seller reducing visibility marketplace eg, increasing search rank suspected buying fake reviews, would offset eliminate financial incentive generally, result show product network structure provides robust source information allow rating platform apply greater scrutiny product list which, turn, deter seller committing fraud thank morrison center marketing analytics generous funding thank seminar participant johnson school management cornell university, ross school business university michigan, pontificia universidad catolica de chile, fox school business temple university, rit marketing workshop, usc marshall ai workshop, scecr helpful comment",general economics
"estimating spillover sampled connection introduction network sampling ordinary least square estimator nonlinear estimator simulation result dependence sampling covariates empirical application conclusion proof calculation caltech cohort study instruction reporting error outline notation example fixed choice design example proximity space link missing random estimator spillover effect debiased estimator robustness sampling estimating average effect exposure exposed standard two stage least square estimator debiased estimator setup case fixed choice design case assuming group fully connected modelling dependence copula simulation result robustness sampling effect climate shock production network peer effect classroom proof proposition theorem proof proposition proof theorem proof proposition proof proposition proof proposition proof proposition theorem content tocatoc aftertochead toc aftertochead atoc empirical researcher often estimate spillover effect fitting linear non linear regression model sampled network data here, show common sampling scheme induce dependence observed unobserved spillover due dependence, spillover estimate biased, often upwards show researcher construct unbiased estimate spillover effect rescaling using aggregate network statistic result used bound true effect sizes, determine robustness estimate missingness, construct estimate missingness depends treatment apply result estimate propagation idiosyncratic shock u public firms, peer effect amongst usafa cadet keywords networks, sampling, peer effect jel code empirical researcher measuring spillover often use data sample many link individual newman, economics education development economics, researcher often collect network data survey ask subject name certain number link rapoport horvath, harris, calv armengol et al, banerjee et al, oster thornton, conley udry, eg industrial organisation economics innovation, researcher often use technological similarity physical distance proxy connection eg jaffe, foster rosenzweig, bloom et al, studying firm level production networks, researcher often observe larger supply relationship firm eg see atalay et al, barrot sauvagnat, payment collected specific bank credit rating firm eg carvalho et al, illustrate prevalence this, surveyed article published american economic review, econometrica, quarterly journal economics january september paper measuring spillovers, use proxy link individual popular empirical strategy construct spillover using sampled links, construct dummy variable denotes least one sampled neighbour get treatment researcher regress sampled spillover outcome measure spillover effects, dummy variable outcome measure average total spillover effect individual least one treated neighbour eg miguel kremer, oster thornton, barrot sauvagnat, first show common sampling scheme induce dependence observed unobserved spillovers, even treatment independently identically distributed across individual dependence observed unobserved spillover bias regression estimate spillover effect upwards dependence positive, downwards dependence negative estimate average total spillover effect individual least one treated neighbour biased downwards size bias economically significant example, applying sampling rule popular national longitudinal adolescent health data set harris, simulated network lead ordinary least square estimate one half time true spillover effect average sampling many link often unavoidable practice newman, beaman et al, so, next construct unbiased estimator spillover average total spillover effect amongst individual least one treated neighbour sampled network data researcher must rescale estimate account expected dependence observed unobserved spillover given sampling rule network structure exogenous distribution treatment, randomised controlled trial quasi experimental designs, researcher must rescale spillover estimate based mean number missing link researcher must rescale estimator average total spillover effect amongst individual least one treated neighbour based degree distribution aggregate network statistic rescaling require knowledge linked so, researcher collect network data surveys, need include one survey question many friend researcher cannot sample network themselves, might use network statistic study survey specific type network detail eg see jackson et al, study partnership universities, bacilieri et al, firm level supply relationship assumption network similar enough researcher cannot ascertain relevant network statistics, show instead determine robustness result missingness construct bound true spillover effect given sampled data also extend result estimator non linear social network models, case network structure depends distribution treatment rescaled estimator perform well simulation common sampling rules, standard estimator heavily biased demonstration, apply result two different case first, estimate propagation climate shock public firm united state barrot sauvagnat, account sampling bias supply link using complete production network statistic bacilieri et al, herskovic et al, estimate average effect given least one supplier shocked accounting sampling network time larger reported second, estimate peer effect high low ability usafa student carrell et al, partially account sampling bias frequency study partnership high low ability student using frequency study partnership high low gpa student caltech jackson et al, correcting undersampling interaction low high ability student rationalise null treatment effect low ability student experiment paper relates literature estimate constructed using sampled network chandrasekhar lewis, lewbel et al, yauck, zhang, hseih et al, approach differs two important way first, write true spillover sum spillover sampled unobserved component network give simple, tractable expression bias linear estimator second, consider case researcher use aggregate network statistic correct estimate then, construct unbiased estimate without dropping observation chandrasekhar lewis, imposing parametric assumption network formation process eg breza et al, boucher houndetoungan, herstad, result nest griffith, specific case fixed choice design analysed idea using additional network data similar lewbel et al, result also closely related literature design based estimation using linear combination exposure exogenous shock borusyak hull, borusyak et al, section characterise effect sampling link observed spillover section derive effect sampling estimate linear models, present debiased estimator section extends result two stage least square estimator non linear model section assess performance estimator simulation section extends result case sampling link may depend treatment finally, section present empirical example proof given appendix denotes either vector scalar matrix scalar depending context denotes set ordered pair denotes number element set denotes th row denotes th column denotes entry distributed according probability distribution plim denotes probability limit use denote convergence probability, denote convergence distribution consider individual outcome treatment covariates individual situated true simple network set edge weight describe network adjacency matrix st denote true mean degree instead true network, observe sampled network adjacency matrix sampled network contains least true link practice, either researcher undersample link researcher oversample link denote observed mean degree split true adjacency matrix sampled adjacency matrix plus unobserved part mean degree researcher construct observed spillovers, equation write equivalently, individual observed spillover equal true spillover researcher sample link common sampling schemes, proportion link correctly sampled depends individual degree induces dependence consider case researcher record link individual, common collecting network data survey coleman et al, calv armengol et al, oster thornton, banerjee et al, unless maximum number link per participant less researcher undersample link high degree individual individual fewer friends, researcher observes friend individual friends, researcher observes friend therefore, here, positively related consider case researcher assume individual within category connected common observational data researcher tell type individual might connected, connected eg miguel kremer, chetty et al, bloom et al, carrell et al, prominent example unless individual category actually connected, researcher oversample link individual fewer connection therefore, here, negatively related sampling error also generate dependence observed unobserved spillover consider case researcher miss true link rate depend individual true degree increases, mean number true missing link also increase therefore, positively related supplementary material contains application design based estimator borusyak et al, assume individual outcome depends linearly possibly weighted sum neighbour treatment sample analogue make standard assumption ordinary least square stochastic regressors cameron trivedi, assume following data generating process equation independently identically distributed lim lim independently identically distributed conditional variance matrix diagonal plim exists, finite, positive definite additionally, lim furthermore, assume researcher sample link depending directly outcome example, putting effort sampling friendship child higher grade ordinary least square estimator using sampled network biased inconsistent bias come dependence projection observed unobserved spillover space orthogonal covariates related are, larger bias estimator upwards downwards biased depending sign dependence observed unobserved spillover assume contains intercept wlog then, consider common sampling scheme discussed section light result case researcher undersample link high degree nodes, fixed choice designs, cov therefore spillover estimate biased upwards magnitude case researcher oversample link lower degree node higher degree nodes, researcher assumes individual within certain category interact, cov therefore spillover estimate biased downwards magnitude bias network sampling alters limit distribution ols make assumption ordinary least square estimator ols limiting distribution limit distribution centered around zero therefore interval estimate ols necessarily centered around furthermore, residual fitted regression required consistency standard heteroskedasticity robust variance covariance matrix estimator mackinnon, therefore, standard error estimated using standard software package incorrect, significance test constructed using incorrectly sized estimated asymptotic variance small therefore, test based reject null converse applies result motivates simple debiasing procedure make assumption estimator unbiased estimator furthermore, consistent estimator rescaled estimator course higher variance ordinary least square estimator observe true network consider debiased estimator make assumption implement estimator, researcher need way characterise without directly observing now, assume treatment independent structure true unobserved network independent plausible case treatment conditionally randomly assigned across agent network real natural experiment eg miguel kremer, oster thornton, barrot sauvagnat, may plausible observational data individual incentive form link based consider case section assumption depends mean number missing link denote mean column mean degree unobserved network mean degree observed network further, assume then, expected bias implies general case equivalent expression mean case assumption applies, constructing unbiased estimate spillover requires researcher know true mean degree individual require researcher know individual individual connected obtaining true mean degree relatively mild compared existing approach constructing unbiased estimate require imputing missing network eg breza et al, conditioning directly network formation model counterfactual exposure process shock herstad, borusyak hull, constructing multiple measure network lewbel et al, require either strong parametric assumptions, much additional data survey, researcher could get true degree including one question many type connection aggregate quantity, data provider easily disclose preserving privacy case researcher cannot sample individual network example using data collected others researcher plausibly construct mean degree mean degree similar observed network researcher could also use additional survey question connection estimate mean missing degree relatively weak assumption example, researcher could use question many friend smoke plus assumption distribution smoker population recover mean missing degree friendship network researcher unable get precise estimate researcher still assess robustness spillover estimate sampling bias two way first, researcher recover mean number missing link needed reduce estimate value threshold rearranging substituting researcher use see many link per individual would erroneously missing included spillover estimate still pas decision threshold, statistically significant given preferred significance level estimated standard error second, researcher bound spillover based plausible range min max then, true spillover estimate contained range upper lower bound may flip mean degree unweighted simple network bounded widest bound spillover unweighted network would analogue assumption bound manski, consider case binary treatment common empirical strategy construct dummy least one sampled neighbour exposed treatment eg specification oster thornton, barrot sauvagnat, regress dummy constructed using sampled network outcome intercept estimand average effect spillover treatment given least one neighbour treated ordinary least square estimator also biased inconsistent estimate small researcher erroneously assigns node treated neighbour group without vice versa thus, sampled difference outcome two group small again, derive debiased estimator make assumption estimator unbiased consistent estimator sample analogue directly computable observed assume assumption hold let probability given node treated now, compute sample analogue term degree distribution here, researcher must know true degree distribution, final two term equal ascertained asking individual many connection survey, disclosed data provider without violating privacy, approximated detailed sampling similar datasets rescaling procedure depends linearisability estimator sum observed unobserved spillover so, extend approach section linear estimator parameter non linear model example two stage least square estimator nonlinear social network model often used peer effect literature eg see blume et al, reference therein assume individual outcome depends linear combination outcome neighbour researcher try estimate using sampled network two stage least square using sampled friend sampled friend instrument denote regressors call denote instrument two stage least square estimator make standard assumption kelejian prucha, bramoull et al, blume et al, assume independently identically distributed independent identically distributed conditional variance matrix diagonal finite nonsingular matrix norm network sampling cause two stage least square estimate biased inconsistent make assumption let denote projection matrix, sl sl two stage least square estimator biased inconsistent see this, write reduced form equation corresponding two stage least square estimator exclusion restriction instrument instrument exclusion restriction fails orthogonal covaries second third term so, estimator biased inconsistent instrument covaries two component so, construct unbiased estimator constructing instrument exogenous first component conditional applying result section correct estimate observing construct instruments, pre multiply true data generating process get substituting back reduced form equation corresponding two stage least square estimator give see immediately exogenous conditional formalise proposition variable valid instrument conditional also deal omitted term second stage problem faced section so, construct unbiased estimate constructing two stage least square estimate using instrument applying correction estimator unbiased estimator resulting estimator consistent, asymptotically normal consider debiased estimator make assumption plim construct sample analogue stage estimators, assumption use expectation place section next, evaluate bias induced common sampling scheme performance debiased estimator monte carlo simulation here, simulate network assumption hold section also assess performance sampling covaries treatment throughout, simulate individual draw true degree connected others uniformly random population binary treatment distributed across agent bernoulli ordinary least square estimators, true data generating process equation construct estimate average total spillover effect amongst individual least one treated neighbour two stage least square estimators, true data generating process equation cases, run simulation per estimator case, debiased estimator constructed empirical analogue additional simulation contained supplementary material first, sample network using fixed choice design researcher sample gender friendship popular national longitudinal adolescent health data set example paper using dataset, see jackson, badev, recent example agent true degree greater five, sample five link uniformly random note red line denotes true parameter value mean true respectively data case simulated linear nonlinear model true network single binary treatment drawn iid bernoulli across node true network degree distributed receiving node sampled uniformly random population sampled network generated sampling link per agent uniformly random true links, degree less figure plot distribution estimate standard debiased estimator mean ordinary least square estimate spillover one half time true spillover effect mean two stage least square estimate spillover nearly double true spillover effect usual ordinary least square estimator underestimate average total effect spillover amongst individual least one neighbour average mean debiased spillover estimates, close true spillover value estimate tightly centered around debiased estimate average total effect spillover amongst individual least one neighbour centred around mean effect, differ average second, sample network assuming agent connected ten others eg see miguel kremer, paper listed agent true degree ten, sample agent link agent true degree less ten, sample additional link uniformly random note red line denotes true parameter value mean true respectively data case simulated linear nonlinear model true network single binary treatment drawn iid bernoulli across node true network degree distributed receiving node sampled uniformly random population sampled network generated sampling additional link per agent uniformly random population figure plot distribution estimate standard debiased estimator spillover linear non linear model standard estimator heavily downwards biased mean ordinary least square estimate approximately half true spillover effect mean two stage least square estimate half true spillover effect usual ordinary least square estimator underestimate average total effect spillover amongst individual least one neighbour average mean debiased estimates, close true spillover value estimate centered around debiased estimate average total effect spillover amongst individual least one neighbour centred around mean effect, differ average assumption get depends assumption hold, instead need compute directly characterise dependence naturally emerge equilibrium common network formation modesl model strategic network formation linear quadratic utility example structure, see calv armengol et al, jackson, equation simplify interpretation, assume without loss generality then, so, need model dependence rescale estimate one route fit parametric model network formation herstad, assume willing impose parametric assumption network formation, natural parametric form marginal degree distribution example, degree distribution firm level production network tend similar shape across different country bacilieri et al, use degree distribution network statistic estimate dependence using copula nelsen, trivedi zimmer, denote observed distribution treatment distribution relevant statistic true network example, degree distribution network pair distributed according unknown joint density function marginal distribution bivariate copula quasi monotone function unit square exists sklar theorem nelsen, represent joint density using copula state theorem explicitly supplementary material given fitted copula dependence parameter compute expected individual degree given treatment status thus, compute expectation fitting copula conditional marginals sampling copula conditional observed treatment status motivates two step estimator fit relevant copula compute compute debiased estimator equation given quality estimate depends choice copula, assumption marginal distribution network statistic variable distributional assumption similar assumption distribution shock process space needed compute unbiased estimate borusyak hull, approach modelling dependence also similar control function approach left hand side selection sample selection literature heckman, smith, next, assess performance example estimator finite sample above, simulate individual draw true degree connected others uniformly random population agent draw continuous treatment marginal distribution marginal distribution treatment degree coupled bivariate gumbel copula control degree dependence treatment degree set left panel figure plot example joint distribution higher treatment node higher degree researcher sample network using fixed choice design sampling link per node national longitudinal survey adolescent health data set note red line denotes true parameter value data simulated linear model true network treatment drawn marginal degree distributed coupled gumbel copula sampled network generated sampling link per agent uniformly random true links, degree less estimate spillover using two step estimator describe first step, estimate dependence treatment degree fitting gumbel copula maximum likelihood using observation correctly sample network second stage, construct spillover estimate constructing sampling copula two step estimator performs well even though ordinary least square estimator mean debiased estimate close true spillover value case researcher unable unwilling make assumption marginal distribution, recover large covariance observed unobserved spillover must reduce estimate value threshold rearranging formula debiased estimate give sensitivity estimate depends value spillover observed unobserved component network plus dependence two here, apply result analyse existing study propagation idiosyncratic shock firm supply relationships, peer effect university student differing ability cases, make use aggregate statistic detailed network data available type network try quantify effect sampling estimate results, therefore, depend two assumption first assumption complete network similar enough application viewed way researcher apply aggregated network data reduce bias estimate able reliably sample network data theselves barrot sauvagnat, study idiosyncratic shock propagate firm looking extreme weather shock sample public firm united state affect sale customer construct network supply link using firm self reported large customer sfas regulation u public firm required report customer make least percent sale therefore, dataset contains subset true supply link public firm mean number supplier median many fewer researcher see complete transaction data assume barrot sauvagnat, trying identify average effect shock supplier amongst firm least one shocked supplier this, run following regression supplier hit dummy whether one sampled supplier firm affected natural disaster quarter sale sale growth firm next year, control pick coefficient estimate table paper representative example effect find result barrot sauvagnat, depend assumption firm firm report supplier depend extreme weather event present evidence case so, construct debiased estimate assumption construct aggregate network statistics, use result degree distribution binary firm level production network herskovic et al, bacilieri et al, observed complete production network datasets, assume true degree distribution well described discrete power law distribution top censored bacilieri et al, take estimated tail exponent factset dataset completely sampled dataset similar type firm u public firm barrot sauvagnat, sample herskovic et al, study u public firm this, therefore compute estimate mean missing degree using discrete power law sampler clauset et al, get value descriptive statistic paper, shock give u term need compute debiased estimate using table compare debiased estimate coefficient given paper sampling bias reduces estimated average effect idiosyncratic shock supplier firm supplier hit weather shock intuitively, occurs firm unsampled link shocked supplier assigned group firm shocked suppliers, reducing gap two group true network similar factset network, true average effect idiosyncratic shock supplier firm shocked supplier time larger estimate sampled network true network degree distribution tail exponent estimated herskovic et al, true average effect idiosyncratic shock supplier firm shocked supplier time larger estimate sampled network carrell et al, estimate effect share randomly assigned high low ability peer student gpa united state air force academy assuming individual within peer group squadron influence equally specifically, student placed within one squadron individual denote whether student high, middle, low predicted gpa dummy whether high sat verbal score dummy whether low sat verbal score dummy sampled network peer binary network squadron treatment high ability low ability peer squadron student assigned randomly squadron therefore sampled spillover high low sat verbal peer normalising give share type peer squadron carrell et al, estimate spillover coefficient predicted gpa group using reduced form regression use result run treatment assign new student squadron maximise gpa student lowest gpa using estimated predicts positive average treatment effect student lowest gpa, surprisingly, instead find negative treatment effect one reason reassignment might less positive effect expected different type interact different intensity example, student may interact less intensely student low sat verbal score implied share squadron, intensely student high sat verbal score share squadron jackson et al, survey network important study partnership caltech students, compute share study partner across gpa distribution study partnership student median gpa distribution implied share population investigate sampling initial network might affect carrell et al, results, take initial prediction missing interaction low predicted gpa high sat verbal student then, taking value table carrell et al, give estimate then, predicted treatment effect would null effect given forecast standard error reported table paper, find negative treatment effect so, sampling bias cannot entirely rationalise result but, go way explaining relatively small amount endogeneous network adjustment response treatment report could explain negative result show oversampling undersampling connection agent lead bias spillover estimate linear non linear model unlike classical measurement error, cause downwards biases, bias large upwards simulations, show sampling scheme used popular network datasets would induce large bias estimated spillover effect present debiased estimator ordinary least square estimator linear model two stage least square estimator nonlinear model experimental quasi experimental settings, correction depend aggregate network statistics, relatively easy researcher sample tractability, rely linearity estimator sampled unsampled network applied economist commonly fit complicated structural model sampled network data badev, lim, eg see thus, work could extend result moment based estimator linearisable ols estimate solve normal equation solving yield substituting equation taking expectation linearity expectation operator assumption third term now, assumption plim assumption invoke markov law large number cameron trivedi, slutsky lemma assumption next, establish following lemma applying lindenberg levy central limit theorem cameron trivedi, continuous mapping theorem now, write applying lemma continuous mapping theorem give derivation consistency assumption write matrix form, estimator therefore, taking term left hand side give assumptions, then, applying transformation theorem cameron trivedi, give standard result regression dummies, estimator recovers difference mean outcome individual individual angrist pischke, taking expectation substituting give wlog, consider case unweighted simple graph estimator recovers difference mean outcome individual individual angrist pischke, correct estimator would write unbiased consistent estimator now, focus term ols first, let expand now, let expand putting expansion together, pre multiply true data generating process get thus suffices show result let call finally, denote projection matrix onto space spanned instrument two stage least square estimate unbiased instrument note first, show consistency estimator per assumption finite nonsingular finally, need characterise property characterise behaviour second row using standard weak law large number but, vector involves sum random variable so, here, need apply law large number triangular array assumption follows array triangular array kelejian prucha, so, term sum triangular array call triangular array assume sup apply weak law large number triangular array say therefore estimator unbiased consistent next, need characterise asymptotic distribution estimator again, applying slutsky lemma, term right hand side except converge finite limit characterise distribution term, need apply law large number triangular array use central limit theorem triangular array kelejian prucha, let triangular array identically distributed random variable finite second moment denote var assume plim finite nonsingular applying result, therefore, slutky lemma jackson et al, average study partner male students, female student cohort male, female so, average number study partner student answered survey therefore study link exist student study network simple network therefore, possible link number link present per possible link therefore table jackson et al, report fewer link per potential link pair student median gpa pair student gpa opposite side median link average, link drawn uniformly random across student would link within across gpa category result imply instead link within gpa categories, link across gpa category implied share population continuing ",general economics
"nonparametric estimation matching efficiency elasticity private job search platform evidence japan, introduction data model estimation result conclusion instruction reporting error related literature data source trend comparison matching efficiency elasticity platform industry level matching efficiency elasticity platform use proprietary data online job scouting platform bizreach japan, spanning estimate matching function high skill employed worker private job search platform, employing novel nonparametric approach developed lange papageorgiou analysis compared public job search platform, hello work result indicate matching efficiency private platform volatile higher public platform, suggesting increasing popularity private platform matching elasticity respect user consistently hovers around elasticity respect vacancy reach approximately indicating higher balanced elasticity compared hello work platform additionally, study reveals evidence industry level heterogeneity private platform keywords matching efficiency, matching elasticities, job search, matching platform jel code job search play crucial role labor reallocation, leading wage productivity improvement moscarini postel vinay us, job job transition account one third one half hire faberman et al contrast, japan labor market historically characterized long term employment stability, worker typically staying single employer career proportion employed individual changed job remains low million representing employed worker however, reflecting japanese government policy aimed promoting job mobility, number employed individual seeking change job explore new opportunity reached million representing employed workforce mark tenth consecutive period growth highest figure record despite growing importance job search understanding labor market dynamic many country particularly private platform empirical evidence extent, matching efficiency, elasticity process remains limited contrast sharply abundant research job search behavior among unemployed individual paper seek address gap providing new evidence job search platform employed, high skill worker using proprietary aggregate data bizreach, prominent private online job scouting platform japan, estimate matching function within context job search recover matching efficiency elasticity applying novel nonparametric approach developed lange papageorgiou platform allows registered job seeker upload resumes, become active, receive scouting message company headhunter actively searching specialized talent worker platform apply posted job wait scouted, contrasting conventional job search platform worker actively apply vacancy july million employed self employed worker japan seeking change job explore new opportunity registered platform, indicating reasonable degree representativeness job job seeker compare private platform public sector counterpart studied otani incorporate data report employment service shokugyo antei gyomu tokei using month level aggregate data analyze trend matching unemployed worker full time vacancy via public employment platform, hello work comparison offer insight differing feature outcome private public job search platform japan result highlight significant difference matching efficiency elasticity hello work public employment platform private bizreach platform hello work, matching efficiency remained relatively stable sharply declined elasticity respect unemployment consistently lower, ranging elasticity respect vacancy gradually increased indicating change vacancy greater impact job matching change unemployment offer different implication finding otani used broader time range private platform, matching efficiency highly volatile, peaking elasticity private platform also variable generally higher observed hello work elasticity respect user consistently hovered around elasticity concerning vacancy steadily increased, reaching around suggests responsive matching process change number user balanced elasticity user vacancy compared hello work industry level analysis private platform reveals consulting sector exhibit higher matching efficiency responsiveness labor market changes, especially contrast manufacturing sector finding underscore industry heterogeneity, sector like internet characterized stable efficiency, similar manufacturing, consulting sector experience variable matching efficiency sectoral insight provide deeper understanding labor market dynamic private platforms, clear contrast public hello work system overall, paper offer quantitative insight proprietary aggregate data matching function job search labor markets, though noted private platform analyzed may fully represent broader job search labor market japan paper contributes three key area research nonparametric matching functions, job search, online job search platform operated private firm first, add empirical literature estimation matching function, foundational component macroeconomic model using novel nonparametric approach developed lange papageorgiou examine trend matching efficiency japanese labor market via online job scouting platform method enables identification estimation matching function without imposing standard independence assumption matching efficiency search effort either side labor market approach accommodates multiple type job seeker lange papageorgiou highlight positive correlation efficiency market structure variable like labor market tightness, introduces positive bias vacancy elasticity estimate unless unobserved matching efficacy accounted traditional cobb douglas matching function models, unobserved factor often ignored, resulting potentially biased elasticity estimate second, paper relates japanese labor market literature, particularly context public job search platform, hello work otani estimate matching efficiency mismatch japan hello work platform showing declining trend matching efficiency consistent decreasing job worker finding rate match elasticity respect unemployment found elasticity concerning vacancy range comparison, otani kanayama apply similar nonparametric method estimate matching efficiency elasticity privately operated spot worker platform, contrasting finding hello work part time data paper complement extends finding focusing high skill, employed worker platform, filling important gap literature table provides overview recent empirical study japanese labor market january april contributing new evidence matching efficiency, elasticity, mismatch japanese government effort enhance labor market flexibility significantly contributed increase job search activity initiative work style reform laws, aimed reducing overwork, improving work life balance, promoting diverse career trajectories, encouraged worker explore new career opportunity without societal stigma previously associated job change reform reshaped attitude toward job mobility created flexible labor market environment, enabling worker transition role easily still employed yamamoto owan policy context underscore relevance quantitative study private job search platforms, examined paper second, paper contributes literature job search, key aspect labor search theory since burdett recent theoretical models, including cahuc et al eeckhout lindenlaub bagger lentz emphasize role search effort job search connection job ladder dynamic empirical research, mueller ahn shao relied data american time use survey atus document job search behavior however, due limitation atus capturing search outcomes, gap evaluating efficiency job search notably, faberman et al roussille scuderi provide crucial insights, faberman et al focusing relationship search effort outcome roussille scuderi exploring wage markdown using data hiredcom however, study lack long term macro level insight matching function, efficiency, elasticity proprietary data paper offer unique advantage allowing evaluation matching efficiency job search labor market via private platform note bgt burning glass technologies, unemployed, employed, note unemployed, employed, e, ombc ooc mundial, bumeran, computrabajo third, paper contributes expanding literature online job search platform analysis job matching within real world market institution gained prominence due increasing availability data online job platform autor summarized table much literature emphasizes application level vacancy level behavior assess search behavior wage elasticity instance, faberman kudlyak leverage proprietary application level data online job search engine explore relationship search intensity duration, primarily focusing lower skill, hourly job employed unemployed worker similarly, kambayashi et al estimate elasticity application, interview attendance, offer acceptance relative posted wage using detailed process level data private job search matching intermediary platform japan, became significant recruitment channel shown figure contrast, paper adopts broader macro level perspective, evaluating overall efficiency private matching platform best knowledge, first paper estimate matching efficiency elasticity online job scouting platform, offering relatively long term insight private online job search trends, complementing micro level study source cabinet office, government japan author reproduces figure annual economic fiscal report chapter survey asks sampled firm whether evaluate channel first, use report employment service shokugyo antei gyomu tokei month level aggregate data january april examine trend matching unemployed worker vacancy via japan public employment platform, hello work datasets include number job openings, job seekers, successful job placements, primarily sourced ministry health, labour welfare mhlw japan, regularly publishes monthly report statistical data public employment security office, commonly known hello work hello work play crucial role japan labor market providing government operated employment counseling, job placement services, vocational training extensively used estimating traditional cobb douglas matching functions, seen study like kano ohta kambayashi ueno sasaki higashi well nonparametric estimation otani study, focus full time worker ensure consistency comparison across different datasets chosen period provides consistent timeframe comparison following platform data second, utilize proprietary data bizreach, private job scouting platform japan, analyze trend matching employed worker vacancy maintain consistency hello work data, include active workers, defined logged platform given month, excluding inactive registered user unlike hello work, bizreach caters high level professional executives, offering premium job scouting service candidate either use platform free pay monthly subscription fee approximately u dollar gain priority access job opportunity service bizreach platform allows job seeker upload resume receive scouting message company headhunter searching specialized talent system encourages proactive recruitment, enabling direct communication job seeker employer user also gain insight market value scout receive, even actively searching new opportunity platform focus high skill professional contrast broader service provided hello work, includes support entry level part time position bizreach emphasizes efficiency high level recruitment, may suitable individual seeking entry level role comprehensive career counseling services, hello work provides note confidentiality reasons, axis level right panel masked, making directly comparable left panel additionally, labor market tightness platform reported maintain confidentiality figure provides comparative analysis labor market dynamic hello work public employment platform left panel private scouting platform right panel confidentiality reasons, axis level platform panel masked therefore directly comparable hello work panel hello work panel, unemployment trend remains relatively stable, fluctuating around million observed period, slight decline noted number vacancy increase steadily, resulting moderate rise labor market tightness, although ratio stay throughout period hiring count job worker finding rate number matching hire divided number vacancy worker exhibit downward trend, suggesting two possible explanation first existence potential challenges, inefficiencies, mismatch job placement facilitated hello work platform second alternative explanation could growing presence private job search platforms, offer alternative avenue unemployed worker seeking career transition important note, however, private platform analyzed paper primarily caters employed workers, thus limiting direct evidence regarding impact unemployed worker right panel updated figure illustrate labor market trend private platform high skilled employed worker steady consistent increase employed users, especially starting around according japanese labor force survey, total number employed worker million million additionally, labor force statistic office report approximately million employed individual seeking change job explore new opportunity thus, around total employed workforce nearly actively exploring job change registered platform, indicating engagement job search activity however, necessarily imply active job pursuit registered user conversely, vacancy increase gradually remain relatively modest, resulting low labor market tightness ratio, reported confidentiality reason low tightness ratio necessarily indicate mismatch job supply demand platform, registered worker may passively exploring opportunity rather actively searching new position right panel figure illustrates hiring count, show gradual steady increase beginning around however, even upward trend, overall hiring level masked figure remains relatively modest compared hello work, particularly considering substantial rise number user pattern may suggest many user engaging platform passive manner rather actively seeking new employment panel present job worker finding rates, worker finding rate displaying slight fluctuation maintaining generally comparable level hello work meanwhile, job finding rate remains consistently low throughout period compared worker finding rate pattern suggest notable disparity worker side vacancy side matching probabilities, despite marked growth platform user job posting primary focus lie analyzing matching efficiency matching elasticity respect number registered worker vacancy labor market, facilitated online job scouting platform operated private firm japan matching function derived search model play pivotal role labor economics matching function operates premise random search side labor market, job seeker represent labor supply recruiter represent labor demand conceptually, paper examines two independent matching function job job search labor market examining interdependence two matching function theoretically scope paper estimate matching function recover matching efficiency, adopt novel approach proposed lange papageorgiou paper highlight two critical issue endogeneity matching efficiency borowczyk martin et al overly restrictive nature cobb douglas specification, assumes fixed matching elasticity address limitations, lange papageorgiou propose nonparametric identification estimation framework matching efficiency specific condition discussed later let unscripted capital letter denote random variables, time specific realization subscripted consider matching function map period user per caput search efficiency matching efficiency vacancy hire private platform analysis, represents number employed worker registered platform, whereas hello work refers unemployed worker registered public system assume stationary data generating process, sufficient time series data treat joint distribution observable additionally, denote joint distribution identify matching function unobserved, time varying matching efficiency, first, assume conditionally independent given ie, second, assume matching function exhibit constant return scale cr two assumption commonly used literature applying nonparametric identification result matzkin proposition lange papageorgiou demonstrates joint distribution identifies matching function normalization one point, denoted within support following lange papageorgiou begin estimating across support achieve this, use distribution hire conditional users, observed vacancies, specifically, represent respective conditional distribution varying parameter trace across entire support given data finite, rely estimate constructive estimator consider arbitrary point obtain calculate proportion observation fewer hire taken observation proximate space practice, done averaging across observations, assigning smaller weight value distant via kernel discount distant observation resulting estimate expressed denotes bivariate normal kernel bandwidth distribution function recovered, invert derive observation dataset, using finally, recover matching function compute matching elasticities, employ lasso regression, projecting hire onto original squared value vacancy users, interacted implied matching efficiency resulting estimate approximate derivative matching function respect vacancy users, interacted implied matching efficiency provides estimate elasticity matching function figure present comparison matching efficiency matching elasticity hello work public employment platform left panel private scouting platform right panel hello work platform, depicted panel matching efficiency remains relatively stable around baseline normalized january sharply decline thereafter panel illustrates matching elasticity respect unemployment vacancy elasticity respect unemployment remains consistently lower, around elasticity respect vacancy show gradual increase, reaching value near suggests change vacancy larger impact number match change unemployment private scouting platform right panel panel show significantly higher volatility matching efficiency, especially peak sharply declining stabilizing around indicates private platform experienced large fluctuation ability efficiently match job seeker vacancies, potentially due shift demand change platform user base panel display matching elasticity respect user vacancy private platform elasticity respect user remains consistently around elasticity respect vacancy generally higher, rising steadily reaching around suggests responsive matching process change number vacancy higher volatility responsiveness private platform, along balanced elasticity user vacancies, highlight key distinction hello work, dynamic comparatively stable less responsive note confidentiality reasons, axis level masked figure illustrates labor market dynamic across three sector consulting, internet, manufacturing private job platform category represent high skill full time employed workers, though differ used hello work confidentiality reasons, precise number users, vacancies, hires, axis level disclosed, trend provide valuable insight sector specific pattern panel show labor market tightness generally increased across three sector consulting internet sector exhibit higher volatile tightness ratios, particularly reflecting job opening per user contrast, manufacturing sector show lower stable tightness ratio, indicating fewer vacancy relative job seeker field panel depicts matching efficiency, internet sector exhibiting highest variability levels, especially panel illustrate matching elasticity respect user vacancies, respectively consulting sector show negative elasticity respect user early on, likely due small user base, increase sharply time meanwhile, elasticity respect vacancy slightly decrease internet manufacturing sector show stable elasticity pattern overall trend highlight significant industry level heterogeneity, consulting experiencing dynamic growth, internet manufacturing follow stable slower trend paper us proprietary data bizreach, online job scouting platform japan, spanning estimate matching function high skill employed worker private job search platform result compared public job search platform, specifically targeting unemployed worker seeking full time job finding suggest matching efficiency private platform volatile generally higher public platform, highlighting increasing reliance private platform high skill job search furthermore, private platform demonstrates higher matching elasticity respect unemployment compared public platform, elasticity respect vacancy similar indicates balanced responsiveness change user vacancy private platform, compared stable less dynamic public platform, hello work additionally, industry level heterogeneity evident across platforms, reflecting differing labor market dynamic sector however, paper provides key insight matching function job searches, analysis may fully represent broader job search labor market, particularly non high skill worker japan moreover, standard assumption homogeneity among worker vacancy may overlook important nuance future research focus expanding analysis private platform exploring individual level behavior, discussed study like kambayashi et al roussille scuderi provide comprehensive understanding labor market dynamic continuing ",general economics
"stylized fact money market empirical analysis eurozone data introduction ii excess liquidity declining unsecured interbank market iii evergreen repos answer lcr regulation iv collateral use bond scarcity interbank network topology vi conclusion vii acknowledgment appendix data source instruction reporting error sparse core periphery structure stable bilateral relationship asymmetric degree general data retreatment identification evergreen repos using secured transaction recorded within money market statistical reporting database european central bank, test several stylized fact regarding interbank market largest bank eurozone observe surge volume traded evergreen repurchase agreement followed introduction lcr regulation measure rate collateral use consistent literature regarding topology interbank network, confirm high level network stability observe higher density higher degree symmetry reported unsecured market money market venue bank carry refinancing activity great financial crisis gfc led heightened counterparty risk and, consequently, significant change money market across western economy response, european central bank ecb introduced full allotment procedure october allowing bank access unlimited central bank financing meanwhile, basel regulation mandated liquidity coverage ratio lcr improve bank short term liquidity resilience, requiring hold sufficient amount high quality liquid asset meet liquidity need stress scenario rule resulted creation excess reserve within financial system additionally, banking system refinancing increasingly relied collateralized lending, particularly repurchase agreement repos notable rise practice collateral use network topology money markets, transaction among bank identified link nodes, evolved consequence yet documented study aim quantifying change secured funding operation largest bank eurozone following gfc, ecb introduced full allotment procedure, enabling bank meet liquidity requirement without limitation consequently, volume overnight unsecured interbank market declined markedly see fig noted recent ecb survey increase excess liquidity attributed three main factor heightened demand central bank liquidity banks, ii implementation full allotment procedure, iii provision longer term refinancing operation since ecb asset purchase program app augmented excess liquidity banking system, bank reporting client inflow predominant factor subsequent decrease unsecured lending exacerbated introduction lcr january impeded liquidity redistribution indeed, le coz et al demonstrated, accounting analysis, interaction app lcr requirement contributes persistence excess liquidity financial system gfc underscored presence counterparty risk among banks, prompting shift unsecured secured lending markets, collateralized borrowing executed repurchase agreement repos involve exchange collateral cash specified period shift towards secured market reinforced introduction lcr, repos effectively navigate regulatory constraint evergreen repo, contract continually renewed mutual agreement, exemplifies adaptation le coz et al demonstrate evergreen repo one month notice period impact lcr party involved, collateral provided offset lcr loss due cash exchange figure show introduction lcr regulation coincides increase volume traded evergreen repos notice period longer one month see also allen observe volume evergreen repos traded among largest bank eurozone increased negligible amount ten billion per day empirical result presented established largest bank eurozone required report transaction money market statistical reporting database mmsr detailed appendix one month notice period evergreen repos prevents immediate unwinding position cash lender face liquidity requirement constraint facilitates use collateral market specifically, cash lender use collateral received reverse repo secure cash another repo transaction rate collateral used defined various way within literature here, define use rate collateral reported le coz et al various level collateral use, ranging measured across time region notably use rate around observed european money market australia switzerland u confirm use rate around eurozone fig measuring weighted number time isin code given collateral appears banking system given day define link interbank network presence least one repo exposure two bank specified aggregation period, range one day one year historically, interbank market network exhibited low density core periphery structure configuration, central core highly interconnected node surrounded periphery less connected node primarily link core rather switch market towards secured transaction led, according mmsr data, increased network density indeed, fig show network density ranging deepening link definition assume higher density due longer transaction maturity limited number bank sample prevented u studying core periphery structure secured market existence stable interbank relationship lending documented by, among others, furfine afonso et al blasques et al confirm result case secured market measuring share stable link one period another, namely jaccard network similarity index figure show jaccard network similarity index ranging depending aggregation period several author reported asymmetry degree within unsecured interbank lending network notably, craig von peter anand et al observe bank germany general fewer lender borrower observe symmetrical pattern case repo exposure among largest bank eurozone figure show degree expressed function degree almost symmetrical study, analyzed secured transaction documented money market statistical reporting database european central bank investigate various characteristic interbank market among largest bank eurozone finding reveal significant increase volume evergreen repurchase agreement coinciding implementation lcr regulation additionally, measurement collateral use rate aligns existing literature subject examining structure interbank network, result confirm high level stability however, also identified higher network density pronounced symmetry degree degree connection compared unsecured market insight contribute deeper understanding current dynamic structural property eurozone interbank market grateful financial research division directorate general research european central allowing u access mmsr database indebted stefano corradin, contributed research fruitful discussion finally, thank bertrand hassani anrt cifre number providing u opportunity conduct research quant ai lab research conducted within econophysics complex system research chair, aegis fondation du risque, fondation de cole polytechnique, cole polytechnique capital fund management empirical analysis rely money market statistical reporting mmsr database contains transaction statistic secured unsecured leg euro area money market july december database contains transaction transaction level data euro money market reported sample euro area bank required report transaction maturity inferior one year financial institution segments, access information type money market instrument, date trade, start termination contract, interest rate transaction, volume, sector counterparty, volume transaction, maturity transaction direction trading lending v borrowing also identifier reporting bank identifier counterparties secured transactions, also identify isin collateral bank mmsr obligation report transaction mature, deposit another entity reported balance sheet given bank reported everyday entity withdraws deposit either partly entirely keep interbank transaction mmsr reporting agent non missing reported information transaction volume, lei reporting agent, lei counterparty agent, isin code collateral direction transaction borrowing v lending remove canceled transaction database ie canceled transaction corresponds transaction initially reported later canceled, equivalent transaction approved bank later matured transaction keep analysis additionally, make sure date sample correspond official euro area trading calendar date main data transformation consists extracting information evergreen repos mmsr database evergreen repos repos infinite maturity flagged mmsr database evergreen notice period usually vary day reported repo transaction maturity band everyday day one trading counterparties decide stop transaction day, two counterparties agree date final maturity, reported database thus identify evergreen repeated transaction two counterparties least day specifically, identify unique repo combination two identifier transacting counterparties lender borrower nominal amount maturity isin code transaction repeated combination unique repos day considered evergreen continuing ",general economics
"economic consequence widowed war life cycle perspective introduction institutional background data empirical strategy socioeconomic effect wwii widowhood intergenerational spillover conclusion online appendix appendix compensation war widows, appendix alternative definition control group appendix effect heterogeneity appendix evidence attitude towards work gender norm appendix additional table figure appendix static model labor supply instruction reporting error data empirical strategy sociodemographic outcome labor market outcome mechanism data description work attitude gender norm war widow attitude gender norm war widow child despite million war widow worldwide, little known economic consequence widowed war use life history data west germany show war widowhood increased woman employment immediately world war ii led lower employment rate later life war widows, therefore, carried double burden employment childcare child young left workforce child reached adulthood show design compensation policy likely explains counterintuitive life cycle pattern examine potential spillover next generation jel code keywords war widow labor market career female labor force participation world war ii many conflict zones, war widow constitute large share population buvinic et al, example, world war wwi resulted million war widow bette, rwandan genocide united nations, one two million war widow lived afghanistan mid irb, chandran, women, many young children, play central role rebuilding postwar societies, lack evidence economic situation br ck schindler, broun u et al, work gendered consequence spousal loss due natural cause eg, dr ze srinivasan, burkhauser et al, fadlon nielsen, war widow face unique challenge due sudden violent nature spouse death, often young age, limited childcare financial support postwar society paper provides first quantitative evidence individual economic effect widowed war focus world war ii wwii deadliest conflict history although million soldier died, support survivor key policy issue literature individual effect wwii eg, ichino winter ebmer, kesternich et al, akbulut yuksel et al, yet examined economic plight surviving widow drawing rich life course data west germany, analysis focus labor market effect life cycle particular, test hypothesis war widow increased labor supply due adverse income shock losing husband boehnke gay, addition, examine whether daughter widow held progressive norm female employment increased labor supply accordingly fern ndez et al, gay, indeed find war widowhood significantly increased employment immediate postwar period war widow born percentage point pp likely market work otherwise comparable woman lose husband war however, positive employment effect gradually declines, war widow pp less likely work time likely rely welfare peer finding especially surprising given war widow remained unmarried less likely married labor force participation higher unmarried married woman time child war widow left school entered labor force earlier peers, presumably due financial hardship postwar period educational penalty particularly pronounced boys, lose full year education however, find long run effect widowhood either son daughter employment rate overall, widowhood leaf clear mark employment trajectory socioeconomic outcome million war widow living west germany niehuss, lasting effect woman labor force participation derive result comparing war widows, directly identify data, woman comparable prewar socioeconomic characteristic several observation support causal interpretation estimate first, difference prewar characteristic widow non widow small explain variation widowhood status second, adding control variable leaf estimate unchanged improving model fit third, war widowhood uncorrelated spousal parental characteristic either finding consistent fact woman sample married men whose cohort largely entirely conscripted war, minimizing selection war service death braun stuhler, widow counterintuitive labor supply trajectory likely explained design compensation system initially, financial support war widow limited, forcing many employment germany economic boom s, compensation became generous, especially mean tested component, created disincentive work standard substitution effect pattern typical compensation war widow often inadequate war torn societies, generous policy become feasible economy recovers number widow eligible compensation shrink boehnke gay, document pension payment french war widow wwi initially low increased similarly, skocpol, document benefit u civil war veteran dependent expanded massively time find back loaded compensation scheme force widow bear double burden employment child care young, incentivize withdrawal labor market later life moreover, show war induced labor market entry necessarily increase woman labor force participation long run work experience war widow often negative working widow accused neglecting childcare responsibilities, many widow struggled balance work household responsibility face social stigma lack childcare schn delbach, likely consequence, war widow hold progressive view compatibility family work, show using survey data attitude gender norm also place higher value work non widows, likely contributing withdrawal labor market later life fact, daughter war widow likely agree statement woman young child work paper first provide representative individual level evidence effect war widowhood labor market outcome contribute growing literature examining effect war mobilization military fatality female labor force participation flfp much literature focused case wwii us, suggesting mobilization men drew woman labor force goldin, acemoglu et al, goldin olivetti, jaworski, doepke et al, however, recent evidence caution wwii decreased female opportunity white collar job bellou cardia, suggests war production rather mobilization primary cause wartime surge flfp rose, extant literature emphasizes shift aggregate labor demand, examine individual experience widowed war affect woman labor supply life cycle especially country high military casualty rates, japan, germany, soviet union, experience war widow indispensable understanding overall impact wwii flfp related study, boehnke gay, note negative income shock losing one spouse may led war widow enter labor force wwi using variation across french regions, show higher military death increased flfp estimate widowed woman accounted nearly half effect however, study individual labor market careers, paper also relates study analyze intergenerational persistence war shock flfp fern ndez et al, use variation wwii mobilization rate across u state document intergenerational spillover woman labor supply fern ndez, develops learning model cultural change, wwii mobilization increase flfp next generation, woman drawn labor force war learn true cost working gay, find woman born french county experienced higher military death rate wwi likely work decade war ended study also capture intergenerational spillover demand driven shift woman employment due war mobilization focus spillover individual change labor supply due spousal loss total number german military dead missing five million, similar number soldier injured overmans, ller, fate surviving family member war disabled thus pressing social problem postwar germany bundesversorgungsgesetz bvg october aimed physical vocational rehabilitation war victim families, paid social assistance rehabilitation not, partially, possible diehl, however, difficult financial situation time limited generosity compensation payment war widow initially received unconditional basic pension grundrente dm mean tested compensatory pension ausgleichsrente dm per month latter paid woman age unless child care unable work maximum pension dm represented roughly average gross labor income time child age received additional orphan pension postwar society skocpol, boehnke gay, pension level gradually increased time maximum amount basic compensatory pension average labor income moreover, condition receiving compensatory pension lowered age limit decreased year additional damage compensation schadensausgleich introduced widow whose income less half husband would earned, increasing maximum pension nearly average income appendix describes maximum pension payment increased since mid s, real term share gross labor income three feature bvg worth highlighting first, compensatory pension reduced proportion earned income basic allowance mean tested part widow pension gained importance mid onwards, especially introduction likewise mean tested damage compensation see appendix second, woman entitled compensatory pension later life, unless unable work care child third, war widow lost pension right remarried received lump sum settlement upon remarriage war widow frequently faced dilemma labor market participation schn delbach, woman employment still controversial early s, employment war widow considered particularly undesirable due concern would neglect care child scarce institutional childcare available, working mother often depended relative childcare niehuss, hand, gainful employment often essential financial reasons, given initially low compensation payment main data source analysis mzu mikrozensus zusatzerhebung, representative mandatory survey provides detailed information change social occupational structure west german population covering population aged german citizenship, survey contains information individual survey asked respondent employment status occupation also recorded whether respondent owned house education level, main source income, net monthly income latter recorded seven category missing farmer survey also contains place residence allows u identify person displaced eastern europe wake wwii refugee gdr importantly purposes, survey asked woman whether war widow allows u identify war widow even remarried treatment group consists woman married time wwii whose husband killed war, died captivity, missing action focus woman born year old observation period woman birth cohort married lose spouse war form control group drop woman never married married risk losing spouse war table report mean standard deviation prewar covariates war widow column non widow column column report statistic testing null difference covariate mean two group given large sample size even small difference statistically significant therefore, column also report normalized differences, scale difference mean square root sum variance assess overlap covariate distribution imbens wooldridge, normalized difference prewar covariates smaller except two age displacement status war widow tend slightly older non widow earlier cohort likely married wwii, likely lose husband war widow also somewhat likely displaced non widows, presumably elevated death rate soldier germany former eastern territory overmans, however, even difference small robustly controlled standard linear regression note sample mean standard deviation prewar covariates war widow non widow baseline sample dropping observation missing prewar characteristic data refer except education, schooling, number siblings, measured self employed outside agriculture farmer land statistic column refers two sided mean difference test normalized difference column calculated sample mean sample variance war widow non widows, respectively detailed life cycle analysis, use ghs, retrospective survey eight west german birth cohort draw second wave ghs conducted surveyed respondent born woman mayer, mayer, a, sample size much smaller, ghs contains respondent complete marriage, education, employment, occupational history thus study war widow labor market outcome entire life cycle classify woman whose husband died war widow control group woman also married lose husband war complementary evidence work attitude gender norms, consider allbus, survey attitudes, behavior, social structure german population conducted biannually since data allow u examine work attitude war widow child appendix describes data detail examine whether widow non widow comparable war fared differently estimate ols regression model following type particular postwar outcome person time dummy variable identifying war widows, row vector prewar control variables, error term main parameter, measure widowhood effect, ie, average difference given outcome war widow otherwise comparable non widow report robust standard errors, clustered selection district also compare ols estimate estimate based inverse probability weighting ipw identification requires conditional widowhood status uncorrelated unobserved prewar difference still affect economic outcome postwar germany assumption would violated woman better unobserved labor market skill married high skilled men less likely die wwii non widow better labor market prospect average, would explain find lasting impact widowhood employment several piece evidence speak concern first, woman sample predominantly married men whose cohort largely entirely conscripted war important difference conscription rates, rather unequal survival rates, main explanation mortality rate differed birth cohort overmans, importantly, result also apply younger woman born see appendix almost married men born cohort fully conscripted war, selection military service played negligible role cohort also far young middle higher officer ranks, might promised better survival prospect consistent arguments, braun stuhler, show socioeconomic background predict war service injury among war survivor born second, table document small prewar difference widow non widow main mzu sample explaining merely variation widowhood status, see appendix table third, appendix table show ghs auxiliary sample war widowhood uncorrelated woman prewar characteristics, also spouse parent characteristic fourth, show adding extensive set prewar covariates listed table virtually effect estimates, helping explain variation outcome variable thus unlikely omitted variable drive result table show effect war widowhood sociodemographic outcome mzu quarter century war end woman sample year old time column present estimate parsimonious ols model, controlling age column add control variable house ownership displacement status, number siblings, full set education dummy full fledged specification column additionally account sectoral occupation affiliation finally, column present ipw estimate using full set control predict treatment status follows, discus point estimate ipw model, estimate hardly change across specification support unconfoundness assumption invoke identification note mean control group estimate war widowhood estimate stem separate regression estimate column ols, estimate column ipw regression include following prewar covariates full set age dummies, plus indicator house ownership indicator expellees eastern europe refugee gdr, number siblings, full set education dummies, plus seven category sector employment agriculture, industry, construction, trade transport, finance, public private services, unknown seven category occupational employment status self employed, farmer, civil servant, white collar worker, blue collar worker, helping family member, labor force including apprentices, education, unemployed robust standard error clustered selection district auswahlbezirke reported parenthesis square root scale divide total household income square root household size observe younger household member born later mzu panel table show war widowhood striking long term demographic consequence war widow pp lower probability married baseline probability see column finding new partner often proved elusive, war led acute shortage men although war widow likely cohabit non family member, overall probability low, thus, find little evidence support widespread belief many war widow cohabited without marrying order retain pension right war widow also twice likely live alone, slightly fewer child woman sample often child top panel figure illustrate demographic consequence life cycle, based ghs pooled ols regression interact full set age indicator indicator war widow figure show war widow pp less likely married war end gap shrink widow remarry, stabilizes around pp widow reach late gap start shrinking widowhood becomes common also control group figure illustrates war widow fewer child war ended socio demographic characteristic employment career outcome intergenerational spillover note ghs, estimated effect war widowhood life cycle woman born estimate pooled ols regression, interacting indicator war widow panel child panel birth year full set age indicator panel also control year marriage point estimate marked dot vertical band indicate confidence interval estimate shaded area indicates duration wwii panel table show mzu war widow less likely employed pp lower probability market employment, pp lower probability helping family member, thus pp higher probability labor force non widow finding surprising, war widow remained unmarried, unmarried woman considerably higher participation rate time better understand patterns, table report effect war widowhood employment occupational status focus ipw estimate full set control panel show war widow pp likely perform market work non widow similar prewar characteristic baseline probability however, difference shrink pp war widow less likely work life cycle pattern cannot explained change aggregate labor demand, would affect treatment control group negative long term effect labor force participation reinforced fact that, years, war widow half likely non widow work helping family member appendix highlight woman market work war particularly drawn labor force among helping family members, war widow pp nearly likely market employment even group, positive employment effect eventually disappears moreover, highly educated woman much likely enter employment spouse death low educated women, modest positive employment effect persisting old age aligns u finding wwii mobilization increased employment among highly educated woman goldin olivetti, negative employment effect old age driven woman child see appendix figure confirms life cycle pattern ghs, showing higher employment among war widow compared non widow postwar period, similar lower employment rate mid retirement widow reduce labor supply age share remarried widow increase figure appendix figure confirms coincidence widow employment rate drop pp immediately remarriage however, long run, also observe drop employment war widow ghs remarry older cohort widow mzu rarely remarried see table despite higher employment rate early age, war widow reported similar average occupational prestige score non widow see figure note mean control group ipw estimate war widowhood estimate stem separate regression regression include control full set age dummies, indicator house ownership indicator expellees eastern europe refugee gdr, number siblings, full set education dummies, indicator sector employment agriculture, industry, construction, trade transport, finance, public private services, unknown occupational employment status self employed, farmer, civil servant, white collar worker, blue collar worker, helping family member, labor force including apprentices, education, unemployed robust standard error clustered selection district auswahlbezirke reported parenthesis panel table show evidence occupational status larger main sample conditional market work, war widow less likely work blue collar worker war widow pp less likely blue collar worker baseline probability instead, war widow overrepresented white collar occupation also time likely employed civil servant albeit baseline likely result policy favored war widow civil service employment panel table show personal net income war widow twice non widows, largely due higher support state war widow time likely report welfare support main income source baseline probability focus woman market work, war widow dm non widow baseline dm considerably less unconditional basic pension dm paid war widow time panel also show household income, measured square root equivalence scale, lower war widow non widow finally, panel show war widowhood reduced probability owning house pp despite initial increase employment, war widow eventually lower employment rate non widow s, thus bore double burden work childcare without partner however, s, child left home, war widow less likely work non widow discus mechanism might contributed counterintuitive life cycle pattern fix ideas, consider simple static model labor supply mother choose consumption hour work leisure time child care time maximize utility function subject disutility work might vary age social norms, constraint time child quality budget, hourly wage rate source household income optimal choice leisure work time characterized slope indifference curve consumption leisure consumption child quality budget constraint see appendix detail although simple, model rationalize peculiar life cycle labor supply trajectory observe similar boehnke gay, interpret loss spouse negative income shock, ie, decrease assuming leisure normal good, income loss decrease leisure time spent childcare, increase hour worked income effect appendix figure provides illustration war widow also received compensation see section but, since offset part decline household income decreases, shown table would yet explain war widow less likely work older age however, widow pension partially mean tested, also decrease effective take home wage, reduces work incentive substitution effect crucially, mean tested form compensation grew disproportionately time, accounting maximum pension therefore, budget curve war widow respect hour worked became flatter time, disincentivizing participation labor force implied negative substitution effect hour worked dominate positive income effect reduction total income, illustrated appendix figure compensation scheme thus created perverse life cycle incentive war widow low compensation earlier year forced labor force, despite limited childcare stigma society placed working single mother child reached adulthood, war widow time available, increasingly mean tested compensation scheme discouraged work less aggressively mean tested compensation scheme could maintained labor force participation, reduced public spending, provided similar utility war widow see appendix figure negative work experience s, double burden work childcare environment hostile working mothers, may also explain war widow supportive woman young child working non widows, although tended progressive gender norm domain show appendix d, nine ten war widows, among non widows, disapproved woman working outside home small child home war widow also place importance work life probably contributed withdrawal labor market, physical exhaustion double burden work childcare younger age also examine intergenerational spillover war widowhood, first wave ghs ghs conducted early s, interviewed child born shortly war mayer, b, treatment group consists whose father mother died wwii control group includes child cohort whose father absent least one year war educational outcomes, also include respondent siblings, ghs provides educational information close family member use information estimate variant equation dummy variable indicating whether father individual died war, measure intergenerational spillover male child war widows, differential impact daughter relative son control include mother birth year interaction indicator child birth year gender table report estimate column show son war widow half year less schooling, line previous finding ichino winter ebmer, report negative effect father wwii service death child year schooling tertiary schooling university vocational training even lower treatment group column overall, educational attainment decline one year column contrast, little decline educational attainment among daughter war widow estimated effect gender gap opposite sign almost large main effect note estimate effect war widowhood educational attainment, employment year occupational score maximum score child partner estimate stem separate ols regression including mother birth year interaction indicator child birth year gender control variable ghs birth cohort including sibling column robust standard error clustered household level reported parenthesis less time spent education, child war widow instead enter labor force earlier, presumably financial hardship faced war shown column son war widow spent nearly year employment age control group figure confirm decline educational attainment mirrored corresponding increase employment despite lower educational attainment male children, find spillover employment mid age table column occupational score column importantly, find persistent employment effect daughter war widow either and, anything, negative effect occupational success likely work s, gap disappears mid also find positive spillover work attitude anything, daughter war widow held less progressive view compatibility woman work childcare responsibility see appendix also find spillover son gender norm appendix occupational score son wife table column fern ndez et al, show woman labor force participation affect son preference working wife, find spillover son war widow result complement previous work long term effect two world war woman employment war induced increase woman employment transform work gender norm trigger intergenerational spillover fern ndez et al, fern ndez, gay, find effect treatment group war widow positive attitude toward woman work, transmit progressive attitude son daughter likely reflecting challenging condition endured working single mother postwar period employment spell born necessity war widow thus appear less lasting effect resulting higher aggregate labor demand due men wartime mobilization million woman worldwide lost husband violent conflicts, yet little known economic situation includes wwii, devastating conflict history present first evidence complex effect war widowhood, using life course data postwar germany war widowhood dramatic long term consequence family formation, widow remaining unmarried despite persistent negative shock household income, war widow likely work middle year life cycle, positive employment effect gradually diminished, war widow less likely work time likely rely welfare peer finding underscore importance public policy shaping widow economic outcome low compensation inadequate child care immediate postwar period created dilemma war widow young child needed earned income faced accusation neglecting child worked dire financial situation likely also forced widow child leave school early compensation became generous increasingly mean tested time, creating disincentive work long war ended poor work experience war widow may also explain war induced labor market entry spillover effect participation next generation given often dire financial strait government conflict zones, problem insufficient support war widow specific study, applies similarly contemporary conflict see eg mednick, york, south sudan civil war russo ukrainian war, respectively international effort address challenge faced war widow thus particularly important immediately conflicts, many widow face double burden childcare employment support also critical break intergenerational reproduction conflict related poverty widow headed household buvinic et al, study suggests may operate reduced educational opportunity finally, country fiscal space expands postwar recovery, important design widow compensation way preserve incentive work figure document evolution maximum attainable war widow pension panel show increase maximum compensation since mid s, measured relative gross labor income black solid line considering real increase since gray dashed line relative labor income, compensation nearly doubled early second revision bvg time, maximum attainable war widow pension increased fivefold real term increase began second half continued relatively evenly that, notable spike significant damage compensation schadensausgleich introduced widow whose income less half deceased husband expected income figure show three different type compensation non mean tested basic pension, mean tested compensatory pension, mean tested damage compensation contributed increase ratio war widow pension average gross labor income seen, basic pension relatively stable time, fluctuating average labor income increase war widow pension initially largely due fact compensatory pension payment outpaced growth labor income later, introduction damage compensation spurred increase maximum war widow pension mean tested form compensation accounted total maximum pension note figure show maximum compensation war widow panel show total compensation relative gross labor income full time worker black solid line real increase maximum compensation since gray dashed line value normalized panel decomposes total compensation relative gross labor income black solid line part due basic pension non mean tested black dashed dotted line compensatory pension mean tested gray dashed line damage compensation mean tested gray solid line see description section appendix detail source author calculation based bundesversorgungsgesetz various version data average gross labor income taken bundesamt justiz bmjv, price index standard living person household medium income taken statistisches bundesamt, unfortunately, mzu contain respondent entire marriage history, year last marriage married pose two problem definition control group first, cannot exclude possibility divorced widowed woman control group married consider minor problem woman sample well average age first marriage year second, married woman married exclude analysis, could principle earlier marriage war observe last year marriage again, consider minor problem, less married woman sample married importantly, show main text result hold second survey, german life history study, observe woman complete marriage history nevertheless, additional robustness checks, drop widowed divorced woman control group keep married woman control group table report result main result labor force participation result virtually unchanged keep woman married control group, even last marriage expected since woman sample married difference somewhat larger drop widowed divorced woman control group expected since married woman remain control group tend relatively low employment rate time result, initial employment gain war widowhood somewhat larger relative baseline even compared control group, find war widow likely labor force however, effect entirely driven negative impact probability helping family member table also show counterintuitive effect widowhood labor force participation life cycle elevated depressed extends younger cohort born almost woman married men born whose cohort fully conscripted war, selection military service negligible note mean control group ipw estimate war widowhood across different sample microcensus sample differ birth year cohort considered definition control group estimate stem separate regression regression include control full set age dummies, indicator house ownership indicator expellees eastern europe refugee gdr, number siblings, full set education dummies, indicator sector employment agriculture, industry, construction, trade transport, finance, public private services, unknown occupational employment status self employed, farmer, civil servant, white collar worker, blue collar worker, helping family member, labor force including apprentices, education, unemployed robust standard error clustered selection district auswahlbezirke reported parenthesis control group consists woman married whose marriage year earlier compared baseline sample, widowed divorced woman control group dropped control group includes woman ever married compared baseline sample, control group also includes woman married whose last marriage main result section war widowhood increased probability market employment immediately war longer run, war widowhood actually decreased market employment here, document negative long term effect participation strongest less educated woman child table present estimate effect widowhood market employment separately subgroup indicated left first row, replicate baseline result ease comparison first distinguish woman child surprisingly, woman without child much higher employment rate middle age example, control mean twice high without child child versus however, pattern widowhood effect time large positive declining similar group see, negative long term effect visible woman child them, war widowhood reduced market employment pp second, show high educated woman much likely low educated woman take market employment death spouse wwii moreover, them, positive effect persists, albeit muted, late life find highly educated women, war widowhood increased probability market employment pp respectively contrast, effect size percentage point woman low education differential effect consistent previous finding u wwii mobilization increased female labor supply among highly educated woman goldin olivetti, finally, table also examines effect widowhood occupational status distinguishing woman market employment, worked helping family members, labor force war notable difference among group widowhood effect largest worked family helper increasing probability market work percentage point compared control group probability increase also substantial woman work war, modest already labor force widowhood effect decline three groups, disappears market employment group also experienced largest negative effect percentage point note mean control group ipw estimate war widowhood estimate stem separate regression subgroup indicated left regression include control full set age dummies, indicator house ownership indicator expellees eastern europe refugee gdr, number siblings, full set education dummies, indicator sector employment agriculture, industry, construction, trade transport, finance, public private services, unknown occupational employment status self employed, farmer, civil servant, white collar worker, blue collar worker, helping family member, labor force including apprentices, education, unemployed robust standard error clustered selection district auswahlbezirke reported parenthesis section summarizes evidence impact war widowhood attitude towards work gender norm first describe data source discus finding separately war widow child allbus survey collecting data attitudes, behavior, social structure german population every two year since use data five wave gesis leibniz institut sozialwissenschaften, b, gesis leibniz institut sozialwissenschaften, a, wave interviewed random sample west german citizen age foreigner excluded exact question vary, outcome variable interest typically available subset wave five wave contain information complete marital history respondent allows u identify woman lost spouse treatment group compare woman married lose spouse control group restrict sample woman born order look similar cohort main analysis regression control full set dummy year birth year first marriage, year interview, year schooling respondent father addition, wave includes year death respondent father mother thus, wave, also examine child war widow comparing respondent whose father died world war ii whose father focus cohort born drop respondent whose mother died regression control respondent year birth father year schooling allbus wave asked respondent importance different domain life, including family, job, leisure, friends, relatives, religion, politics, measured scale unimportant important table show war widow placed a, overage, lower value importance family child life relative control mean domain life, difference war widow control group small particular, find evidence war widow attach greater importance job work life anything, impact negative small statistically insignificant note control mean estimate effect war widowhood importance different domain life sample consists woman born allbus wave outcome variable measured scale unimportant important estimate come separate ols regression, controlling full set dummy year birth year first marriage, year interview, year schooling respondent father robust standard error shown parenthesis allbus wave asked several question woman role family work unfortunately, question changed wave thus directly comparable summarize respondent attitude towards gender role measuring proportion progressive statement respondent agreed column table show progressive gender role index pp higher among war widows, albeit comparatively low baseline words, war widow tend progressive gender role still disagree progressive statement agree traditional statement note control mean estimate effect war widowhood work related gender norm sample consists woman born allbus wave outcome variable column summarizes response six nine statement work related gender norm asked waves, respectively indicator measure proportion progressive statement respondent agreed including negation traditional statement outcome variable column indicator variable indicating whether respondent agreed question table header estimate come separate ols regression, controlling full set dummy year birth year first marriage, year interview, year schooling respondent father robust standard error shown parenthesis particular importance woman labor supply decision compatibility work child care responsibility west germany, birth child often led previously employed woman give work altogether favor family, interrupt career many year eg matysiak steinmetz, previous research based allbus wave shown west german strongly disapproved woman working outside home preschool child home, even respondent uk u alwin et al, result column indicate war widow exception, supportive woman young child working column show war widow slightly less likely agree statement young child suffer mother works, statement nearly control group respondent agreed war widow likely approve woman working situation childcare issue column even slightly likely disapprove woman working child column table show also child war widow hold progressive gender norm peer neither progressive gender role index column agreement statement young child suffer mother work column differs statistically significantly two group applies approval woman work column one exception daughter war widow pp higher probability agreeing statement woman young child work baseline probability pp thus, anything, find evidence experience growing without father made daughter war widow less supportive compatibility woman work caring young children, potentially experienced challenge faced mother postwar period case, even among respondent born disapproved woman working outside home preschool child home note control mean estimate effect war widowhood work related gender norm child sample consists respondent born allbus lose mother panel restricts sample woman daughter panel restricts sample men son outcome variable column summarizes response nine statement work related gender norm asked wave indicator measure proportion progressive statement respondent agreed including negation traditional statement outcome variable column indicator variable indicating whether respondent agreed question table header estimate come separate ols regression, controlling respondent year birth father year schooling robust standard error shown parenthesis note table report regression relating war widowhood status german microcensus increasing number covariates regression include following prewar covariates full set age dummies, plus indicator house ownership indicator expellees eastern europe refugee gdr, number siblings, full set education dummies, plus eight category occupational employment status self employed, farmer, civil servant, white collar worker, blue collar worker, apprentice, helping family member, labor force, education, unemployed plus six category sector employment agriculture, industry, construction, trade transport, finance, public private service note table report coefficient estimate regression war widowhood status set prewar individual, spousal, parental characteristic woman born robust standard error parenthesis note figure show share respondent reporting ill health life cycle ghs, separately war widow non widow child born note figure show employment rate war widow remarried ghs axis event year relative year remarriage consider simple static model labor supply mother choose consumption hour work leisure time child care time maximize utility subject production function child quality constraint time budget, hourly wage rate source household income including labor income woman spouse given constraint budget time, express consumption hour worked function leisure child care time ie, individual maximization problem simplifies parameter utility function represents disutility work may vary age social norms, ie stigma society might place working single mother taking first order condition respect optimal choice leisure child care time characterized ie, marginal rate substitution consumption leisure equal wage, ie, marginal rate substitution consumption child quality equal ratio wage marginal effect child care time child quality optimal choice hour worked consumption follow time budget constraint note budget constraint indifference curve static model labor supply sub figure illustrates income effect losing one spouse, modeled reduction non labor income hour worked increase point sub figure illustrates effect mean tested compensation scheme partially offset reduction also reduces effective take home wage work decreasing hour worked c, solid line alternative policy compensation less mean tested increasing hour d, dotted line figure provides illustration loss spouse sub figure mean tested compensation scheme sub figure affect hour worked consumption illustration, assume cobb douglas utility function stigma sub figure interpret loss spouse negative income shock ie, decrease budget curve decrease accordingly dashed line assuming leisure normal good, income loss decrease leisure, decrease time spent childcare, increase participation, increase working hour conditional participation income effect illustration, hour worked increase point sub figure illustrate effect compensation scheme partially mean tested income additional hour work crowd compensation, effective budget curve flatter green solid line corresponding budget curve without compensation blue line reduction effective wage rate disincentive labor supply substitution effect example, compensation payment decrease hour worked point sub figure also plot alternative compensation policy characterized lower unconditional payment ie, budget curve higher intercept however less rapidly withdrawn labor income income therefore increase rapidly hour worked dashed green line consequence, income effect dominates substitution effect, hour worked increase point continuing ",general economics
