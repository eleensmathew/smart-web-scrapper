content,newcol
"new view hypercube genus introduction hypercubes two cell embeddings graph genus embeddings hypercubes parallel genus embeddings instruction ringel discovered formula minimum genus torus dimensional hypercube graph embedded give new proof formula building surface union certain face hypercube skeleton odd dimension entire skeleton decomposes copy surface, intersection two copy hypercube graph graph drawn surface without crossed edge kuratowski theorem theorem implies complete bipartite graph figure cannot drawn sphere plane without crossed edge min one try draw sphere, always fail however, drawn torus, shown figure genus graph denoted least integer drawn closed, connected, orientable surface genus without edge crossing sphere genus surface hole genus thus figure also show together drawing torus genus respectively indeed, ringel proved thus drawing figure optimal genus formula established well known family graph instance, difficult proof simple formula instrumental settling heawood map coloring conjecture chapter dimensional hypercube graph ringel beineke harary used recursive argument exploiting hypercube product structure deduce proof lead generalization like contrast, short, visual proof directly construct genus surface square face cube show odd skeleton cube union copy genus surface, common faces, intersecting pairwise section define hypercubes, skeleta, cell embeddings graph surfaces, state euler formula genus proof equation section section give bonus factorization skeleton genus surface let denote unit interval let denote boundary use notation useful regard interval active inactive manner described dimensional hypercube, cube polytope thus intersection half space see introduction polytopes vertex element identify binary string length example, etc edge connected component product one active factor inactive factor thus edges, line segment joining two vertex differ exactly one coordinate namely active coordinate face square connected component two factor rest thus faces, boundary face consists four edge likewise face formed choosing three position face cube whose boundary six face general, cube face formed choosing active factor face cube brevity call faces, faces, face vertices, edges, faces, respectively, stated face called facet two opposite facet two component sole th factor reader verify two nonopposite facet intersect face collectively facet form boundary skeleton union faces, skeleton union square face skeleton hypercube graph, denoted vertex digit binary strings, edge connects two vertex differ exactly one position figure show hypercube graph dimension bipartite, is, vertex partitioned two set say, black white edge join black vertex white vertex black vertex binary string odd number s, white vertex even number s, figure figure illustrates another nice feature hypercubes edge colored color edge whose endpoint differ th coordinate get color note vertex incident exactly one edge color surface mathematical object look locally like plane, differ radically plane globally earth surface example look locally like plane least flat land globally plane all, sphere exactly, surface compact connected topological space point neighborhood homeomorphic open disk see introductory text chapter development informal remark make orientable surface sphere, torus, holed torus, and, general, surface hole nonorientable surface one cut bius band of, focus number hole orientable surface called genus denote unique surface genus arbitrary orientable surface, genus denoted sphere genus thus denoted figure show example noted earlier, genus graph smallest integer drawn without crossed edge drawing regarded continuous injection called embedding embedding surface genus called genus embedding figure show genus embeddings embedding divide regions, connected component cell embedding one region homeomorphic open disk region cell embedding called face every genus embedding cell embedding theorem example, embedding figure three face two square one octagon embedding eight faces, square euler formula theorem implies cell embedding connected graph closed orientable surface vertices, edges, faces, checking embedding figure get figure get face cell embedding connected graph vertex edge face gon, edge exactly two faces, get graph bipartite, triangles, equation yield lemma corollary vertices, edges, bipartite, ready theorem genus hypercube graph color edge color edge joining vertex differ th coordinate given color face whose edge colored bicolored pair assemble collection face one bicolors one bicolors, face particular bicolor, edge belongs exactly two face color two face bicolors addition modulo thus face arranged cyclicly around vertex, manner described figure follows face form surface skeleton embedded surface square regions, connected connected assume moment surface orientable genus formula thus embedded surface genus lowest genus possible lemma say yes finish proof must verify orientable indeed something prove here, skeleton contains bius strip figure left must verify none exist this, note face local orientation given right hand rule either one black vertex place right hand black vertex finger pointing edge color edge color thumb point direction square, finger indicate counterclockwise orientation square white vertices, thumb point figure show orientation preserved move square adjacent square follows orientable let carry construction proof first, color edge solid, dashed, dotted, figure construction, form surface including solid dashed faces, dashed dotted faces, dotted solid face fact face get six face shown upper left figure form surface cube, topologically equivalent sphere next, consider edge colored figure construction dictate form surface including solid dashed faces, dashed dotted faces, dotted dash dotted faces, dash dotted solid face sixteen face see bottom left figure resulting surface torus surface include solid dotted dashed dash dotted face clearly see perimeter edge belong included face walking hole torus, one walk four solid dotted face see perimeter four dashed dash dotted faces, inside torus representation figure long history according robbin perspective view standard originated schlegel let apply construction get genus embedding assign specific color edge avoid visual clutter image say five edge color thus include cube face bicolored obtain embedding shown figure embedding include cube face bicolored thus embedding exactly half face cube one walk model see edge half face without intersection half face cube form surface isometric one see section missing face clearly visible perimeter edge face belong embedding one nice feature embeddings aid greatly visualization hypercubes one can, example, easily pick ten facet see fit together highlight this, offer exercise related model figure exercise locate face square model exercise identify ten facet facet cube exercise cube face one cube find least one, locate two cube facet share exercise arbitrary vertex, find five cube facet share vertex approach cube embedding extrinsic describe recursive procedure hook together two lower genus surface family connecting tube contrast, intrinsic method interesting consequence entire skeleton decomposed copy genus surface recall cycle graph hamiltonian cycle contains vertex graph complete graph graph vertex set edge joining pair distinct vertex ordering give rise hamiltonian cycle whose edge arithmetic modulo arguing proof theorem hamiltonian cycle union face bicolored addition mod surface genus embedding fact, permutation induces permutation standard unit vector carry isometrically onto sending vertex vertices, edge edges, face face another hamiltonian cycle share edge, call family surface parallel family every face square belongs exactly one collection hamiltonian cycle hamiltonian decomposition edge belongs exactly one cycle long known odd hamiltonian decomposition hamiltonian cycle problem recreational mathematics, asking whether one could find seating arrangement around round table gave pair people unique side side appearance see get nice consequence hypercube odd hamiltonian decomposition give rise parallel family genus embeddings is, skeleton decomposed face disjoint isometric copy genus embeddings let take hamiltonian decomposition genus embeddings intersect pairwise proof theorem faces, copy contain face completing article, found da also obtained theorem theorem using general version approach, avoiding issue nonorientability induction dimension da credit idea using skeleton coxeter construction certain skew polyhedron indeed, two coxeter skew polyhedron coincide genus surface though coxeter refer graph genus fact, idea generalized direction decomposition edge disjoint cycles, possible odd theorem euler yield parallel family surface skeleton see parallel family given theorem surface pairwise isometric polytopal perspective applied graph genus question nonorientable genus cube seems many nice",mathematics
"extremal problem martingale transforms, introduction simplest foliation example linear quadratic function horizontal herringbone investigation vector field equation fissure example polynomial third degree instruction paper, begin series study extremal problem estimating distribution martingale transforms bounded martingale bellman function corresponding problem pointwise minimal diagonally concave function horizontal strip, satisfying certain given boundary condition describe basic structure arise constructing function present solution case asymmetric boundary condition sufficiently small width strip article, start series paper going describe algorithm constructing bellman function extremal problem described inspired successful description algorithm constructing bellman function sufficiently wide class integral extremal problem bmo realized also recent generalization result general class functions, including among others muckenhoupt classes, see original extremal problem infinite dimensional functional space reduced problem constructing pointwise minimal locally concave function corresponding two dimensional domain parabolic strip case bmo given boundary condition, see minimal locally concave function turn linear along direction interior point domain thus, two dimensional domain foliated linear segment two dimensional subdomains, call structure foliation foliation constructed, possible reconstruct bellman function obtain sharp estimate original extremal problem similar approach used obtain sharp estimate various question martingale theory general random process go back called burkholder method many example usage method literature review topic found studying estimate martingale transformations, instead locally concave function called diagonally concave function arise concave along line segment form const recently, discovered certain class extremal problem martingale transforms closely related corresponding extremal problem bmo burkholder method reduces problem estimating distribution martingale transform bounded martingale finding minimal diagonally concave function horizontal strip, satisfying certain symmetric boundary condition upper lower boundary strip turn structure function sense coincides structure minimal locally concave function parabolic strip corresponding boundary data detail found discovering connection, desire consider broader class problem horizontal strip arose naturally, arbitrary, necessarily symmetric, boundary value specified boundary strip solving problem, guided two consideration first, generalization seemed natural dictated logic development theory is, interested understanding construct bellman function specific problem understand algorithm allows constructing necessary function wide class problem since guided internal task method development, looking specific application although many example series papers, example applying theory external problem second, since considerable interest various estimate martingale transforms see lose hope theory may find application future external problem however, ask reader seek application proposed text let proceed formal statement problem let standard probability space, dense filtration trivial algebra let two martingale space generated integrable function let martingale difference due triviality say martingale martingale transformation martingale exists sequence function measurable respect follows, restrict case almost everywhere given consider following two dimensional domain pair function generating martingale called admissible point almost everywhere set admissible pair denoted adm let two measurable function set define function formula main goal study construct bellman function given solving problem, provide description joint distribution function martingale transformation recent work problem solved case symmetric boundary condition description given condition function defined two dimensional domain called diagonally concave concave direction const following theorem go back burkholder proof found, example, chapter book function diagonally concave strip satisfies boundary condition moreover, pointwise minimal among function satisfying property function defined subdomain called bellman candidate candidate bellman function following condition satisfied diagonally concave satisfies boundary condition point one following condition hold exists straight line segment going one direction const connects point function linear function linear direction const neighborhood recent paper novikov proved remarkable theorem allows one verify given diagonally concave function pointwise minimal among function boundary value present simplified version, theorem let diagonally concave function say extremal direction endpoint segment endpoint lie parallel function linear, differentiable direction let function diagonally concave upper semi continuous discrete set discontinuity let assume interior point one following condition hold linear extremal direction linear extremal direction extremal direction linear direction neighborhood pointwise minimal among diagonally concave function boundary value future, construct diagonally concave function satisfy assumption theorem thus obtain minimal function according theorem function bellman function original extremal problem simplicity, assume boundary function smooth, although presented constructions, smoothness sufficient use theorem also assume function satisfy estimate since looking minimal possible diagonally concave function, concavity must degenerate point least one direction either along line segment const along line segment const call line segment extremal first case, call right extremal segments, second case, left extremal segment section, consider simplest case subregion foliated one type extremal segment either right one left one subregion foliated right extremal segment denoted similarly, subregion foliated left extremal segment denoted case right left extremal segment symmetric suppose linear along right extremal segment foliate mean boundary point connected extremal segment along linear words, equivalently, construction, linear therefore concave along direction const need check concavity along direction const fixed point define check function concave compute derivative value function derivative evaluated value derivative evaluated fix extremal segment passing point is, line concavity point extremal segment orthogonal direction implies inequality hold expression linear non negative non negative thus, obtain condition proved following statement function defined bellman candidate region condition satisfied symmetric case left extremal segments, bellman candidate given formula instead condition obtain following inequality formulate symmetric statement characterizing bellman candidate case function defined bellman candidate region condition satisfied approach inequality condition take limiting form limiting form condition approach opposite inequality lead following statement let sufficiently small exists function defined bellman candidate sufficiently small exists function defined bellman candidate since function sufficiently smooth, condition implies condition hold sufficiently small given also neighborhood size therefore, statement follows proposition case conclusion follows proposition let function uniformly bounded entire real line uniformly separated zero, sufficiently small function simple right foliation case simple left foliation case conclusion follows directly rewrite condition using taylor formula case similar let function identically equal constant expression left side coincide bellman function given simple foliation similarly, expression left side coincide bellman function given simple foliation bellman function linear let suppose define condition satisfied condition satisfied thus, two region simple foliations, remaining triangle vertex triangle, bellman function linear diagonal direction foliation symmetric one described respect axis need swap so, left consider case relation hold foliation similarly, relation hold, foliation particular, function linear along diagonal direction consider foliation arise neighborhood point two family extremal segment distinct direction meet point lying curve, call foliation herringbone, considering curve spine herringbone extremal segment expanding point spine rib rib go spine boundary, call herringbone vertical see fig go opposite boundary strip, call horizontal vertical herringbone extend upwards downwards horizontal herringbone extend left right right left, depending direction extending, call left right, respectively see fig horizontal herringbone whose spine connects two opposite boundary strip called fissure fissure one four direction right fissure start bottom boundary, call southeast se fissure start top boundary, call northeast ne fissure left fissure start bottom boundary, call southwest sw fissure start top boundary, call northwest nw fissure see fig note cases, name fissure indicates extends section consider different fissure boundary subdomains left right foliation study local behavior horizontal herringbone consider case left herringbone extends left right right one, everything symmetric assume spine left herringbone graph function interval, say foliation defined follows point e, point spine, two rib start one go point upper boundary, go point lower boundary, see left part fig parameter considered function variable point lying domain foliated rib rib going lower boundary foliate domain extremal segment spine herringbone call lower rib function implicitly defined identity similarly, extremal segment going spine upper boundary called upper rib identity holds, condition necessary foliation assume strict inequality except possibly finite number point spine know value spine denote def calculate value rib using linearity writing formula let agree following simplification notation future, omit argument functions, assuming derivative always calculated value derivative calculated value derivative calculated special case argument satisfy rule, explicitly written let write formula bellman candidate left herringbone function must completely determined boundary condition first step, derive important relationship function bellman candidate smooth corresponding foliation left herringbone described above, case right herringbone, consider case left herringbone symmetric case considered absolutely similarly however, formally obtained symmetry this, need change direction axis, e, change sign first derivative consider plane containing following three point segment belong graph function linear corresponding direction since diagonally concave smooth, plane tangent graph point therefore, vector tangent graph along spine herringbone parallel plane hence, coincides let show equation necessary also sufficient condition function smooth proving this, simplify calculation introduce three auxiliary function variable rewrite follows take following form meaning coefficient evident formula sign slope corresponding extremal line condition function defined smooth start auxiliary differentiation formula useful later first, relation lead identity differentiating let calculate derivative respect using equivalent form took account introduce two notation rewritten similarly, obtain differentiate respect see continuous side spine, limit side point spine equal e, continuous since function smooth, enough continuity gradient alternatively, also easy directly verify continuity using differentiate respect therefore, continuous side spine, limit side point spine equal function defined bellman candidate condition concave direction const functions, concavity equivalent inequality check inequality separately part herringbone, thanks smoothness, implies desired concavity entire herringbone let defined using function satisfying condition concave direction const defined boundary value follows first, differentiate respect differentiate expression respect thus, prove diagonal concavity need calculate compare obtained expression first, consider case differentiating respect obtain expression linear extremal line e, fixed non positive value non positive thus, obtain following necessary condition consider lower half herringbone, similarly, obtain necessary condition follow note condition necessary also sufficient diagonally concave comparing obtain necessary condition equivalent equality defines spine non zero given condition satisfied, obtain remaining condition transform formula implies left horizontal herringbone intersect axis point cannot calculate directly however, point isolated, pa limit find term boundary value slope spine point value derivative evaluated formula work happen e, multiple root case considered one subsequent paper symmetrically, right horizontal herringbone intersect axis point see spine horizontal herringbone intersects axis coincides segment, condition show possible function differ constant corresponding interval small bellman function inside interval resemble one built symmetric strip, e, everywhere see however, ready consider case therefore postpone investigation two equation two unknown function consider definition term function defined differential equation derive substituting defines spine left horizontal herringbone foliation diagonally concave function boundary value satisfies following differential equation differentiate get using obtain written substituting formula collecting term obtain coincides conclude section listing change formula left horizontal herringbone need made obtain corresponding formula right herringbone mentioned beginning proof proposition need change direction axis, thus formally reverse sign first derivative distinguish right left herringbones, use index example, function defining spine right left herringbones, value corresponding spines, end section, consider right herringbone, object marked index usually omit index subtle change made argument derivative argument function function satisfies relation instead therefore, instead obtain definition remains same, well definition change sign derivative take form formula given proposition see make change definition changing sign derivative instead write then, instead get formula remains same, need change sign instead condition obtain condition diagonal concavity lead relation giving definition different sign front instead obtain instead expression remains must change sign condition diagonal concavity situation, natural introduce function definition, condition diagonal concavity remains unchanged finally, analogue following equation far, used notation function variable introduce function defined entire plane except axis function defined case right left herringbone function respectively, expressed term follows state condition necessary sufficient diagonal concavity herringbone also region condition concavity rewritten condition concavity section, explore behavior integral curve vector field differential equation describing left herringbone shift first coordinate instead write remains second coordinate thus, left herringbone, argument instead argument instead convenient consideration evolution integral curve parameter increase node move grows corresponding point intersection left herringbone central line strip e, left herringbone move right following, consider parametrization investigated integral curve system write shorter formulas, omit argument derivatives, assuming function sign always argument thus, instead write start description stationary point system, e, point right hand side equation zero first, consider stationary point lying central line form determined equation interval central line stationary point integral curve vector field left herringbone intersect central line strip point solution symmetrically, point intersection right herringbone central line form describe behavior integral curve neighborhood stationary point, calculate jacobian matrix system let root stationary point furthermore, assume equation finite number simple root therefore, jacobian matrix identity operator scalar multiplier mean stationary point always dicritical node, local behavior integral curve shown figure mentioned earlier, assume following condition consider two curve neighborhood defined equation mean mean smooth, equation unique smooth solution neighborhood follows implicit function theorem fact derivative left hand side respect equal curve intersect node later, see small intersection curve boundary intersection curve boundary give two stationary point vector field curve neighborhood described equation curve neighborhood described equation sign function right curve coincides sign expression left, sign opposite fixed consider function interval small enough, function opposite sign endpoint interval therefore, inside interval, exists root uniqueness root guaranteed implicit function theorem sign function right curve coincides sign derivative left, sign opposite prove representation expand function second order term then, constant term give coefficient give proof second part proposition completely similar instead consider let calculate slope curve similarly, slope curve given thus, make following conclusion small slope curve positive le upper half strip greater lower half small slope curve negative sufficiently small, exists unique root equation e, moreover, similarly, exists unique root equation e, moreover, following simple statement play important role investigating behavior integral curve vector field slope integral curve field point strictly increasing strictly decrease obtain following expression slope integral curve differentiating expression respect give formula directly implies desired result investigate vector field around stationary point since satisfies formula take form small value parameter eigenvalue matrix right hand side e, saddle point eigenvectors meaning two integral curve passing stationary point slope behavior integral curve around stationary point shown fig need detailed approximation eigenvector corresponding eigenvalue approach easy compute corresponding eigenvector equal thus slope corresponding integral curve important compare slope curve slope curve use calculate slope curve thus, relative position two curve near determined sign consider stationary point since satisfies formula take form therefore, small matrix eigenvalue also saddle point eigenvectors meaning two integral curve passing stationary point slope behavior integral curve near stationary point shown fig combining information, understand behavior integral curve vector field near three stationary point small value overall picture shown fig end section, list change need made consider vector field equation integral curve may spine right herringbone case, symmetric picture sufficiently small following three stationary point unique solution equation interval unique solution equation interval furthermore, defined ready construct foliation call fissure first, let consider left fissure recall horizontal herringbone extend left right one boundary fissure must intersect middle line strip, meaning must value previous section, know point must stationary point, also seen directly right herringbone, condition thus, precisely point around could construct either right left simple foliation small see section section, sufficiently small build fissure near point solves equation sw fissure shown fig term sw fissure mean fissure come southwest words, horizontal herringbone extending left right bottom boundary top denote region foliated fissure sw here, first coordinate endpoint segment intersection foliated region middle line foliation may appear possible boundary value therefore, impose following additional condition simple root equation meaning foliation appear additional condition satisfied complicated considered later goal prove following statement let let root equation described corollary sufficiently small exists sw fissure spine function defined interval solves equation formula function given defines bellman candidate sw foliated fissure exists standard bellman candidate see together described candidate sw form smooth bellman candidate union three region sign second third derivative determine direction corresponding fissure thus, reflection respect line give se fissure let let root equation described corollary sufficiently small exists se fissure spine function defined interval solves equation formula function given defines bellman candidate se foliated fissure exists standard bellman candidate see together described candidate se form smooth bellman candidate union three region reflection respect line swap lead following statement let let root equation described corollary sufficiently small exists nw fissure spine function defined interval solves equation formula function given defines bellman candidate nw foliated fissure exists standard bellman candidate see together described candidate nw form smooth bellman candidate union three region let let root equation described corollary sufficiently small exists ne fissure spine function defined interval solves equation formula function given defines bellman candidate ne foliated fissure exists standard bellman candidate see together described candidate ne form smooth bellman candidate union three region consider case sw fissure neighborhood this, need solve equation seek solution interval boundary condition satisfying convexity condition investigating vector field preceding section, claimed exists exactly one integral curve field connecting node saddle point upper boundary prove statement describe detailed property curve recall, field horizontally shifted compared field generated equation mentioned integral curve give upper half herringbone point obtain lower half herringbone, must take unique integral curve starting node, directed towards lower boundary, together upper half form smooth curve natural parametrization see one bold curve figure need verify convexity condition satisfied ensure slope herringbone spine exceed e, construct desired foliation see figure corresponding function diagonally concave let denote integral curve field originating positive slope know curve exists unique moreover, slope described imposed condition derivative function ensure see slope curve e, le slope curve noted proposition region lie right curve upper half strip left curve lower half strip see figure consider open subdomain upper half strip bounded curve middle line vertical line explained, curve originating saddle point neighborhood point lie curve enters need prove cross boundary node note due assumption inequality satisfied neighborhood thus sufficiently small hold well inequality implies hence also satisfied then, see mean integral curve vector field graph function first coordinate slope integral curve field equal point intersection curve except, possibly, stationary point slope curve upper half strip strictly le see thus integral curve upper half strip intersect curve top bottom moving right left therefore, integral curve cannot exit boundary upper half strip furthermore, two integral curve vector field intersect stationary points, e, middle line intersect node thus, proved connects two stationary point saddle point node see figure fix temporarily consider slope curve equal see slope curve see meaning latter curve steeper neighborhood point therefore, sufficiently close lie consequently, curve also lie neighborhood point now, suppose intersects point since lie first point intersection, slope point intersection must le slope impossible within according proposition due continuity curve respect conclude lie left thus, curve intersect node shown integral curve thus slope strictly le upper half strip, need verify node fact, need check integral curve unit slope node purpose, calculate integral curve second order compare curve e, let integral curve interested defined equation then, obtain recall given smooth integral curve implies comparing obtained equation investigated integral curve equation curve e, see integral curve go left curve e, domain therefore cannot coincide conclude slope strictly le continue lower half strip, choose integral curve starting left slope thus, obtain smooth curve entire strip slope curve lower half strip strictly greater see remark reasoning similar given upper half strip show curve lower half strip intersection curve lie domain proved point curve second condition automatically satisfied sufficiently small now, prove small exists point intersection curve lower boundary strip denote first coordinate point check fix consider curve domain fix curve intersects line consider reason upper half strip, curve intersect curve larger located curve smaller therefore, exists point point intersection curve since slope strictly first coordinate point consequently, thus, constructed sw fissure domain sw point root equation construct required domain sufficient satisfy condition due need check first condition positive since expression definition see derivative strictly positive small conclude hold sufficiently small unfortunately, cannot say anything similar since slope curve inside strip lie strictly inequality always true sufficient construct simple left foliation domain left fissure this, need check condition satisfied left neighborhood again, due suffices check first condition, e, expand expression since expression strictly positive sufficiently small section, partially consider case boundary function third degree polynomial consider possible polynomial since described foliation arise third degree polynomial however, considered foliation allow describe case sufficiently small possible foliation considered forthcoming paper start case case considered section symmetry respect axis allows consider case otherwise, replace using symmetry respect axis, assume otherwise, swap first, consider simplest case constant, and, therefore, foliation symmetric case horizontal herringbone, spine axis see since assumed left herringbone case course, symmetric right herringbone thus, assume assumption, construct simple foliation small indeed, direct calculation, condition transforms condition take form small condition satisfied precisely, satisfied thus, right simple foliation condition satisfied left simple foliation construct infinite left herringbone, spine line consider case opposite case obtained swapping fact, explicitly solve equation since take following simple form solution equation represented family two special solution know herringbone impossible see remark herringbone spine given generate diagonally concave functions, minimal diagonally concave function generated spine check this, compute function see simple case, direct calculation give herringbone spine admissible diagonally concave function, integral line must lie region e, strip consider extremal line field generated equation easy plotting graph function value constant see fig obtain integral line passing given point, must shift graph appropriately along axis see sought extremal line foliate strip two horizontal asymptote get moreover, exponentially decay infinity show exp then, using conclude increase exponentially whereas herringbone increase polynomial mean herringbone give minimal diagonally concave function indeed, corresponding function minimal diagonally concave function according theorem concluding consideration case note obtain bellman function taking left herringbone right herringbone appear let turn case situation, expression one root construct fissure assumption sw fissure, assumption proposition satisfied addition proposition want check foliation take place e, foliation entire strip follows check this, need verify three fact construct sw fissure region sw construct simple right foliation region e, condition satisfied construct simple left foliation region e, condition satisfied purpose, need examine vector field closely convenient consider field strip also entire plane considered vector field four stationary point three already known fourth point second intersection two parabola given equation respectively see fig direct calculation show coordinate understand behavior integral curve around points, need compute jacobian matrix point see see always node point saddle since see behavior field two stationary point important goal simplest part task construct simple right foliation direct calculations, see turn note second inequality follows first one condition hold strictly increasing respect consider integral curve field start end lower boundary, corresponds spine sw herringbone reasoning repeat argument proof proposition there, used fact small enough here, consider arbitrary use specific expression boundary function find slope integral curve need compute eigenvectors matrix represent matrix characteristic polynomial matrix form thus eigenvalue eigenvectors given choose one two integral curve passing point which, shift right give spine desired sw herringbone specifically, must take eigenvector slope greater le mean take give slope eigenvector equal compare slope slope curve curve parabola see fig given equation slope slope strictly le expression thus, upper half strip, desired integral curve pa curve or, equivalently, right parabola e, domain since curve right parabola integral curve visualization picture presented fig comparison fig add several new line change notation parabola see denoted meaning integral curve field intersects line slope equal hold boundary except singular point also labeled parabola intersects integral curve slope equal therefore denoted slope upper boundary strip except singular point set point integral curve pa horizontally denoted consists two line latter line pa three stationary point cubic parabola pa four stationary point set point integral curve pa vertically except singular point finally, add integral curve fissure starting point together parabola pa parabola next stationary point reasoning explaining two curve cannot intersect earlier slope integral curve point strictly le contained proof proposition need show integral curve lower half strip pa domain this, need check end fissure left stationary point e, indeed, geometrically clear zero slope, integral curve must turn slope equal go vertically intersects slope equal intersects parabola intersects line this, course, happens strip explains guarantee fissure generates diagonally concave function but, see shortly, also ensures possibility constructing simple left foliation subsequent, need check condition situation, take form since slope main curve strictly le inequality first condition follows second condition precisely inequality verified concluding consideration case note sw fissure bounded e, always indeed, description set show line asymptote integral curve therefore, spine herringbone must intersect lower boundary strip finite point finally, let say word case due symmetry, consider case before, need investigate root polynomial discriminant quadratic polynomial negative, const applying proposition conclude simple right foliation small case however, grows, foliation appear considered yet, postpone complete study case also ready consider foliation arises discriminant quadratic polynomial zero, is, multiple root equation therefore, remaining part section, assume discriminant positive, e, equation two root denote root assuming assumption mean therefore, three possible situation see illustration possibility fig nw fissure near proposition sw fissure near proposition ne fissure near proposition sw fissure near proposition ne fissure near proposition se fissure near proposition note case impossible, assumption aim prove small always following foliation number close instead depending sign precisely, take need verify fulfillment condition construct condition interval construct leave verification reader, several hint precisely defined, determine point corresponding quadratic polynomial change sign second condition always weaker small automatically satisfied boundary defined strict, instead checking sign corresponding quadratic polynomial points, check purpose, sufficient know following relation hold slope spine lie strictly",mathematics
"interacting stochastic process sparse random graph introduction classical mean field result interacting stochastic process interacting process sparse graph hydrodynamic limit marginal dynamic tree open question instruction reporting error background question interest interacting diffusion mean field limit nonlinear diffusion process interacting jump process mean field limit limitation mean field approximation local convergence sparse graph sequence hydrodynamic limit markov random field property outline derivation local equation diffusion line local equation diffusion unimodular galton watson tree marginal dynamic pure jump process generalization approximation long time behavior invariant measure local equation refined convergence result analytic characterization interacting particle system game experimental large ensemble stochastically evolving interacting particle describe phenomenon diverse field including statistical physics, neuroscience, biology, engineering systems, infinitesimal evolution particle depends state history state history neighboring particle respect underlying, possibly random, interaction graph high dimensional process typically complex amenable exact analysis, dynamic quite well understood interaction graph complete graph case, classical theorem show limit number particle go infinity, dynamic empirical measure law typical particle coincide characterized term much tractable dynamical system reduced dimension called mean field limit contrast, recently much known corresponding convergence result complementary case interaction graph sparse ie, uniformly bounded average degree article provides brief survey classical work describes recent progress sparse regime relies combination technique random graph theory, markov random fields, stochastic analysis article concludes discussing ramification application posing several open problem keywords interacting particle systems, markov random fields, mean field limits, nonlinear processes, sparse random graphs, local convergence, erd nyi graphs, galton watson trees, unimodularity msc subject classification primary secondary recurring theme probability theory emergence deterministic predictable behavior aggregation many random element classical result strong law large number established kolmogorov state given sequence random variable independent identically distributed iid finite mean equivalently, distributed according product probability measure probability measure borel set satisfies probability one, similar spirit, glivenko cantelli theorem, also established provides information asymptotic behavior empirical measure iid random variable specifically, show probability one, represents dirac delta measure denotes law distribution random variable convergence called kolmogorov distance, particular implies weak convergence, is, every bounded, continuous function similar result also hold random variable independent, exhibit form weak dependence instance, consider triangular array dependent random variable common mean, finite variances, exhibit asymptotic correlation decay sense exist positive real number sup cov represents covariance follows chebyshev inequality normalized partial sum satisfies hand, many interesting case one want analyze large collection strongly dependent random element analysis often facilitated graphical model representations, capture conditional independence property random element via graph specific class graphical model important present discussion markov random field mrf precise definition given section theory mrfs associated gibbs measure go back late pioneering work dobrushin lanford ruelle motivated model statistical physic involving static interacting random element case key question efficient computation analytical characterization marginal distribution high dimensional ensemble random element article focus dynamic large ensemble stochastic process whose interaction governed underlying graph represents finite countably infinite vertex set subset unordered pair distinct vertex represent undirected edge graph graph always assumed simple ie, pair comprised two distinct vertex locally finite, is, size neighborhood finite notation often also used indicate given graph initial condition interested collection stochastic process indexed vertex satisfies whose interaction structure governed graph specifically, infinitesimal evolution time depends state history state history neighboring particle time note includes case markovian, infinitesimal evolution depends current state particles, well non markovian evolutions, infinitesimal evolution particle depend history history particle neighbrhood conciseness, restrict discussion two type dynamic interacting diffusions, described section interacting jump processes, described section given markovian non markovian interacting process large finite graph, quantity interest include following macroscopic behavior system captured global empirical measure process, defined note random probability measure state space encodes fraction particle taking value different measurable subset state space microscopic behavior, particular marginal dynamic typical particle mean dynamic vertex referred root, assumed chosen uniformly random finite vertex set important question ascertain dynamic depends graph topology due complexity high dimensionality dynamics, quantity typically amenable exact analysis efficient computation goal instead identify tractable approximation reduced dimension rigorously justified limit theorems, number particle go infinity desirable goal obtain autonomous characterization limiting marginal dynamic typical particle evolution empirical measure, refer full particle system dynamic section review well understood case clique complete graph vertices, pair distinct vertex connected edge see figure suitable initial condition convergence result context interacting diffusion model go back half century seminal work mckean fall rubric mean field limit briefly described section broad conditions, limits, law exist coincide, described certain nonlinear stochastic process recent work also considered interacting process certain dense random graph sequence generic example random graph called erd nyi graph graph vertex pair vertex edge probability independently edge see figure realization respectively motivated study synchronization phenomena, work considers suitably scaled pairwise interacting diffusion dense erd nyi graph sequence divergent average degree show law converges mean field limit complete graph case key idea regime, particle weakly interacting become asymptotically independent, thus empirical measure behaves iid case described section main focus article complementary setting interacting stochastic process sequence sparse possibly random graphs, average degree vertex uniformly bounded typical example erd nyi graph sequence extensive analysis various interacting stochastic process deterministic sparse graphs, originating work spitzer followed significant analysis several markovian model including contact process, exclusion process, voter model first studied dimensional lattice see monograph regular tree eg, recent work also considered process sparse random interaction graph see, eg, incomplete list none latter work appear address main question listed autonomous characterization marginal dynamic typical particle fact, interacting diffusion sequence sparse erd nyi graph obtaining characterization remained important open question eg, see sparse regime challenging particle strong interactions, neighboring particle remain correlated limit topology graph strong influence section describe recent progress particular provides resolution open question article concludes section generalization open question work mean field model various aspect interacting particle system extensive impossible representative short article instead, hope provide enough pointer reader get flavor classical result set context recent result monograph covering various aspect interacting particle system include given simple, locally finite, undirected graph use cl denote closure note cl always finite, denotes cardinality set describe dynamic locally interacting diffusion interacting jump process rather provide general setting, make simplifying assumption whenever convenient illustrate key issue given initial condition every consider collection diffusive particles, indexed node graph evolve according following coupled system stochastic differential equation sdes iid standard brownian motion independent vertex isolated, represents local empirical measure neighborhood time drift coefficient sufficiently regular ensure sde unique weak solution isolated, precise definition important set equal arbitrary quantity special case interest linear dependence measure term, say, form interaction potential symmetric last two variable case, system reduces following system pairwise interacting diffusion model phenomenon different fields, including statistical physic neuroscience trajectory particle lie space continuous real valued function endow topology uniform convergence compact set consider sde complete graph, assume without loss generality vertex set present sufficient condition drift one establish standard mean field result given polish space wasserstein metric defined follows infimum coupling namely probability measure first second marginals respectively let space probability measure equipped wasserstein metric suppose bounded every map lipschitz continuous, uniformly respect compact subset note assumption satisfied drift form interaction potential lipschitz continuous bounded, uniformly respect compact subset suppose assumption holds, exists initial condition satisfy unique strong solution sde moreover, unique solution sde global empirical measure defined satisfies furthermore, law converges weakly product is, bounded continuous function interaction, theorem would simply functional strong law large number result however, even particle weakly interacting symmetry interaction ensures influence particle drift another particle vanishes limit property finite subset random variable asymptotically independent referred chaoticity, well known equivalent convergence deterministic law proposition now, implies initial condition chaotic thus theorem asserts dynamic chaoticity also hold positive time phenomenon referred propagation chaos turn, lead autonomous description limiting marginal process markov process whose infinitesimal evolution time also depends law time result, forward kolmogorov equation master equation partial differential equation pde describing evolution marginal law nonlinear consequently, process referred nonlinear markov process drift form suitable condition shown law absolutely continuous respect lebesgue measure density satisfies granular medium equation thus, pde technique useful studying nonlinear markov process see, eg, many different approach establishing mean field limits, including pde analysis, fixed point arguments, martingale technique stochastic coupling construction first, one need establishing well posedness nonlinear sde analytical approach problem entail proving uniqueness nonlinear pde describing evolution marginal law another, probabilistic, approach first consider mapping take continuous measure flow measure flow unique solution sde replaced observing flow must fixed point mapping, well posedness equivalent uniqueness fixed point mapping latter established showing mapping contraction exploiting lipschitz continuity drift given well posedness, coupling approach proving convergence proceeds first defining dimensional process whose every coordinate independent copy nonlinear process one couple process original process driven brownian motion using formula, lipschitz condition drift standard estimates, one show distance empirical measure vanishes since strong law large number ensures empirical measure latter converges law equal concludes proof alternative approach proving convergence first use generator markov process identify martingale involving empirical measure process next show sequence relatively compact tight characterize subsequential limit satisfies known nonlinear martingale problem, finally establish well posedness latter one consider general dynamic drift diffusion coefficient function current state empirical measure process, well non markovian version depend history process also interested interacting pure jump processes, describe model statistical physics, engineering, epidemiology dynamic opinion formation concreteness, consider voter model aim capture opinion dynamics, particle take value state space represents two possible opinion allowed transition jump direction particle lie set rate particle change opinion equal fraction neighbor opposite opinion note dependence rate neighboring state symmetric generally, state system jump rate particle could complicated symmetric functional neighboring state also depend time addition state symmetric dependence neighboring state succinctly captured saying rate functional unnormalized empirical measure neighboring state note lie space locally finite nonnegative integer valued measure general setup, consider finite state space subset possible jump directions, collection jump rate function given simple finite graph initial condition valued process representing configuration associated ip evolves according following system jump sdes iid poisson random measure intensity measure leb leb represents lebesgue measure random unnormalized empirical measure corresponding state particle neighborhood time sde capture simple evolution time particle node make transition state rate depends current time, state node prior current time, symmetrically state neighboring node prior current time, encoded use unnormalized measure instead empirical measure allows one capture broader class model jump rate depend number neighboring node particular state fraction case model like contact process note trajectory particle lie dl space right continuous valued function finite left limit solution jump sde markov jump process law also characterized via associated infinitesimal generator function vector th coordinate elsewhere however, jump sde representation convenient generalization non markovian process see furthermore, jump sde formulation also better suited describing form limiting marginal dynamic sparse graphs, described section mean field result analogous theorem also hold jump setting following regularity assumption jump rate function jump rate function take form otherwise, function lipschitz continuous, uniformly compact subset assumption reflects fact mean field setting, dependence jump rate neighboring particle must sufficiently regular function usual normalized empirical measure following result established theorem see also suppose assumption hold initial condition chaotic, is, converges total variation metric deterministic limit converges weakly unique solution following nonlinear jump sde poisson process intensity leb independent furthermore, law converges weakly evolution law mean field diffusion limit characterized nonlinear pde, evolution law nonlinear jump process characterized unique solution forward equation, nonlinear integrodifferential equation theorem meant provide flavor mean field result survey mean field limit current focus, worth mentioning diffusive jump process settings, one obtain mean field limit weaker assumption much general dynamic diffusion coefficient also function current state empirical measure process, well non markovian version drift coefficient jump rate depend history process see, eg, propagation chaos result interacting non markovian jump diffusion large deviation analysis non markovian weakly interacting diffusion mean field limit theorem established theorem indicate law nonlinear markov process respectively, used approximate quantity interest interacting diffusion jump process finite graph particular, consider voter model described section jump rate take explicit form case, one would expect dynamic reates could provide approximation probability agreement two neighboring particle voter model sufficiently large complete graph however, lack better alternative, mean field approximation used even dynamic graph approximation may reasonably well dense graph vertex high degree inaccurate sparse graph figure plot evolution probability state root agrees precisely two neighbor voter model rooted regular tree generations, given time zero, particle independently opinion probability vertical bar figure provide confidence interval simulation mean field approximation assumes neighboring vertex independent, thus performs poorly ad hoc refinement mean field approximation take account correlation also remain inaccurate setting strongly motivates development convergence theory empirical distribution marginal dynamic sparse graph sequence could lead principled approximation turn interacting process sparse graph sequence initial condition assume finite vertex chosen uniformly random vertex unlike case complete graph even dense graph sequence degree vertex remains bounded neighboring vertex become asymptotically independent thus, number neighbor becomes important clear one cannot expect limit sending number vertex infinity, without imposing additional consistency requirement graph sequence lead following question graph sequence would one expect limit sequences, converge deterministic limit converges deterministic limit, limit always coincide limit law autonomous reduced dimension description limit marginal whenever limit exists light first question above, review natural notion convergence sparse graph called local convergence section notion used study asymptotic property static model gibbs measure discrete valued marked random graph given graph two vertex path length sequence every graph said connected exists finite path two vertex graph distance two vertex minimum length path rooted graph graph special vertex referred root useful notion convergent sequence connected rooted sparse graph local convergence, introduced benjamini schramm reference local convergence include first introduce terminology required define local convergence isomorphism one rooted graph another bijection vertex set edge edge two rooted graph said isomorphic exists isomorphism let denote set isomorphism class connected rooted graph also need consider convergence graph carry mark representing initial condition trajectory state dynamic vertex mind, given polish space define marked rooted graph tuple rooted graph vector marks, indexed vertex say two marked rooted graph isomorphic exists isomorphism rooted graph rooted graph map mark mark ie, let denote set isomorphism class marked rooted graph define topology local convergence space let denote induced subgraph rooted containing vertex graph distance root distance defined supremum isomorphic, interpret now, let denote metric induces polish topology metrize similarly defining distance two marked graph supremum exists isomorphism respective topologies, polish space see lemma appendix polish space let denote space bounded continuous function always assume space equipped borel algebra one talk weak convergence convergence distribution random graph random marked graph random element specifically, sequence random valued random element said converge distribution local weak sense valued limit every bounded continuous function likewise, convergence distribution local weak sense isomorphism class random marked graph equivalent weak convergence space figure illustrates two generic example locally convergent graph sequence let cycle, connected graph vertex every vertex degree along root chosen uniformly random vertex converges weakly infinite line graph rooted fixed vertex see figure le trivial example illustrated figure given sequence erd nyi graph converges distribution local weak sense galton watson gw tree offspring distribution given poisson distribution latter example unimodular galton watson ugw tree, defined follows given probability distribution finite nonzero first moment, is, satisfies random tree ugw root whose neighborhood size distributed according neighbor vertex referred offspring root form first generation tree recursively, vertex nth generation tree independent random number offspring equivalently, neighbor away root distribution th generation tree comprised offspring vertex th generation easy verify poisson distribution, hence, galton watson tree poisson offspring distribution fact ugw poisson distribution another special case regular tree, given ugw ugw tree sense canonical object since arise local weak limit many sparse random graph sequence including erd nyi graphs, configuration model preferential attachment graph see section discussion example extend notion convergence graph necessarily connected, given unrooted graph vertex define isomorphism class connected component contains root furthermore, finite, let denote random vertex chosen uniformly set case denotes connected component random vertex sequence finite random graph said converge distribution local weak sense sequence finite random graph said converge probability local weak sense every analogously, given marked unroooted, necessarily connected graph denotes connected component containing root corresponding mark notion convergence distribution probability local weak sense marked graph defined exactly analogous fashion definition place respectively unmarked marked graphs, convergence probability clearly implies convergence distribution use notation graph isomorphism class often omit root notation simply refer rather given sequence random graph converges either distribution probability local weak sense limit graph iid mark polish space distribution irrespective easy show marked graph sequence also converges local weak sense unmarked counterpart iid distribution fact, shown proposition convergence marked graph sequence hold larger class possibly dependent mark distributed according gibbs measure graph respect fixed pairwise interaction functional address raised beginning section first result state sequence graph marked initial condition converges either probability distribution local weak sense limit graph, graph marked trajectory solve corresponding sde also converge limit graph sense result also characterizes limit global empirical measure suitable condition suppose assumption holds, sequence necessarily connected, finite random marked graph converges distribution local weak sense valued limit also, let solution sde initial data let unique weak solution sde limit graph converges distribution local weak sense valued element particular, converges weakly moreover, converges probability local weak sense also converges probability local weak sense additionally, converges weakly law result follows theorem establish result general, possibly non markovian diffusive dynamic version first assertion theorem also established slightly different class interacting diffusion theorem seen establishing continuity local weak topology dynamic respect initial data, comprising graph marked initial condition also provides condition empirical measure shown deterministic limit equivalently, hydrodynamic limit additionally coincides limit law root particle, thus answering affirmative beginning section discussed earlier, complete graph analogous phenomenon hold due asymptotic independence trajectory two particle contrast, sparse regime, neighboring particle remain dependent limit instead, proof relies showing trajectory finite neighborhood two independent vertices, chosen uniformly random graph become asymptotically independent limit latter property relies certain correlation decay property dynamic spirit see lemma detail however, emphasized sparse regime deterministic hydrodynamic limit result hold initial data converges stronger sense convergence probability local weak sense indeed, shown theorem limiting empirical measure stochastic initial data converges distribution local weak sense particular, fix suppose graph obtained taking connected component vertex chosen uniformly random erd nyi graph setting root chosen vertex also, let initial condition iid common distribution let denote restriction initial condition converge distribution local weak sense iid distribution ugw poi however, whereas converges weakly law dynamic root vertex converges weakly following random limit given limit truly stochastic because, well known elementary theory branching process always positive probability ugw tree finite positive probability infinite furthermore, also exist example show even limiting empirical measure deterministic, need coincide law root particle limit example, occur graph homogeneous root chosen uniformly random vertex graph see, eg, section discussion show existence nature hydrodynamic limit far subtle sparse regime case complete dense graphs, even diffusive dynamic setting jump processes, additional subtlety arise whereas diffusion setting, assumption ensures drift particle node experience effect perturbation state neighboring particle, analogous assumption would stringent cover jump model interest sparse graph latter case, effect neighboring particle jump intensity vertex either remains constant voter model, grows degree vertex many models, including contact process see precisely accommodate dependence jump intensity expressed function unnormalized sum dirac mass neighboring state introduced rather normalized empirical measure hydrodynamic limit sparse graphs, suffice impose following mild assumption rate every suppose exist constant nondecreasing every sup note jump sde describing dynamics, third argument equal unnormalized empirical measure state neighbor vertex, defined thus, irepresents degree vertex assumption allows uniform bound jump rate vertex grow degree vertex state analog theorem jump diffusion recall definition ugw tree given remark suppose assumption holds, sequence necessarily connected, finite random rooted marked graph converges probability local weak sense limit ugw tree finite, strictly positive first second moment let solution jump sde initial data let unique strong solution sde limit graph converges probability local weak sense valued element furthermore, converges weakly law theorem follows general result established theorem corollary diffusion case, proof theorem involves establishing continuity property dynamic respect graph initial condition well correlation decay property however, proof property considerably involved diffusion case due weaker condition imposed jump intensity assumption one, jump setting even well posedness particle system infinite random graph unbounded degree automatic shown appendix exist example simple jump particle system uniformly bounded jump rate function multiple solution certain graph exponential growth quote liggett given intuitive description behavior particles, often clear whether exists process corresponds description therefore important find condition infinite particle system exist finite graphs, finitely number jump bounded interval, process remains constant jump thus, one simply order jump define process recursively problem infinite graph setting one cannot always identify first jump liggett used analytical construction invoking theory semi group establish general existence theorem law markovian particle system infinite graph quite general necessarily finite range interaction context nearest neighbor interaction lattices, alternative, probabilistic approach used establish well posedness markovian interacting particle system harris however, approach seem apply graph finite maximal degree hand, graph particular interest like ugw poisson tree discussed see remark unbounded degree assumption well posedness possibly non markovian interacting jump process established theorem large class possibly random graph satisfy certain finite dissociability property almost surely, property shown hold ugw tree corollary proof theorem follows combining well posedness result continuity property dynamic respect initial data correlation decay property established proposition theorem respectively hydrodynamic limit result reduces characterization limit law understanding marginal law root dynamic infinite limit graph given local weak limit many random graph tree see remark focus understanding marginal dynamic random tree evolution root driven local neighborhood empirical measure unnormalized counterpart complete sufficiently dense graph case, limit number particle go infinity, local empirical measure coincides global empirical measure thus, case hydrodynamic limit yield autonomous characterization limit marginal dynamic contrast, graph sequence sparse, neighboring vertex remain strongly correlated, local neighborhood empirical measure remains stochastic thus hydrodynamic limit result section adequate provide autonomous characterization marginal dynamic instead, adopt different perspective, better suited analysis large collection dependent random element mentioned section first step try identify conditional independence structure random variable end, identify certain markov random field mrf property trajectory section describe exploit property, along filtering result stochastic analysis symmetry property graph, identify autonomously defined local equation satisfied marginal dynamic cl root neighborhood first diffusion line section diffusion ugw tree section finally jump process section unlike mean field case, consideration marginal root neighborhood rather root appears necessary order obtain autonomous characterization also necessary order capture correlation neighboring vertices, vanish sparse regime discussion local equation given section worth noting since graph consider locally finite, neighorhood root almost surely finite thus, local equation describes evolution almost surely finite number interacting particle combined convergence result theorem finite dimensional interacting process serf approximation marginals possibly non markovian interacting process arbitrarily large number particles, thus constitutes significant dimension reduction first introduce definition mrf fix measurable space possibly infinite, locally finite graph random element said first order mrf abbreviated mrf respect every finite set conditionally independent given denote hand, said first order global mrf hold possibly infinite furthermore said first order semi global mrf abbreviated sgmrf hold finite furthermore, said second order mrf mrf respectively, second order sgmrf sgmrf respect mrf respectively, sgmrf respect square graph contains well vertex pair distance two apart cases, say exhibit certain mrf property whenever valued random element law satisfies mrf property sgmrf property, introduced viewed generalization tree indexed markov chain chapter general graphs, clearly strictly stronger mrf property collection path either let represent trajectory interval respectively, subset let certain mrf property preserved evolution interacting processes, sense made precise following theorem let deterministic graph uniformly bounded degree almost sure realization ugw tree suppose valued element form mrf sgmrf respect assumption hold unique solution diffusive sde valued trajectory also form mrf respectively, sgmrf respect hand, suppose assumption holds, valued random element form mrf sgmrf respect unique solution jump sde also form mrf respectively, mrf cases, assertion also hold replaced discussion section provides insight second order, general first order, mrf property preserved dynamic preservation mrf property diffusion graph bounded degree follows theorem proof proceeds first establishing result finite graph appealing girsanov theorem gibbs markov theorem theorem also often referred hammersley clifford theorem suitably approximating infinite system sequence finite system proof preservation mrf sgmrf property jump process theorem follows rather different approach exploit certain duality marginals interacting system nonexplosive point process directly establish infinite dimensional girsanov theorem, obviating need approximation argument approach also allows general initial condition incorporate infinite histories, required characterize solution local equation described section flow suitable path space result diffusion generalized similar fashion using approach developed prior work question largely focused interacting diffusions, specifically characterizing gibbs measure path space order construct weak solution infinite dimensional sdes deuschel initiated perspective diffusion drift gradient type although explicitly stated, mrf property implicit proof existence weak solution, relies estimate dobrushin contraction coefficient crucially require additional smoothness boundedness property drift cattiaux, roelly, zessin relaxed boundedness condition allow markovian, malliavin differential drifts, using variational characterization integration part formula subsequent work used cluster expansion method applies system obtained small perturbation non interacting system dereudre roelly established gibbsian property path interacting one dimensional diffusion possibly history dependent drift sublinear growth using specific entropy, crucially requires shift invariant initial condition another direction, several work considered mrf gibbsian nature marginals rather paths, diffusion jump process context preservation property hold general sufficiently small time horizon interaction strength furthermore, none work seems considered sgmrf property, crucial derivation local equation, elaborated section describe sgmrf property theorem used obtain autonomous characterization marginal dynamic root neighborhood regular tree simplicity, identify identify root additionally, rather consider general form focus special case pairwise interacting diffusion without time dependence drift dropped superscript denoting graph dependence notational conciseness also assume shift invariant sgmrf given setup, goal understand marginal dynamic root neighborhood characterization marginal via local equation entail four key ingredients, elaborate upon mimicking theorem rewrite dynamic marginal interest follows let denote filtered space support adapted process root node, observe time drift depends however, time drift depends likewise drift node depends since lie closure root, system equation autonomous since drift time depends random element beyond nevertheless, together show known process, mean drift progressively measurable consequence continuity fact adapted continuous process therefore, one appeal mimicking theorem process filtering theory see appendix allows one express solution sde whose drift time functional past time rather arbitrary adapted process mimicking theorem allows one conclude extending probability space necessary exist independent brownian motion extended probability space satisfies progressively measurable version conditional expectation recall clearly, conditioning alter drift coefficient root particle, remains original system however, altered conditioning see mrf property used simplify expression ii markov random field structure compute drift provide self contained description law dynamic one need able express conditional law given past term joint law preferably, term law get nonanticipative description dynamic end, invoke property theorem trajectory time form sgmrf second order markov chain use property, let consider corresponding first order property namely ask whether fact expect every one may attempt bolster hypothesis reasoning conditioned become decoupled satisfy following sde independent brownian motion however, careful inspection would reveal reasoning fallacious evolution thus random element directly depends state turn dependent brownian motion thus, conditioning cause driving brownian motion become correlated thus, conditioning, independent follow sde driven independent brownian motion however, show conditioning driving noise process remain decoupled ie, independent although conditioning alter distribution longer brownian motion even martingale returning simplification expression drift given note since relation implies independent conditioned drift rewritten reasoning, analogous expression hold iii symmetry consideration despite simplification last section, second term right hand side still involves thus written purely term law however, rewritten form exploiting shift variance particle system since true initial condition dynamic precisely, fact distribution allows conclude along analogous expression equation show independent dimensional brownian motions, modulo additional technical measurability integrability conditions, identifies form local equation satisfied marginal dynamic line see definition complete definition observe even though original system describes linear markov process, marginal characterized local equation system nonlinear, describes nonlinear non markovian process since drift functional depends history time law however, structure ensures coupled system longer depends value process thus autonomously defined iv uniqueness solution local equation argument show law marginal solves local equation system complete autonomous characterization marginal remains show law marginal unique solution local equation system rather, complete specification stated definition method described section prove well posedness nonlinear markov process characterize limit marginal law node complete graph case run difficulty due path dependence and, importantly, nonlinearity occurring dependence conditional laws, le regular nevertheless, possible prove well posedness using approaches, entailing relative entropy estimate symmetry properties, via correspondence infinite particle system detail found section local equation root neighborhood regular tree derived manner similar case invoking mimicking theorem theorem exploiting additional rotational transational symmetry arising automorphism group place translational reflection symmetry however, full expression local equation omitted special case ugw tree discussed next section, whose analysis subtle let probability distribution satisfying let ugw tree remark again, would like describe marginal dynamic particle process root node random neighborhood elucidated last section, main ingredient derivation local equation line mimicking theorem, conditional independence property, symmetry consideration and, finally, well posedness local equation mimicking theorem applied without change also however, mrf property theorem applies deterministic graph thus sufficient instead, one need annealed version, is, one also take account random structure tree one show event root isolated child root, conditioned trajectory trajectory particle subtree rooted independent trajectory cl root neighborhood, and, moreover, conditional law given depend see proposition case would follow theorem homogeneity dynamics, general case, one also account randomness root neighborhood furthermore, symmetry property considerably subtle appropriate notion unimodularity unimodularity viewed analog infinite graph property finite graph root uniformly distributed graph",mathematics
"complete space like self expanders minkovski space introduction preliminary proof main theorem instruction purpose study complete space like self expanders minkovski space use maximum principle omori yau type, obtain rigidity theorem dimensional complete space like self expanders minkovski space complete space like self expanders dimension give classification assumption constant squared norm second fundamental form dimensional smooth immersed hypersurface called self expanders mean curvature flow mean curvature vector satisfies equation denote position vector inward unit normal field, respectively denote standard inner product equation equivalent self expanders self similar solution mean curvature flow, is, family hypersurfaces satisfying equation mean curvature flow self expanders important model behavior mean curvature flow coming conical singularity also model long time behavior flow starting entire graph many classification result self expanders ishimura halldorsson classified self expander curve halldorsson state complete self expander curve immersed convex, properly embedded asymptotic boundary cone vertex origin cheng zhou studied property complete properly immersed self expanders recently, ancari cheng studied immersed self expander hypersurfaces whose mean curvature linear growth control obtained rigidity property hyperplanes self expanders euclidean space result self expanders done cf paper, use maximum principle omori yau type, obtain classification complete space like self expanders minkowski space let complete space like self expander constant squared norm second fundamental form inf hyperbolic space hyperbolic cylinder component second fundamental form, completely classify complete self expanders constant squared norm second fundamental form minkovski space study follows let dimensional complete space like self expander squared norm second fundamental form constant, one space like affine plane origin, hyperbolic cylinder hyperbolic space component second fundamental form, fact, using proof method theorem also give classification complete self expanders euclidean space condition constant squared norm second fundamental form, classification result plane origin, indicates conclusion ancari cheng still hold without assumption scalar curvature let dimensional space like hypersurface dimensional minkovski space choose local orthonormal frame field dual coframe field that, restricted tangent paper, shall make use following convention range indices, structure equation levi civita connection hypersurface restricting form get taking exterior derivative obtain called second fundamental form mean curvature respectively let squared norm second fundamental form gauss equation given defining covariant derivative obtain codazzi equation taking exterior differentiation defining following ricci identity taking exterior differentiation get let tangent vector field denote bakry emery ricci tensor lie derivative along vector field define differential operator denote laplacian gradient operator, respectively following maximum principle omori yau type concerning operator used paper, proved chen qiu let complete riemannian manifold, vector field bakry emery ricci tensor bounded below, bounded above, exists sequence next suppose self expander, is, simple calculation, following basic formula paper, shall always take formula using ricci identities, get following lemma let dimensional complete space like self expander let dimensional complete space like self expander constant, order use maximum principle omori yau type, need following lemma let dimensional complete space like self expander squared norm second fundamental form constant, bakry emery ricci tensor bounded below, unit vector choose local tangent orthonormal frame field definition self expander, direct computation give yield proof lemma finished arbitrary fixed point always choose local frame field equality inequality hold taking exterior derivative know besides, ricci identity obtain is, cheng peng obtain rigidity theorem complete self shrinkers without assumption polynomial volume growth motivated work, obtain following result self expanders theorem let complete space like self expander constant squared norm second fundamental form inf hyperbolic space hyperbolic cylinder since inf without loss generality, assume inf constant lemma infer bakry emery ricci curvature bounded maximum principle omori yau type concerning operator function exists sequence obvious namely, second fundamental form parallel constant follows infer indicates number distinct principal curvature two one principal curvature, is, totally umbilic, hyperbolic space two distinct constant principal curvatures, congruence theorem abe, koike yamaguchi hyperbolic cylinder order prove main theorem paper, need following theorem let complete space like self expander non zero constant squared norm second fundamental form, inf use proof contradiction suppose inf exists sequence constant, know bounded sequences, one assume follows use obtain yield since non zero constant, draw imply follows follows conclude combining infer implies contradiction also obtain contradiction fact, declare otherwise, know infer contradiction assuming first equation draw consequently following relationship derived simple calculation follows impossible assuming using similar method also obtain contradiction proof theorem thus finished proof theorem know space like affine plane obvious either theorem theorem acknowledgement first author partially supported china postdoctoral science foundation grant second author partly supported grant nsfc, gdups guangdong natural science foundation grant",mathematics
"quick probability oriented introduction operator splitting method scope paper first example matrix lie product formula semigroups chernoff product formula abstract cauchy problem trotter kato formula general formulation splitting scheme multiplicative additive splitting method naive probabilistic example error splitting scheme source remark relation acps practice rate convergence remark error representation deterministic case boundary conditions, inhomogeneous acps phenomenon order reduction general exponential splitting method baker campbell hausdorff formula taylor expansion, kunita expansion exponential method sdes general result spdes sdes example diffeomorphic flow sdes, brownian web non homeomorphic home nv document mine splitting overview vovchanskyi splitting overview biberbib ateverybibitem clearfieldlanguage ateverybibitem clearfieldnote survey devoted operator splitting method abstract formulation application probability survey focused multiplicative methods, bch formula used discus exponential splitting method short informal introduction additive splitting presented introduce framework available deterministic probabilistic result concentrate constructing wide picture field operator splitting methods, providing rigorous description setting abstract cauchy problem informal discussion parallel advance limitation common difficulty listed, well example work provide solution hint new result provided bibliography contains illustrative deterministic example selection probability related work paper extended reworked version short course given author uzbekistan ukrainian reading stochastic process tashkent kyiv, prepared special issue theory stochastic process devoted publishing lecture note aforementioned workshop operator splitting method family well known method decomposing dynamical system providing representation governing mechanism sum simpler component force using representation provide approximation real trajectory dynamical system though idea splitting often associated celebrated abstract trotter kato formula, case approximation constructed using composition subsystem driven exactly one component aforementioned representation, go far beyond includes weighted linear combination subsystems, composition mixed backward forward euler scheme encountered optimization theory disguise specifically, idea follows time interval divided sufficiently small steps, every step solution operator original system replaced approximation constructed splitting procedure, solution combined recursively starting time due general nature idea, operator splitting essentially used anywhere ode pdes natural decomposition arise, decomposition dictated presence co existing physical, chemical biological mechanisms, often acting different space time scales, property available numerical method consider general advection diffusion reaction equation represents diffusion, field possibly superficial velocity source sink may chemical origin, velocity field reflects physical property reservoir etc one may prefer drastically different numerical method integrating subsystem obtaining splitting rh sum differential operator second order treating subsystem separately instance, physically justified first order equation developed theory often explicitly relies conservation law eg hundsver numerical diffusion part typically treated via finite element eg zientayzhu finite assume consider ode try simulate using explicit forward euler method step size necessary condition operator matrix norm, implies order since limited practice, may possible forward euler method stable however, decomposition equation solved explicitly toy model example stiff non stiff part original equation isolated stiffness eg haiwan solving, lam numerical, hundsver numerical deterministic setting mil numerical stochastic setting context operator splitting method understood vague general sense system stiff successful application certain numerical method usually explicit one used field standard integrator requires impractically small time step thus infeasible costly hard implement idea current example combine well previous example since competing mechanism different origin chemical mechanical may act different scales, typical source stiffness directly increase stiffness ratio eg blaca concise development example consider stiff ode constant coefficient eigenvalue distinct, real negative term get negligible comparison grows explicit euler method step size display asymptotic behavior moreover, condition violated, approximation diverge thus stability explicit euler method depends parameter subsystem whose contribution dynamic whole system minor best typical feature stiff system separation problematic direction rest system beneficial case let consider let one dimensional gaussian density variance combining operator interval give two dimensional wiener process thus operator splitting scheme exact trivial case example alternating direction method whose name quite self explanatory result, operator splitting procedure often developed equation problem general formulation instance, navier stokes equation, zakai equation filtration theory, advection diffusion reaction equations, composite optimization problem example non pde setting wide availability method result application physic mechanic fluids, gas solid classical, quantum celestial mechanic electromagnetism symplectic integration etc chemistry, biology, geology, ecology, weather forecasting, finances, general machine learning problem including image processing, large scale optimization etc numerous field time, operator splitting method encountered purely theoretical study proper example given later text scope survey purely pedagogical suggest brief quick introduction operator splitting methods, presenting basic form accessible newcomer background probability still discussing limitation technical issue method provide wider picture least mention direction whole theory go beyond trotter kato formula give example result developed use operator splitting method field probability show randomness lead new insight new technique probabilistic orientation simply mean prefer probabilistic examples, assume standard level knowledge probability, concentrate multiplicative exponential splitting include short survey general theory multiplicative splitting spdes same, also lead asymmetry text discussion baker campbell hausdorff formula rather lengthy material expected covered textbook probability reader assumed familiar spdes variational method part devoted spdes explain setting emphasized enough information around person interested topic, including high quality introductory level text textbook even trying compete classical texts, merely concentrate gathering least form bibliographic reference important basic facts, hint probabilistic result expanded lecture note aforementioned course giving total newcomer basic understanding map navigate level exposition thus le basic shallow even though result cited often deep extremely technical obtain given scope goal survey, would irreparably pretentious, futile plainly impossible proceed otherwise thus refer original source proofs, detail precise formulation result discussed paper known obviously, sheer amount publication devoted theoretical applied study operator splitting method immediately render impossible task providing exhaustive even representative bibliography unless attention restricted limited partial case specific problem task highly nontrivial even result, choice illustrative example extend random, apologize advance whose contribution represented accept critique gaps, claiming ill intent also give link survey collection reference instead citing source directly occasion still, hope bibliography independent value real attempt give historical note track result initial source made reader interested general broad picture may proposed consult following selection work entry point pazy semigroups, goldstein semigroups, enna one parameter, da one parameter, itoka evolution, cher product, ethkur markov trotter kato formula, perturbation theory semigroups formulation term abstract evolution equations, glowoshyin splitting, faha splitting survey, general theory, history, connection optimization problems, pdes variational inequalities, examples, hundsver numerical treatment advection diffusion reaction equations, example discussion numerics, reedsai methods, si functional, johnla feynman, lohibetz feynmankac, hall quantum, reedsi method zeid applied physical exposition application feynman path integral feynman kac formula, holkarlkenlie splitting operator splitting method rough solutions, glowoshyin splitting, gloleta augmented, glo finite, ya method, ryuyin large scale, baucom convex, mar methods, mar splitting, mar splitting surveys, innumerable references, applications, using operator splitting numerical method solving pdes variational nonlinear inequalities, convex optimization problem including sparse large scale problem fixed point algorithms, problem monotone operator etc, hailu geometric, blaca concise, mclachquis splitting, sanzcal numerical application geometric integration ode source contain vast bibliography additional reference given later text follows aforementioned source used starting point start recalling famous lie product formula matrix let set matrix function solution given arbitrary matrix norm original source theorem seems untrackable cofriedkake eigenvalue one possible proof lie product formula based following telescopic identity id let identity implies local error finish proof arithmetic identity thus hold unbounded operators, despite triviality, standard well known tool estimating global error term local error encountered numerous occasion across whole selection work referenced present paper see, idea proof theorem extends abstract setting directly suitable form uniform boundedness stability hold max otherwise, new method proposed implies method least second order matrix commute, is, however, matrix commute, corresponding exponential hence method exact fact statement theorem alternative proof theorem usually use property matrix logarithm additionally cannot easily extended general abstract setting give simplest example operator splitting technique given consider ode then, theorem theorem also find application theory matrix lie group corresponding homeomorphisms hall lie matrix trace inequality petz survey etc next theorem originally proposed one two dimensional difference scheme also proved direct calculation arbitrary matrix norm common agreement strang gi marchuk independently proposed use idea theorem derive one popular operator splitting method obviously, theorem used solve ode example simple installment strang splitting scheme achieves second order accuracy almost increase number necessary calculation since three subsequent step equal local error strang splitting hundsver numerical venture forth, need recall standard material semigroups abstract cauchy problem acp trotter kato theorem chernoff product formula pazy semigroups, goldstein semigroups, enna one parameter, da one parameter, itoka evolution, cher product, ethkur markov omit detail technicality integral bochner integral let banach space family bounded linear operator one parameter strongly continuous semigroup, semigroup, id mapping strongly continuous denote domain linear operator linear operator generator semigroup generator closed densely defined pair defines semigroup uniquely semigroup exists st called contraction semigroup though customary write semigroup generated follow convention unless stated otherwise bounded linear operator eg family semigroup generator feller valued process automatically defines contraction semigroup space continuous function vanish infinity ethkur markov, bottschiwang levy particular, feller one dimensional diffusion interval generator precise description incorporates boundary condition thus behavior process boundary corresponds killing note possible general give full description feller process often sufficient consider core instead, is, set closure equal ethkur markov however, heat semigroup semigroup thus one carefully choose space semigroup act wiener process analogously defines semigroup generator bokryro fokker however, possibility extend feller semigroup onto linked property adjoint operator thus property fokker plank kolmogorov equation discussion condition see eg stroock partial, ca generators, bottschiwang levy enna one parameter, section vi assume densely defined closed linear operator non empty resolvent set banach space consider autonomous inhomogeneous abstract cauchy problem given classical solution valued function st continuous continuously differentiable term norm hold homogeneous acp well posed unique classical solution depends uniformly continuously initial data following result give well known relation acps semigroups homogeneous acp well posed generates semigroup generates semigroup function take value function unique classical solution type solution particular, mild solution often used function fail satisfy regularity assumption stated non autonomous acp called evolution problem classical solution defined similarly autonomous case simple analog theorem exists see pazy semigroups, goldstein semigroups theory nani well posedness, schnau wellposedness batcsofarni operator, remark survey reference moreover, requires compatibility domain question time dependent, standard condition equation solved however, well posedness non autonomous homogeneous acp implies existence evolution family bounded operator also called propagator st id mapping strongly continuous fixed solution given via mild solution analog given via general, non autonomous inhomogeneous acps, unavoidable applications, may behave unexpected way one careful draw conclusion property corresponding propagator nani well posedness notice, consider homogeneous acps following theorem version celebrated trotter kato theorem whose general form provides basis numerous approximation scheme theory semigroups, including yosida approximation one consult goto convergence, gokoto general, itoka evolution survey general approximation theory semigroups, result rate convergence operator norm, reference number reference concerning chernoff trotter kato product formula given later pfei approximation, pfei probabilistic, pfei some, pfei general use probabilistic method develop unified exposition many approximation formula see also bentpau optimal roughly speaking, trotter kato theorem connect convergence semigroups, resolvent generator let semigroups banach space generator st fixed following assertion exists densely defined operator st strongly core range id dense exists bounded linear operator dense range st id strongly semigroups converge strongly uniformly bounded set semigroup generator st id hold probabilistic formulation theorem feller process found kallenberg trotter kato theorem behind result approximation feller process markov chains, particular kallenberg counterexample trotter kato theorem, particular probabilistic origin, found bob limitation variational nonlinear version trotter kato theorem, itoka evolution generalization norm operator topology, zag notes, cazag operator next theorem called chernoff product formula another fundamental tool approximation theory semigroups let family bounded linear operator st id let limit exist id dense subspace closure generates semigroup sequence positive integer positive sequence satisfying convergence uniform bounded interval formula provides approximation semigroup term family exposition method obtaining approximation given survey method reference application stochastic process including manifold domain dirichlet robin boundary condition found method, chernoff, chernoff killed, mamoresmo chernoff, butgrosmo lagrangian, nitt approximations, sha chernoffs, ne chernoffarx, smoweizwi chernoffs, mamoresmo chernoff, ob representation, smototru hamiltonian, feynman, butschismo hamiltonian, butgrosmo lagrangian, chernoff, smoweizwi brownian reference given later text trotter kato theorem context approximation theory relevant, following additional reference illustrate possibility strengthen conclusion chernoff product formula zag notes, zag comments, za note chernoff formula, cazag operator, galre rate, galre upper arx, prud speedarx establish convergence operator norm obtain estimate rate convergence self adjoint operator quasi sectorial contraction semigroups etc pau operator norm, zag comments, zag notes, cazag operator obtain estimate using probabilistic argument convergence arbitrary slow may hold stronger topology theorem yield exponential formula bounded operator theorem used deduce series representation taken definition exponential method cf lejay girsanov assume real valued function lipschitz continuous bounded, inf consider sde standard wiener process euler maruyama approximation side, one show family defined via satisfies condition theorem implying sufficiently smooth compactly supported see also smoweizwi chernoffs, mamoresmo chernoff, smoweizwi brownian application chernoff product formula pathwise approximation random process note result recover first order weak euler maruyama scheme butgrosmo lagrangian let one dimensional gaussian density mean variance rewritten representation original semigroup limit iterated integral wrt finite dimensional projection pseudo measure phase space wiener measure called feynman formula smototru hamiltonian present alternative approach feynman kac formula see method, chernoff killed, smoweizwi chernoffs, mamoresmo chernoff, ob representation, smototru hamiltonian, feynman, butschismo hamiltonian, butgrosmo lagrangian, chernoff, smoweizwi brownian result feynman formula method setting passing limit give particular case girsanov theorem eg lipshi statistic behavior solution pde differentiability thus behavior corresponding semigroup subtle moment applications, particularly probabilistic interpretation used typical example function min moment feller process hit boundary domain discontinuous though usually result, weak variational formulation term gelfand triple pawin first weak distributional formulation lerarey probabilistic, trizab pfaffian suggested alternative see also feepop stochastic, wang viscosity one particular example versatility chernoff product formula used prove central limit theorem goldstein semigroups state one core result theory abstract operator splitting, trotter kato formula let semigroups banach space generator respectively, st define id dense closure generates semigroup uniformly compact interval theorem formulated finite number semigroups eg pazy semigroups result belongs trotter kato yul daletskii also obtained similar product formula time see dafo measure reference choice topology matter convergence may hold stronger topology neidsteza remark stability assumption cannot dropped kuhnwa lie assume complex valued function shr dinger operator describes motion spinless quantum particle action real valued potential follows wave function solution probability density time position particle interpreted acp hilbert space operator essentially self adjoint is, self adjoint extension rather mild assumption semigroup generated unitary semigroup, particular since semigroups respectively, trotter kato theorem implies polygonal approximation feynman integral history trajectory space continuous trajectory starting reedsai methods, reedsi method goldstein semigroups, johnla feynman action integral expression purely formal trotter kato formula standard way give representation rigorous meaning reedsai methods, si functional, johnla feynman, lohibetz feynmankac, hall quantum, reedsi method customary textbook quantum mechanic derive feynman kac formula shr dinger operator corollary trotter kato formula understand idea formally recall solution following autonomous homogeneous pde assumption used follows given via standard wiener process hand, solution combining semigroup heat semigroup accordance trotter kato theorem yield approximation solution similarly noted precise formulation physical probabilistic version feynman kac formula may dictated different point focus physicist often concerned result laplacian singular irregular different sen potential eg belonging kato class remark applies primarily textbook lejay girsanov cf example possible derive girsanov theorem using trotter kato formula assumption regularity drift following original source, explain intuition behind let heat semigroup semigroup alternatively given small thus shown wiener process since trotter kato formula self adjoint operator reedsai methods, hall quantum usually written self adjoint operator self adjoint extension bounded additionally also importance version physic follows stone theorem hilbert spaces, every unitary group generator form self adjoint every symmetric semigroup generator form bounded self adjoint exactly situation quantum mechanic trotter kato formula admits special proof independent trotter kato theorem case particular, densely defined self adjoint proof rather direct reference extension see lohibetz feynmankac, johnla feynman, si functional particular however, rate convergence found recently additional assumption see eg example related reference formulate formal non autonomous version trotter kato formula, consider operator corresponding non autonomous acps well posed propagator respectively additionally, assume depend one expects note condition domain constant rather limiting one excludes time dependent boundary condition general bc usually incorporated description domain enna one parameter also batcsofarni operator trotter kato formula used derive approximation non autonomous acp autonomous acps constant coefficient cf example that, assume propagator well posed non autonomous acp define semigroups equation strongly uniformly compact set example may small even sum defined via quadratic form johnla feynman, chapter hall quantum, chapter fact, one use trotter kato formula define generalized sum two operator incompatible domain goldstein semigroups, remark original formulation trotter kato theorem pdes requires boundary condition time independent general, adding non autonomous boundary initial condition lead significant technical issue moment, almost attention given question rate convergence even though extremely important question application another feature formulation theorem usage strong topology know either question may stronger result due reference given chernoff product formula rate convergence arbitrary slow convergence stronger topology may hold understand reason behind fact thus emphasize limitation standard version trotter kato formula need short discussion proof theorem since theorem direct corollary theorem subsequent reasoning well known note original proof theorem fall apart soon operator involved unbounded eg contain differentiation condition set id dense implies nontrivial way densely defined closed exists indeed generator semigroup condition seen enna one parameter extension hille yosida theorem fact, formulation trotter kato formula require generator semigroup applies chernoff product formula eg da one parameter practical terms, mean one careful domain trying replicate original proof rest proof theorem consists two separate claim first one relies following observation linear bounded operator satisfying poisson random variable mean therefore bounded operator one prove assumption thus left prove second part proof since trotter kato theorem implies possibility either bound expression replace strong convergence convergence operator norm general proof trotter kato theorem produce result internally result, standard chernoff product formula trotter kato formula formulated term strong convergence bound may possible refine strengthen convergence trotter kato theorem special class generator eg self adjoint maximal accretive one one combine improved estimate particular, obtained using property poisson distribution consistency estimate trotter kato theorem yield conclusion convergence operator norm provide estimate speed cazag operator, zag notes, pau operator norm, zag comments, za note chernoff formula see also pazy semigroups, chapter lemma may compared goto convergence, gokoto general estimate speed convergence often include original element see also itoka evolution, itoka trotter result type reference concerning bound rate convergence added later decomposition proof condition theorem illustration one overarching principle numerical analysis stability consistency imply convergence fundamental result known lax richtmyer theorem lax equivalence theorem context finite difference approximation pdes consistent finite difference scheme well posed linear initial value problem convergent stable principle extends setting situation soon approximation scheme arises see itoka evolution discussion setting evolution equation glowoshyin splitting, chapter discussion case trotter kato formula condition give stability scheme convergence generator behavior family consistency condition case etc however, one forget that, contrary case lax richtmyer theorem, principle stability consistency imply convergence longer rigorous statement also reflect full nature proof since proof deal range domain unbounded operator obtain generator semigroup side, principle remains extremely powerful tool often encountered situation various bound developed discussion consistency term resolvent see itoka trotter discussion possible trade consistency stability, itoka trotter, huitoka aspect version inhomogeneous acps, huitoka aspect composition generator contraction semigroups automatically stable alternatively, method expected stable operator involved commute bjor operator common duality theory multiplicative splitting method also obvious aforementioned scheme classical proof possible way establish stronger version trotter kato formula topic revisited later let solution operator acp initial value let solution operator recurrent approximation scheme uniform time mesh converge original solution setting id is, global error sum propagated local truncation error propagated initial error partial case decomposition revisiting formulate following typical meta theorem generator contraction semigroups respectively, obviously, tricky part obtain estimate often achieved ad hoc method faou analysis consider pde bounded derivative satisfies let heat semigroup possible, using formula property wiener process, show local error satisfies wiener process, used derive consistency bound combined energy stability estimate original semigroup example implies trotter kato formula first order accurate note rate convergence obtained using probabilistic technique faou analysis also establishes estimate linear case result version trotter kato formula case one step approximation strang splitting generalization trotter kato, bounds, developments, extension type semigroups reference see, besides source listed above, ro error, cazag operator, neidzag error estimate, neizag fractional, ichita error, ichita error, johnla feynman, ichi recent, caneidza accretive, faouosschratz analysis, neidza convergence, za trotter, hanos dimension, hanos dimension, neidza fractional, ichineidza trotter, ichitataza note, ichita norm, fa product, bjor operator, vui generalization, neidsteza operator, vuiwresza general, vuiwresza trotter, neidza trotter, neidsteza remarks, caneidza comments, neidsteza trotter, vuiwres product, csoehrfas operator chernoff product formula trotter kato formula particular, non autonomous case studied dafo measures, ichita error, neidza convergence, hanos dimension, batcsofarni operator, enna one parameter, fa product, vui generalization, vuiwresza general, vuiwresza trotter, neidsteza trotter, vuiwres product particular, vuiwresza general, vuiwresza trotter, vuiwres product study time dependent domain version non autonomous trotter kato formula alternative setting established te stabilite, dafo measures, eisenhan variational, itoka evolution, batcsofarni operator particular, te stabilite, eisenhan variational use framework gelfand triple rigged hilbert space result nonlinear trotter kato formulae, see reference reedsai methods, supplement viii splitting level semigroups mean splitting time numerical scheme also include spatial discretization practice result combining time splitting spatial discretization particular, version chernoff formula see itoka evolution, batcsoni operator splittings, bacsofarni operator spatial see also remark revisiting example feller processes, one see action corresponding semigroup defined well behaved necessarily function outside class though function may appear application see doerteich semigroup one extension splitting scheme larger class function preservation rate convergence spdes previous section contain rigorous description trotter kato formula semigroups henceforward care idea illustration longer aim give precise formulation step domain general operator splitting method numerical theoretical scheme approximate original solution without priori expectation convergence unified exposition abstract initial value problem ivp assumption corresponding operator eg multivalued discontinuous used mostly follow exposition glowoshyin splitting, hundsver numerical consider autonomous ivp possibly nonlinear assume section write similar term lh ivp later text resume writing rh assume fixed let fixed time step integer set form partition following scheme general version trotter kato formula called lie trotter splitting scheme particular, general version theorem general setting, define follows general, one expects lie trotter splitting first order accurate however, conclusion guaranteed adjustment non autonomous case standard though may nontrivial mathematically treated rigorously eg time considered additional variable new operator introduced explicit approach example used use second option scheme consider assume next scheme called strang splitting scheme asymmetrical way treated matrices, theorem introduce abstract formulation, consider defined via one expect second order general case but, earlier, guaranteed repeat universal remark absence universal rate given splitting scheme future strang splitting quite popular due second order, also require doubling number computation compared lie splitting already seen finite dimensional case indeed, propagator semigroup get lie trotter strang splitting scheme multiplicative splitting scheme formal semigroups combined via composition exclusively following peaceman rachford douglas rachford operator splitting scheme called additive formulate underlying idea, consider ode solution approximated using explicit forward euler method using implicit backward euler method formally respectively cf idea peaceman rachford splitting follows divide half, run forward euler scheme backward euler scheme run algorithm half interval, switching role setting autonomous linear version douglas rachford splitting similar idea autonomous linear version douglas rachford splitting extended case glowoshyin splitting last additive scheme write explicitly development peaceman rachford splitting called fractional scheme additive splitting scheme expected first order accurate general second order accurate operator nice operator computationally problematic eg multivalued peaceman rachford douglas rachford splittings modified exclude second subproblem instance, solving first equation get peaceman rachford splitting common additive operator splitting scheme tseng splitting eg suchogimouk parallel, alge iteration davis yin splitting eg arato direct, chenchangliu three operator general, additive operator splitting scheme considered known convergent provided operator involved monotone let recall basic fact last assumption optimization theory baucom convex, zeid nonlinear briefly explain terminology often encountered context operator splitting method optimization let banach space possibly nonlinear multivalued operator called monotone operator monotonicity one cornerstone optimization theory general convex optimization particular browder minty theorem state additionally hemicontinuous coercive is, mapping continuous equation solution moreover, subdifferential proper closed convex function necessarily maximally monotone operator so, roughly speaking, one solve instead original optimization problem is, one find function zero set define proximal operator operator prox coincides resolvent id additionally, prox id lipschitz operator admit decomposition called firmly non expansive, fixed point proximal iteration guaranteed converge relation present variational inequality convex function one find numerous application operator splitting method context theory monotone proximal operator particular, context fixed point iteration result often formulated either term fixed point proximal operator term resolvent zero set monotone operator technically, however, zero set sampled running fixed point iteration algorithm, method based lagrange multiplier commonly used formulation moreover, popular effective alternating direction method lagrange multiplier addm actually reformulated peaceman rachford douglas rachford splittings additive operator splitting scheme baucom convex called forward backward splitting derived follows want find note alternatively show fixed point id id one may expect sufficiently small fixed point iteration converge monotone also cocoercive operator cocoercive firmly non expansive cocoercive operator often appear proper gradient note corresponding ivp splitting scheme usually spatially discretized additionally practice high dimensional system possibly nonlinear differential equations, one selects method solve system separately outer splitting scheme instance, starting second order parabolic pde replacing spacial derivative corresponding difference quotient obtain spatial high dimensional ode possibly non uniform grid space basis function finite element scheme used matrix depends grid size grid explicitly space time discretizations used, high dimensional possibly nonlinear equation time space discretizations treated differently larger scale additive method usually built discretization time multiplicative splitting schemes, contrast, usually dictate subproblems solved choosing concrete method lead variation initial scheme instance, considering non autonomous lie trotter splitting choosing step backward euler method obtain marchuk yanenko splitting define autonomous case alternative version trotter kato theorem outer inner optimization share time step alternatively, one use runge kutta type method step smaller time step splitting scheme etc multiplicative method feature fixed one step internal optimization step marchuk yanenko splitting called alternatively locally one dimensional method lod generalized sense hundsver numerical peaceman rachford douglas rachford splittings known alternating direction implicit method adi multiplicative splitting method subclass exponential operator splitting method also called simply higher order splitting method method formally represented linear combination formal semigroups form number necessarily non negative even real method often used construct higher order scheme however, term exponential splitting sometimes simply mean standard lie trotter splitting autonomous strang splitting exponential splitting scheme matrices, scheme second order accurate hundsver numerical using one define formally forth order requires solving pde backward time special constructive operator splitting scheme build simpler one usually multiplicative often called hybrid, weighted, additive alternative meaning iterative briefly treated context exponential splitting method later text operator splitting method encountered probabilistic setting mostly multiplicative modern classification operator splitting method presented glowoshyin splitting however, multiplicative additive method historically different origin different society contributor specific operator splitting scheme particular version general scheme eg st rmet verlet integration method may developed rediscovered narrow ad hoc method particular problem, nomenclature rather diverse necessarily posse integrity researcher interested historical accuracy would desire following short interlude collect alternative name start lie trotter splitting standard historically justified alternative name fractional step method method fractional step also include similar scheme possibility revolve around sur name lie, te trotter kato different combinations, one common lie splitting glowoshyin splitting analyst often speak trotter kato formula probabilists may use splitting physicist may speak suzuki trotter expansion decomposition sequential splitting another alternative strang splitting called marchuk strang splitting autonomous peaceman rachford marchuk yanenko splittings written term revolvents thus sequential splitting resolvent splitting eg considered separately another example ryu splitting eg arcamtam strengthened, matam resolvent additive, sequential, weighted iterative splitting scheme may mean different thing different author refer section example particular version algorithm include st rmet verlet leapfrog method see section time evolving block decimation ursol parallel, hahamccu hybrid split hamiltonian method casanzshaw split, shanlanjohnneal split split step fourier alezashei split step, tasmithwolf analysis mapping method wi origin, mal mapping gradient projection cuishanb analysis, finowright gradient split bregman method golbreosher geometric, oberoshertatsai numerical primal dual splitting botcsethend recent, conkiconthi proximal rosenbrock approximate matrix factorization botver new, beckgonpewei comparison aforementioned tseng, davis lin, ryu splittings others intermediate value approximation real solution additive splitting method true multiplicative scheme additive splitting method seen particular instance implicit explicit mixed method imex note matrix contains case second derivative thus introduces stiffness system even present originally particular, implicit method advised solving ode section consider basic idea behind actual implementation splitting scheme parabolic pde, usage mc since additional layer spacial discretization almost always present, total error operator splitting scheme composed theoretical error splitting procedure itself, error space time discretization procedure used obtain finite dimensional formulation subproblems, ordinary calculational error chosen method corresponding program implementation used solve finite dimensional problem error additive, obviously, though one try obtain additive bound occasion, stability final scheme may vary greatly different choice internal sub routine discretization may involve choosing mesh, basis expansions, interpolation point space time grid, choosing specific formula first second higher derivative boundary, variable grid steps, finite difference finite volume general, using volume mass preservation formulation etc alternatively, probabilistic interpretation available, one may apply mc methods, upper bound error becomes, roughly speaking, statistical discrepancy due insufficient number simulation estimated eg using berry esseen, bikelis concentration inequality grata stochastic error actual simulation procedure corresponding random process let consider basic naive example explain situation consider ordinary pde inhomogeneous term lie trotter splitting scheme separate ode semigroup markov process assume square root lipschitz continuous bounded, independent wiener processes, function satisfies suitable growth condition process semigroup well defined suppose time step splitting scheme exact expression one step two possible lie trotter splittings let family numerical approximation flow whose nature may arbitrary sense let number mc simulation step splitting scheme let simulation time step one step splitting procedure mc solve respectively error numerical scheme come number source semigroup recover original flow unless ode solved explicitly, number simulation finite, simulation perfect random number generator produce pseudorandom number actually, value simulated using smaller time step limit small get, higher order simulation scheme require either calculating iterated stochastic integral reliably providing family random variable moment given order etc, splitting however, mc unavailable specific pde even applicable, method rarely first choice pdes practice note one cannot really simulate discretized whole straightforwardly instance, standard finite difference scheme properly modified unbounded domain eg introducing artificial boundary transforming original pde one bounded domain hand, real world engineering pdes usually stated bounded domain automatically though mc significantly le sensitive problem unbounded domains, presence boundary cause problem one think using classical euler maruyama scheme simulate one dimensional sde whose solution always stay positive impossible keep approximation positive since use symmetrical random increments, one consider corrected suitable implicit scheme etc remedy consider bounded domain bc boundary assumed piecewise lipschitz, customary apply feynman kac formula get analog defined one could try consider decomposition cf section family degenerate first order pdes define instead since bc function only, alternative setting however, reference section show naive approach bc proper one transforms time hit even though consider dirichlet bc, clear decomposition cannot arbitrary even accommodate eg set may unreachable bc make sense process cannot reflected neumann bc cannot imposed etc recalling classification boundary point diffusion exists dimension higher equal see particular difficulty probabilistic origin assume also given family possibly non uniform grid tessellation whose size converge following ode finite dimensional spatially discretized version term appears due boundary correction calculating derivative explicitly depends discretized version ic change step splitting scheme let denote finite dimensional approximation grid time step one use standard scheme time step solving ode get solved remarked already, matrix depends contains second power grid size thus need implicit sufficiently stable method whose step size get smaller thus limit choice grid practice introduces error value depends domain property etc scheme run every step splitting procedure however, let choose simplicity forward euler method time step instead linear matrix valued equation also need family numerical approximation flow whose nature may arbitrary appropriate sense approximation also finite dimensional live grid may defined arbitrary also make sense therefore combine operator need introduce interpolation procedure well defined simplest example linear interpolation uniform grid get instead left write corresponding version mc defined thus get additional source error decomposition bc corresponding correction solving ode part corresponding pdes interpolation point grid space discretization, property grids, choice difference quotient etc internal time discretization associated internal error continue discussion bc affect splitting later practice, grid is, fixed choosing proper mean choosing sufficiently numerically efficient spatial discretization however, different subproblems diffusion ode case may use different spatial discretizations different grid instance, assume dimension splitting applied second order operator decomposed itse",mathematics
"homeomorphism type floyd boundary infinite ended group introduction preliminary construction floyd boundary amalgamated free product hnn extension homeomorphism type floyd boundary free product homeomorphism type floyd boundary amalgamated free product hnn extension main theorem component floyd boundary infinite ended group instruction reporting error coarse geometric notion floyd completion group tree cayley graph corresponding amalgamated free product tree cayley graph corresponding hnn extension boundary stabilizer two topology equivalence topology hnn extension case amalgam case hnn extension case proof theorem proof theorem proof theorem experimental suppose finitely generated infinite group graph group decomposition edge group finite paper establishes topology floyd boundary uniquely determined topology floyd boundary vertex group one first compactification group introduced floyd flo known floyd boundary general, floyd boundary depends scaling function known floyd function compactification exhibit strong connection theory hyperbolic relatively hyperbolic group given hyperbolic group exists floyd function floyd boundary respect homeomorphic gromov boundary see gro similarly, finitely generated group hyperbolic relative collection subgroups, gerasimov ger show exists floyd function continuous equivariant map floyd boundary respect bowditch boundary floyd boundary also connection convergence action see kar martin wi polhkatkowski proved topology gromov boundary free product hyperbolic group uniquely determined topology gromov bounary free factor paper, drop hypothesis free factor hyperbolic prove similar result floyd boundary throughout paper, group assumed finitely generated following main result paper theorem theorem suppose two infinite group suppose graph group decomposition respectively edge group finite then, following vertex group elementary infinitely many end floyd boundary homeomorphic cantor set suppose least one vertex group either non elementary let denote set homeomorphism type floyd boundary non elementary vertex group respectively floyd boundary homeomorphic floyd boundary non elementary group one virtually cyclic one interesting consequence theorem that, floyd function, floyd boundary virtually free group homeomorphic cantor set see corollary need following result prove previous theorem, tell homeomorphism type floyd boundary free product theorem theorem let two free product least one free factor either non elementary let denote set homeomorphism type floyd boundary non elementary free factor respectively floyd boundary homeomorphic floyd boundary remark theorem, free factor elementary either floyd boundary contains point homeomorphic cantor set see corollary next, look connected component floyd boundary infinite ended group obtain partial converse theorem theorem theorem suppose two finitely generated infinite ended group suppose graph group decomposition respectively edge group finite, non elementary vertex group ended also, assume least one vertex group non elementary then, following let denote set homeomorphism type floyd boundary non elementary vertex group respectively floyd boundary homeomorphic floyd boundary organization paper section recall basic fact floyd boundary exlain cayley graph amalgamted free product hnn extension section contains construction floyd boundary amalgamated free product hnn extension finite group section discus homeomorphism type floyd boundary free product then, section discus homeomorphism type floyd boundary amalgamated free product hnn extension there, deduce number interesting corollary section give proof theorem finally, section finish paper discussing connected component floyd boundary graph group finite edge group let metric space let geodesic joining isometric embedding two point joined geodesic called geodesic metric space geodesic joining denoted throughout paper, graph assumed connected shall denote quantity inf suppose two metric space given bi lipschitz map one map said bi lipschitz bi lipschitz notion floyd boundary group introduced floyd flo let group generated finite set, say, let cayley graph respect assigning edge unit length, see naturally complete geodesic metric space denote metric let function satisfying following two condition exists call floyd function simplify construction floyd boundary, floyd function f, de ne example floyd function define new metric scaling length edge let denote identity element edge connecting vertex define new edge length path given consecutive edge floyd length defined define easy see metric called floyd metric cauchy completion metric space called floyd completion subspace called floyd boundary denoted definition depend choice finite generating set see flo lemma thus, suppress dependence generating set denote completion note finite diameter summable compact since group act isometry action extends action homeomorphism see kar detail similarly, one define floyd boundary locally finite graph sequence said shortest sequence if, shortest sequence cauchy sequence since given exists shortest, hence lemma suppose two finitely generated groups, finite group let amalgamated free product monomorphisms choose finite generating set let cayley graph respect generating set denote associated word metric start subsection defining bass serre tree ser corresponding let unit interval vertex define tree called bass serre tree divided transitive closure relation defined follows tree come natural action vertex denote stabilizer let cayley graph respect respectively let subgraphs vertex respectively since subgraphs subgraphs diameter define graph union identified thus, obtain subgraph union identified denote subgraph finally, define graph equivalence relation induced note cayley graph respect define map sending contain subgraph sends well since distance apart coarsely well defined notation write edge if, either vertex cayley graph isometric either denote preimage nothing similarly, denote preimage vertex denote preimage denote subgraphs point, using notation assume shortest possible coset representative similarly, assume cosets let finitely generated group finite subgroup group let hnn extension let isomorphism then, presentation let finite generating set contains let cayley graph respect stable letter denote word metric firstly, give description bass serre tree, say, vertex set say, set left cosets set edge say, set left cosets vertex connected edge let cayley graph respect consider graph induced following equivalence relation denote equivalence class subgraph spanned vertex connected component isometric word metric now, cayley graph defined using graph follows vertex connected bass serre tree similarly, join vertex denote subgraph spanned vertex discussion, say subgraphs connected subgraph hence, define natural projection map, case well defined amalgamated free product case let subsection next subsection devoted construction floyd boundary hyperbolic trivial, martin wi polhkatkowski gave construction gromov boundary closely follow construction let floyd function notation retain notation used subsection denote scaled cayley graph respect generating set floyd metric sake ease, denote metric subspace respectively similarly, denote metric subspace define metric completion let floyd boundary respectively let set divided equivalence relation induced equivalence class element denoted set come natural action left also come natural projection onto set vertex preimage vertex denoted identified lemma let denotes gromov boundary then, set, denote boundary also, set, define compactification set come natural action natural map coarsely well defined preimage vertex identified, set, metric completion two way put topology here, give description topologies, prove two equivalent topology using neighborhood system point set basis open neighborhood basis open neighborhood define basis open neighborhood point fix vertex let suppose vertex let open neighborhood define set first edge geodesic geodesic ray vertex set neighborhood basis collection set run neighborhood basis let let subtree consisting element first edge suppose vertex distance let denotes gromov boundary let define take collection basis open neighborhood skip straightforward verification collection set satisfy axiom basis open neighborhood metric recall floyd metric notation metric subspace indicated first paragraph section defining metric record following observation follows kar natural translation map bi lipschitz hence induces homeomorphism similarly, homeomorphic let fix vertex let sequence vertex lie geodesic ray joining suppose connected edge choose straightforward show cauchy sequence choice cauchy equivalent call sequence cauchy representative definition metric define metric following manner suppose vertex let cauchy sequence representing then, lim limit exists cauchy, independent chosen sequence suppose let cauchy sequence representing respectively then, lim since cauchy, limit exists, independent chosen sequence let three distinct point let cauchy representative respectively, discussion show following definition depend chosen sequence lim lim cauchy sequence representing lim definition metric directly conclude vertex restriction completion metric metric space definition, follows pseudo metric remains check positivity thus, following three case remaining consider case suppose then, remark suppose let first last edge geodesic suppose joined similarly, suppose joined then, following inequality suppose cauchy sequence representing respectively then, putting equation applying limit sides, get remark fact compact subset hence, conclude case suppose let let cauchy representative let first edge geodesic ray suppose joined then, case get let cauchy representative putting last equation taking limit sides, get case suppose respective cauchy representative let geodesic respectively exists unique vertex let first edge suppose joined joined then, sufficiently large geodesic joining pa implies hence, conclude now, ready prove following floyd boundary isometric recall every two possible proof, choose value closest let natural inclusion map, isometric embedding hence extends isometric embedding denotes cauchy completion show fact isometry note nothing cauchy completion let shortest sequence then, lemma cauchy sequence also, distance non decreasing hence, following two case case exists sufficiently large n, distance since shortest sequence exists vertex large hence, converges point case distance go since shortest, exists geodesic ray, say, let point represented then, subsequence becomes cauchy representative hence, converges let exists shortest sequence two cases, know exists hence, continuity implies hence, conclude since, construction, dense turn implies hence, isometry give desired result let topology defined neighborhood basis let topology induced metric subsection, show finer let let represents coset reduced representative let radius ball show exists neighborhood choose let note compact subset define evident open neighborhood let element let first edge either geodesic geodesic ray assume joined since every path joining pa since representative necessarily reduced contained get thus, using inequality get using triangle inequality, get hence, conclude now, let let open ball radius choose unique sequence along unique geodesic converges let edge reduced representative coset associated vertex cauchy representative thus, converges choose easy see every path pa hence, using inequality triangle inequality, get hence finer let vertex let neighborhood neighborhood since open exists ball radius contained let radius ball then, follows definition neighborhood let let neighborhood choose let ball radius then, again, easy see subsection, retain notation subsection let floyd function denote scaled cayley graph respect generating set floyd metric sake ease, denote metric subspace similarly, denote metric subspace define metric completion boundary stabilizer let set divided equivalence relation induced equivalence class element denoted set come natural action left also come natural projection onto set vertex result similar lemma hold implies homeomorphic hence, every vertex identified let denotes gromov boundary then, set, define boundary also, set, define compactification set come natural action natural map case well defined preimage vertex identified, set, metric completion subsection similarly define topology metric following step employed previous subsections, one easily show topology topology induced metric homeomorphic well metric isometric hence, subspace topology induced homeomorphic main goal section prove following theorem section, assume group infinite unless mentioned otherwise suppose two free product infinite group let two floyd function homeomorphism easy application induction give following suppose two free product infinite group let two floyd function then, notation let fixed homeomorphism floyd boundary denote homeomorphism induced let bass serre tree respectively finally, denote cayley graph respectively construction cayley graph free product section taking trivial suppose two finitely generated groups, two floyd function respectively let cayley graph respectively floyd metric then, compact metrizable space one metric subspace metric respectively following lemma analog lemma context floyd boundary let homeomorphism bijection homeomorphism define map take exists compact easy application triangle inequality show dense order element sequence define choose required iterate following two step alternatively step suppose smallest number yet defined since dense choose image map then, define step suppose smallest number chosen image since dense hence dense choose yet defined then, define performing two step alternatively, see bijection since compact metrizable, prove homeomorphism, sufficient prove continuous consider sequence converges then, lim thus lim implies lim using triangle inequality, therefore converges hence, continuity converges definition follows lim thus, converges hence, continuous immediately following exists bijection following hold let let open neighborhood exists neighborhood let bijection lemma thus, homeomorphism prove required bijection since open neighborhood viewing subspace open neighborhood since compact exists open neighborhood clear using argument lemma get following topological result corollary, use coming section let compact metric space countable dense subspace every element isolated respectively denote assume exists homeomorphism exists bijection map homeomorphism using corollary prove following topological lemma, turn useful later following lemma, closure subset metric space shall denoted let compact metric space countable dense subset containing isolated point define then, exist metric subspace exist bijections induce homeomorphisms identity map let metric space isometric embedding let let let quotient map note set, now, bh lemma define metric follows inf metric compatible topology defined quotient map clear definition restriction either isometric embedding also, countable dense subset contains isolated point now, define note restriction isometry onto nothing identity map since compact, applying corollary get bijection induces homeomorphim let then, take restriction composition restricted hence lemma previous lemma generalized many property lemma using notation used lemma assume many property mentioned lemma let neighborhood straightforward check exists neighborhood isomorphism corresponding homeomorphisms let bijections lemma let edge stabilized respectively recall non trivial element expressed uniquely, reduced form, allowing also define map map edge edge easy check isomorphism now, ready prove homeomorphic sufficient prove homeomorphic note that, set representative form similarly, set representative form choose unique smallest possible case choose unique representative element called reduced represenatives finally, define map following manner let let reduced representative define let represent infinite word subword consisting first letter corresponds th edge geodesic via correspondence define infinite word right give geodesic ray starting note restriction map induced isomorphism map homeomorphism definition follows bijection show homeomorphism, sufficient prove continuous two case considered case let let vertex let open neighborhood corollary open neighborhood then, definition neighborhood follows case let integer consider subtree defined respect let subtree respect base vertex again, definition neighborhoods, follows completes proof theorem end section proving following interesting case let floyd function let infinite group finite group homeomorphic assume lemma and, exists bijection extends homeomorphism sake distinction, let let extends homeomorphisms denote scaled cayley graph bass serre tree respectively let set vertex represents cosets vertex set discussion section know sufficient produce homeomorphism since finite group, empty implies every representing coset empty progressing along line proof theorem define homeomorphism domain codomain subspace topology induced let represents unique reduced form discussed section let denotes natural number define map follows map induces required homeomorphism discussed proof theorem every element exists unique reduced representative define map following manner remark corollary deduce continuous every straightforward check also continuous every point hence, conclude continuous since compact bijection, also homeomorphism hence, conclude proof far, proved homeomorphism type floyd boundary free product infinite group depends homeomorphism type floyd boundary free factor now, proceed prove similar result group admitting decomposition amalgamted free product hnn extension finite group fix floyd function section main result subsection following suppose infinite group then, following also infinite finite homeomorphic cantor set non trivial finite group infinitely many end denote scaled cayley graph bass serre tree respectively let edge joining respectively let subset contain exactly one coset representative coset respectively also assume identity contained edge unique reduced form allowing case infinite, empty easy check countable, dense subset respectively applying corollary get bijections extend homeomorphisms id id define reduced form element map graph isomorphism inducing homeomorphism define map follows following discussion proof theorem every element choose reduced representative reduced form define define assume let map take since remark show continuous every point vertex represents coset applying similar argument give conclusion continuous every point since homeomorphism, easy see also continuous every point since continuous bijection compact, homeomorphism case finite group empty let index show use map defined last case let bijection let edge joining bass serre tree define take edge reduced form note isomorphism hence induces homeomorphism now, used define homeomorphism last case finally, proposition get completes proof case let denote bass serre tree cayley graph respectively section know since, finite groups, empty, implies empty hence, since degree vertex bounded fixed natural number, homeomorphic cantor set theorem ended virtually cyclic hence see kar proposition immediately following corollary whose proof easy application induction let tree vertex let graph group edge group finite suppose fundamental group vertex group then, following infinite infinite and, finite then, reindexing required suppose exists infinite finite then, finite infinite ended homeomorphic canter set subsection devoted prove following theorem let finite subgroup then, following infinite group finite either equal homeomorphic cantor set sake distinction, let isomorphic copy let generating set denote bass serre tree cayley graph respect generating set respectively discussion subsection sufficient produce homeomorphism let set left coset representative respectively, every coset exists unique reduced representative coset form possible proof, denote identity map id lemma disjoint subset bijections id homeomorphisms since dense exist bijections id homeomorphisms see corollary define map similarly, define map isometric copy construction, conclude id id homeomorphisms firstly, define graph isomorphism follows induces homeomorphism define map follows let define define using remark show continuous since compact bijection, conclude homeomorphism since finite, empty hence, however, regular homeomorphic cantor set theorem finite case, virtually cyclic hence let free product elementary group least one free factor infinite then, floyd boundary homeomorphic cantor set two case consider case reindexing, required, assume infinite finite then, corollary since virtually cyclic, thus, theorem let non trivial finite group then, proposition since isomorphic floyd boundary homeomorphic now, theorem homeomorphic cantor set case reindexing, necessary, suppose exists infinite finite then, corollary infinite virtually cyclic induction, easy prove homeomorphic cantor set end subsection proving following remove dependence floyd boundary free product virtually cyclic group let free product infinite group that, virtually cyclic then, homeomorphic prove induction let then, since isomorphic homeomorphic theorem suppose now, theorem homeomorphic theorem corollary follows case combining corollary corollary following let non elementary elementary group then, following floyd boundary homeomorphic let two floyd function fixed next section here, main goal prove following suppose two finitely generated infinite group suppose graph group decomposition respectively edge group finite then, following vertex group elementary infinitely many end homeomorphic cantor set suppose least one vertex group either non elementary let denote set homeomorphism type floyd boundary non elementary vertex group respect respectively homeomorphic prove theorem, use following result let two free product least one free factor either non elementary let denote set homeomorphism type floyd boundary non elementary free factor respect respectively floyd boundary homeomorphic floyd boundary getting proof theorem prove following result turn useful proving theorem suppose free product infinite group homeomorphic homeomorphic immediately following corollary suppose free product infinite group applying theorem see homeomorphic theorem suppose free product infinite group suppose homeomorphic then, homeomorphic prove induction theorem follows suppose then, theorem homeomorphic using theorem proposition immediately following corollary let infinite group finite let free product group infinite group finite group prove induction proposition let assume now, proposition see inductive hypothesis, hence, theorem finally, corollary let theorem let bass serre tree suppose let bass serre tree subsection, first all, prove isomorphism using isomorphism, define map prove fact homeomorphism isomorphism let cayley graph respect finite generating set then, compact metrizable space restricted metric, compact, dense contains isolated point then, lemma exist exist bijections induce homeomorphisms respectively since homeomorphic lemma exists bijection induces homeomorphism let identity map element written identity respective group shall call standard form let edge edge respectively note edge translate similarly, edge either translate translate define map following manner case let edge standard form two subcases subcase suppose then, define otherwise otherwise case, define subcase suppose then, define where, otherwise otherwise case, define case let edge standard form two subcases subcase suppose then, define where, otherwise otherwise case, define subcase suppose then, define otherwise otherwise case, define construction follows isomorphism homeomorphism let scaled cayley graph respectively let compact metrizable space constructed section proposition follows homeomorphic homeomorphic let identity homeomorphisms, let homeomorphism homeomorphism since isomorphism, induces homeomorphism define map following manner suppose let vertex discussed proof theorem exists unique reduced representative define suppose then, define remark corollary continuity every point follows definition neighborhoods, straightforward check continuity every point since compact bijection, conclude homeomorphism hence, complete proof theorem let natural number reindexing groups, required, elementary group now, following two case occur case suppose then, corollary since reindexing necessary, then, theorem done then, corollary corollary exists again, done theorem case suppose corollary get using corollary corollary see easy application corollary induction give since following process above, exist finally, corollary let undeline graph let maximal tree respectively then, restriction tree group finite edge group whose fundamental group are, say, infinite then, theorem homeomorphic cantor set corollary corollary suppose finite since repeated hnn extension infinitely many ends, least one edge outside give hnn extension, say, infinite group then, repeated application theorem see again, theorem homeomorphic cantor set now, theorem corollary give homeomorphic corollary hence, floyd boundary homeomorphic cantor set similarly, analysis, one show homeomorphic cantor set let vertex group respectively two case consider case reindexing required assume non elementary and, elementary then, corollary since reindexing required assume non elementary and, elementary thus, now, theorem corollary give similarly, hence, theorem case reindexing required assume exists non elementary elementary similarly, assume exists non elementary elementary thus, combining corollary corollary now, theorem give since theorem give complete proof theorem well known gromov boundary hyperbolic group connected ended section, first all, prove analog fact context floyd boundary let ended group floyd function denote scaled cayley graph respect finite generating set floyd metric denotes metric cayley graph assume metric completion metric connected define map sake contradiction, assume non empty, disjoint open subset let denote closure definition follows sequence converging point also converges thus, see check let let sequence suppose exists infinite subsequence contained turn implies give contradiction disjoint hence, eventually contained applying similar argument lead following conclusion since non empty, exists assume sequence respectively, every denote closed metric ball radius since ended, exist subsequence path joining contained let edge since compact, exists subsequence converges since easy see implies give contradiction hence, desired result now, record following fact whose proof proof proposition let group split graph group edge group finite infinite ended suppose non elementary vertex group ended then, connected component either homeomorphic floyd boundary non elementary vertex group singleton set now, ready prove following give partial converse theorem suppose two finitely generated infinite ended group suppose graph group decomposition respectively edge group",mathematics
"introduction setting theory theoretical data driven information level numerical experiment result proof bias conditional monte carlo discrete distribution instruction reporting error heavy tailed case light tailed case empirical truncation level heavy tailed case light tailed case validating theory impact tail truncation impact tail heaviness data driven estimation quantifying tail uncertainty using bootstrap detection tail heaviness summary experimental takeaway experimental propagation input tail uncertainty rare event estimation propagation input tail uncertainty rare event estimation light versus heavy tail dichotomy zhiyuan huang affdepartment management science engineering, tongji university, huangzy tongjieducn authorhenry lam affdepartment industrial engineering operation research, columbia university, henrylam columbiaedu authorzhenyuan liu affdepartment industrial engineering operation research, columbia university, zl columbiaedu consider estimation small probability risk quantity associated rare catastrophic event model based literature, much focus devoted efficient monte carlo computation analytical approximation assuming model accurately specified paper, study distinct direction propagation model uncertainty impact reliability rare event estimate specifically, consider basic setup exceedance iid sum, investigate lack tail information input summand affect output probability argue heavy tailed problem much vulnerable input uncertainty light tailed problems, reasoned large deviation behavior numerical evidence also investigate approach quantify model error problem using combination bootstrap extreme value theory, showing positive outcome also uncovering statistical challenge uncertainty propagation, model uncertainty, rare event estimation, large deviation estimating small probability risk quantity associated rare catastrophic event ubiquitous risk analysis management example include prediction large asset loss finance cash flow imbalance insurance system overload service operation breakdown communication system model based approaches, namely model built capture internal dynamic system, much focus literature devoted efficient monte carlo computation analytical approximation, assuming model accurately specified eg, however, virtually cases, target rare event quantity computed model affected input misspecifications, inaccuracy calibrating model propagated output make target estimate erroneous even meaningless study impact input misspecifications gathered growing attention recent years, generally known problem model uncertainty input uncertainty main focus develop methodology quantify error output estimation decision attributed model misspecifications, measured term bound variance see, eg, stochastic simulation literature, finance, economics, control operation management application extremal estimation, problem intimately related extreme value theory, one attempt extrapolate tail beyond scope data statistically justified fashion, along uncertainty quantification recently, framework called distributionally robust optimization studied construct bound extremal measure additional robustness property beyond statistical asymptotics approach utilizes postulation acknowledgement true distribution within neighborhood baseline model marginal information extremal coefficient moment shape assumption tail monotonicity convexity simulation based rare event analysis, studied method efficiently compute sensitivity rare event probability respect model parameters, proposed averaging distribution fit input model enhance tail performance contrast past literature focused technique quantify impact model uncertainty, paper aim understand significance impact relation level input information propagation mechanic rare event problem specifically, consider basic problem large exceedance probability iid sum, input model refers probability distribution governing summand here, suppose input data informs summand distribution first question would simply using empirical distribution input model fit, would rare event probability reasonably close truth assuming computational monte carlo error negligible address question viewpoint main uncertainty input model undermines accuracy rare event estimation lack knowledge tail central, non tail part input distribution typically fit parametric nonparametric techniques, adequate data perform fit question simply empirical distribution contrast, tail portion often ill informed due inadequate data, yet high impact aggregated tail behavior thus, address question first focus truncating tail input model affect rare event estimate main contention heavy tailed problem suffers much larger impact input model truncation light tailed counterpart truncation level represents amount tail knowledge obtained data, maximum data remaining data discard fixed number largest data point consequence, using empirical distribution even moderate data size, asked question fails estimate heavy tailed rare event quantity reliably hand, effect missing tail light tailed estimation relatively milder hence reliable estimation case achievable much le data requirement different effect truncating input tail explained different large deviation behavior heavy versus light tailed system specifically, former pertains one several big jump ie, invoke rare event, one several input component exhibit huge values, latter invokes rare event component contribute small shift adding contribution thus, accurately estimate heavy tailed rare event, one need accurately estimate far tail input component, whereas necessary light tailed system mathematical analysis rigorize intuition relies berry en expansion exact large deviation asymptotics, allow compare rare event probability true truncated distribution particular, expansion asymptotics derived triangular array growing truncation levels, requires elaborate analysis new best knowledge above, go ask whether statistically error arising input uncertainty, specifically point estimate question could bootstrap give rise valid confidence interval account input error would incorporating extreme value theory fitting input tail lead reliable uncertainty quantification address question ran extensive experiment evaluate performance bootstrap extreme value theory enhanced bootstrap technique across various scenario involving different tail distributions, sample sizes, target probability find that, particularly situation exhibiting heavy tailed behaviors, even sample size relatively large, ie, approaching inverse target probability, using empirical bootstrap question significantly ignores tail content would fail estimate rare event quantity vastly estimate uncertainty uncertainty estimation could come power law tail non power law subexponential tail using extreme value theory question extrapolate tail peak threshold method, eg, help extent, could introduce extra bias, least using fitting method introduction bias primarily due presence unknown slowly varying function true data distribution, making generalized pareto distribution misspecified tail model positive side, numerical experiment demonstrates extreme index estimator effectively identifies case prone uncertainty estimation, irrespective whether caused power law tail non power law subexponential tail identification serf indicator additional data collection necessary improve precision reliability estimation uncertainty quantification finally, contrast study question related work especially investigated sensitivity large deviation rate input model deviate within nyi divergence ball showed similar context imposing single ball inputs, thus allowing distortion dependency structure among inputs, lead substantially heavier tail original model kullback leibler divergence used studied robust rare event simulation input tail unknown subject geometric assumption studied impact waiting time tail service time misspecified truncated relating investigated truncation threshold needed retain heavy tailed characteristic system also contrasted light tailed case observed required threshold higher heavy tail observation regard thus similar different setting aggregation iid variable requires derive elaborately berry en expansion exact large deviation asymptotics truncated distribution order compare rare event probability truncated true distribution moreover, focus statistical implication asked question validate theory numerically investigate error assessment scheme remainder paper follows section describes estimation target explains impact tail truncation light versus heavy tailed case section discus data requirement threshold reliable unreliable estimation section show numerical result use truncated distributions, empirical distributions, bootstrapping, detection heavy tail appendix contains proof supplemental result throughout paper, sequence write exists integer exists integer consider estimating overshoot aggregation iid variables, ie, consider iid variable drawn distribution denote generic copy convenience assume density exists denote correspondingly, let tail distribution function let suppose high level grows investigation pertaining question following suppose truncate distribution point density becomes ie, consider truncated distribution function given correspondingly truncated density denotes indicator function convenience, denote probability governed arbitrary distribution simply denote governed would like investigate approximation error definition note that, roughly speaking, situation capture case use empirical distribution plug input model, probability mass zero region outside scope data close zero tail data proportional constant introduced ensure proper truncated distribution little effect mass reasonably big first consider pareto tail case suppose regularly varying tail form slowly varying function suppose generally log case, known approximately least one probabilistically, rare event happens likely due big jump one eg, thus, truncation level small compared big jump contributes dominating mass rare event barred, making substantially smaller situation, becomes negligible compared approximation error effectively words, using truncated input distribution lead substantial estimate bias almost equal magnitude rare event probability alternately, write approximation error again, relatively small compared event least one inside probability least one redundant, making probability asymptotically equivalent asymptotically equivalent summarize suppose iid random variable regularly varying tail distribution form let log assume log discrepancy using truncated distribution original distribution evaluating probability given hand, truncation level large enough, probability least one negligible compared error would asymptotically negligible summarized following theorem suppose iid random variable regularly varying tail distribution form let log assume discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, consider case theorem state log rare event estimation essentially void, least asymptotically hand, theorem ensures estimation reliable larger words, truncation level grow faster linear function get reliable estimation rare event probability number input component large, could difficult sustain accuracy level given finite set input data consider posse finite exponential moment, ie, logarithmic moment generating function log neighborhood define consider constant suppose exists unique solution equation exhibit exponential decay ie, log rate function given legendre transform convex conjugate fact, assumed non lattice, following accurate asymptotic theorem although asymptotic proof applied lattice, ie, integer largest number property called span also get accurate asymptotic remark remark truncated distribution, similarly define logarithmic moment generating function log let consider non lattice case example like asymptotic original distribution, approximate solution equation truncation level large enough, converge fast error caused replacing negligible, ie, fact, assume choice satisfies st exists since approximation made precise follows consider constant suppose exists unique solution equation further, suppose choice satisfies distribution non lattice, suppose lattice distribution, ie integer span assume ie, lattice proof lemma quite lengthy need establish berry en expansion specific triangular array order obtain exact large deviation asymptotic theorem particular, requires many precise estimate characteristic function generalize case iid sequence section xvi theorem section theorem although establishes edgeworth expansion general triangular arrays, unclear technical assumption hold characteristic function appendix thus resort self contained analysis triangular array berry en expansion based lemma see asymptotically equal therefore, relative error using estimate asymptotically negligible summarized following theorem consider constant suppose either lattice non lattice moreover, suppose exists unique solution equation then, long truncation level chosen satisfied, discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, theorem postulate long truncation level chosen high enough satisfied, model error using truncated input negligible contrast heavy tailed case, condition dictate typically logarithmic requirement illustrate choice different distributions, consider following example first show increasingly stringent requirement tail heaviness increase suppose normal distribution direct calculation show choice number satisfying log suppose exponential distribution direct calculation show choice number satisfying log suppose gamma distribution direct calculation show choice number satisfying log example, let generalize three example suppose admits density function satisfying further, suppose choice number satisfying log contrast heavy tail setting, establish result unreliable estimation light tail case since condition subtle example, consider extreme case bounded estimation would eventually zero error long truncation level go infinity moreover, theorem enough support point estimation problem harder heavy tail case see discussion section finally, besides quantity targeting, also consider although reliability result probability estimation truncated distribution change, asymptotics probability change lattice case completeness, present result related appendix section assume fully know truncated distribution section, connect developed theory data combining theorem extreme value theory, aiming give guidance reliability rare event probability estimation term data size consider estimating sum iid random variable unknown distribution suppose iid sample construct empirical distribution want answer question whether estimation true probability reliable closely related question many sample need get reliable approximation natural approach connect theorem data set truncation level threshold informable data, namely use properly defined empirical truncation level know asymptotic order empirical truncation level respect data size transform condition truncation level theorem condition judge estimation reliability term note natural definition empirical truncation level converge infinity otherwise never approximate true distribution even lead inconsistent estimator due restriction, appears good choice define empirical truncation level as, eg, empirical quantile since empirical quantile converges true quantile instead infinity simplicity, set empirical truncation level sample maximum max empirical truncated distribution exactly empirical distribution alternatively, discard fixed number, eg, largest sample data take maximum remaining data truncation level latter affect analysis since asymptotic order truncation level remain corollary remaining task analyze asymptotic order borrow tool extreme value theory following, consider heavy light tailed case separately behaves differently two case summary analysis selected light tailed distribution displayed table heavy tailed case, suppose unknown distribution tail slowly varying function index parameter estimated tail index estimator theorem know fr chet distribution parameter normalizing constant satisfies slowly varying function thus rough approximation according theorem truncation level log fixed number approximation reliable log ie, log log estimate reliable theorem similar argument, reliable moreover, approximately represented true probability plugging condition know unreliable log reliable light tailed case complicated since asymptotic order varies different distribution conclusion also different different distribution illustrate, consider two example first, suppose true distribution exponential distribution exp example log thus rough approximation log according theorem truncation level log approximation reliable log log log ie, estimate reliable like heavy tailed case, approximately represent true probability large deviation principle second order taylor expansion log plugging know estimate reliable log second, suppose true distribution normal distribution example log as, lead approximation log log theorem truncation level log arbitrarily small approximation reliable log log ie, arbitrarily small estimate reliable derive required data size target probability level according large deviation implies following approximation plugging obtain reliably estimating target probability level discussion also explains estimation problem usually harder heavy tailed distribution light tailed distribution suppose target probability level fixed heavy tailed case, reliable light tailed distribution exponential, reliable log since log large see heavy tail requires data light tail estimate level rare event probability caution analysis intuitive fully rigorous however, give guideline sufficiency data size reliably estimating rare event probability next section report numerical result validate analysis herein investigate numerically quality estimating finite input data consider different number summands vary magnitude changing value setting, given certain pair tail distribution viewed variable experiment examine three group parametric distribution representing different type tail regularly varying tails, including generalized pareto distribution student distribution positive half whose density tail index reflects tail heaviness, equal inverse shape parameter generalized pareto distribution degree freedom distribution according karamata theorem distribution satisfy assumption theorem light tailed distributions, including standard exponential, standard normal positive half weibull shape parameter whose density given since weibull shape parameter lighter tail normal, call light tailed weibull distribution experiment three distribution satisfy assumption theorem several distribution scope analyses, namely log normal whose logarithm follows weibull shape parameter call heavy tailed weibull distribution distinguish light tailed weibull distribution power law tail, subexponential exhibit heavy tail behaviors, eg one big jump behavior numerical investigation divided four part section provides empirical validation theoretical finding discussed section considering estimation using tail truncated distribution input model section evaluates validity relation reliable estimation data size section section evaluates performance bootstrap combination extreme value theory tools, particular generalized pareto distribution, quantifying estimation uncertainty lastly, given observed challenge estimation uncertainty quantification, appears dependable strategy ensuring accurate estimation sample size significantly larger case inadequate sample size could result uncertainty estimation section then, discus recommend diagnostic method detecting case validate theoretical finding discussed section demonstrating heavy tailed distribution vulnerable truncated tail set experiment, use true distribution, conditional truncation point, generate sample evaluate target rare event probability use tail quantile truncation point, defined compare rare event probability driven truncated distribution, denoted driven untruncated distribution, denoted use gaussian distribution representative light tail distribution heavy tail measure effect tail heaviness, consider distribution three different degree freedom also consider various number summands enhance computational efficiency, apply various variance reduction technique including importance sampling light tailed case conditional monte carlo heavy tailed case details, see result displayed figure maintain consistent true probability level approximately across settings, shown figure figure show relative errors, appear increase heaviness tail particular, heavier tailed distributions, specifically relative error close indicates poor estimation relative true magnitude probability observation align analysis presented section asserts absence tail information particularly harmful problem involving heavy tailed distribution investigate error rare event probability estimation relation data size, various tail rare event probability level consider problem pair independently generate data set sample size use approximate empirical distribution constructed size data setup, repeat experiment time report relative error ratio approximation error ground truth experimental outcome using box plot plot show median central red mark, top bottom edge box represent percentile whisker extend outside box extreme data within range time box height data outside range considered outlier represented red cross reliability estimate determined coverage box box cover smaller height suggests concentrated estimates, sign approximation relatively accurate box fails cover box would mostly close case mean approximation poor due insufficiency using empirical distribution given data size like section variance reduction needed speed computation heavy tailed problems, apply conditional monte carlo sample size constructing empirical distribution sufficient sample since method relies equation max hold discrete, estimator biased simulation based empirical distribution however, demonstrated appendix bias negligible run crude monte carlo, estimate sample drawn empirical distribution conditional monte carlo cases, use sample problem involving light tailed distributions, conditional monte carlo method also employed sufficient sample size note that, despite availability efficient alternatives, select latter method exclude influence variation among different estimator decision affect essential finding experiments, conclusion would remain consistent regardless use efficient approach unfold experiment result three direction section compare heavy light tailed distribution section compare distribution within family different tail heaviness section investigates impact slowly varying function distribution light power law tail figure a, b, show comparison among generalized pareto distribution tail index heavy tail exponential, gaussian light tailed weibull light tail set figure a, sample size relatively small estimate light tailed case accurate, evidenced coverage box however, heavy tailed estimate significantly estimate rare event probability box fail cover truth three case increase sample size figure b, light tailed case start highly reliable estimates, concentrate within relative error bound meanwhile, heavy tailed box still cannot cover truth figure c, increase sample size observe heavy tailed case similar performance light tailed case figure a, box barely cover truth hand, samples, light tailed estimate already highly accurate mostly relative error similar observation found figure d, e, f, set start small sample size figure d, light tailed estimate inaccurate box edge close box capable covering truth, heavy tailed estimate tend estimate probability even though heavy tailed box cover truth, median estimate close indicates half estimate severe estimation sample size increased figure e, light tailed estimate become concentrated box edge light tailed case around heavy tail cases, estimate close relative error case concentrated box edge still tend estimate median close top edge lower even increase sample size figure f, observe heavy tailed case still cannot obtain reasonable estimates, estimate relative error close result indicate problem associated heavy tail prone estimation light tail amount data, consistent discussion section note that, many heavy tailed case eg, figure relative error approach suggesting estimate significantly smaller actual value coincide theorem addition comparison heavy tailed light tailed distributions, find heavy tailed distribution different tail heaviness exhibit different estimation error instance, figure f, observe tail lighter estimate better accuracy heavier tail eg subsection, drill phenomenon investigate impact tail heaviness within parametric family consider heavy tailed distribution pareto student different tail index set consider two setting figure show heavier tail would increase data requirement obtaining accurate estimate particular, figure, distribution ordered left right decreasing tail heaviness figure c, pareto distribution case show similar pattern tail relatively heavy tail index equal estimate approximately relative errors, represent significant estimation tail index increase observe median estimate gradually grows near pareto case figure student case figure finally, tail relatively light tail index equal half estimate closely concentrated around therefore much reliable similar observation found figure well, setting, estimate fail badly tail index smaller equal pareto distribution cases, shown near median relative error increase tail index, lead lighter tail, estimate improve finally box edge concentrate relative error pareto case figure student case figure comparison within parametric family support finding section demonstrating problem heavier tail lead greater estimation next investigate performance non power law tail note figure d, tail index equal pareto box fails cover truth, whereas distribution box larger range contains since tail index, appears slowly varying function inside distribution affect coverage estimate subsection study issue even further, considering additionally subexponential distribution without power law tails, namely log normal heavy tailed weibull distribution figure order distribution left right decreasing tail heaviness asymptotic sense figure a, use light tailed case exp lweib exhibit accurate estimate distributed within approximately relative error heavy tailed cases, box fail cover truth estimate smaller relative errors, estimate well concentrated within relative error note subexponential distributions, whose tail asymptotically lighter estimate fact much worse particular, observe estimate log normal case even worse estimates, top edge box much closer estimate heavy tailed weibull better log normal ones, box still fail cover truth present similar result figure b, c, figures, observe estimate log normal heavy tailed weibull distribution consistently worse estimate distribution even though tail follow power law hence lighter experiment indicate tail falling pareto light tail lead significant estimation issue like pareto tail moreover, comparative estimation performance relative data size tail appear subtle intuitive notion tail heaviness alone might adequately inform estimation reliability next investigate use bootstrapping input uncertainty, particular whether bootstrap confidence interval ci provide valid coverage following, consider two bootstrap scheme nonparametric bootstrap, bootstrap assisted generalized pareto tail fitting create bootstrapped empirical distribution repeated resampling replacement, resample size equal original data size resampling repeated times, resample used input model drive rare event estimation bootstrap ci constructed using empirical quantiles resample estimate present experimental result two problems, one representing heavy tailed scenario another light tailed scenario particular, consider gaussian distribution light tailed case distribution heavy tailed case scenarios, set rare event probability around focus evaluating efficacy bootstrap cis, specifically whether achieve desired coverage level, set experiment obtain coverage levels, make experimental replications, replication construct bootstrap ci whether cover true probability figure present result figure show that, light tailed problems, coverage ci considered case blue solid line result indicate bootstrap ci valid, provide coverage close target level even number sample relatively small compared probability question example, sample versus probability moreover, observe figure ci width relatively big compared estimated probability example, time larger target probability sample wider interval might seem overly cautious, important effectively identifying instance probability estimate unreliable hand, heavy tailed case, figure show bootstrap ci badly cover truth number sample smaller compared light tailed case, sample size small, given target probability around experimental result suggest bootstrap work well light tailed problems, fails heavy tailed problem tie explanation section impact tail uncertainty profound heavy tailed case experiment suggests heavy tailed problems, lack tail information cause problem estimating probability itself, also deem assessment input uncertainty challenging attempt overcome challenge section using generalized pareto distribution inject additional information tail estimation specifically, bootstrap conducted similarly section key variation resample, fit tail using generalized pareto distribution latter conducted via various estimation technique including maximum likelihood estimation mle method moment mom probability weighted moment pwm detailed identifying tail data required fitting, experiment different truncation points, specifically using empirical tail quantiles data experiment, focus heavy tailed case section follows distribution degree freedom consider sample size ranging which, demonstrated figure insufficient standard bootstrap method function effectively similar experiment section ci calculated number resamples run experimental replication obtain statistic coverage interval width experiment result presented figure table figure show scenarios, improvement coverage compared standard bootstrap, indicated provided coverage close target level hand, coverage provided method notably affected chosen truncation point depicted figure a, coverage decrease significantly, even dropping zero, increase sample size note true distribution case distribution, implies mismatch tail fit due model misspecification interval width shrink increasing number samples, model biasedness start surface among three approach fitting generalized pareto distribution, mle pwm turn reliable mom revealed table coverage mom le two approach case performance match documented fact mom unreliable shape parameter sample size smaller observation pwm give smaller average interval width mle, providing similar coverage eg, tail quantile width mle pwm therefore suggests pwm suitable smaller sample sample size large observation mle upper hand term interval width eg, tail quantile width mle pwm experimental result show although overall performance enhanced bootstrap scheme better standard bootstrap, obtained ci still misleading latter caused model biasedness generalized pareto distribution bootstrap cannot overcome seen evidence theory well experiment heavy tail may cause severe estimation using data inform input model rare event estimation moreover, reliably detecting estimation, word providing ci correctly capture amount uncertainty, could challenging well address these, approach devise procedure detect risk uncertainty estimation, word identify case uncertainty estimation, well probability estimation, prone occur inadequate data procedure detects risk, mitigate collecting data big enough size confidently larger magnitude explained section conversely, procedure detects otherwise, analysis section previous experiment demonstrated obtain reliable estimate moderate sample size, sample experiment discussed section note first case, would need get pilot estimate could obtained collected data along suitable conservative inflation, prior knowledge magnitude however, could well case cannot even get rough magnitude access data, either case mean decision making account estimation risk recommend use properly chosen tail index estimate conduct detection extreme value theory literature, various graphical estimation method applied obtain tail information data, including quantile quantile qq plotting mean excess plotting eg chapter tail index estimation detailed discussion, see chapter chapter approaches, assessment tail heaviness achieved estimating tail index, form slope plot explicit estimator among various choices, focus estimators, denoted designed extreme value index also known shape parameter distribution domain attraction generalized pareto distribution compared classical tail index estimator classical hill estimator extreme value index estimator advantage dissecting light heavy tail negative estimate suggests sample light tailed hand, distribution power law tail consistent estimating particular, consider pickands estimator moment estimator important note tail index estimators, including extreme value index estimators, specifically designed pareto tail mean presence slowly varying function distribution could lead model misspecification address issue, common practice excluding data outside tail portion minimize impact slowly varying function truncation point data selected prior implementing estimation process since estimator might sensitive selection truncation point, convention plot pair denotes number order statistic decreasing order tail data truncation, represents corresponding estimate following experiments, collect data distribution section estimate extreme value index using pickands estimator moment estimator section observed one cannot obtain relatively accurate estimate small sample heavy tailed problem want check whether able detect case similar amount sample hence provide warning estimation caused heavy tail experimental results, including pareto distribution, distribution, distributions, presented figure respectively figure show performance estimator data generated pareto distribution classify data exhibiting heavy tailed behavior estimate majority notably characteristic observed case presented figure, showing estimator capable detecting heavy tail pickands estimator figure estimate values, though estimate unstable varies instance, estimate fall purple solid line however, variation would affect conclusion since rest value compared pickands estimator, moment estimate stable estimate consistently especially increase number sample figure d, estimate estimator clearly stronger warning heavy tail term estimating extreme value index, pickands estimate figure perform worse moment estimate figure le consistent varying additionally, estimate appear accurate enough correctly rank tail heaviness hence cannot reliably imply severity heavy tailed behavior instance, cyan solid line consistently smaller estimate dark red solid line whereas true index respectively next, figure present result data generated student distribution observe pickands estimator may lead misclassification heavy tailed data light tailed yielding estimate smaller value performance le reliable compared performance pareto case particular, sample figure a, observe estimate dark red solid line consistently smaller estimate green solid line cyan solid line also cross value around sample figure c, estimate dark red solid line still hand, moment estimator consistent le variation varying sample figure d, estimate positive similar pareto cases, moment estimate capable detecting heavy tailed behaviors, cannot rank heaviness correctly sample size small eg, figure lastly, consider sample light tailed distribution subexponential distribution non power law tail recall section log normal heavy tailed weibull distribution similar performance pareto tail distribution term estimation figure show extreme value index estimation successfully detect risk estimation classifying non power law subexponential distribution heavy tail distributions, extreme value index estimate consistently positive range mostly again, find extreme value index estimator unable accurately gauge severity heavy tailed behavior evident fact index estimate log normal heavy tailed weibull distribution substantially different figure however, discussed section log normal distribution require larger sample size heavy tailed weibull distribution obtaining reliable estimation experiments, concluded extreme value index estimator effective detecting risk estimation classifying whether data heavy tailed particularly prominent moment estimator appear give correct classification across considered setting however, also note estimator may provide precise estimate tail index and, result, may accurately severity heavy tailed behavior key finding experimental study summarized follows heavy tailed problem vulnerable lack data compared light tail reliable estimation rare event probability heavy tailed scenarios, significantly larger sample size required needed light tailed distribution moreover, assessing uncertainty equally difficult subexponential distributions, even absence power law tail, prone estimation point estimate uncertainty evident similar sample size requirement reliable estimation rare event probability subexponential distribution heavy tailed distribution problem standard bootstrap method effectively provide valid uncertainty quantification heavy tailed problem sample size moderate incorporating generalized pareto tail extrapolation bootstrap improves coverage bootstrap cis, reliability coverage affected model misspecification estimator extreme index, especially moment estimator, appear effective detecting risk estimation point estimate uncertainty classifying whether distribution heavy tailed suggestion dependable approach ensure reliable estimation two step procedure first detect whether data prone risk estimation so, employ sample size confidently larger or, case possible, decision making account substantial estimation risk define target probability governed arbitrary distribution using estimate overshoot make difference heavy tailed case fact, following theorem assumption theorem discrepancy using truncated distribution original distribution evaluating probability given assumption theorem discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, light tailed case, asymptotics probability change lattice case since change asymptotics affect reliability result theorem summarize following theorem assumption theorem non lattice case, lattice case moreover, cases, discrepancy using truncated distribution original distribution evaluating probability asymptotically negligible, ie, proof theorem recall prove theorem, suffices show since log exists st log large first let log define variance show normalizing s, note tail distribution function normalized random variable karamata representation theorem theorem see slowly varying proposition iii know slowly varying function applying equation equation also hold defined equation similarly, applying equation karamata representation theorem theorem thus therefore, follows comparing show recall log proposition implies combining get log log since truncated distribution stochastically dominates ie, must have, given non decreasing property usual stochastic order theorem thus hold log concludes proof proof theorem argument proof theorem show formula approximation error suffices show least one inequality asymptotic property prove suffices show recall form choice property proposition prof proof theorem theorem argument proof theorem see also hold probability replaced respectively therefore, following analog hold remaining argument proof theorem applied here, prof theorem theorem proved similarly let turn proof light tailed case explained lemma proof quite lengthy would like provide roadmap go detail recall choice depends therefore truncated random variable actually triangular array varies lemma essentially establishes exact asymptotics triangular array special case truncated distribution varying truncation level theorem give exact asymptotics case iid random variable use technique prove lemma key technique proof berry en expansion order well known iid case need make much effort establish similar expansion truncated distribution varying truncation level ie, lemma since proof light tailed case require notations, use",mathematics
"property set valued tensor complementarity problem main result instruction introduce set valued tensor complementarity problem element involved tensor defined based set valued mapping study several property solution set framework set valued mapping provide necessary sufficient condition zero solution set valued tensor complementarity problem introduce limit property set tensor establish connection limit property level boundedness merit function corresponding set valued tensor complementarity problem keywords set valued tensor complementarity problem, tensor, semi positive tensor, tensor, merit function, limit property subject classification song qi introduced tensor complementarity problem associated function special polynomial constructed help tensor detail see huang qi showed multilinear non cooperative game formulated tensor complementarity problem, establishes connection two class problem given th order dimensional tensor dimensional vector tensor complementarity problem find problem denoted tcp tensor complementarity reduces linear complementarity problem linear complementarity problem defined follows given matrix vector linear complementarity problem, denoted lcp find satisfies following condition concept complementarity take account wide range optimization problem linear programming, linear fractional programming, convex quadratic programming, bimatrix game problem among issue classified linear complementarity problem widely used operation research, control theory, mathematical economics engineering also well recognized literature mathematical programming recent work problem application see reference cited therein well known linear complementarity problem served initial inspiration notion ppt ppt fundamentally involves transforming matrix linear system unknown exchanged relevant entry detail see numerous matrix class subclass undergone extensive research result computing, complexity theory, theoretical foundation linear complementarity problem recent work problem application see game problem multivariate analysis see reference cited therein many mathematical concept extended framework set valued mapping set valued mapping becomes famous kakutani fixed point theorem, generalization brouwer fixed point theorem function set valued mapping map individual element set subset set consider set valued mapping case modeling uncertainties, disturbance error stability issue study ill posed inverse problem solution set topological property semi continuity, well posedness related property case lack bijection continuity issue allow characterize many important property function along domain codomain significant component sensitivity analysis complementarity problem set valued complementarity problem set valued nonlinear complementarity problem provides unified framework nonlinear complementarity problem, exteded complementarity problem, implicit complementarity problem, quasi variational inequality, mixed nonlinear complementarity problem minimax programming problem detail set valued complementarity problem see motivated study, introduce set valued tensor complementarity problem subclass set valued complementarity problem difficult study set valued complementarity problem imposing tensor structure existence uniqueness theorem paper organized follows section present basic notation result needed subsequent section section introduce set valued tensor complementarity problem prove necessary condition feasible solution set establish connection two set study tensor consider merit function set valued tensor complementarity problem establish necessary sufficient condition level boundedness connection limit property set tensor basic idea notation used throughout text outlined section vectors, matrix tensor considered real entry positive integer set denoted denote let denote dimensional euclidean space vector column vector unless specified otherwise let vector component euclidean norm vector defined th order dimensional real tensor multidimensional array entry set th order dimensional real tensor denoted shao introduced product tensor let order order two dimensional tensor product tensor order dimension entry tensor vector defined scalar defined given vector tensor set feasible solution tcp defined fea solution set tcp sol fea consider definition result required next section th row subtensor denoted entry given function said level bounded every level set bounded tensor said tensor every tcp solution tensor said tensor system solution tensor strictly semipositive tensor tensor said tensor tcp unique zero solution tensor solution set tcp bounded mapping define given set valued mapping define lim sup lim inf lim sup lim inf function outer semicontinuous if, lim sup inner semicontinous lim inf function continous outer semicontinous inner semicontinous let two metric space set valued map characterised graph denoted graph defined two different way define inverse image subset set valued map said inverse image said core set valued mapping upper semicontinuous core neighbourhood neighbourhood set valued map lower semicontinuous inverse image open subset intersecting neighbourhood consider metric space two normed space two set valued map respectively, single valued map satisfying following assumption lower semicontinuous convex value continuous affine posit following condition set valued map defined lower semicontinuous nonempty convex value paper always assume set valued mapping closed valued, ie closed begin introducing definition set valued tensor complementarity problem svtcp set valued tensor complentarity problem svtcp defined follows find vector set valued mapping, set solution set svtcp denoted sol theory tensor complementarity problem tensor give condition feasibility solution set tcp consider set tensor complementarity theory tensor nonempty clearly tensor however kind implication fails hold case set valued complementarity problem ie, set imply consider following example illustrates phenomenon let order dimension let element given element zero let otherwise case hold therefore, however present condition tensor claim inner semicontinuous continuous let max denote th row subtensor hence max given since inner semicontinuous theorem theorem sequence implies max implies, equality follows continuity ensured continuity since arbitrary sequence converging obtain implies lower semicontinuity again, let equivalent again, lim inf sufficiently small hence propose necessary condition feasibility svtcp consider svtcp bounded svtcp feasible let mapping bounded therefore suppose satisfy given assumption hence obtain then, particular, observe following process find sequence since taking large enough satisfy max write implies implies feasible point svtcp set tensor said strongly semi positive nonzero weakly semi positive nonzero svtcp following statement hold set tensor strongly semi positive, positive mapping ie, svtcp zero unique solution svtcp zero unique solution, set tensor weakly semi positive prove part showing non zero solution set tensor strongly semi positive note that, positive mapping solution svtcp assume another nonzero solution ie, want prove set tensor strongly semi positive let set tensor strongly semi positive exists hence contradicts condition hence set tensor strongly semi positive prove part showing set tensor weakly semi positive svtcp zero unique solution assume weakly semi positive then, exists nonzero choose let therefore according construction, implies nonzero vector solution svtcp set tensor strongly semi positive sol sol nonempty since set tensor strongly semipositive, svtcp zero unique solution also sol thus every tcp tcp zero solution therefore corollary item conclude tensor implies sol nonempty svtcp tensor sol sol nonempty consider svtcp suppose tensor sol nonempty compact also suppose sol theorem know since sol sol nonempty, starting next result, set valued tensor complementarity problem transfer system equation unconstrained optimization via merit function characterise solution set set valued tensor complementarity problem establishing necessary sufficient condition level boundedness merit function function said merit function residual function complementarity problem solution complementarity problem svtcp define merit function define limit property set tensor definition extends definition tensor case set valued tensor complementarity problem set tensor corresponding svtcp said limit property show limit property provides necessary condition merit function level bounded consider svtcp suppose bounded set continuous set tensor limit property, merit function, min min level bounded establish result showing level bounded svtcp bounded set continuous set tensor limit property approach first assume level bounded sequence bounded then, minimizer attained whose existence ensured compactness since closed bounded taking subsequence necessary, assume converges converges have, since continuous bounded lim taking limit side equation obtain, since nonzero vector, implies set tensor limit property svtcp suppose compact set continuous merit function min min level bounded, prove showing exists svtcp continuous compact set merit function min min level bounded suppose particular, observe following process find sequence therefore, consider following case case consider case using conclude imposing continuity function compactness set conclude max bounded implies sufficiently large max hence, case consider case consider following two subcases subcase subcase obtain using fact thus combining putting fact together obtain, implies level bounded paper, introduce set valued tensor complementarity problem provide necessary condition feasibility solution set svtcp set strongly semi positive tensor svtcp zero unique solution weakly semi positivity involved set tensor provides necessary condition uniqueness zero solution svtcp case tensor fixed one additional assumption, sol nonempty limit property svtcp generalizes concept tensor case set valued tensor complementarity problem show level boundedness merit function exists case limit property set tensor additional assumption",mathematics
"adapting mlops diverse network intelligence era challenge solution introduction ii preliminary iii mlops reinforcement learning rlops iv mlops federated learning fedops mlops generative ai genops vi conclusion instruction reporting error ii mlops ii evolutionary trend ran ii challenge applying mlops advanced ran iii ops challenge rl iii rlops iii rlops open ran baseband placement case study iv ops challenge fl iv fedops iv fedops retail case study ops challenge genai genops experimental seamless integration artificial intelligence ai machine learning ml technique wireless system crucial step ainization however, integration face challenge term model functionality lifecycle management ml operation mlops offer systematic approach tackle challenge existing approach toward implementing mlops centralized platform often overlook challenge posed diverse learning paradigm network heterogeneity article provides new approach mlops targeting intricacy future wireless network considering unique aspect future radio access network ran formulate three operational pipelines, namely reinforcement learning operation rlops federated learning operation fedops generative ai operation genops pipeline form foundation seamlessly integrating various learning inference capability network outline specific challenge proposed solution operation, facilitating large scale deployment ai native network artificial intelligence ai machine learning ml technique shaping various industrial segment wireless network also proactively embracing ai ml technique perspective hardware, software, protocol, standardization next generation networks, envisaged ai ml based design facilitate network protocols, improve operational efficiency, embed native intelligence sustainability corroborate, itu recently agreed recommendation imt framework wherein ai communication regarded pillar framework defines development, standardization, deployment networks, setting stage transforming conventional technological landscape standardization front, etsi operational coordination group ai ocg ai actively standardizing ai across various sector architectural model etsi zero touch service management zsm leverage ai key enabler automation gpp, nearly working group wgs engaged ai ml related activity objective manage entire lifecycle network ai ml models, training emulation deployment inference gpp wg sa studied distribution, transfer, training ai ml model various application sa documented ai ml management specification described generic operational workflow considerable effort dedicated establishing general ai ml framework air interface recent open radio access network open ran initiative consider ai ml capability crucial innovation ran architecture integrates ai ml network ran intelligent controller rics provide base ai ml model deployment actuation different ai ml model deployed depending reaction time target task technological front, various new research activity relying ai native design future wireless system prominent example semantic goal oriented communication leverage ai ml called beyond shannon capability meanwhile, recent advancement generative ai contextual understanding content generation trigger enthusiasm integration wireless network so, wireless network equipped understanding reasoning capabilities, improving efficiency robustness generalization ability ai ml remains long standing issue ai ml model merely work well specific task constant training inference feature pose one critical question network operational ai ml, ie, ensure effectiveness ai ml model complex diversified wireless environment certainly, adapting ai ml model different task using learning technique domain adaption, transfer learning, incremental learning proven solution however, network deployed ai ml application, trigger adaptation important question wireless network need method measure monitor performance ai ml model update model accordingly also termed ai ml model lifecycle management lcm aiming ensure ai ml take effect wireless infrastructure fully controllable lifetime ml operation mlops solution ai ml lcm based operational principle data engineering, ai ml model, continuous integration continuous delivery deployment ci cd pipeline work well ai ml application streamlined engineering environment relatively simple task like supervised learning task however, circumstance getting complicated applying learning paradigm realistic wireless communication system typical learning paradigm peculiarity challenge implementation, would echoed amplified wireless system feature current network virtualization deployment rely upon cloud native tool framework developing deploying application wireless network short living containerized application automatically deployed managed using orchestration tool kubernetes specific data processing, model evaluation updating requirement different ai ml model usually overlooked deployments, hindering service assurance capability network ai article focus crafting network ai ml model mlops pipeline corresponding different learning paradigm believe could serve organic substrate forming ai native capability key contribution summarized follows systematically analyze system pipeline requirement integrating reinforcement learning rl federated learning fl generative ai genai wireless network, perspective lcm identifying uniqueness network functioning ai ml model raise customized ops technique adapt learning paradigm rlops, fedops, genops feature best practice wireless system rlops, fedops, genops presented according engineering experience linked ops framework specific vertical application rlops discussed intelligent management orchestration open ran fedops designed cater requirement large scale iot device edge intelligence genops refers process integrating generative model network broadly foundational element within mlops framework, merging software development dev operation ops enhance efficiency, quality, speed software development delivery devops methodology widely adopted across software development industry set practice tools, devops streamlines automates collaboration software development operations, improving shortening system development life cycle emphasizes collaboration, communication, process automation facilitate faster reliable software development, testing, deployment, maintenance devops aim dismantle barrier development operations, fostering integrated continuous approach software development deployment data engineering specialized domain within data science analytics focused process data collection processing involves designing, constructing, managing infrastructure system needed gathering, storing, organizing data analysis, reporting, data driven activity data engineer work diverse data source technology ensure data accessible reliable context ai ml, data engineering play crucial role two key aspect high quality training data generation data engineering support collection, filtering, annotation process create high quality training datasets continuous data capturing model inference data engineering enables continuous capture processing data required model inference mlops refers methodology aimed managing lifecycle ml models, design, training, evaluation distribution deployment integrates devops, data engineering, ml principle ensure reliable efficient deployment maintenance ml model controllable production setting essentially, mlops data devops model mlops applies devops practice ml development deployment, focusing optimizing accelerating process summary, mlops offer following benefit practical ml automation automates ml pipeline ci cd processes, reducing manual intervention, minimizing errors, accelerating application delivery quality control ensures consistent reliable deployment maintenance ml model production environment, maintaining service quality standard reducing risk error unified workflow provides cohesive framework managing lifecycle ml models, fostering collaboration efficiency across team currently, leading entity ai ml domain, microsoft, aws, google, widely adopted implemented mlops principle additionally, databricks recently introduced unity catalog support full lifecycle ml model leveraging unity catalog capability share asset across databricks workspace trace lineage across data model article focus mlops implementation ran level ran, critical component wireless networks, includes hardware software connects user equipment ue core network via radio link serf network entrance provides service ue recent advancement ran highlight following important feature virtualization refers decoupling hardware resource software function ran, abstracting ran hardware functionality virtualized environment allows flexible efficient use network resource disaggregation recent trend involving separating network hardware software components, allowing sourced different vendor developed independently prime example open ran, split gnb radio unit ru distributed unit du central unit cu hierarchical computing involves co location ran computational entities, multi access edge fog computing, optimize network performance, reduce latency, minimize transport overhead, improve resource utilization complicated network intelligence compelling ongoing research topic network operation stated ai communication key pillar scenario adoption ai ml fully harness benefit network virtualization, disaggregation, hierarchical computing, thereby enhancing performance, improving energy efficiency, fostering innovation prevalence ai ml integration network, holistic model monitoring, management, updating mechanism foundational support correct seamless functioning ml model dynamic environment lifecycle delivered mlops framework however, mlops performs well centralized cloud environment relatively simple controllable, data originates singular source, model involved straightforward instead, applying mlops wireless system becomes problematic scenario get complicated due following reason data variety data source diversified data could come cloud, edge, ran, application function af ues hierarchical network architecture lead hard define common data processing pipeline meanwhile, ml model prone affected input features, highly related model executive environment wireless setting learning variety network optimization may involve different learning paradigms, requiring specific environmental setting instance, rl need interaction network environment explore optimal policy, fl must consider bias factor among clients, variation communication channels, computational capability, dataset balance deployment variety deployment venue ai ml model diverse, including cloud, core network, rics, edge device venue requires tailored ai ml workflow, encompassing interface api definition model distribution method un closed ops loop ai ml training deployment update loop wireless network lack clear definition fig illustrates example ml framework open ran according open ran specifications, task understanding, data processing, model training, actuation carried within component however, monitoring management scheme standardized typically developed implemented system integrator therefore, general purpose mlops pipeline must adjusted accommodate specific feature different learning paradigm moreover, network natively support customized mlops mechanisms, considering effectiveness, timeliness, sensitive data protection embracing customized mlops advanced ran offer clear benefit streamline development automated self organized networks, unifying network control management single pipeline integration enhances scalability ai ml operations, fostering development ai native network new communication paradigm following sections, discus implementation mlops ran different learning paradigm rl, fl, genai detail key constraint learning approach propose countermeasure enhance mlops rl type ml agent learns make decision interacting environment agent receives feedback form reward based actions, goal learn optimal action maximize cumulative reward time deep rl drl deep neural network learns optimal mapping state action maximize reward context ran operation, drl emerges appealing solution due inherent self learning capability drl agent learn optimal ran operational policy across various factor time scales, facilitating attainment cross layer domain, long term, short term balance optimization typical application drl ran include wireless access control, traffic steering, baseband placement optimization, etc large scale adoption drl ran challenge policy learned drl shaped interactive environment optimization objectives, making construction environment critical factor influencing learning process challenge commonly known sim real problem drl within ran system, sim real pertains system modeling issues, including factor reward delays, partial observations, system variation degradation time ensure successful deployment operation drl model practical ran, important guarantee fidelity training environment maintain time conversely, drl training infamous time consuming accelerating drl training process essential meeting diverse deployment need across various scenario two key consideration raise challenge ops rl concept rlops, introduced publication present structured approach rl model lcm, specifically tailored intelligent open ran system principle rlops outlined work offer comprehensive framework, categorizing essential element across design, development, operations, safety security consideration article aim delve deeper analysis rlops focusing two key factor hindering widespread adoption drl environmental fidelity training acceleration integrating digital twin dts within rlops framework deemed fundamental component addressing challenge dt concept practical application extensively discussed foundational technique developing network scope functionality digital modeling, apis, interface design explored wealth literature essentially, dt provides high fidelity virtual representation physical entity facilitating communication real network setting parameters, configurations, pattern synchronization update thus, rlops could leverage dt environment drl training update furthermore, tailored learning knowledge transfer technique module incorporated rlops pipeline accelerate iterative training fine tuning drl model representative scheme include transfer learning, incremental learning, knowledge distillation, domain adaptation, etc selection specific technique based characteristic different drl agent placing baseband function user plane function upf conjunction multi access edge computing mec accommodate diverse service crucial challenge modern network architecture usecase address joint placement problem within context open ran, aiming devise function placement strategy optimizes resource usage reduces network power cost maintaining service quality objective firstly, function placement problem, including du, cu cp, cu up, upf, modeled maze solving task within markov decision process mdp graph convolutional network gcn encoder introduced, enabling drl agent generalize across different network topology approach unifies network features, reduces retraining needs, enhances adaptability scalability diverse ran architecture drl training, dt built serve customized setting optimal rl policy exploration dt model service types, baseband function chains, mec component along energy cost detail problem set found pre simulation stage, drl agent interacts dt explore optimal actions, include decision routing direction function placement state drl framework includes information network resources, current placements, path lengths, service requests, vary one deployment site another therefore, deployment stage, site specific information must updated dt accordingly update drl agent, shown fig drl agent deployed near rt ric open ran, utilising internal interface messaging additionally, drl policy transfer technique, specifically incremental learning, applied speed fine tuning process drl agent one deployment environment another demonstrated fig policy directly applied new open ran mec setup, performance degrades significantly green line however, optimal policy transfer applied, new drl convergence occurs around step red line significant improvement compared training new agent scratch, converges step blue line fl, model trained across multiple decentralized device server fl commonly visible wireless communication system enables ml model trained directly data edge without transmitting sensitive data central server fl reduce communication overhead, preserve user privacy, allow personalized model update tailored individual device network condition paradigm flexibly applied ran setting multiple computational layers, edge, ue, associated iot device applying fl networks, distributed intelligence realized, correspondingly, wireless network efficiency adaptability enabling device model updating improved operational challenge fl stem inherent bias wireless network system fl operates distributed training centralized aggregation algorithm, effectiveness convergence global aggregation hinge characteristic participating devices, representing system bias bias viewed three perspective data, hardware, communication link bias data bias pertains uneven distribution data across clients, like non independent identical distribution non iid hardware bias manifest variation hardware capability among devices, encompassing difference local memory, processing speed, power constraints, etc communication link bias predominantly arises wireless channel, influenced fluctuation communication link quality disparate bandwidth availability, turn cause asynchronous communication affect model parameter updating, aggregation, broadcasting interplay bias necessitates delicate solution data engineering, hyperparameter configuration, model sharing, synchronization aspect traditionally overlooked standard mlops practices, thus requiring fedops ensure long term reliability fl model term fedops introduced proposes framework analyzing client system heterogeneity using small subset client data subsequently, appropriate client selected based consideration communication cost overall model accuracy work mark promising beginning exploring fedops engineering, important address long term stability robustness fl operation beyond solely selecting client article, underscore importance implementing monitoring mitigate hardware communication bias enhance fedops, particularly wireless system environment monitoring fundamental aspect mlops, scope need expanded effective fedops support perspective network fl model lcm, fl monitoring encompass two key dimension global level monitoring client level monitoring global monitoring fedops closely integrated observable metric wireless network, ue connectivity channel quality metric serve crucial criterion client selection algorithm optimization client monitoring fedops aim ensure proper functioning client involves examining operational state container client regular report corresponding metric relayed global model reporting messaging mechanism leverage internal data interface wireless systems, open ran, reduce latency improve efficiency fedops enables robust scalable deployment fl method agnostic particular domain section, consider real world use case deploying fedops context dynamic heterogeneous retail environment retail domain, two primary service category emerge end user services, encompassing personalized recommendation engines, dynamic pricing strategies, trend identification algorithms, retail owner services, including critical application like point sale po device remote maintenance, theft prevention systems, intelligent advertisement service consider utilization fedops agnostic service category could enable critical use case po devices, handle sensitive financial transactions, limited compute resource vulnerable hardware failures, software glitches, security breaches, necessitating robust monitoring maintenance mechanism fedops enable deployment federated anomaly detection model detect anomalous behavior performance issue po device without compromising customer data privacy dataflow fedops deployment begin po device collecting operational data, transaction logs, system logs, sensor reading etcthese stored premise local, private processing see fig locally stored data securely privately used local edge device processing within retail establishment, ensuring sensitive customer data never leaf premises, preserving privacy local edge device, serf client fl system, data multiple endpoint device aggregated used train local model, eg, anomaly detection model po terminal maintenance periodically, fedops client selection scheduling module intelligently selects locally trained model subset retail establishment client module employ strategy like clustering technique rl approach prioritize client based computational resources, network conditions, data quality global model shared selected client via open ran infrastructure, illustrated fig selected client perform local training, ensuring qos optimization training inference policy local training, updated client model transmitted ric wireless link ric service management orchestration smo layer, fedops orchestrates secure aggregation locally trained model using efficient communication protocol tailored fl, structured updates, quantization, sparsification technique aggregation process yield globally trained model capture collective knowledge multiple retail establishment without exposing individual establishment customer data globally trained model distributed back participating retail establishments, local edge device used inference enhance privacy distribution phase, fedops employ differential privacy mechanisms, noise addition data subsampling throughout entire dataflow, fedops ensures efficient utilization wireless resource adapting communication strategy based network condition employ technique like air aggregation protocol eg, coded computing, analog hierarchical aggregation reduce communication overhead minimize impact straggler disconnected client intelligent client selection algorithm leveraging fedops federated anomaly detection capability utilizing local edge device clients, retail establishment proactively identify address potential issue po device improves reliability, security, overall operational efficiency maintaining strict privacy standard customer data accommodating limited computing resource individual po device genai involves technique generate new data instances, text, images, sounds, videos, leveraging pattern learned existing data typical generative model include autoencoders, generative adversarial network gans diffusion models, modality generation remarkable success large language model llm sparked surge development generative model across various domain today, significant stride made text text, text image image text, even text video generation advancement also drawn attention potential wireless communication integration genai wireless networks, design, configuration, operation, become focal point research one prominent approach involves goal oriented semantic communication, information encoded latent space encoder reconstructed decoder aforementioned generative model serve encoder decoder pair incorporating genai different network layers, network enhance operational efficiency reducing overhead energy consumption seamless integration genai wireless network protocol level still explored here, examine potential challenge genai network operation lcm following perspective vast knowledge base kb kb comprises essential data feature generating coherent relevant content context crucial producing accurate, contextually appropriate response interaction given input compared larger cloud based counterparts, optimally usable genais vertical application task specific trained extensive knowledge base pose significant cost energy challenge genops extracting incorporating human value information notable feature large generative model ability gather human feedback enhance performance align human preference value technique human loop hitl reinforcement learning human feedback rlhf enable continuous improvement toward relevant coherent response however, integrating model network complicates scenarios, user feedback collection must pa network extracting, interpreting, incorporating human value network pose long term operational challenge ci cd model integration integrating genais network present challenge due size cost additionally, combining various purpose specific generative model raise concern performance guarantees, potentially compromising superiority single task specific genai models, energy resource consumption, impacting sustainability effort article, genops refers pipeline aimed seamlessly integrating genai application future networks, ensuring long term reliable operation customization maintenance genai model pioneering effort, summarize key solution aforementioned challenges, differentiating genops ops firstly, genops must facilitate loop updating knowledge base fine tuning generative model iterative process occurs external network initiated either network internal task demand external safety security requirement secondly, genops integrate human feedback collection network facilitate model self adaption facilitated by, eg, web based feedback form restful apis mobile apps lastly, genops capable offering different strategy trade consideration based scale generative model smaller models, containerized onboarding feasible, whereas larger models, alternative solution integrating subscription based model considered generative model also monetized exposing apis marketplace, enable tight integration network different business model based requested frequency service level looking ahead, integrating model intent based networking open service platform could enable network network service paradigm approach would facilitate sophisticated orchestration service across various network operated different entities, employing diverse technology like satellite, terrestrial, high altitude platform seamlessly integrated manner mlops within ran represent exciting dynamic field research, yet standardized practice remain nascent gpp initiated discussion generic mechanism overseeing ml training, particularly context core ran, detailed exploration diverse ai ml learning paradigm vertical application remains gap article introduces mlops principle tailored specifically ran, encompassing diverse learning paradigm rlops, fedops, genops outline associated challenge approach propose potential solution author anticipate outlined ops principle contribute future development standardized network mlops framework framework essential advancing reliability efficacy ai ml application within ran beyond peizheng li research engineer bristol research innovation laboratory, toshiba research europe ltd ioannis mavromatis lead future network technologist digital catapult tim farnham chief research fellow bristol research innovation laboratory, toshiba europe ltd recent research includes applying digital twin data space optimizing wireless, water distribution energy network system collaborative evaluation technique performed within eu horizon uk project adnan aijaz currently programme leader beyond bristol research innovation laboratory, toshiba research europe ltd, uk recent research interest include systems, open ran, time sensitive networking, high altitude platforms, robotics autonomous system aftab khan currently distributed ai programme leader bristol research innovation laboratory, toshiba europe ltd, uk research interest include federated learning, ai driven cyber security, computational behavior analysis, pattern recognition",networking and internet architecture
"dynamic content caching waiting cost via restless multi armed bandit introduction ii system model iii infinite caching capacity iv finite caching capacity numerical result vi proof theorem vii proof theorem viii proof lemma instruction reporting error ii optimal content caching delivery problem iii problem reformulation iv single content problem holding cost iv whittle index based policy comparison effect waiting cost experimental consider system base station associated local cache, turn connected backend server user content get continuously updated backend server, local copy subset content upon receiving request user, either fetch fresh version or, serve local copy wait additional request serving fetching content incurs fixed fetching cost, serving locally incurs aging cost, request waiting bs, waiting cost per unit time aging cost relies freshness content, measured metric age version aov aim minimize average cost subject cache capacity constraint pose problem restless multi armed bandit problem rmab propose whittle index based policy performs close optimal policy real time applications, social medium platforms, commerce sites, news websites, hotspot internet user widely use real time applications, timely delivery content essential quality service content generated application highly dynamic quickly become outdated recent version content directly delivered backend server however, due massive demand applications, enormous number content get exchanged users, making timely communication challenging directly delivering content backend server lead network congestion content stored local cache deployed content distributed network address however, essential periodically replace cached content ensure user receive fresh relevant information therefore, dynamic content caching play vital role real time applications, ensuring timely delivery content high quality service metric age information aoi widely used metric freshness, defined time elapsed since last fresh version fetched backend server however, aoi limitation fully reflect relevance content freshness information also depends frequently update occur backend server words, even aoi indicates data recent, may accurately represent actual significance timeliness information based ongoing update age version aov newly introduced metric capture number update since last fresh version fetched backend server accurately measuring freshness content however, aov hard obtain local cache depends upon occurrence content update backend server consider system base station connected backend sever connected via core network end user population server host set dynamic content local cache store content content dynamic get updated server time, one content cache may stale copy user send request specific content requested content, serve locally cached, potentially stale, copy available, fetch fresh copy server serve, choose wait additional request content fetching fresh copy server serving furthermore, fetching content server, may cache evict existing content let denote set cached content local cache time note potentially change content request epoch content get updated according independent poisson processes, update rate content server always hold recent version content let number time content updated since last fetched time refer age version aov content time note aovs cached content observable aggregate request process end user poisson process rate request could content probability independently request denote relative popularity content instance, content popularity world wide web widely modelled zipf distribution wherein popular content proposed request dynamics, content request arrival constitute poisson process rate let number request content waiting served note stay zero long keep serving cached version content however, grows chooses fetch serve fresh copy content wait additional request specifically, request queue evolves follows arrival request content serf cached version fetch fresh copy serves, becomes wait additional request increase content, say content requested time one following scenario may encountered content cached case, may serve cached version incurring ageing cost ageing cost per unit aov alternatively, may wait additional request fetching fresh copy content serving content cached scenario also, may wait may fetch serve latest version content incur fetching cost waiting request also associated waiting cost per unit time so, also incurs running waiting cost per unit time let request content time let represent various action using number whose annotation figure let serve content although could pending request content argued optimal action content request arrival wait request it, optimal action continues wait new request arrives brevity omit proof consider serve action content clearly, action available content using denote action vi vi content aim develop policy prescribes action request arrival epoch minimize long term average content fetching, ageing, waiting cost let denote request epoch requested content respectively let denote aov content action vi vi content respectively, let request queue length content immediately prior arrival request focus cost incurred recall incurs instantaneous fetching ageing cost requested content also running waiting cost content let cost associated content so, incurs total cost further, let denote total number request time max aim minimize average cost formally expressed follows treating state, action random noise, respectively, pose problem mdp recall observable prior taking action so, pomdp hand pomdp suffers curse dimensionality however, notice action state revolution different content coupled cache capacity constraint so, formulate problem rmab problem show rmab problem indexable propose whittle index based policy also provide explicit expression whittle index observe that, unlike classical rmab setting binary actions, state dependent actions, rendering optimal problem complex describing rmab formulation section iv, discus optimal caching problem case infinite cache capacity assume infinite capacity cache, ie, case, action different content need depend so, decouple optimal caching content delivery problem separate problems, one corresponding content let focus optimal caching content delivery problem associated tagged content, say content here, let denote request epoch content brevity, section omit superscript representing content index variable instance, let number pending request aov content respectively, let denote action taken denotes serve cached copy, denotes wait denotes fetch serve let denote cost incurred vi vi content aim minimize average cost, ie, solve pose problem pomdp decision epoch state action noise following, reformulate problem mdp find optimal policy know update content server fetched content particular, know prior taking action nevertheless, know time since last fetch content denote max so, compute expected ageing cost moreover, independent given hence, reformulate mdp considering state now, state space action space continues following state dynamic single stage cost mdp given state exponential expected value single stage cost define stationary policy mapping state space action space let set stationary policy shown exists stationary optimal policy mdp hand hence mdp problem since embedded discrete time markov chain single recurrent class, independent section moreover, bellman equation continuous time mdp written way discrete time problem let relative cost function optimal cost, respectively bellman equation different state follows section proof lemma induction relative value iteration standard optimal policy threshold based policy threshold queue length time since last fetch following theorem provides policy optimal policy follows solution following equation moreover, optimal cost please see appendix vi section, propose whittle index based policy optimal content caching delivery problem cache constraints, ie, subject first consider problem following relaxed constraint minimize optimal caching problem subject relaxed constraint write lagrangian multiplier follows minimizing subject entail first minimizing maximizing optimal values, say optimal policy relaxed problem need feasible policy original problem need satisfy hard capacity constraint however, policy provides whittle index associated different state content turn used design feasible policy original problem section whittle index based policy asymptotically optimal original problem number content approach infinity cache capacity also grows proportionately conjecture observe minimizing optimization problem corresponding different content decoupled moreover, lagrange multiplier interpreted holding cost per unit time cached content so, section iv a, focus single content problem holding cost note optimal policy always keep content resulting non negative whittle index content state hence, consider design whittle index based policy section iv suppose content, say content requested since running cost keeping content cache, evicting content serving also potential action argued optimal action serve cached version wait additional request fetching optimal evict content optimal action serve cached version wait additional request fetching, keeping evicting cached version incur cost so, specify action wait evict instead wait figure moreover, segment action specifying whether content kept evicted serving accordingly, introduce action whose annotation figure associated action set remain figure focus optimal caching delivery problem associated tagged content, say content however, unlike section iii, content acted upon even request epoch content hence, section ii, consider request epoch decision epoch omit content index variable section iii let request epoch across content section ii, let requested content queue length aov, respectively, content let also define binary variable indicating whether requested content content otherwise let another binary variable content cached ie, define state system recall request queue remains empty wait evict action taken point evicted hence state feasible so, state take value frame optimal content caching delivery problem mdp state action random noise exponential bernoulli random variables, respectively next state next state next state observe figure action applicable state action taken state state action pair expected single stage cost follows express mdp problem set stationary policy underlying embedded discrete time markov chain weakly accessible, hence, independent section bellman equation continuous time mdp similar discrete time problem let relative cost function optimal cost, respectively let define bellman equation different state follows section using rewrite bellman equation follows state monotonicity property relative cost function following lemma property used derivation optimal policy non decreasing non decreasing given non decreasing part standard proof using relative value iteration since integrand definition non decreasing establishes part following theorem give optimal policy problem let define let solution following equation furher, let solution following equation finally, let solution following equation optimal policy described table please see appendix vii following lemma characterizes use characterization designing whittle index based policy section iv exists unique solution decreasing increasing functions, respectively, non decreasing function furthermore, please see appendix viii section, introduce concept indexability demonstrate content indexable subsequently, present whittle index based policy observe set action figure requested content cached, ie, need evict content optimal action case given theorem specifically, serve cached copy wait fetch, serve cache solution following equation suppose requested content cached, ie, chooses fetch must also choose content keep state content whereas plotted optimal action single content problem figure state figure optimal action content wait hence, need choose content queue length furthermore, content mean never serve cached content content requested, wait fetch fresh version implies content evicted replaced hence, need choose content content subsequently, propose policy discard content lowest whittle index thus, base station chooses content retain based whittle index policy towards this, first demonstrate content indexable compute whittle index content establish indexability, need define passive set content discussed earlier computation whittle index needed content define passive set content introduce notion indexibility whittle index content called indexable passive set content satisfies following condition rmab problem consideration called indexable every content indexable whittle index associated state content, minimum cost move active set passive set precisely, min whittle index defined following way well max shall use latter establish indexability following, use denote whittle index content state whittle index content max content indexable theorem since decreasing non decreasing function respectively lemma hence, hence, content indexable following theorem provides whittle index different content whittle index content solution following equation whittle index content is, solution following equation proof follows theorem recall, definition whittle index max max recall state optimal action either wait fetch fresh version content requested future hence, cached copy never served content hence, consider whittle index state following outline whittle index based policy requested content cache recall that, state content wait keep content compute whittle index content theorem compare whittle index minimum index evict corresponding content replace freshly fetched version minimum index, wait fetch discard section evaluate performance whittle index based caching policy derived section iv consider number contents, request arrival rate, popularity update rate backend cache content ageing cost per unit time, fetching cost, waiting cost, compare average cost whittle index based caching policy relaxed rmab problem compute optimal cost relaxed rmab problem numerically theorem vary cache capacity demonstrate figure whittle index based caching policy close optimal cost relaxed rmab problem since optimal cost optimal caching problem hard constraint optimal cost relaxed rmab problem, conclude whittle index based policy performs close optimal policy furthermore, compare greedy policy, take action minimize immediate cost figure show whittle index based caching policy significantly outperforms greedy algorithm vary waiting cost plot average cost cache size value figure demonstrate increase average cost increase beyond average cost change since, increasing result depletion number request waiting bs, certain value number request waiting becomes see figure hence, increasing waiting cost effect average cost furthermore, sufficiently large optimal policy single content problem holding cost theorem becomes theorem suggests whittle index based caching policy yield result whittle index based policy figure show average cost aligns average cost whittle index based caching policy let define following lemma characterizes cost function exists that, note that, hence, always optimal serve cached copy irrespective value queue length once, serve cached copy queue length becomes suppose exists optimal wait hence, show cost function suppose, exists optimal action serve cache copy case optimal action wait hence, let consider another action optimal serve cached content cost function case since, non decreasing function hence, beyond optimal serve cached content beyond next lemma obtain value hold finite value solution following equation lemma last equality obtained replacing following similar approach before, establish recursive relationship following, obtain value define obtain value follows depends upon hence, hence lemma moreover, last equality obtained change variablesafter taking derivative wrt obtain equation obtained replacing solving differential equation obtain integrating constant following, obtain value recall moreover, replace value obtain defined earlier, equality obtained replacing value solving quadratic equation obtain equation provides relation obtain value require another equation obtain following since min equality obtained lemma hence, min implies replacing value obtain, exists unique solution following equation first show exists solution equation rewrite compute ratio let define ration hence, take limit side obtain hence, lim since hence large enough line lie curve line lie curve hence exists solution uniqueness follows fact optimal cost",networking and internet architecture
"dynamic spectrum access ambient backscatter communication assisted system quantum reinforcement learning introduction ii system model iii problem formulation iv quantum reinforcement learning performance evaluation vi conclusion instruction reporting error related work motivation main contribution ii communication channel model ii ambient backscatter communication channel model iii state space iii action space iii immediate reward iii long term average throughput optimization formulation iv preliminary reinforcement learning deep learning iv proposed quantum reinforcement learning iv parameter complexity analysis parameter setting simulation result experimental spectrum access essential problem device device communication however, recent growth number mobile devices, wireless spectrum becoming scarce, resulting low spectral efficiency communication address problem, paper aim integrate ambient backscatter communication technology device allow backscatter ambient rf signal transmit data shared spectrum occupied mobile user obtain optimal spectrum access policy, ie, stay idle access shared spectrum perform active transmission backscattering ambient rf signal transmissions, maximize average throughput users, deep reinforcement learning drl adopted however, drl based solution may require long training time due curse dimensionality issue well complex deep neural network architecture that, develop novel quantum reinforcement learning rl algorithm achieve faster convergence rate fewer training parameter compared drl thanks quantum superposition quantum entanglement principle specifically, instead using conventional deep neural networks, proposed quantum rl algorithm parametrized quantum circuit approximate optimal policy extensive simulation demonstrate proposed solution significantly improve average throughput device shared spectrum busy also achieve much better performance term convergence rate learning complexity compared existing drl based method rapid development wireless technologies, expected future communication systems, eg, advanced g, need support enormous number heterogeneous wireless device many wireless device require short range, high rate, low latency communication accommodate requirement increase spectrum efficiency, device device communication proposed particular, communication enables communication adjacent wireless device without use network infrastructure like base station such, communication enable direct communication device reduce end end latency key advantage communication technology reuse spectrum cellular system direct communication devices, resulting better spectrum energy efficiency features, communication expected essential part advanced g, especially iot vehicular communication however, communication may introduce interference cellular user cu reuses spectrum cu currently occupying particularly challenging future wireless network large number wireless device operate dense area that, demand effective spectrum access strategy device opportunistically reusing cellular spectrum numerous method proposed literature enable dynamic opportunistic spectrum access communication example, author considered spectrum sharing problem communication cellular network considering overlay underlay modes, author aimed obtain optimal spectrum sharing strategy enables device orthogonally share spectrum cu opportunistically use frequency time resource occupied cu then, analytical rate expression derived optimize two spectrum sharing mode based weighted proportional fair utility function similarly, author optimized spectrum sharing based ultra reliable low latency communication rate optimization problem considered network first formulated, successive convex approximation based iterative algorithm adopted solve non convex optimization problem differently, author proposed spectrum sharing approach based contract based cooperative technique obtain opportunistic spectrum access policy user maximizing cellular network profit specifically, cooperative spectrum trading process cu device modeled based pre defined principal agent approach approach, cellular network act principal offer power payment contract pair that, pair, act agent, try choose contract maximize utility function based design, author derive optimal contract cellular system offer obtain optimal contract based spectrum sharing policy although demonstrating good performance spectrum sharing communication, application study may limited existing solution mainly based static optimization technique require information system advance formulate problem obtain optimal solution unfortunately, difficult, impossible, obtain complete prior knowledge system due dynamic uncertainty wireless communication mobility user deal problem, deep reinforcement learning drl emerged promising tool recently observing system state outcome performing actions, drl efficiently learn dynamic uncertainty system converge optimal spectrum access policy without requiring prior knowledge cus, bss, user example, author developed drl based algorithm help user dynamically access shared spectrum maximize system sum throughput without using prior knowledge system proposed drl based solutions, transmitter learn characteristic cu decide access shared spectrum simulation result showed proposed drl based approach achieve better sum throughput compared baseline based cooperation unfortunately, aforementioned study others literature may work well large number cu operating shared spectrum scenarios, shared spectrum always heavily occupied transmission cus, resulting low communication efficiency user frequent collision cu address essential issue, paper, propose use ambient backscatter communication ambc technology help user transmit data even shared spectrum occupied cu key fundamental ambc technology transmit information backscattering ambient rf signal without generating active signal that, shared spectrum occupied, user switch ambient backscatter mode backscatter rf signal generated transmit data receiver backscattered signal user introduce noticeable interference cu since active signal demonstrated worth noting ambc technology integrated communication study however, dynamic spectrum access communication considered work particular, author proposed new self sustainable communication paradigm communication using ambient backscatter communication theoretically analyze average throughput, energy outage probability, coverage probability proposed hybrid communication system author instead focused designing passive relay ambient backscatter communication wireless powered system addition, current drl based spectrum access approach may take long time converge optimal policy, especially complex problem high dimensional state space moreover, drl based approach usually require large deep neural network architecture efficiently learn highly dynamic complex environments, resulting long training time thus may applicable application low latency requirement inspired quantum superposition quantum entanglement principles, develop quantum reinforcement learning rl based solution obtain optimal dynamic spectrum access policy communication instead using conventional deep neural networks, proposed solution employ parametrized quantum circuit approximate optimal dynamic spectrum access policy device extensive simulations, demonstrate proposed quantum rl approach achieve faster convergence rate much fewer trainable parameter compared existing drl method worth noting proposed quantum rl approach efficiently run classical computer using tensorflow quantum cirq library far know, first study take account quantum rl ambc technology dynamic spectrum access communication main contribution summarized following propose integrate ambc technology device data transmission backscattering ambient rf signals, eg, signal generated bs, shared spectrum occupied cu new design, device still maintain communication avoid collision cu even shared spectrum always busy use markov decision process model dynamic uncertainty system caused user mobility wireless environment then, develop drl based approach, namely deep learning, find optimal spectrum access policy, ie, stay idle, access shared spectrum perform active transmissions, backscatter signal transmissions, maximize long term average throughput user improve convergence rate reduce training complexity proposed solution, develop novel quantum rl approach learn environment property efficiently quickly particular, parametrized quantum circuit used approximate optimal policy instead conventional deep neural network quantum circuit, proposed algorithm leverage quantum superposition quantum entanglement principle better handle high dimensional system state space achieve better learning system performance conventional drl algorithm finally, extensive evaluation provided verify effectiveness proposed solution particular, ambc technology, user transmit data even shared spectrum occupied, resulting better communication performance addition, proposed quantum rl approach significantly improve convergence rate fewer training parameter much lower training time compared existing solution based drl rest paper organized follows considered system model, including ambient backscatter channel models, presented section ii section iii introduces proposed mdp framework capture dynamic uncertainty considered system that, section iv provides fundamental deep rl proposed quantum rl algorithm section present performance analysis several scenario finally, section vi concludes work paper, consider enabled cellular network consists multiple cu bs, illustrated fig considered network, wireless device communicate without routing packet cellular network using communication without loss generality, assume node cu share spectrum resource time splitting manner similar time slot allocation among cu orthogonal define access probability cu access shared spectrum time slot mentioned, node also access shared spectrum using time slot however, transmitter may generate interference disrupt transmission cu access shared spectrum time such, node must find appropriate time slot communicate avoid introducing interference cu addition, studied cu suffers le interference node near thus, define protected maximum distance cu allows cu communicate without affected interference node define protected probability cu secure area, ie, distance le protected future wireless networks, large number diverse wireless device share communication spectrum dense area such, challenging device opportunistically access shared spectrum transmit data improve spectrum usage efficiency improve system throughput, propose use ambc technology node particular, ambient backscatter circuit, node communicate simply reflecting absorbing ambient rf signals, ie, cellular signal considered system that, node eg, mobile phone iot device equipped rf switch switch two different load reflect absorb cellular signal reflecting state, node transmit bit contrast, node transmit bit absorbing state way, ambc technology help node transmit information even current time slot occupied cu without introducing transmission disruption cu denote set channel state particular, channel idle, channel used cu, channel used pair, channel used cu pair transmission without loss generality, assume considered system saturated node always information transmit node transmit information beginning assigned time slot must finish transmission within time slot paper, aim obtain optimal dynamic spectrum access policy node maximize average throughput following, present channel model communication ambient backscatter communication overall, ambc technology, transmitter simply absorbs reflects ambient rf signal transmission instead generating active signal like communication practically, link modeled using probabilistic path loss model, including non line sight nlos link line sight los link described los path loss expressed follows tr distance transmitter tx receiver rx center frequency similarly, nlos path loss expressed follows average path loss link db calculated follows los los represent probability los link nlos link, respectively based distance tx rx, los calculated follows let transmit power tx average signal power received rx expressed follows connection achievable transmission rate calculated follows bandwidth channel noise power paper, adopt ambc technology allow node communicate even spectrum occupied cu particular, communicating cu share spectrum, node reflect absorb cellular signal transmit information without generating active rf signals, thus interrupt transmission cu interested reader refer information design, principles, circuit ambc technology following, provide channel model formulate achievable rate ambient backscatter communication specifically, rf signal sent expressed transmit power bs, transmitted signal th symbol interval then, ambient rf signal received tx formulated follows st channel coefficient tx let denote reflection coefficient tx denote tx signal th symbol interval, express backscatter signal tx follows backscattered signal received rx expressed follows tr channel coefficient tx rx signal received rx also expressed follows dr channel coefficient rx then, total received signal rx expressed gaussian noise rx zero mean variance ie, similar assume rx equipped successive interference cancellation sic technique decode received signal particular, sic technique, common physical layer approach, usually used handle two signal received receiver sic, rx decode stronger signals, ie, signal, first, subtract received signals, extract weaker signal, ie, backscattered signal, residue way, signal noise snr ratio rx expressed st st tr tr channel power gain tx tx rx, respectively finally, achievable backscatter rate calculated follows work, aim maximize average throughput node obtaining optimal dynamic spectrum access policy particular, node need decide access shared spectrum communication technology, ie, communication ambc, use transmit data given fact cu randomly arrive coverage area access shared spectrum, challenging optimal dynamic spectrum access policy address practical problem, following, present novel quantum rl approach dynamically intelligently learn system property cu behavior approximate optimal spectrum access policy superior convergence rate compared existing solution use markov decision process mdp formulate optimization problem order address dynamic uncertain nature system consideration particular, tuple denotes state space, represents action space, denotes immediate reward function, theoretically used define mdp practically, channel state accurately observed end time slot agent make action beginning time slot such, system state space includes channel state previous time slot addition, help agent learn cu behavior system property efficiently, also consider chosen action location cu previous time slot discussed section ii, achievable rate communication ambient backscatter communication depend greatly distance node well distance tx reason, two factor also included system state space given above, formally defined follows denotes previous action taken agent, denotes previous channel state, denotes cu previous time slot secure area ie, otherwise ie, dt distance tx bs, tr distance tx rx way, system state time slot formally expressed dt tr mentioned section ii, tx choose perform communication ambient backscatter communication transmit data rx addition, choose stay idle that, action space formally defined follows tx stay idle, tx performs communications, tx chooses leverage ambc technology transmission work, aim maximize average throughput device minimizing interference introduced cu that, immediate reward tx take action state defined follows specifically, tx chooses stay idle ie, immediate reward tx transmits information communication ie, cu actively using shared spectrum, immediate reward defined addition, active cu cu secured area, immediate reward also contrast, cu outside secured area, immediate reward low value ensure agent avoid action introduce interference cu finally, tx chooses use ambient backscatter transmit data ie, immediate reward defined long term average throughput maximization problem device given formulated mdp expressed follows spectrum access policy mapping state action represents immediate reward received taking action following policy state average long term throughput policy worth noting formulated mdp, independent initial state system underlying markov chain irreducible thus, optimal dynamic spectrum access policy exists obtained efficiently solve optimization problem section iii, rl algorithm adopted among rl algorithms, learning deep learning dql common algorithm adopted field communication networking fundamentally, learning dql algorithm designed based bellman equation perform simple value iteration update approximate value state action pair specifically, learning algorithm store value possible state action combination table given state algorithm take action based greedy approach approach, random action taken probability action highest value given current state chosen probability then, immediate reward next state system observed taking action observation, learning algorithm update value state action pair represents immediate reward taking action state discount factor determines future reward importance, represents algorithm learning rate theoretically, small value indicates short term reward important differently, algorithm prefers action maximize long term reward approach since aim maximize long term average throughput devices, set high values, eg, differently, learning rate denotes significance new observation existing observation enable stable learning process, learning rate learning set small values, eg, based learning algorithm gradually update value state action pair system converge optimal spectrum access policy however, learning algorithm several limitation particular, requires state space discrete order build table may result information loss addition, learning algorithm cannot work well high dimensional state space due high complexity nature table such, performance learning limited practical problem communication networking demonstrated literature solve practical issue learning, google deepmind introduced dql, combination learning deep neural networks, key idea using deep neural network, called deep network, approximate value instead using table power handling high dimensional data, deep network help dql learn environment effectively compared learning addition, state space continuous, thus avoiding information loss problem learning due discretization process improve learning efficiency stability algorithm, two mechanisms, namely experience replay quasi static target network, adopted experience replay mechanism, memory pool used store previous experience observation algorithm randomly take number experience train deep network training step quasi static target network mechanism, separate deep network employed, called target network parameter target network slowly frequently updated copying parameter deep network target network used approximate target value result, target value estimated value correlated, thus minimizing overestimation stabilizing algorithm loss function dql algorithm expressed follows denotes parameter deep network time slot represents parameter target network time slot update parameters, stochastic gradient descent algorithm extension adopted minimize loss work, adam optimizer used minimize loss update deep network parameter although drl algorithm dql presented section iv widely adopted solving problem wireless communication good performance, still several limitation may hinder application future wireless communication system particular, since drl deep neural network approximating policy, training time long, especially complex problem high dimensional state space may make drl inapplicable highly dynamic communication system system condition changed quickly real time scenario overcome issue, paper, develop novel quantum rl algorithm efficiently approximate optimal spectrum access policy much faster convergence rate compared drl key idea use quantum circuit approximating optimal policy instead using deep neural networks, illustrated fig way, quantum entanglement quantum superposition property quantum computing utilized speed learning process rl, resulting high convergence rate next, present proposed quantum rl approach detail proposed quantum rl approach, employ parametrized quantum circuit pqc approximate optimal policy particular, proposed pqc take system state input output vector expectation value then, output vector processed obtain policy ie, policy based method, approximated value ie, value based method work, use policy based rl train proposed pqc studied pqc design significant impact learning performance among several factors, data encoding strategy play essential role designing pqc based theoretical analysis data uploading technique outperforms others constructing highly expressive learning model particular, instead encoding data variational layer, data uploading method aim encode data several encoding layer interlayed variational layer reason, use data uploading technique build pqc paper illustrated fig proposed pqc first variational layer handle input state vector performing single qubit rotation trainable angle output variational layer processed entangling layer consists several qubit controlled cz gate that, output entangling layer fed encoding layer trainable input scaling parameter next, output encoding layer processed another variational layer pqc multiple entangling layers, encoding layers, variational layer define quantum layer consist variational layer, entangling layer, encoding layer fig illustrates detailed architecture quantum layer worth noting last layer proposed pqc variational layer variational layer help increase circuit expressibility representing quantum state encoding layer addition, encoding layer learn sine function input, resulting le efficient training process estimated policy obtained observing expectation value last variational layer number expectation value number action proposed mdp, ie, similar also employ trainable weight augmented expectation value action optimizing trainable weight learn environment approximate dynamic spectrum access policy device following, present detail proposed pqc process system state ie, classical data quantum state feed system state pqc, number qubits number feature state space ie, paper qubits, pqc represented dimensional complex hilbert space quantum state pqc defined vector unit norm quantum superposition defined follows complex coefficient illustrated fig pqc, several quantum gate defined unitary operation performing variational layers, consider single qubit pauli gate whose matrix defined follows variational layers, classical data encoded quantum state using single qubit rotation corresponding single qubit gate follows rotation angle th variational layer given above, state ie, classical data encoded quantum state follows number dimension state space, ie, number qubits, rotation angle corresponding single qubit rotation th qubit initialized state encoding layers, consider gate together trainable scale parameter entangling layers, use qubit controlled gate defined mentioned, output last variational layer, defined observable used obtain policy however, studied policy obtained pqc may direct adjustable greediness affect exploration exploitation rl process address problem, softmax activation function used generalize expected value projection given state input proposed pqc, quantum state corresponding unitary expressed number qubits number feature system state space defined section iii, ie, considered dynamic spectrum access problem given quantum state, policy associated parameter defined follows inverse temperature parameter set trainable angles, trainable input scaling parameters, trainable weight defined expectation value observed output proposed pqc expressed follows weighted hermitian operator corresponding action iteration similar simplify tensor product pauli matrix computational basis states, ie, updating parameter proposed pqc, approximate optimal policy mentioned, work, consider simple rl approach based policy based mechanism optimize shown algorithm particular, algorithm aim interact environment, ie, ambc assisted system work, update pqc parameter gradient descent value function loss function derived based policy gradient theorem follows batch experience collected interacting environment size experience batch loss function minimized performing gradient descent thus updating pqc parameter work, perform training every iteration instead, algorithm performs training every iteration reduce computational complexity algorithm also stabilize learning process mentioned, quantum rl learn environment efficiently leveraging superposition quantum computing also significantly reduce number training parameter compared traditional deep neural network architecture section, analyze complexity proposed quantum rl algorithm dql algorithm term number trainable parameter dql algorithm usually standard multilayer perceptron architecture, consists multiple fully connected layers, deep neural network that, assume dql algorithm employ deep neural network consists input layer fully connected hidden layer output layer well known trainable parameter deep neural network weight bias such, number trainable parameter connecting layer calculated number neuron layer based this, total trainable parameter deep neural network formulated follows well known typical deep neural network requires several hidden layer neuron layer good training performance, resulting thousand trainable parameter complicated problems, number parameter much larger layer neuron needed efficiently learn complex environment similar above, formulate computational complexity proposed pqc term trainable parameter following particular, variational layer, use three gates, ie, qubit rotation qubit such, qubits, size variational layer differently, encoding layer, use gate qubit that, size encoding layer summary, number trainable parameter quantum layer calculated follows number quantum layer worth noting variational layer end pqc size final variational layer also recall expectation value action, use trainable weight better distinguish potential action impact learning process such, number trainable weight number action action space, ie, given above, total number trainable parameter proposed pqc formulated follows clear complexity proposed pqc relatively small compared dql algorithm example, considered problem, dimension state space, thus three quantum layers, total trainable weight proposed pqc meanwhile, deep neural network dql algorithm may need thousand parameter good performance example, deep neural network consists hidden layer neuron trainable parameter next section, show significantly smaller number parameters, quantum rl achieve much better performance compared dql algorithm low complexity, proposed quantum rl deployed efficiently run devices, eg, mobile phone vehicle resource constrained device wireless sensor iot devices, proposed approach may applicable instead, deployed cluster head gateway, distribute dynamic spectrum access policy device cluster network section provides extensive performance evaluation quantum rl approach compared baseline various scenario particular, first present parameter setting considered system also proposed quantum rl approach then, analyze simulation result term convergence rate, running time, average throughput different scenario unless otherwise stated, probability cu access shared spectrum time slot access set mentioned section ii, considered system, secure area near interference device affect signal reception cu access shared spectrum time that, set probability cu secure area protected paper, consider case device randomly placed considered area without loss generality, distance tx st randomly generated meter meter distance tx receiver tr randomly generated meter meter transmit power set dbm transmit power device set dbm noise power set dbm bandwidth center frequency set mhz ghz, respectively set prevent action cause interference cu ambient backscatter circuit, set reflection efficiency similar set st st tr tr effective area antenna dql algorithm, use standard parameter used widely literature particular, employ hidden layer size neuron activation function tanh learning rate set optimizer adam greedy method, set beginning training gradually reduced decay factor memory pool store experience target update frequency set batch size set proposed quantum rl approach, use quantum layer employ three adam optimizers optimize learning rate respectively tensorflow quantum library used build proposed quantum circuit paper, compare proposed quantum rl approach three baseline term average throughput calculated number bit tx transmit one second three baseline used paper include following random method, tx randomly choose action transmission used show system performance non learning approach greedy method, tx always chooses access shared spectrum actively transmit data method used show advantage ambc technology, especially shared spectrum mostly occupied cu dql baseline, use proposed deep learning algorithm solve formulated mdp section iii comparing method, better highlight advantage proposed quantum rl approach compared state art solution literature fig compare convergence rate proposed quantum rl algorithm dql algorithm different learning rate scenario, deep network two fully connected hidden layer size observed figure, proposed quantum rl algorithm much faster convergence rate compared dql algorithm specifically, proposed quantum rl approach converge average throughput around mbps training step dql algorithm cannot converge performance iteration demonstrates effectiveness using proposed pqc learn considered environment, thanks quantum superposition principle next, increase size hidden layer deep network compare convergence rate deep learning proposed quantum rl method, shown fig observed, neuron hidden layer, dql algorithm learn faster however, still cannot converge better policy iterations, proposed quantum rl algorithm quickly learn environment obtain much better average throughput iteration worth noting dql algorithm achieves best performance learning rate therefore, following simulations, set learning rate dql algorithm table i, compare number trainable parameters, running time training step, achieved performance training step proposed solution dql algorithm different setting observed, number training parameter proposed quantum rl significantly smaller dql algorithm, ie, parameter quantum layer, quantum layers, quantum layers, respectively, compared parameter hidden layer size respectively run proposed quantum rl dql algorithm standard laptop core cpu gb ram observed table i, proposed quantum rl algorithm also run ten time faster dql algorithm, thanks use pqc clearly, quantum layers, proposed quantum rl algorithm achieve best performance such, following evaluation, use quantum layer proposed pqc quantum rl dql algorithm evaluated training step fig vary probability cu access shared spectrum time slot compare average throughput method seen, proposed quantum rl algorithm achieves best performance compared baseline proposed pqc help algorithm learn considered environment efficiently, resulting better performance worth noting access high, performance gap becomes bigger stem fact shared spectrum frequently occupied cus, transmitter cannot actively transmit data receiver contrast, ambc technology, proposed solution still allows transmitter backscatter information receivers, resulting better throughput importantly, access higher average throughput obtained quantum rl dql method increase because, cu likely access shared spectrum communicate bs, device chance backscatter rf signal generated demonstrates effectiveness ambc technology since dql algorithm slow convergence rate, performance fluctuates inferior proposed quantum rl approach finally, vary probability cu secure area compare average throughput obtained methods, illustrated fig observed protected increases, average throughput method increase reason cu likely secure area, le vulnerable interference caused device use shared spectrum, resulting better throughput however, cases, proposed quantum rl approach achieves best average throughout, thanks use quantum proposition principle paper, proposed dynamic spectrum access approach communication leveraging ambc technology quantum rl particular, using ambc technology, device transmit information even cu accessing shared spectrum simply backscattering rf signal sent base station approach particularly effective shared spectrum usually busy common situation future dense heterogeneous wireless network addition, challenging obtain optimal spectrum access policy device given dynamic uncertainty system due nature wireless communication well mobility behavior mobile user address problem, developed quantum rl efficiently quickly learn environment approximate optimal policy leveraging quantum superposition principle extensive simulation demonstrated proposed solution improve average throughput communication also quickly learn environment significantly fewer training parameter compared state art method",networking and internet architecture
"key expansion based internet public key infrastructure anonymous voting introduction convention definition key expansion anonymous voting case study security consideration instruction reporting error internet public key infrastructure elliptic curve cryptography generation original key pair end entity generation temporary public key registration authority generation formal public key certificate authority generation temporary private key formal private key end entity case study social network platform case study citizen digital certificate document focus developing key expansion method based internet public key infrastructure elliptic curve cryptography, applied context anonymous voting method enables end entity maintain anonymity end entities, registration authority, certificate authority, still allowing validity end entity certificate verified, thereby facilitating anonymous voting service keywords internet public key infrastructure key expansion anonymous voting given privacy protection critical issue internet services, safeguarding user privacy process accessing service enhance user satisfaction engagement light this, document develops key expansion method built upon existing internet public key infrastructure pki security assured elliptic curve cryptography ecc ability ensure anonymity via key expansion therefore, section introduce internet public key infrastructure elliptic curve cryptography, followed sequent section covering convention definitions, key expansion, anonymous voting, case study document reference internet public key infrastructure defined encompassing end entity ee registration authority ra certificate authority ca end entity generates key pair, consisting private key public key, sends certificate request registration authority certificate request includes end entity public key registration authority review end entity eligibility access application service and, upon verification, forward certificate request certificate authority certificate authority verifies correctness request issue end entity certificate, includes public key end entity document reference elliptic curve defined include prime number coefficient coefficient base point prime order cofactor specifically, let prime finite field element set solution satisfies equation mod asymmetric cryptography applications, random positive integer generated, within range serving private key public key derived private key base point key word must must required shall shall recommended recommended may optional document interpreted described bcp when, when, appear capitals, shown document reference propose key expansion method anonymous voting, consisting four step generation original key pair end entity, generation temporary public key registration authority, generation formal public key certificate authority, generation temporary private key formal private key end entity temporary public key generated based expanded original public key, formal public key generated based expanded temporary public key similarly, temporary private key generated expanded original private key, formal private key generated expanded temporary private key specific detail presented following subsection first, end entity generates original key pair based elliptic curve cryptography, consisting original private key original public key shown follows end entity hold valid pre existing certificate, includes original public key posse corresponding original private key process obtaining valid pre existing certificate beyond scope document subsequently, end entity generates random integer within range encrypts using public key registration authority, resulting ciphertext end entity also generates advanced encryption standard aes secret key s, encrypted using public key certificate authority, resulting ciphertext encryption algorithm based ecies end entity sends certificate request registration authority, signing request original private key certificate request includes valid pre existing certificate, ciphertext ciphertext signature, relevant request detail upon receiving certificate request end entity, registration authority verifies signature using original public key confirms eligibility end entity validated, key expansion process could performed registration authority first decrypts ciphertext using private key obtain plaintext performs key expansion original public key derive temporary public key calculated follows registration authority forward certificate request certificate authority, replacing original public key temporary public key removing personal sensitive information, signing request private key certificate request includes temporary public key ciphertext signature, relevant request detail registration authority also store hash value certificate request certificate authority receives certificate request registration authority, verifies signature using registration authority public key confirms relevant qualification validated, key expansion process begin certificate authority generates random integer within range performs key expansion temporary public key derive formal public key calculated follows certificate authority creates end entity anonymous certificate, storing formal public key certificate public key field next, certificate authority decrypts ciphertext using private key obtain plaintext aes secret key used encrypt anonymous certificate integer producing ciphertext certificate authority sends certificate response registration authority, signing response private key certificate response includes ciphertext signature, hash value request, relevant response detail registration authority receives certificate response, identify end entity request corresponds based hash value request forward certificate response appropriate end entity upon receiving certificate response, end entity first verifies signature using certificate authority public key signature verified, process private key expansion begin end entity decrypts ciphertext using aes secret key retrieving anonymous certificate integer expands original private key derive temporary private key expands temporary private key obtain formal private key using following equation voting process, end entity use formal private key sign ballot end entity retrieve formal public key anonymous certificate use verify ballot signature mod mod demonstrate proposed key expansion method anonymous voting, two case study provided first case study, using social network platform example, user connect platform using end entity, equipped certificate social network platform serf registration authority, impartial third party certificate authority issue anonymous certificate second case study, using citizen digital certificate example, user connect voting system using end entity citizen digital certificate based certificate local district office server act registration authority, election commission server serf certificate authority, issuing anonymous certificate case study, user device social network platform act end entity, social network platform server function registration authority additionally, impartial third party serf certificate authority, responsible issuing anonymous certificate end entity initially, user device already posse original private key corresponding certificate includes original public key user wish participate anonymous voting social network platform, user device sends request containing certificate social network platform server verifying user eligibility, server generates random integer expands original public key certificate derive temporary public key server forward request, along temporary public key impartial third party impartial third party generates random integer expands temporary public key derive formal public key impartial third party issue anonymous certificate containing formal public key encrypts anonymous certificate random integer sends back user device important note encryption done using shared aes key user device impartial third party, ensuring two entity access anonymous certificate random integer finally, user device expands temporary private key formal private key allowing user sign ballot using formal private key anonymous certificate also included ballot curve id brainpoolp selected case study, test vector shown follows case study, citizen posse citizen digital certificate, installed computer, computer acting end entity citizen digital certificate contains original private key corresponding certificate includes original public key local district office server serf registration authority, election commission server act certificate authority, responsible issuing anonymous certificate end entity citizen wish cast anonymous vote local representative election, computer sends request, including certificate, local district office server verifying citizen eligibility, local district office server generates random integer expands original public key certificate derive temporary public key request, along temporary public key forwarded election commission server election commission server generates random integer expands temporary public key produce formal public key election commission server issue anonymous certificate containing formal public key encrypts anonymous certificate random integer returning citizen computer important note process, anonymous certificate random integer encrypted using shared aes key citizen computer election commission server, ensuring two entity access information finally, citizen computer expands temporary private key formal private key citizen digital certificate formal private key used sign ballot, also include anonymous certificate curve id secp selected case study, test vector shown follows security consideration apply accordingly key expansion method proposed document based elliptic curve cryptography, meaning security primarily relies difficulty solving discrete logarithm problem furthermore, certificate verification method employed based internet public key infrastructure, meaning security limitation associated internet public key infrastructure also apply document based aforementioned security measures, registration authority decrypt ciphertext using private key obtain likewise, certificate authority decrypt ciphertext using private key retrieve certificate authority encrypt generate ciphertext allowing end entity obtain plaintext since registration authority know value cannot determine relationship temporary public key formal public key similarly, certificate authority know value cannot establish link original public key temporary public key pleased share document made available draft ietf website datatrackerietforg doc draft chen anonymous voting would like express sincere gratitude ietf consideration draft continuing improve html version papers, feedback help enhance accessibility mobile support report error html help improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",networking and internet architecture
"optimal ground station selection low earth orbiting satellite introduction problem formulation experiment conclusion commercial gsaas station list surrogate optimization assumption analysis mission cost minimization problem data volume maximization problem maximum communication gap minimization problem instruction reporting error ip formulation objective function constraint function mission cost minimization problem mission data maximization problem paper present solution problem optimal ground station selection low earth orbiting leo space mission enables mission operator precisely design ground segment performance cost space mission operator increasingly turning ground station service gsaas provider supply terrestrial communication segment reduce cost increase network size however, approach lead new challenge selecting optimal service provider station location given mission consider problem ground station selection optimization problem present general solution framework allows mission designer set overall optimization objective constrain key mission performance variable total data downlink, total mission cost, recurring operational cost, maximum communication time gap solve problem using integer programming ip address computational scaling challenges, introduce surrogate optimization approach optimal station selection determined based solving problem reduced time domain two different ip formulation evaluated using randomized selection leo satellite varying constellation size consider network commercial gsaas provider atlas space operations, amazon web service aws ground station, azure orbital ground station, kongsberg satellite service ksat leaf space, viasat real time earth compare result standard operational practice integrating one two primary ground station provider recent years, easier access space led significant rise new constellation mission launched commercial, government, academic organization change driven new launch providers, cheaper ride sharing launch opportunities, successful demonstration commercial shelf based small satellite historically, mission operator provisioned dedicated ground segment support satellite constellation separately however, lead significant front capital expenditures, poor asset utilization rates, limited communication opportunities, low data downlink volume address challenges, industry moved increasingly gsaas model ground station provider build global network station location mission operator subsequently contract provider integrate network model reduces mission operator capital expenditure cost spreading cost multiple customer simultaneously increasing usage antenna mission operator also benefit increased scalability able access existing global antenna networks, increasing number potential communication opportunity turn improves data downlink volumes, reduces communication gaps, enables greater operational flexibility, reduces mission lead time however, new model also come challenge integration operational cost associated using provider additionally, overall mission performance parameter data downlink volume contact frequency depend combined selection station location well satellite orbit selecting provider station support mission involves weighing consideration desired coverage, operational costs, latency data throughput, uplink downlink capabilities, reliability, scheduling availability selection complicated number different potential providers, large selection potential locations, varying cost model provider largest ground station providers, ground station location currently operation provider station considered listed appendix global distribution coverage station shown fig paper present solution ground station selection problem based integer programming ip formulation early work proposed idea federated ground station networks, loose, virtual association global station increase mission data downlink access simultaneously lowering cost reducing integration barrier primary focus work software engineering challenge architectural approach networking, scheduling, data dissemination multi mission, multi operator ground station network term station selection, past author focused improving ground station placement reducing downlink latency promoting site diversity evade problematic weather condition research area focused leveraging historical cloud data optimize optical ground station network site selection, significantly impacted adverse weather, ensure high availability minimize number required station subsequent work account variable cloud coverage using advanced models, historical data, machine learning technique efrem et al consider ground station installation costs, optimize outage probability independent weather condition work focus ground station activity planning scheduling various optimization techniques, maximize contact time prioritize mission requirement though work consider problem selecting station instead optimize mission plan pre selected set station similar problem ground station placement include sensor placement facility warehouse location placement antenna selection computing resource allocation ambulance routing surveillance drone deployment problem often consider multiple objective including coverage, network connectivity, detecting desired event targets, monitoring environment factors, redundancy fault tolerance, placement future, dynamically changing condition often optimized genetic algorithm mission operator face challenging decision problem determining ground station provider ground station select support mission optimize overall system performance paper present solution ground station selection problem integer programming solve surrogate optimization selecting individual contact opportunity maximize selected objective within bound system constraint constraint provider location extracted based selected contact opportunity approach applied optimize station selection across six current gsaas provider atlas space operations, aws ground station, azure orbital, ksat, leaf space, viasat consider three different optimization objective maximizing total data downlink, minimizing total cost, minimizing maximum time gap contact viability approach demonstrated comparing optimized station selection traditional fixed provider solution simulated scenario provider associated cost randomized trial consider problem selecting ground station network optimizes single performance objective adhering relevant selection constraint mission may include one satellite defined set set potential ground station provider station location known problem simply determining location selected mission start time end time define optimization window total duration oracle could compute possible contact opportunity spacecraft entire mission duration using perfect knowledge object predicted trajectory, ground station selection problem would equivalent satellite task planning problem selecting ground contact opportunity optimize desired objective however, due non conservative orbital perturbations, possible accurately predict spacecraft orbit leo multi year mission therefore, instead consider surrogate problem optimizing provider location selection short segment mission duration defined simulation start time end time total duration optimal station selection duration considered optimal selection entire mission assumption appropriate long simulation window long enough distribution contact simulation period representative distribution contact entire mission appendix discus depth, find propagation window day sufficient, though least day recommended alternatively mission repeat ground track orbit simulation window match repetition period, optimization provider location surrogate problem exactly optimizing entire mission duration problem provider location selection becomes problem optimizing selected contact opportunity set satellite optimal provider location simply provider location corresponding selected contact planning problem extensive work domain satellite task planning many different algorithmic approach presented literature since first presented hall et al solution approach include dynamic programming ant colony optimization mixed integer linear programming monte carlo tree search maximum independent set local search heuristic paper, adopt integer programming approach inspired past mixed integer linear programming work due unique benefit approach optimization problem expressed ip, solved using software library gurobi coin library fast, efficient, undergone extensive validation use across numerous discipline importantly, part solution problem, solver return optimality certificate state whether returned solution globally optimal, suboptimal, problem infeasible possible valid solution certificate useful system engineering understanding overall performance mission ground segment next step express ground station optimization problem ip integer program variation linear program objective constraint linear function decision variable integer express ground station optimization problem ip, consider set ground station provider provider, tuple design variable provider selected otherwise, data object provides constant information associated specific provider provider set ground station location denoted set station denoted station associated design variable location fixed data rate ground network optimized respect individual satellite satellite fixed data rate compute set contact simulation window defined contact binary decision variable indicates whether contact selected number constant variable associated individual contact contact start time contact end time total duration contact contact data rate location associated particular contact denoted satellite associated contact denoted formulate different constraint considering different subset contact associated particular provider station satellite finally, introduced auxiliary decision variable indicate whether satellite location also introduce number constant problem one time expense associated engineering work integrate provider cost setup location includes one time cost procuring radios, servers, equipment support operation location monthly recurring cost associated using location cost includes, limited to, cost associated internet, power, security charged location used incurred even one contact taken location one time cost associated licensing satellite communicate specific station fixed cost taking contact location cost per minute associated using antenna provider implement either fixed cost per pa cost per minute pricing, three potential objective function mission designer might want consider optimization problem depending primary system engineering goal mission minimum cost objective represents goal minimizing total cost mission concern may appropriate budget constrained mission total cost downlinked entire mission constant weighting factor front term monthly contact cost ensures objective function represents total cost entire mission duration maximum data downlink objective represents desire maximize total amount data transmitted mission duration objective appropriate mission expected data constrained designing station network able maximize total data return mission primary concern total data downlinked entire mission objective weighted optimal value objective total data volume able downlinked mission last objective minimum max gap objective, seek minimize maximum time gap contact satellite objective reflects desire design operationally responsive ground network ensures vehicle regular contact ground earth observation mission objective would bound maximum latency uplinking new tasking request downlinking data data collection implement constraint introduce auxiliary binary decision variable contact next contact contact taken given satellite, optimization problem auxiliary variable introduced represent maximum contact gap across pair sequentially scheduled contact constraint equation enforces one contact next contact contact expression force auxiliary variable bound gap every sequentially scheduled pair contact finally, expression enforce associated contact also number required constraint must introduced ensure collect selected, decision variable corresponding provider location also set first, ensure contact selected, associated location also scheduled enforce similar constraint single location given provider selected provider selected well finally, contact satellite station scheduled, associated vehicle indicator variable must set ensure per station, per satellite license cost counted constraint expressed also possible introduce number different constraint function impose system engineering requirement resulting solution constraint need added formulation problem, may included model design requirement minimum constellation data downlink constraint enforces total data volume downlinked across constellation minimum threshold appropriate constellation inter satellite communication long minimum data downlink volume achieved data downlinked across constellation constraint constraint enforces total data downlink contact across satellite within duration exceeds minimum threshold constraint applied contact discrete time window separated useful ensuring minimum amount data downlinked specific cadence every orbit every day minimum satellite data downlink constraint enforces total data downlinked satellite minimum value given period similar constellation downlink constraint, however requirement applied satellite separately constraint maximum operational cost constraint ensures recurring operational cost monthly station charge combined cost associated taking contact exceed set monthly threshold used mission budgeting ensure expected cost stay within set limit constraint constraint similar equation though considers operational cost normalized cost term dollar per month station contact exclusion constraint ensures location communicate one satellite time enforces physical constraint planning arise one antenna given site could modified limit number antenna set number, though consider single antenna per location work constraint added problem constraint satellite contact exclusion constraint ensures satellite communicate single location time constraint added problem unless satellite support simultaneous contact multiple location simultaneously constraint expressed maximum contact gap constraint ensures maximum time gap two contact le specific duration similar minimum maximum contact gap objective instead trying minimize gap, ensures requirement gap met constraint expressed maximum provider constraint ensures number ground station provider selected minimum contact duration constraint ensures contact duration greater considered planning constraint eliminates short duration contact might operationally useful minimum contact per period constraint ensures satellite take least contact given period duration constraint enforced discrete period incremental offset simulation window required provider constraint ensures specific provider selected required location constraint ensures location selected station number constraint ensures least station selected selected evaluate performance ip optimization solution, simulate optimization problem randomizing cost data downlink parameter across provider station appendix range potential value used generate random scenario listed table spacecraft randomly sampled set object altitude km km celestrak active satellite database spacecraft dynamic propagated using sgp propagator simulation window set day long optimization window set day case simulation window selected propagating spacecraft dynamic various simulation window analyzing point number contact per day mean gap contact duration level result shown appendix minimum elevation mask applied location calculating contact opportunity simulation run workstation core ghz intel amd epyc processor consider two primary problem variation total mission cost minimization problem data downlink maximization problem problem variation constructed represent practical system design trade study might undertaken part designing space mission ground segment problem variation constructed composing objective function subset possible constraint function section evaluate ip formulation performed trial constellation satellite type optimization problem trial, generate new problem scenario randomly setting simulation parameter uniformly sampling value table provider solve ip formulation gurobi optimizer provide solution baseline, calculate optimal solution restricted problem location selected one two provider mimic behavior mission operator integrating one two gsaas provider support mission compare performance ip optimized solution fixed solution mission cost minimization problem variation seek minimize total cost ground station network mission duration, also enforcing minimum per satellite data downlink requirement met problem formulation includes station contact exclusion satellite contact exclusion constraint minimum contact duration constraint added ensure short duration contact excluded minimum per satellite data downlink constraint required ensure non degenerate solution, utilizing locations, provider otherwise result optimal zero cost solution full set equation defining problem formulation found appendix value constraint design parameter used simulation listed table figure show optimal solution cost minimization problem compare average one provider two provider solution expected, ip optimization problem free optimize potential ground station provider performs best possible network one two ground station provider considered one surprising result that, despite minimizing total cost, ip optimzied solution also outperforms one two provider solution term total data downlinked well, would normally expected since objective include explicit regularization term would encourage data downlink maximization see ip formulation relatively fast average solution time second constellation satellite one interesting trend observed total normalized cost appears plateau two provider solution constellation size reach satellite explained saturation ground station network inability support contact new satellite is, constellation size become large enough antenna nearly constant use, saturating network, adding satellite lead increase number contact taken therefore added cost mission data maximization problem seek maximize total amount data downlinked mission, also ensuring solution adheres maximum operational cost constraint problem formulation includes station contact exclusion satellite contact exclusion constraint minimum contact duration constraint also included maximum operational cost constraint required ensure optimizer simply select provider location provide potential downlink opportunity resulting degenerate solution design constant problem maximum allowed monthly operational cost minimum acceptable contact duration full set equation defining problem formulation found appendix design parameter used simulation listed table figure show optimizing ground station network maximizing data downlink significantly increase total amount data compared one two provider ground station network without significantly increasing cost satellite mission data optimized ground station network able downlink data entire life mission increase cost compared one provider solution, able downlink data compared two provider solution satellite constellation optimized ground station network still downlink nearly data one two provider network increased cost explanation significant performance improvement ip formulation able use lowest cost station region overlapping station coverage eg europe well add single station non saturated region eg pacific ocean increase total capacity runtime solution increase nearly linearly constellation size optimal network satellite constellation found within second average paper introduced solved problem ground station provider location selection space mission designer problem posed integer programming problem three different objective function fourteen different potential constraint function presented objective function constraint function composed conduct different type design study satellite ground station network two primary class optimization problem analyzed mission cost minimization data volume maximization mission cost minimization, ip solution shown reduce total mission cost simultaneously improving total data downlink data volume maximization problems, ip optimized ground station network seen increase total data downlink compared optimal single provider network compared optimal two provider network future work, would desirable consider multi objective optimization ground network instead optimizing single design parameter, network optimized simultaneously multiple consideration additionally, would desirable investigate unconstrained network design problem, instead selecting set fixed locations, network optimized viable terrestrial location finally, map gap objective constraint introduce large number auxiliary variable equation significant negative performance impact, finding alternative formulation solution approach desireable software utilized formulate contact optimization problem prepare publication available githubcom sisl ground station optimizer list current major commercial gsaas location provided table please note due security concern exact station coordinate coordinate provided two decimal place accuracy request participating provider non participating providers, station location obtained correlating publicly available data provider stated ground network accuracy sufficient analysis purpose site list location inferred publicly available data site list provided gsaas provider paper employ surrogate optimization approach ground station network optimized short simulation window le entire mission duration assumed good proxy optimizing entire mission provides benefit reducing problem size, thereby improving runtime performance also serf address challenge accurately predicting contact window potentially multi year space mission eliminating need simulate entire mission duration surrogate optimization appropriate long distribution contact contact property surrogate problem similar longer propagation test whether appropriate assumption randomly sampled different active satellite altitude km km propagated orbit varying time durations, computed contact opportunity duration, computed statistic distribution contact contact property figure show result experiment see mean gap duration start level day propagation near steady state value day propagation appears significant variation mean contact duration average number contact per day, absolute number total range variation relatively small second contact per day respectively cause variation need investigated, though may artifact propagation method sample size may large enough result recommend simulation optimization window least days, however day preferred computationally possible mission cost minimization problem detailed section aim reduce overall expense ground station network throughout mission duration ensuring satellite achieves specified minimum data downlink requirement formulation incorporates constraint station contact exclusion satellite contact exclusion maintain schedule physically realistic additionally, constraint minimum contact duration included guarantee contact meet required minimum length enforcement minimum data downlink per satellite necessary prevent degenerate solutions, ground station provider selected, resulting optimal non functional zero cost outcome design constant problem required per satellite, minimum data downlink volume, duration minimum data downlink amount must achieve, discrete increment adherence minimum data downlink constraint checked full optimization problem problem presented section designed maximize total volume data downlinked throughout mission period imposing constraint maximum allowable operational cost formulation includes station contact exclusion satellite contact exclusion constraint ensure scheduling remains physically feasible additionally, constraint minimum contact duration incorporated ensure contact meet necessary minimum time requirement maximum operational cost constraint needed prevent optimizer selecting available provider locations, would maximize downlink opportunity result impractical degenerate solution design parameter problem denotes highest permissible monthly operational cost, representing minimum acceptable duration contact full problem problem minimizing maximum communication gap final problem variation problem variation represents design optimization study performance oriented mission design seek minimize communication gap subject station exclusion, satellite exclusion, minimum contact duration constraint minimum satellite data downlink constraint also must included otherwise problem admits degenerate solution contact scheduled additionally, maximum monthly cost constraint need introduced prevent degenerate solution scheduling contact design constant problem maximum monthly cost, per satellite, minimum data downlink amount, duration minimum data downlink amount must achieve, discrete increment adherence minimum data downlink constraint checked full problem duncan eddyfigures duncan eddy headshotpdf postdoctoral research fellow stanford intelligent system laboratory sisl executive director center ai safety stanford university research focus decision making safety critical, climate, space system received mechanical engineer rice university phd aerospace engineering stanford university prior returning stanford director space operation capella space corporation built fully automated constellation tasking delivery system later founded led constellation management space safety organization amazon project kuiper michelle hofigures mtho headshot croppedpdf phd candidate stanford intelligent system laboratory sisl department aeronautics astronautics stanford university research focus decision making uncertainty complex environments, spacecraft autonomy, optimal learning based control received mechanical aerospace engineering minor robotics intelligent system princeton university mykel kochenderferfigures kochenderfer webpdf associate professor aeronautics astronautics associate professor, courtesy, computer science stanford university director stanford intelligent system laboratory sisl conducting research advanced algorithm analytical method design robust decision making system prior joining faculty mit lincoln laboratory worked airspace modeling aircraft collision avoidance received phd university edinburgh studied institute perception, action behaviour school informatics received degree computer science stanford university continuing improve html version papers, feedback help enhance accessibility mobile support report error html help improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",networking and internet architecture
"improved contact graph routing delay tolerant network capacity buffer constraint introduction ii background motivation iii contact capacity node buffer challenge dtns iv proposed global capacity buffer management solution benchmark source routing cgr vi simulation environment setup vii simulation result viii conclusion instruction reporting error ii key notion ii contact graph routing ii source routing cgr iii contact capacity management iii buffer management iv model parameter modification iv capacity buffer management iv booking resource forwarding safety margin iv information sharing network vi environment vi communication parameter vi simulation parameter assumption vi simulation tool vii impact contact capacity management vii impact buffer management experimental html improve accessibility invite report rendering error learn project help improve conversion satellite communication present challenging characteristic continuous end end connectivity may available due large distance satellite moreover, resource link capacity buffer memory may limited routing satellite network therefore complex crucial avoid packet loss long delay delay tolerant network dtn paradigm emerged efficient solution managing challenging network contact graph routing cgr deterministic routing algorithm, one popular dtn algorithm cgr compatible store, carry, forward principle, whereby node receives message store buffer transmission opportunity becomes available however, cgr relies simplified model incorporate potential constraint route search instance, linear volume assumption often used consider capacity constraint moreover, capacity management buffer management mostly performed forwarding phase, issue occurred paper, propose take measure route search order find route respect contact capacity limit node buffer limit introduce contact splitting edge pruning operation effectively account routing constraint ensures cgr output optimal solution among subset valid solution proposed approach also used book resource used case issue forwarding step satellite communication belong category intermittently connected network icns characterized intermittent connectivity node network, preventing continuous end end connection resulting high delay intermittent nature induces multiple discontinuous episode communication opportunity pair node called contacts, see following section transmission thus delayed immediate communication opportunity node must therefore operate store, carry, forward principle result, since traditional internet protocol suited challenges, need new protocol arose delay tolerant network dtn architecture new protocol layer proposed internet engineering task force ietf handle issue bundle protocol bp considered consultative committee space data system ccsds instance protocol mentioned above, routing challenging discontinuous time dependent connection main routing issue icns inability establish complete route due lack connectivity moreover, addition delivery time objective, optimizing delivery rate resource consumption also considered instance, use transmission resource must carefully optimized limited availability additionally, data unit often held node buffer long periods, optimizing storage resource avoid congestion loss crucial efficient routing algorithm therefore needed addition suitable network capability via mentioned protocol routing algorithm dtns classified three category depending availability network information opportunistic probabilistic deterministic, depending whether contact unpredictable, determined certain probability, completely predetermined, respectively paper, focus space communications, natural artificial satellite deterministic motion thus, contact predetermined, making deterministic routing algorithm suitable widely used deterministic routing algorithm dtns contact graph routing cgr since invention, cgr gained attention research community several improvement proposed instance, using dijkstra algorithm route search choosing best case delivery time bdt objective presented then, earliest transmission opportunity eto introduced compute time bundle transmitted contact eto take account time bundle wait transmitted scheduled bundle transmission contact later, complementary overbooking management added eto improve routing decision enhancement among others result currently used version cgr nevertheless, version provides local reactive contact capacity buffer occupancy managements, lead sub optimal solution therefore, important explore alternative approach one modern application, capacity buffer management may critical, cislunar communication advent artemis program many project lunar environment arose, triggering high need communication resource another application low earth orbit satellite constellation constellation expected utilized extensively future however, future constellation large enough maintain end end connectivity time even large constellation may deploy satellite initial stage, requiring establishment network limited number satellite initial phase result, many constellation expected temporarily buffer data main contribution paper, provide routing solution based cgr global proactive congestion control propose perform contact capacity management buffer limit management route search obtained route optimal respect two constraint objective achieved follows propose managing contact capacity route search modifying network information, provided contact lists, using contact splitting contact splitting remove part contact used routed bundle propose track node buffer occupancy function time using forecast buffer table buffer occupancy managed temporarily modifying network information, also via contact splitting, routing specific bundle avoid buffer overflow temporarily forbidding edge contact route search specific bundle avoid buffer overflow modified network information enables remove route respect constraint route subsequently, route search algorithm, cgr, find optimal solution among subset valid solution proposed approach also considered book resource utilized case failure event forwarding phase resources, referred safety margin paper, used intermediate node limited information network state structure paper paper structured follows section ii, first introduce key term used paper provide review cgr section iii, focus existing capacity buffer management challenge dtns introduce motivation proposed solution introduced section iv benchmark source routing cgr, considered benchmark, detailed section simulation assumption result comparing method benchmark given section vi vii, respectively first define key term used paper node satellite communication scenario, node satellite ground station illustrated figure contact contact defined communication opportunity two node thus characterized sender receiver nodes, start time end time data rate capacity bit per second bps volume contact rate multiplied duration contact plan cp cp list contact time period reflects evolution network topology time example provided figure edge edge exists two contact receiver one contact match sender second contact, end time latter later start time former bundle bundle data unit encoded bp bundle characterized size bit bundle generated source node provided destination node route route path series contact used deliver bundle source node destination node cgr divided three main phase first, cp, example constructed mission control unit, forwarded node network second, forwarding ie, transmission phase, node receiving bundle performs route search using dijkstra algorithm determine next hop third, check performed intermediate node transmission verify system constraint respected deterministic network case, cp constructed source node using network information transmitted intermediate node route search phase given destination, route source node destination node computed using dijkstra algorithm however, adaptation algorithm used consider discontinuity icns main idea use contact graph representation network rather node graph representation dijkstra algorithm thus implemented contact graph representation network output dijkstra search route source destination bdt yen algorithm enables determine list shortest route iteratively exploring route source destination, using dijkstra contact graph representation avoiding loop previously discovered path standard cgr implementation, node computes list shortest route node network using yen algorithm, input parameter then, bundle reach given intermediate node, node determines feasible precomputed route route list determine next hop forwarding phase, local queuing state buffer bundle property available remaining contact volume buffer queuing time bundle scheduled contact taken account checks, among others, help verify validity previously computed route route list prevent local congestion list candidate valid route thus determined shortest route valid route guarantee contact volume availability given size bundle moreover, one also check that, taking account transmission queuing time, bundle effectively transmitted end corresponding contact, see eto best route among valid route selected determine bundle next hop route selected, bundle queued transmission, available volume contact used decreased size bundle although widely used, cgr computationally complex node perform many check bundle determine next contact use moreover, since check performed route search, valid solution may found among candidate route may trigger time consuming iterative search process dijkstra algorithm check one solution reduce cgr complexity source routing sr unlike per hop routing, idea sr compute route source node encode bundle extension block bundle, whose route already calculated, arrives intermediate node, node check validity encoded route case invalidity, traditional cgr performed intermediate node following two type sr implemented bundle independent sr, source performs route search without bundle property queuing information forwarding time, check cgr eto volume availability performed validity encapsulated route checked using available information bundles, like size, local queue state available initial route search time, bundle properties, eg, size priority, utilized case bundle dependent sr then, forwarding phase, information local queue taken account viability route checked solution go paradigm incorporating network information alongside bundle property initial route search mentioned previously, cgr capacity consumption availability managed forwarding phase common approach take contact capacity account route search check available volume contact greater size bundle called linear approach however, prevent exceeding capacity limit track time bundle contact linear volume model represented right side figure see also detail issue example figure example, using linear model, one may think bundle hatched rectangle reaching node use contact immediately nevertheless, reality contact volume consumed represented left side figure case, bundle reaching node cannot transmitted using contact immediately bundle striped rectangle transmitted capacity specific time traditional cgr, problem detected forwarding step, route search, using eto example transmission bundle thus delayed accordingly nevertheless, delaying transmission bundle forwarding phase may cause multiple problem inaccurate estimate delivery time, end unavailability current future contact planned route, reaching bundle delivery deadline delivery collision problem better managed, even avoided, capacity consumption modeled differently example, use precise moment known advance, alternative route might effective solution delivering bundle dtns, node buffer management important task, bundle wait long time node buffer transmitted addition, available buffer capacity may limited buffer management strategy usually consist addressing problem occurred example buffer full, decision reroute drop bundle take place spot, like reactive custody transfer author suggested strategy refuse custody order preserve buffer space node however, strategy rely information coming local neighbor node alternative approach would global vision buffer occupancy handle buffer space issue initial route search note however that, unlike volume capacity managed contact level, buffer occupation managed node level instance, multiple bundle using distinct contact affect buffer node therefore, one careful addressing challenge contact graph representation network framework considered bundle dependent sr cgr see section ii propose address buffer capacity constraint route search reminder, opposed approach reported state art action taken issue occurred solution ensures route found respect buffer capacity limit moreover, proposed modification remove viable solution, enables route search find optimal solution given constraint achieved modifying cp starting route search, capacity buffer constraint moreover, buffer constraints, allowed edge contact also modified route search words, modify parameter cgr performs search among valid solution optimal route respect buffer capacity limit encoded bundle, forwarded network manner sharing bundle transmission path source routing cgr solution consists two key element first, propose modify cp used route search algorithm eg, dijkstra search via contact splitting differentiate two kind cp modification definitive ones, shared network, temporary bundle specific modifications, performed locally one node within route search process specific bundle second, propose imposing additional restriction allowed edge contact rule respected inside route search algorithm restriction implemented locally node, route search specific bundle assume cp shared entity performing route search eg, source node introduce contact splitting operation let consider original arbitrary contact data rate sender node receiver node contact splitting consists replacing original contact cp, two split contact node one one see figure split contact data rate original contact note part original contact erased moreover, one split contact might last time, meaning contact splitting result contact shortening define edge pruning act forbidding edge contact action taken pair contact original split example, figure one choose forbid edge contact mean that, route search, option choose route contact followed contact explain contact splitting edge pruning used address capacity buffer constraint discussed section iii assume knowledge bundle size first, route search first transmitted bundle performed contact skipped bundle size greater contact volume similarly linear volume approach shortest path selected bundle, cp modified follows remove part contact consumed bundle cp performing route search subsequent bundle length contact erased tx, starting start time contact arrival time bundle contact sender node, whichever occurs later variable tx, represents time needed transmit bundle contact selected path operation contact splitting operation creates two new contact two new contact added cp original contact removed operation performed contact selected route then, subsequent route search use modified cp cp modification, performed selection route bundle, definitive shared node performing route search example example figure route search route selection initial bundle striped rectangle cp becomes represented figure new cp used route search subsequent bundle case, part contact tx,a option future bundle collision therefore occur first introduce notion forecast buffer table goal table store buffer occupancy status node function time, including future time similarly cp, assume table shared entity performing route search explain use table respect buffer constraint forecast buffer table assume node maximum buffer capacity limit max overflow occurs limit exceeded proposed buffer management solution temporary bundle specific cp modifications, shared network see following subsection however, route selected, forecast buffer table updated accordingly shared entity performing route search words, route validated, one check bundle reach given node long stay buffer according validated route since buffer table updated soon route validated, routing node know advance status buffer function time, even bundle travel network algorithm respect buffer constrains main idea proposed algorithm enforce buffer limit constraint follows since bundle size forecast buffer table available route search time, one check whether bundle buffer node time not, algorithm must forbid route leading storage bundle potentially problematic buffer hence, performing route search, cp temporarily modified using contact splitting then, edge pruned using edge pruning inside route search algorithm algorithm formulated four following main step step begin with, size bundle virtually added node buffer table time potential overflow detected determined location node time start end time set node potential overflow bundle denoted number potential overflow forming set overflow denoted start end time overflow denoted respectively example figure present example bundle arrives source node need routed figure depicts one node two potential overflow potential overflow identified virtually adding size bundle vertically striped rectangle buffer level node dotted rectangle buffer level node virtually adding size bundle b, determined validated route previous bundle dotted rectangle corresponding forecast buffer table node shown figure step then, original cp temporarily modified accordingly starting route search one remove part contact cp might forward bundle node overflow start end time using contact splitting problematic contact contact start end overflow end start example problematic contact potential overflow descried previous example shown figure contact node receiver regardless sender node start end problematic duration intersects period overflow problematic portion contact horizontally striped figure may forward bundle potential overflow duration part contact intersect overflow duration temporarily removed using contact splitting applies potential overflow node step removing problematic contact potential overflow part sufficient one also address problematic contact succession problematic contact succession occur contact end time beginning potential overflow succeeding contact route start time beginning overflow succession contact problematic result bundle buffer node potential overflow step therefore consists identifying problematic contact succession described via following example example step contact receiver span duration figure nevertheless, contact receiver ending using one contact eg, bundle arrives potential overflow however, bundle must leave beginning overflow avoid potential problem bundle leaf node contact succeeding previous one route succeeding contact eg, sender, regardless receiver result, succeeding contact start overflow avoid otherwise, succession route cause overflow therefore problematic step finally, last step forbid edge contact yielding problematic contact succession words, edge contact starting late pruned edge pruning performed route search example example figure route search, contact forward bundle node edge contact third node accepted start applies overflow node described steps, invalid route removed modification proposed contact capacity buffer management solution words, proposed modification route search omit feasible solution hence, subsequent use cgr give optimal route subset valid solution proposed solution source node keep track buffer contact capacity occupancy status due feature, avoid overflow overbooking nevertheless, due unpredictable disruptions, like antenna pointing error node power outage intermediate node may perform routing forwarding time since intermediate node may access buffer capacity status, routing decision may cause overflow overbooking reason, propose let part original contact buffer resource unused source node unused portion referred safety margin utilized intermediate node reroute bundle without resulting overflow overbooking quantity resource allocated method determined function network disruption level safety margin implemented follows first, regarding contact capacity management, two cps created contact splitting, slot kept margin, performed safety margin therefore removed original cp obtained cp provided used source node safety margin part contact removed original cp forwarded intermediate node may perform routing unpredictable situation term buffer management, source node utilize fraction buffer capacity, leaving rest available intermediate node solution therefore enhances robustness potential unexpected events, despite poor knowledge current network status intermediate node mentioned above, modified network information contact splitting except bundle specific cp modification modified forecast buffer table allocating route bundle shared source node performing route search similar sharing date cp source node standard sr cgr safety margin resource shared node network low frequency mentioned first part manuscript, network issue handled route search standard sr cgr retransmission mechanism exist long round trip time communication, licklider transmission protocol ltp retransmission mechanism case failure standard sr cgr well described literature many manner address issues, describe detail assumption made considered sr cgr benchmark proposed algorithm compared benchmark section vii, simulation result presented begin with, benchmark algorithm, bundle transmitted contact, assumed link occupied time required transmit bundle words, whole link capacity used ie, time division multiplexing tdm approach initial cp constructed source broadcasted node network then, source node performs route search using yen algorithm dijkstra search list yen constant shortest route generated list kept change occurs cp, end contact case, route list discarded new list generated, route list pruning list candidate route constructed explained section ii candidate route found list, bundle delayed route search performed one time step regarding capacity buffer management performed route search route found, volume occupied bundle selected route deducted available volume corresponding contact cp ie, linear volume approach described section iii buffer information available considered source finally, route encoded bundle bundle sent network bundle encapsulated route transmitting node source intermediate node subject check verify whether route used contact capacity buffer management forwarding phase benchmark detailed hereafter first, time corresponding contact must used bundle transmission verified case collision another bundle, transmission bundle highest id delayed similar behavior determining eto id increase bundle generation time source two case occur delaying bundle cause problem, time future hop simply updated encapsulated route according delay caused bundle using contact delaying bundle cause transmission time later corresponding contact end time, new route computed node problem happened, avoiding problematic contact time new route search call problem detection time provide detail regarding second case reroute bundle, date cp problem detection time loaded instantly source node note advantageous assumption benchmark moreover, since remaining part old route longer used, volume future contact old route updated locally cp node ie, incrementing available volume unused contact size bundle cp update performed intermediate node reported source newly computed route, any, encapsulated within bundle forwarding none shortest route valid, bundle sent instantly source rerouting source performed one time step forwarding phase, assume node access state buffer neighbor node contact bundle transmitted, current node verifies enough room buffer receiving node case, next node buffer occupancy increased book space bundle bundle transmitted waiting time evaluated determine long bundle remain buffer next node time equal transmission time current node next node tx, well wait time start next contact wait exists wait transmission time next node distant node route tx, tx, wait total bundle size assumed occupy buffer next node tx, space occupied bundle linearly reduced time pa ie, bundle leaf buffer according data rate contact used transmission room bundle buffer next node, bundle rerouted current node via route avoids problematic neighbor well previously visited node avoid loop note node whose buffer fully occupied considered problematic must therefore avoided this, problematic contact used route removed cp rerouting bundle node note bundle pa problematic node later route, buffer emptied example valid route found among shortest routes, bundle instantly sent back source rerouted one time step alternative solution, considering, would continue trying transmit via fully booked node time step valid route found place becomes available buffer problematic node, whichever come first note solution requires lot computing resource route search repeated time step suitable solution found simulations, consider sat satellite orbiting orbital plane distributed according walker delta constellation zero phasing orbital plane evenly distributed range hence, angle right ascension ascending node raan two satellite adjacent plane furthermore, plane, true anomaly sat satellite evenly separated sat consider circular orbit eccentricity inclination radius m, earth radius constant consider two bundle generated source bundle transmitted source destination satellite intermediate node network cp constructed hour scenario starting pm august assume contact rate snapshot one walker constellation sat pm august illustrated figure generated using matlab satellite communication toolbox using cislunar constellation evaluate algorithm considered future work see also conclusion considered constellations, orbital plane sat satellite define plane hop number plane communication two satellite cross table depending communication parameter satellite dynamics, satellite located orbital plane communicate satellite located plane zero plane hop, raan adjacent plane one plane hop, one difference raans satellite distant plane one plane hops, meaning plane restriction case number plane limited characteristic used constellations, also depending communication parameter provided following subsection, given table satellite mounted transmit receive gaussian antenna dish diameter aperture efficiency transmission frequency power hz db, respectively receiver gain noise ratio energy noise sensitivity equal db kelvin db, respectively source equipped transmit antenna whose property similar satellites, except transmission power considered db destination equipped receive antenna whose property similar satellites, exception sensitivity db free space channel model considered considered minimum required elevation angle communication two satellite communicate line sight power received receiving satellite transmitting satellite greater sensitivity receiving satellite satellite communicate gs, elevation angle former relative latter must greater minimum elevation angle latter, addition line sight within communication range condition met, link closure two node contact extends beginning end link closure two node example figure constellation represented figure illustrates, green, link closure pair node sat sat sat sat sat example link closure happens time snapshot link sat limit one time sample one second later, link longer exists two node cease respect elevation angle constraint link closure thus interrupted even though remain line sight communication range addition, sat sat may within communication range, communication blocked earth, preventing line sight time step, one bundle byte generated source bundle generated period seconds, starting beginning scenario time, equal inter arrival time total bundle generated forwarded mean one bundle generated second bundle inter arrival time decrease total number bundle generated source, increase yen constant chosen equal finally, assume external disruption network is, provided cp valid rerouting needed intermediate node due external factor given assumptions, therefore need consider safety margin contact capacity buffer space section iv use matlab satellite communication toolbox simulate presented satellite communication scenario calculate link closure pair node function time obtain cp used benchmark solution, also implemented matlab alternative algorithmic implementation would use interplanetary overlay network ion however, chosen main focus cgr evaluate performance using two main metric first metric average time bundle spends network computed difference destination arrival time bundle generation time source includes buffer waiting time, transmission time, potential rerouting delay metric number rerouting event sr cgr, includes rerouting source route found among shortest one well bundle instantly sent back source also includes, sr cgr proposed solution, rerouting intermediate node buffer capacity check fails evaluate impact contact capacity management buffer management separately course, two management technique used together obtain greater gain section, evaluate performance proposed contact capacity management therefore, consider constraint associated buffer limits, ie, maximum node buffer capacity max node figure show average time spent network sat constellation function number bundle generated source three value contact data rate considered bps contact expected, one see time spent network increase number bundle decreasing data rate low load eg, bps proposed algorithm sr cgr similar performance increases, gap curve increases, le time spent network using proposed method due increased number rerouting event forwarding time using sr cgr number rerouting event shown figure sat constellation value function low load, overbooking event happening contact case, traditional sr cgr satisfactory performance number bundle increases, overbooking phenomenon increases, making rerouting likely case overbooking event, intermediate node try overcome issue rerouting bundle location toward destination new route longer one avoiding overbooking computed using proposed algorithm moreover, route found node, bundle rerouted source see assumption benchmark also causing additional delay proposed algorithm efficient shortest route always computed directly source node, always avoiding overbooking indeed, expected, rerouting required proposed solution simulation due contact capacity check failure moreover, although case time spent network sr cgr similar proposed solution, node complexity significantly higher benchmark due multiple check rerouting event then, figure illustrates time spent network satellite constellation respectively contact data rate considered equal bps four satellite one satellite per orbital plane number node limited distant compared constellation higher number satellite thus, number communication opportunity limited, limiting routing degree freedom case, proposed algorithm show improvement compared benchmark number satellite increase algorithm present improvement compared benchmark, particular high load section, evaluate performance proposed buffer management contact capacity restriction implemented, ie, average time spent bundle network function buffer size per node, expressed number bundle buffer store, given figure consider sat constellation buffer storage size identical intermediate node source node infinite buffer size result shown bundle generated second expected, storage capacity buffer increases, time spent network reduced gain significant proposed solution, especially buffer size limited reach performance infinite buffer capacity solution requires buffer store bundles, compared bundle almost half achieve performance benchmark difference even higher reach performance infinite buffer buffer size bundle small box figure using solution benchmark, respectively similarly capacity case, difference due number rerouting event intermediate node shown figure also sat constellation using sr cgr moreover, expected, rerouting performed proposed solution due buffer check failure finally, figure show impact different constellations, namely performance related buffer constraint number node limited, frequently used limited storage capacity induces additional delay solution sat two solution reach infinite buffer performance buffer capacity bundle per node nevertheless, constellation lower buffer size per node, proposed solution manages significantly reduce average time bundle spends network increasing number node constellation using proposed solution lead low delay even low buffer capacity per node work, proposed enhanced contact capacity management buffer management improve state art cgr routing algorithm proposed managing resource taking action route search solution global solution considers track evolution contact capacity buffer occupation contact node network resulting route optimal respect contact capacity node buffer constraint manage contact capacity, introduced contact splitting allows consideration previously consumed portion contact routed bundle buffer management, proposed temporary bundle specific contact splitting edge pruning avoid portion succession contact might result buffer overflow temporary modification depend forecast buffer table track future state node buffer occupancy level function time compared performance proposed solution benchmark sr cgr solution offer considerable gain term time spent network intermediate node complexity, measured number rerouting call limitation although proposed solution offer improvement state art meeting capacity buffer constraints, limitation could taken account improvement solution based sr cgr, usually used reduce cgr complexity reduction achieved performing one route search per bundle rather multiple route search per hop routing nevertheless, solution split contact two contacts, bundle occupies contact capacity buffer space splitting action increase size cp, directly impact complexity route search solution, additional complexity tractable route search performed source node low power intermediate node nevertheless, moving distributed solution, one consider additional complexity centralized solution also limitation study examination efficient distributed solution therefore interesting research direction improvement work future work plan proposed cislunar constellations, communication perspective, using presented routing technology believe proposed routing algorithm may help design communication storage system embedded satellite lunar constellation also plan investigate traffic level solution rather per bundle solution state art work, route chosen based optimal criterion bundle level, entire traffic transmitted therefore, per bundle strategy likely optimal overall communication performance finally, mentioned previous limitation subsection, investigating distributed solution rather centralized one also interest continuing improve html version papers, feedback help enhance accessibility mobile support report error html help improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",networking and internet architecture
"towards safer heuristic plain introduction heuristic analysis case comprehensive analysis challenge plain proposal related work acknowledgement appendix formalizing plain dsl instruction reporting error domain specific language adversarial subspace generator explainer generalizer instance generator plain node description plain model linear optimization name pantea, color orange pk many problem cloud operator solve computationally expensive, operator often use heuristic algorithm faster scale better optimal solve efficiently heuristic analyzer enable operator find much heuristic underperform however, tool provide enough detail operator mitigate heuristic impact practice discover single input instance cause heuristic underperform full set explain propose plain, tool extends analyzer help operator understand heuristic underperform present promising initial result show extension viable operator use heuristic approximate algorithm faster scale better optimal counterpart production system solve computationally difficult expensive problem heuristic perform well across many typical instances, break unexpected way network condition change namyar et al, goel et al, arun et al, arashloo et al, community developed tool enable operator identify situation namyar et al, agarwal et al, goel et al, arun et al, agarwal et al, tool find performance gap one heuristic algorithm compared another heuristic optimal identify example instance input cause given heuristic underperform example, metaopt namyar et al, describes heuristic deployed microsoft wide area traffic engineering solution show could underperform see mean company would either overprovision network support traffic, drop traffic, delay potential benefit heuristic analyzer clear allow operator quantify risk heuristic want deploy although heuristic analyzer already shed light performance gap many deployed heuristics, still nascent stage limited use operator sufficient expertise formal method optimization theory crucial feature missing operator model heuristic want analyze term mathematical construct tool support manually analyze output tool understand fix heuristic scenario tool provides performance gap example input caused produce full space input cause large gap describe heuristic underperformed instance latter problem limit operator ability use output tool fix problem either improve heuristic, create alternative solution underperforms, cache optimal solution instance earlier examples, operator look tool example demand matrix understand heuristic route le traffic optimal state heuristic analyzer today reminiscent early day community exploration network verifier potential help network operator configure manage network way network verifier enabled operator identify bug configuration yang lam, kazemian et al, khurshid et al, zhang et al, lope et al, mai et al, horn et al, jayaraman et al, beckett et al, fayaz et al, gember jacobson et al, tang et al, kakarla et al, heuristic analyzer help find performance gap algorithm deploy tool allow operator leverage heuristic analyzer easily, identify heuristic underperform, devise solution remediate issue serve similar purpose tool community crafted explained impact configuration bug tang et al, kakarla et al, jayaraman et al, tian et al, producing set packet bug impacted configuration line caused impact propose plain vision generalizer augment existing heuristic analyzer help operator either improve heuristic helping find heuristic underperform use safely finding region underperform propose domain specific language allows concretely describe heuristic behavior benchmark want compare automated analysis rooted network flow abstraction, allows model behavior many heuristic operator use today networks, including namyar et al, goel et al, compiler convert input language existing heuristic analyzer efficient iterative algorithm analyzer, extrapolates adversarial input finds, find adversarial subspace heuristic underperforms use language visualize ie, different decision heuristic made compared optimal caused underperform heuristic underperforms case also discus open question possible approach built solution propose work uncover property input problem instance cause heuristic underperform proof concept implementation idea metaopt namyar et al, underlying heuristic analyzer open source proposal applies heuristic analyzer agarwal et al, goel et al, agarwal et al, well heuristic analyzer namyar et al, agarwal et al, goel et al, take heuristic model benchmark model eg, optimal input goal characterize performance gap heuristic compared benchmark recent tool namyar et al, goel et al, use optimization theory first order logic solve problem return single input instance cause heuristic underperform example heuristic work include demand pinning dp deployed microsoft wide area network dp heuristic traffic engineering problem optimal algorithm assigns traffic demand path maximizes total flow route network without exceeding network capacity operator use dp reduce size optimization problem solve dp first filter demand pre defined threshold route pin shortest path route remaining demand optimally using available capacity see fig metaopt author modeled dp directly optimization problem also provided number helper function allow operator model easily metaopt solves bi level optimization produce performance gap demand cause flow easy see missing operator examine single output find dp underperformed dp amenable manual analysis see namyar et al, heuristic also hard operator extrapolate example adversarial input find region input space dp may underperform limitation exacerbated move larger problem demands, harder pinpoint heuristic decision route particular demand interferes ability route others vector bin packing vbp place multi dimensional ball multi dimensional bin minimizes number bin use operator use vbp many production systems, place vms onto server barbalho et al, vbp problem apx hard woeginger, one heuristic solves vbp first fit ff greedily place incoming ball first bin fit show encode metaopt metaopt produce adversarial ball size percentage bin size example ball equal sized bin use single dimensional ball optimal bin ff show complex version fig again, operator reason example identify ff underperforms input cause problem harder ff vbp heuristics, best fit first fit decreasing, evidenced year research theoretician space panigrahy et al, paper, use dp vbp running example example representative heuristic prior work studied namyar et al, goel et al, scheduling example virley study conceptually similar vbp, think discussion directly translate use case prior work arashloo et al, show that, using single adversarial instance, difficult understand heuristic underperformed even harder generalize adversarial input cause heuristic underperform single problem instance instance property input problem instance cause underperform prior work namyar et al, agarwal et al, arashloo et al, show explaining adversarial input benefit improve dp performance gap order magnitude produce congestion control algorithm meet pre specified requirement agarwal et al, result require manual analysis namyar et al, problem specific model agarwal et al, arashloo et al, see opportunity new tool enables operator identify full risk surface heuristic set input heuristic underperforms identify heuristic underperforms automatically produce description entire area heuristic high performance gap description choice heuristic make cause underperform difference action heuristic optimal point heuristic underperforms outputs, tool make safer operator use heuristic practice mitigate case underperform maybe even design safer heuristic three level information provide given problem instance, set input cause heuristic underperform given problem instance, reason heuristic underperforms contiguous region adversarial input space general case, characteristic input problem instance cause heuristic underperform take dp example ideal tool would produce type given topology, adversarial input set form represents contiguous subspace dimensional dimensional demand space given entry demand pinning threshold small positive value multiple path node call demand pinnable demand portion path node intersects shortest path pinnable demand min here, set contains capacity link path adversarial instance example fit behavior type given topology, dp route pinned demand shortest paths, optimal route alternate path expect pinned demand contiguous subspace would common pattern shortest path, dp shortest path routing demands, whereas optimal type heuristic performance worse length shortest path pinned demand longer capacity link along path lower pinned demand limit heuristic ability route demand hard arrive low level model heuristic order use existing analyzer namyar et al, goel et al, agarwal et al, operator need expertise either formal method goel et al, agarwal et al, optimization theory namyar et al, boyd vandenberghe, see analogy writing imperative program assembly code write program assembly take time, high risk buggy, make code review ie, explanation difficult low level model operate variable construct often hard connect original problem greek letter auxiliary variable instead human readable text model first fit behavior, metaopt auxiliary, binary variable capture whether bin first bin ball fit in, set value hard derive explanation model harder still connect heuristic work explain behavior need better descriptive language encode behavior heuristic also need find adversarial subspace validate subspace input space input fall subspace cause heuristic underperform find them, need search algorithm iterates extrapolates adversarial input existing analyzer find similar sat problem mcmillan, grumberg et al, yu et al, input space large, cannot blindly search find adversarial input namyar et al, find potential adversarial subspace, validate need check whether heuristic performance gap higher input belong adversarial subspace compared statistical significance find input subspace cause bad performance reasonable assume input contiguous adversarial subspace trigger bad behavior heuristic find explain behaviors, need automatically reason heuristic action compare benchmark need concretely encode heuristic benchmark choice part language design solution challenge ensure language applies broad range problem amenable type automation desire generalize beyond single instance perhaps hardest challenge generalize instance based explanation one applies heuristic behavior general case find valid extrapolation instance based example discover pattern apply heuristic behavior across different problem instance propose plain fig user describe heuristic benchmark domain specific language main purpose domain specific language dsl concretely define behavior heuristic benchmark, allows automated system analyze, compare, explain behavior compiler translates dsl low level optimization construct adversarial subspace generator generates set contiguous subspace input subspace cause heuristic underperform significance checker filter output ensures subspace statistically significant check input fall subspace produce higher gap compared statistical significance explainer describes heuristic action differ benchmark contiguous subspace given problem instance generalizer extrapolates instance based observation produce property input instance cause heuristic underperform instance based explanation across many instance use instance generator create instance auto generate information described need dsl concretely encode heuristic benchmark algorithm need dsl represent diverse heuristic use automatically compile optimization efficiently solve existing solver support introduce many additional constraint variable compared hand written model easy intuitive use design abstraction based network flow problem bertsimas tsitsiklis, network flow problem optimization that, given set source destinations, optimize route traffic respect capacity constraints, maximize link utilization, etc network flow problem impose two key constraint total flow link link capacity, come node go flow conservation advantage using network flow problem intuitive graph representation bertsimas tsitsiklis, operator know reason flow traffic graph easily translate convex optimization feasibility problem bertsimas tsitsiklis, many variant use build upon use network flow model extend set new node behavior ensure apply broad class heuristic node behavior set constraint operate flow coming going node split node enforce flow conservation constraint pick node enforce flow conservation constraint allow flow single outgoing edge copy node copy flow come onto outgoing edge source sink node produce consume traffic etc node enforce multiple behavior simultaneously include node behavior enforce flow conservation constraint copy node capacity constraint default model broad set heuristic user also add metadata node edge, use later improve explanation produce user encode problem, heuristic, benchmark dsl abstract term example, model vbp specify problem operates abstract sequence different node type correspond ball bin vbp problem user also encode action heuristic optimal make term relationship different sequence node edge connect rule govern flow traverse one node next analyze specific instance vbp problem, user input number ball bin plain concretizes encoding show concretized example one dimensional ball bin dsl allows model example prior work model dp split, source, sink node use pick node limited capacity allow ball assigned single bin model ff prove represent linear mixed integer problem small set node behavior abstraction sufficient app easily compile node behavior efficient optimization encoding allows solve optimization faster compared hand coded optimization dsl allows find redundant constraint variable this, turn, reduces number variable constraint metaopt add writes implemented complete dsl linq torgersen, style language compared original metaopt implementation, compiled dsl analyzes dp example faster metaopt write ff, provide run time gain case open question describe heuristic metaopt analyze dsl support analyzer eg, goel et al, may need change compiler add node behavior also need understand metadata user provide enable plain may require co design plain component although proved mixed integer program mapped dsl app mean mapping efficient representation heuristic dsl may achieve better performance model heuristic directly dsl need research formalize guide user optimize representation random search cannot find adversarial subspace may even find adversarial point namyar et al, propose algorithm extrapolate heuristic analyzer output use analyzer find adversarial example find adversarial subspace around example exclude subspace repeat longer find adversarial example heuristic significantly underperforms outside subspace found far find adversarial subspace, first find rough candidate region sample cubic area around initial adversarial point given heuristic analyzer expand sampling area based density adversarial bad sample find direction define direction based sub cube slice lie respect initial adversarial point metaopt found stop density bad sample drop possible expansion direction go slice slice investigate cubic region around initial bad sample adversarial subspace may uniformly spread around initial point extend sampling region around slice density bad sample high pick number sample use based dkw inequality massart, subspace boundary far exact big pick slice much expand iteration influence many false positive fall subspace refine subspace based idea prior work diagnosis chen et al, train regression tree predicts performance gap sample rough subspace predicate form path start root tree reach leaf contains initial bad sample accurately describe subspace adversarial subspace significance checker ensures subspace find statistically significant point subspace cause higher performance gap compared immediately outside report subspace low value le adversarial use wilcoxon signed rank test wilcoxon, allows dependant sample subspace fully describes point inside point sample two pool dependent find subspace dp vbp value respectively approach allows find statistically significant subspace meet exploration granularity include adversarial input subspace outside region explored analyzer find next iteration user control plain ability find adversarial scenario use smaller cube size explore space detail come cost slower runtime also elect include part initial subspace plain find apply decision tree part metaopt decision space need include number time willing examine area avoid infinite cycle may region statistically significant plain would revisit contain input instance produce high gap open question decision tree help identify predicate form feature threshold describe subspace feature train tree influence predicate get small instance use raw input larger instance would require deep decision tree fully describe space output becomes computationally difficult use next step step need define function input allow describe subspace efficiently use analyzer execute step ie, exclude subspace run analyzer may better apply adversarial subspace generator step directly projected input space function describes one dimension dimensional space note, need dimension input space space defined adversarial subspace sparse approach may allow find adversarial subspace efficiently may need additional mechanism help scale plain may take long time find adversarial subspace analyze large problem instance many disjoint subspace hypothesize input contiguous subspace share root cause cause heuristic underperform network flow based dsl explicitly encoding decision heuristic benchmark algorithm prof useful run sample within contiguous subspace dsl score edge based benchmark heuristic send flow edge score benchmark sends flow score heuristic sends flow score heatmap difference benchmark heuristic show input subspace interfere heuristic given subspace samples, pinnable demand share shortest path red arrow path optimal route alternative path blue arrow path open question instance size scale problem want analyze grows, heatmap may become harder interpret need mechanism allow summarize information heatmap way user interpret use improve heuristic heuristic benchmark also differ much flow route edge need define appropriate data structure represent information user interpretable actionable enable operator improve heuristic know apply mitigation extrapolate type explanation form type property adversarial input cause heuristic underperform aspect problem instance exacerbate need find trend across instance based information find instance agnostic explanation heuristic underperformed discover patterns, need consider diverse set instance identify trend output subspace generator explainer build instance generator problem description dsl create instance feed pipeline imagine generalizer would contain grammar metadata user provides dsl along network flow structure describe trend instance based explanation example, one may consider predicate hypothetical grammar grammar, generalizer go observation sample instance generator produced check predicate grammar statistically significant example, describes set shortest path pinnable demand dp, generalizer might produce increasing dp underperforms predicate suggests gap larger shortest path pinnable demand longer open question one may envision solution similar enumerative synthesis gulwani et al, alur et al, huang et al, search grammar, find predicate hold particular heuristic, form clause explain heuristic behavior need work define generalizer grammar build valid clause knowledge, first work focus general framework provide insight output heuristic analysis tool namyar et al, goel et al, provides explainability feature tool build prior work domain customized performance analyzer work plain also applies custom performance analyzers, apply specific heuristic arun et al, arashloo et al, arun et al, explainable ai plain resembles prior work explainable ai, provided context around different ml model predict ribeiro et al, lundberg lee, wachter et al, part solution including three type inspired work amershi et al, arzani et al, phillips et al, enumerative synthesis field generates program meet specification systematic enumeration possible program candidate gulwani et al, alur et al, huang et al, believe idea help design generalizer large language model llm may able use llm yan et al, various part design include generate dsl, summarize type explanations, generate grammer need produce type explanation llm prone hallucination huang et al, liu et al, also require additional step step mechanism guide wang et al, kambhampati et al, may able build natural language interface help automatically generate dsl interface enable non expert easily use plain this, too, interesting topic future work would like thank basmira nushi, ishai menache, konstantina mellou, luke marshall, amin khodaverdian, chenning li, joe chandler, weiyang wang valuable comment also hotnets program committee valuable feedback prove model linear optimization plain preliminary network flow based dsl directed graph denote set node set directed edge treat edge variable non negative flow value impose constraint flow variable needed define incoming edge node edge directed towards ie, outgoing edge exiting incoming outgoing traffic node sum flow arrives node incoming outgoing edge following node behavior split node split incoming traffic outgoing edge enforce traditional flow conservation constraint also optionally enforce upper bound traffic outgoing edge capacity constraint traffic incoming edge constant pick node satisfy flow conservation allow one outgoing edge carry traffic indicator function otherwise multiply node one incoming one outgoing link multiply incoming traffic constant sending satisfy flow conservation equal node require incoming outgoing edge carry amount traffic make simpler encode heuristic dsl, also add following node type dsl copy node copy total incoming flow outgoing edge recreate node behavior combine split node equal node fig however, using copy node directly intuitive straightforward users, include dsl reason use source sink node define objective source node special case split pick node represent input problem example, illustrates input traffic demand modeled source node enforce split node behavior also, show input ball size source node pick node behavior ball placed one bin sink node specific node incoming edge measure performance problem total incoming traffic edge dsl represents optimization problem, sink node designated objective, compiler translates value sink node optimization objective model linear optimization linear programming mixed integer linear programming flow network using six node behavior optimization problem maximizes minimizes objective subject input fall within feasible space optimization constraint characterize express linear optimization problem linear programming mixed integer linear programming show dsl complete, need show capture feasible space objective correctly flow model every possible linear optimization first present general algorithm express feasible space given linear optimization flow model prove correct next, show use algorithm express linear objective represent feasible space flow model express feasible space linear optimization denote matrix vector bold vector continuous binary variable size respectively constant vector size constant matrix size respectively note enforce equality constraint two inequality constraint eq represent integer variable sum multiple binary variable map variable flow model need transform optimization model node behavior transformation matrix vector may contain negative entry conflict non negativity requirement flow flow model address this, decompose matrix vector positive negative component element non negative one non zero every note hold every matrix size originating matrix substituting decomposition eq transformation eq split node qualitatively represent similar behavior split node split incoming traffic across outgoing edge ensure traffic edge exceed capacity constraint ideally, enforce eq constraint using split node flow conservation constraint problem eq also involves coefficient associated variable split node accept weight address replacing term coefficient multiplied variable eq constraint auxiliary variable define express eq term auxiliary variable vector element equal size respectively auxiliary variable appear exactly one inequality constraint transformation encounter problem enforce constraint eq using multiply node multiply node one input one output edge edge also corresponds one variable mean variable appear two constraints, corresponding two node two end edge however, variable eq appear twice example, appear time address introducing additional variable constraint modifications, variable appears exactly two constraint final resulting optimization transformation equation above, notation mean possible value considered according specific constraint condition given equation constructing flow model encode constraint using flow model first create one edge per variable enforce constraint using one node encode eq using split node node possible input node one edge per variable left hand side constraint one edge constant rate one additional edge associated output one edge per variable right hand side constraint one additional edge constant rate fig show encoding done express eq using multiply node edge originate split node multiply node edge opposite direction so, node model eq input edge output edge conversely, input edge output edge eq hold fig show step model eq using equal node note fixed since one non zero, equation eq eq needed hold eq eq consequently, needed eq hold eq input edge output edge fig illustrates step input variable variable represent binary variable eq using pick node one incoming edge constant rate two outgoing edge one output corresponds binary variable node selects specific edge carry flow, binary variable otherwise, eq inherently satisfied flow non negative flow model provably capture optimization feasible space one one correspondence constraint optimization constraint enforced node capture optimization objective express objective linear optimization max constant vector reformulate add constraint enforces objective optimization change maximizing then, use similar transformations, explained before, capture constraint within flow model add sink node one incoming edge way, express linear optimization objective model continuing improve html version papers, feedback help enhance accessibility mobile support report error html help improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",networking and internet architecture
"solution sustainable resilient communication infrastructure disaster relief management scenario introduction ii background global picture iii energy communication technology enablers iv pre disaster communication energy planning warning disaster response communication energy planning vi post disaster communication energy planning, rescue evacuation vii existing vendor product service viii standardization project ix case study turkiye earthquake open issues, challenge future direction xi conclusion instruction reporting error related survey review comparing survey related survey contribution organization iii communication enablers iii energy enablers iv technology enablers communication pre disaster scenario iv technology enablers energy support pre disaster scenario iv lesson learnt recommendation technology enablers communication disaster response scenario technology enablers energy support disaster response scenario lesson learnt recommendation vi technology enablers communication post disaster scenario vi technology enablers energy support post disaster scenario vi lesson learnt recommendation ix reason network failure ix response network operator ix evaluation lesson learned open issue challenge realizing resilient sustainable infrastructure future direction natural disaster become frequent severe, ensuring resilient communication infrastructure paramount importance effective disaster response recovery disaster resilient infrastructure also respond sustainability goal providing energy efficient economically feasible network accessible everyone end, paper provides comprehensive exploration technological solution strategy necessary build maintain resilient communication network withstand quickly recover disaster scenario paper start survey existing literature related review establish solid foundation, followed overview global landscape disaster communication power supply management introduce key enablers communication energy resource technology support communication infrastructure, examining emerging trend improve resilience system pre disaster planning emphasized critical phase proactive communication energy supply strategy significantly mitigate impact disaster also explore essential technology disaster response, focusing real time communication energy solution support rapid deployment coordination time crisis paper present post disaster communication energy management planning effective rescue evacuation operation main finding derived comprehensive survey also summarized disaster phase followed analysis existing vendor product service well standardization effort ongoing project contribute development resilient infrastructure detailed case study turkiye earthquake presented illustrate practical application technology strategy finally, address open issue challenge realizing sustainable resilient communication infrastructure provide insight future research direction incorporating lesson learned various disaster scenarios, paper present strategic recommendation enhance resilience adaptability communication system context disaster relief management major natural disaster public safety incident significantly disrupt communication network infrastructure aftermath major disasters, earthquake storms, primary telecommunication infrastructure public infrastructures, power sources, often severely damaged completely destroyed result unavailability cellular network internet connectivity telecommunication infrastructure crucial basic life need like shelter, food, clean water disaster without reliable uninterrupted communication channel, challenging coordinate rescue operation find affected also crucial organize provide basic life need rescued people therefore, discontinuity communication severely restrict central controlling authority obtaining timely information, critical ensuring coordination rescue teams, quickly transmitting vital information, responding call help disaster area example, two significant earthquakes, magnitude turkiye february hundred cellular tower damaged resulted lack cellular internet connectivity city reason, crucial critical communication preserved efficient temporary communication infrastructure disaster area conventional communication infrastructure restored temporary network help connect various stakeholders, including volunteer rescue relief teams, enabling exchange information seamlessly timely manner help facilitate effective well coordinated rescue, relief, recovery effort context, public protection disaster relief ppdr agency exploring reliable wireless communication system ensure public safety sector, efficient coordination first responder necessary support affected region reducing likelihood casualty economic damage affected area ppdr communication system primarily rely private professional mobile radio pmr technologies, offer comprehensive range voice service tailored specific need ppdr systems, push talk call priority therefore, data transmission capability comparatively limited lag behind current telecommunication technology initial effort aimed improving communication capability ppdr agency introduction fourth generation technology go beyond capability pmr system emergence rd generation partnership project gpp release originally fifth generation seen crucial standard, encompassing broader range functionality although user access broadband voice, data, video capabilities, including support mission critical services, key limitation interoperability different technology hinder time critical emergency management robust secure ppdr network therefore still required emergency management involves coordination various function deal major emergencies, including prevention, preparedness, response, rehabilitation emergencies, coordination different function crucial law enforcement focus prevention, investigation, apprehension individual suspected convicted criminal offense emergency medical service em provide critical care, transportation, disaster medicine, involving professional doctors, paramedics, volunteer firefighting deal extinguishing hazardous fire threaten people property protection environment involves safeguarding ecosystem monitoring intervention organization forest guard volunteer search rescue aim find missing person bring safety, often carried organization like firefighter em border security, carried police specialized guard services, focus controlling border ensure security economic well overall, emergency management centralizes command control public safety agency emergency realize function within ppdr services, real time access information via broadband connection critical open door variety data centric, multimedia application greatly enhance capability communication emergency scenario white paper proposes next generation disaster data infrastructure successfully collect, process, display disaster data reducing impact natural hazard data collection play crucial role proposed solution time, data collection completed mobile network therefore, uninterrupted connectivity required however, likely affected disaster strike hand, mobile network technology require energy source operate also prone disaster strike united nation un aiming reach net zero co emission energy consumption radio access network ran component base station data centers, powered mainly non renewable sources, pose significant challenge sustainability effort transitioning green energy model powering ran infrastructure energy efficient solution crucial reducing carbon footprint ensuring next generation communication system align global sustainability goal paramount since information communication technology ict sector expected account percent global energy consumption hence, green energy technology integrated communication architecture considered development disaster resistant communication system order emphasize importance communication energy issue disaster scenarios, many survey paper presented section, brief summary explained understand gap literature filled survey paper network solution different phase disaster examined approach network vulnerability assessment strategy enhancing robustness existing network, solution achieving resilient routing, including disaster aware routing, presented hybrid communication network architecture combine ground, air, space level examined emergency communication scenarios, also challenge hybrid network discussed detailed survey design choice current status major wireless based emergency response system proposed literature examined, comprehensive comparison wireless based emergency response technology based various consideration including bandwidth, range, throughput performed concept called network box ie, network characterized low number physical device presented network designed provide demand connectivity rescue operator survivor disaster scenario support soldier battlefield mobile ad hoc network manet technology, established temporarily disaster stricken areas, studied different routing protocol systematic review study focused recent technology emergency communication system also presented widely used communication technology applied setting emergency communication network mitigate disaster aftermath examined author presented detailed survey paper post disaster communication mentioned wireless technology physical network layer issue proposed use case scenario work wireless technology classified three topic recovery terrestrial networks, installation aerial networks, using space satellite network physical layer issues, related work evaluated term channel modeling, coverage, capacity, radio resource management, localization, energy efficiency moreover, existing literature classified discussed term routing, delay tolerant networks, edge computing, integrated space air ground architecture network layer issue extensive research emergency communication technology, including satellite networks, ad hoc networks, cellular networks, wireless private network also presented network currently used emergency rescue future development direction emergency communication network also analyzed technological advancement like remote sensing, satellite imaging, social medium analyzed opportunity challenge different phase natural disaster internet thing iot solution field early warning natural disaster described detail discussed unmanned aerial vehicle uav utilized various task assessing extent damage, identifying affected areas, aiding search rescue mission natural disaster additionally, importance integrating uav wireless sensor network enhance data collection communication capability disaster stricken area emphasized importance uav based solution possible challenge disaster management discussed deeply systematic review focus uav path planning problem emergency situation also given public safety network psns crucial public protection disaster relief, reviewed different technology regulatory standardization issue psns reviewed potential device device communication dynamic wireless network dwns psns analyzed addition, progress standardization dwn public safety communication investigated psns also examined detail long term evolution lte technology respectively advantage uav different areas, including public safety, summarized importance iot technology disaster management system public safety communication highlighted disaster management issue integrated novel concept artificial intelligence ai machine learning ml blockchain also analyzed detail different survey systematic review conducted ai application analyze process social medium big data efficient disaster management overview current application ai disaster management mitigation, preparedness, response, recovery phase provided ml algorithm combined technology address disaster pandemic management examined detail survey integration blockchain aerial communication disaster management provided literature provided present communication solution disaster management however, sustainable eg, supported green energy resources, accessible everyone, economically feasible communication infrastructure withstand challenge disaster also must infrastructure resilient damage, easy repair, energy efficient also affordable accessible potential application recommendation renewable energy source sector discussed paper focus essential energy management approach improve energy efficiency well reduce fuel consumption grid cellular network whose powered hybrid power source including solar photovoltaic pv system diesel generator dg paper proposes new approach configure operate provide ancillary service smart grid depending various system parameter lte, simulation based feasibility analysis hybrid optimization model electric renewables homer used evaluate optimal system, energy production, total net present cost npc cost electricity coe greenhouse gas ghg emission considers cellular system fed renewable grid energy source author provide critical review current resilience definition metric examine widely used approach various organization researcher author review power system resilience term generation, networks, load also discus resilience enhancement strategy involving distributed generation, conventional renewable generators, energy storage, microgrids, load shifting, demand response importance addressing power system resilience standard resilience definition discussed author also review benefit smart microgrids enhancing system resilience demonstrate effectiveness numerical simulation case study author explore resilience framework metric analyzing damage cost risk associated extreme event moreover, examine case study network risk estimation effectiveness resilience improvement technique enhancing grid resilience comparative analysis survey relevant survey presented table indicated defined focused three main topic making comparison disaster phase pre, in, post key contribution energy, communication network structure space, air, ground, sea many devastating disaster series earthquake rkiye revealed importance considering communication energy solution together build resilient sustainable infrastructure earthquakes, communication disrupted even area communication infrastructure remained functional could used due power outage previous literature contains certain study concentrated communication solutions, others concentrated energy solutions, addressing aspect separately compared studies, best knowledge, study first one consider communication energy supply solution jointly different point view, survey focus integrated network model cover ground, air, space sea level contrary many existing survey literature integrated network model vital disaster management provides complete view situation combining information satellites, planes, ground sensors, sea source system offer real time data, improving accuracy damage assessment response planning also enables smooth communication coordination among different organization stakeholder unified data platform utilizing various data sources, integrated network model help risks, respond emergency effectively, allocate resource efficiently overall, integrated network strengthens disaster resilience improves management immediate long term impact another feature set article apart others communication energy technology examined detail phase disaster individually many publications, distinction thoroughly considered several emerging technology integrated disaster management enhance effectiveness across stage life cycle however, existing survey tend focus either communication technology energy solution isolation, missing critical integration enablers paper discus prospective solution sustainable communication infrastructure disaster relief management scenario key issue addressed paper follows paper identifies evaluates emerging key technology enhance communication network pre disaster, disaster, post disaster phase specifically examines technology effectively deployed support disaster relief management, emphasizing role maintaining communication continuity paper underscore critical importance developing robust resilient communication network withstand impact disasters, particularly scenario like turkiye earthquake highlight necessity integrating energy requirement sustainability resiliency, ensuring communication infrastructure remain operational even challenging condition paper explores main advantage emerging communication technologies, uav s, high altitude platform station hap mesh networks, satellite communication, bring disaster relief scenario compared traditional network discus technology enhance efficiency, speed, reliability communication emergencies, thereby improving overall disaster response effort paper address limitation existing new communication technology disaster relief management scenario evaluates challenge implementing technologies, including energy constraints, deployment difficulties, need continuous innovation overcome barrier paper review progress made constructing robust communication infrastructure support disaster scenarios, particular focus energy sustainability resiliency highlight case studies, including turkiye earthquakes, demonstrate infrastructure tested improved real world situations, ensuring enhanced preparedness response capability structure paper schematically displayed fig section ii provides comprehensive background global perspective current state disaster communication energy management section iii discus key enablers communication energy technologies, focusing emerging trend enhance resilience section iv address pre disaster communication energy planning, emphasizing importance proactive strategy mitigating disaster impact section provides detailed exploration technology enablers disaster response phase, including real time communication energy solution support rapid deployment coordination section vi cover post disaster communication planning, focusing rescue evacuation efforts, technology support critical operation section vii examines existing vendor product service section viii provides standardization efforts, ongoing project contribute building resilient infrastructure case study turkiye earthquake presented illustrate practical application discussed technology strategy section ix section paper discus open issues, challenge future direction realization sustainable resilient communication infrastructures, finally, section xi give conclusion paper disaster management life cycle consists pre disaster mitigation preparedness response, post disaster recovery activity phase play critical role mitigating effect disaster facilitating effective recovery detailed explanation phase given follows pre disaster phase pre disaster phase focus activity aimed mitigating effect disaster preparing occurrence phase includes mitigation mitigation involves identifying implementing measure reduce vulnerability community infrastructure disaster may include land use planning, building code regulations, infrastructure improvements, public awareness campaign preparedness preparedness activity include developing plans, procedures, resource respond effectively disaster includes developing emergency plans, conducting exercises, building communication networks, training emergency personnel goal pre disaster phase minimize potential damage loss life proactive well prepared disaster strike response phase response phase take place immediately disaster focus immediate action taken save lives, protect property, meet basic need affected people key element response phase include emergency warning communication rapid accurate communication critical response phase includes issuing early warnings, activating emergency alert systems, establishing communication channel emergency responder affected community search rescue search rescue operation carried find rescue people may trapped immediate danger includes coordination emergency team specialized equipment technique locate rescue survivor emergency shelter relief providing emergency shelter, food, water, medical assistance, essential affected people important aspect response phase emergency shelter distribution center set meet immediate need people affected disaster post disaster recovery phase post disaster recovery phase focus recovery reconstruction disaster affected community post disaster recovery phase aim build stronger resilient community incorporate lesson learned disaster reduce future vulnerability phase includes damage assessment assessing extent damage infrastructure, buildings, environment essential planning reconstruction process includes conducting structural assessments, evaluating damage critical facilities, identifying area require immediate attention infrastructure restoration repairing rebuilding damaged infrastructure roads, bridges, utilities, communication network important part reconstruction phase ensure restoration essential service facilitate return normalcy rehabilitation community recovery phase also includes helping affected community rebuild life includes psycho social support, facilitating access medical care education, assisting restoration livelihood overall, disaster management life cycle described encompasses comprehensive approach addressing challenge posed disaster focusing mitigation, preparedness, response, recovery, agency community work together minimize impact disaster improve resilience current terrestrial mobile network infrastructure inherently vulnerable disaster prone failure interruption event therefore, resilient mobile network structure needed cope natural disasters, becoming frequent due climate change hand, also meet un sustainability goals, least sense becoming cost energy effective operational point view, infrastructure also scalable easy deploy infrastructure redundancy one way ensure sustained operation even infrastructure layer severely damaged fig show multi layered communication infrastructure consisting integrated space based, air based, sea based, ground based networks, interconnected create comprehensive resilient communication system, especially disaster scenario traditional infrastructure may compromised space based network comprises geostationary earth orbit geo medium earth orbit meo low earth orbit leo satellite form mesh network global communication coverage satellite interconnected via cross network link communicate air based network via dedicated downlinks air based network represented hap uavs, act intermediary point space based hap ground based infrastructure hap stationed stratosphere connect uavs aircrafts, forming dynamic network layer provides communication service large areas, including disaster affected area sea based network consists maritime platform ship equipped communication capability platform connected air based network ground stations, facilitating seamless communication ocean large water body ground based network consists various element bss, gateways, autonomous vehicles, smart device component interconnected via network connection facilitate communication within ground network figure also show ground based network connected layer via inter network link ensures network layer work together provide continuous reliable communication various environment satellite network play crucial role disaster response communication planning, particularly context earthquakes, due wide coverage, resilience, ability provide connectivity geographically remote damaged area operate independently terrestrial networks, providing reliable resilient communication infrastructure support emergency response effort remote hard reach area used establish temporary communication infrastructure disaster prone area example, satellite based mobile network deployed provide connectivity emergency responder local community aftermath disaster, terrestrial network may damaged non functional satellite network offer wide area coverage, allowing communication reach even remote inaccessible region affected earthquake provide connectivity disaster response teams, emergency personnel, affected communities, facilitating real time communication, coordination, information exchange large geographical area rescue teams, government agencies, relief organization use satellite connectivity share vital information, coordinate resources, efficiently manage rescue relief operation satellite equipped remote sensing capability provide valuable data disaster response planning decision making capture high resolution imagery, monitor ground movements, create accurate map affected area information aid identifying critical infrastructure damage, assessing extent disaster, guiding resource allocation deployment regarding early warning systems, satellite imagery remote sensing technology used monitor natural hazard enabling early warning better preparedness pre disaster phase, satellite network used establish communication channel emergency responders, local communities, stakeholder network provide connectivity remote hard reach areas, terrestrial network may available may unreliable satellite network also used support exchange critical information, maps, images, video feed emergency responder command center also used support warning dissemination critical information local community example, satellite based warning system used alert people disaster prone area impending natural disaster emergency warning system used deliver text messages, voice messages, form communication people remote hard reach area another use satellite network pre disaster communication planning support situational awareness information sharing among emergency responder satellite network provide real time information extent damage, location survivors, critical information used support emergency response effort although satellite communication offer significant benefits, satellite link susceptible rain atmospheric conditions, disrupt communication storm hurricane additionally, latency communication pose limitation space service specialized equipment often required satellite communication, might easily accessible emergency air based network incorporate innovative technology like haps, tethered balloons, uav haps, particular, hold significant potential enhancing resilience integrated space air ground sea network natural disaster earthquake hap offer several advantage expansive surface area enables almost self sufficient energy generation solar panel single hap serve substitute multiple damaged terrestrial bs, providing extensive coverage essentially, single hap function multi sector directional bs, establishing direct line sight los connection outdoor users, compensating distance related path loss scattering loss without need additional intermediate device like relays, unlike satellite starlink leo constellation, limited los window unlike satellites, hap remain stationary, ensuring stable continuous service without orbital movements, thus facilitating rapid deployment, especially crucial immediate aftermath earthquake ground access affected area challenging hap serf vital alternative ran infrastructure also backhaul efficiently redirect backhaul traffic unaffected area via free space optic fso terahertz thz communication link remote hap ground station additionally, earthquakes, fiber optic line may sustain damage, rendering inactive, hap remain physically unaffected weather event mentioned hap expected function stratospheric climate condition moreover, according international telecommunication union itu decision world radiocommunication conference wrc sub ghz frequency band band allocated high altitude international mobile telecommunication base station hibs compared ka ku band used satellites, band relatively le affected weather event way, uninterrupted service delivery ensured tethered balloon based emergency network system balloon deploy wireless communication network disaster area used wide range communication service including voice, data, video comparatively inexpensive scaled meet need different disaster scenario fully wireless communication solution relying tethered balloon deployed immediately, reliably, easily during, even disaster proposed tethered balloon already used number disaster scenarios, including puerto rico peru disaster respectively uav usage aerial monitoring communication transmission earthquake zone innovative approach gained popularity recent year used establish temporary communication infrastructure disaster prone area example, uavs equipped wireless communication equipment deployed create ad hoc network extend range existing networks, providing connectivity emergency responder local community uavs also equipped thermal imaging camera locate people need assistance identify area high temperature, may indicate gas leak hazard uavs also used support situational awareness information sharing among emergency responder aerial assessment monitoring, drone equipped camera sensor provide real time information extent damage rapid aerial assessment disaster affected areas, location survivors, critical information used support emergency response search rescue effort one important application uavs disaster relief ability provide high resolution aerial imagery used damage infrastructure, identify area requiring search rescue, plan evacuation route hand, drone may difficulty massive packet loss handling enormous traffic used post disaster reconnaissance service area traditional communication network disrupted, uavs equipped communication equipment serve temporary solution act communication relay establish communication first responder affected community particularly useful mountainous remote area cell tower communication infrastructure may damaged order benefit uav full efficiency, problem energy supply trajectory design must overcome ground based network comprise diverse element cellular networks, terrestrial internet utilizes physical cable like fiber optic copper wire data transmission long distance mobile ad hoc network unlike air based networks, ground based network topology tends fixed le mobile natural disaster like hurricanes, earthquakes, floods, ground based communication infrastructure face significant risk severe damage complete destruction technology, offering decentralized resilient communication, effective approach address challenge ground based network disaster response scenario mostly useful scenario use grid power inaccessible, use battery power feasible used enhance communication capability improve coordination among responder affected individual aftermath earthquake, cellular network may congested disrupted, communication provide reliable mean communication responders, allowing share critical information, coordinate efforts, exchange update situation even absence infrastructure ad hoc network formed group mobile device communicate directly, without need centralized infrastructure cellular tower wireless fidelity wi fi access point eg, wireless mesh network wmn based ad hoc network support dissemination emergency alerts, location sharing, resource coordination, survivor tracking search rescue operations, rescuer equipped capable device establish direct communication survivors, allowing gather information location, status, immediate need wireless personal networks, bluetooth, long range lora wi fi technology used establish ad hoc network operate independently cellular network traditional communication infrastructure network established using personal device equipped wireless communication capability vehicular network used variety way disaster response scenario improve speed, efficiency, effectiveness emergency response traditional communication transportation infrastructure severely damaged disrupted first, used establish communication responder affected areas, especially area traditional communication infrastructure damaged overwhelmed second, facilitate transport relief supplies, medical personnel, resource affected area third, vehicle network used collect data road conditions, infrastructure damage, information used create map help responder navigate affected area fourth, vehicle network used coordinate search rescue efforts, especially hard reach area area traditional search rescue method impractical finally, used coordinate emergency response effort among various agency organization ensure resource used effectively efficiently sea based network crucial importance conventional communication infrastructure coastal region collapse disaster situation within network structure, various components, ship unmanned surface vehicles, enhance communication utilizing uavs, haps, satellite technologies, depending respective position expand coverage resilience, offering alternative routes, mitigating risk network congestion failure moreover, facilitate interoperability among diverse network type eg, naval vessels, aircraft, ground based command control center standard customizable protocols, facilitating seamless communication across different service agency emerging technology communication enablers integrated sensing communication isac technology offer significant utility earthquake disaster relief combining multiple sensing technology communication system provide real time, actionable data ground condition first, isac variety sensing method seismic sensors, radar, lidar light detection ranging wireless radio frequency sensing accelerate damage assessment post earthquake sensor used monitor structural integrity, ground movement change environment transmit data immediately via communication system rapid transfer information help prioritize recovery effort locate area require urgent action second, isac help locate survivor trapped debris using thermal imaging, sound vibration sensors, rf based motion detector detect movement, sign life, body heat vital data immediately relayed rescue team speed search rescue operation third, isac provides real time update location survivors, severity damage, progress relief effort made possible combination wireless sensor networks, drone surveillance, ground based radar, enabling informed decision making coordinated response finally, isac support seamless communication response team enabling exchange information real time secure communication links, optimizing resource allocation, streamlining relief effort integrated access backhaul iab technology used pre disaster scenario enhance resilience communication infrastructure ensure connectivity remains available disaster iab combine functionality wireless backhaul access networks, enabling wireless network use frequency band access backhaul allows easier deployment small cell wireless access points, well efficient use available spectrum pre disaster scenario, iab used provide enhanced connectivity critical infrastructure service hospitals, emergency services, government office technology also used establish network small cell wireless access point high risk areas, providing redundancy backup connectivity case emergency ai based solution also used address several problem pre disaster communication risk assessment predictive analytics, ai driven model analyze historical data, climate patterns, variable predict disaster risk specific region paper provides overview current application ai disaster management four phase mitigation, preparedness, response, recovery open ran emergent technology build open interface telecom operator build network mixing equipment multiple vendor vision create cost effective network new innovation enhanced competition modular nature useful disaster situation broken component rapidly replaced new component vendor instead waiting original vendor deliver exact copy broken component make telecom network compliant open ran well suited maintain connectivity facilitate emergency response recovery operation methodology deploying optimizing fl task ran deliver distributed intelligence application studied software defined networking sdn offer vital solution disaster situations, enhance network control, communication efficiency, overall stability survey disaster resilient sdn network presented hierarchical, failure disaster resilient transport software defined network sdn control plane designed, heuristic post failure switch controller reassignment proposed result indicate proposed scheme achieve much higher disaster failure resiliency, cost slightly larger network resource utilization geographical information system gi technology provide powerful tool visualizing, analyzing, interpreting data related disaster risks, vulnerabilities, resource gi help identify vulnerable area analyzing geographic demographic data, enabling better planning preparedness disasters, gi integrates real time data like weather report satellite imagery provide date situational awareness gi optimizes resource allocation identifying efficient route location aid distribution analyzing transportation network population density, gi help design effective evacuation route plan disasters, gi damage informs recovery effort mapping affected area identifying critical infrastructure gi tool also enhance public communication providing clear visual information risks, safety measures, recovery effort microgrids microgrids designed enhance reliability, resilience, efficiency electrical energy distribution, particularly remote area operate autonomously parallel main grid, ensuring uninterrupted electricity generation failure outage energy grid expected shift centralized energy production distributed localized model near future microgrid component include renewable energy source solar panel wind turbines, distributed generation units, energy storage systems, electric vehicle electric vehicle ev utility grid combining multiple energy source eg, solar, wind, diesel generator decentralized energy solutions, microgrids enhance reliability flexibility grid response disaster additionally, powering terrestrial communication system microgrid structure significantly reduce energy related issue disaster renewable energy source given increasing global concern climate change imperative reduce energy costs, especially grid areas, growing interest leveraging also play crucial role improving energy sustainability resilience within microgrids solar, wind, biomass, hydropower example provide clean, sustainable, decentralized power generation terrestrial networks, become focal point integrating res, solar wind power adopting renewable energy terrestrial network component offer numerous opportunity energy conservation, sustainability, resilience disaster battery energy storage system designed store energy renewable source utility grid high capacity battery system stored energy support system peak energy demand main grid meet energy need power outage play critical role communication network providing backup power outages, ensuring continuous operation essential communication infrastructure integration communication system energy storage system solution significant potential various applications, including mobile bss, data centers, emergency service communication, railway communication systems, maritime communication advanced future power management system reliable electrical power essential functioning modern infrastructure, powering homes, businesses, bss, smart grid advanced power grid system incorporates digital technology enhance efficiency, reliability, sustainability electrical energy production, distribution, consumption integrating distributed energy resource solar panels, wind turbines, besss, smart grid ensure continuous power supply critical communication infrastructure, even widespread outage smart grid automatically detect isolate faults, minimizing downtime maintaining service continuity also help conserve energy balance load demand response strategies, crucial emergency energy resource may limited implementing demand response strategies, energy usage adjusted based supply conditions, ensuring critical communication infrastructure remains powered backup generator power supply tool backup generator power supply tools, uninterrupted power supply ups essential ensuring communication system remain operational disaster system provide crucial layer redundancy supplying power main source disrupted, thus preventing critical communication infrastructure going offline ups system provide immediate, short term power outage, allowing seamless transition protecting sensitive equipment damage caused sudden power loss fluctuation hand, despite requiring fuel replenishment operate extended periods, backup generator offer longer term power solutions, ensuring sustained operation communication network prolonged outage tool vital maintaining emergency communication services, supporting coordination efforts, ensuring continuous flow information, crucial disaster response recovery integration reliable backup power system significantly enhances robustness dependability communication networks, enabling function effectively adverse condition energy efficient communication technology energy efficient technologies, low power communication device energy efficient network equipment, crucial ensuring sustainability resilience modern communication system low power communication device help extend battery life, critical situation energy limited, disaster remote grid area restricted intermittent power supply similarly, energy efficient network equipment improves overall efficiency communication infrastructure, allowing data transmitted using le energy enabling use produce le power traditional source save cost contributes sustainability reducing carbon footprint terrestrial communication network furthermore, disaster scenarios, energy efficient technology help maintain critical communication service extended period using backup power sources, thus improving resilience communication system approach energy harvesting significantly reduce energy consumption constraint mobile device disaster also important battery powered system uavs, support terrestrial communication extend coverage natural disasters, operate efficiently meet energy requirement finally, table ii show summary technology disaster response planning phase communication energy domain consider approach taken disaster occurs save guard network, communication energy perspective pre disaster communication planning warning system include various communication technology protocol fema provides disaster emergency communication geographically dispersed mobile emergency response support detachment pre positioned fleet mobile communication office vehicle common alerting protocol used enhance messaging disaster early warning communication system present emerging disruptive technology communication protocol employed internationally early warning communication system information communication tool internet, gis, remote sensing, satellite communication used disaster preparedness, warning, forecasting remote sensing technology enables collection environmental data distance, typically use satellite aircraft beneficial monitoring tracking natural disaster like hurricanes, wildfires, flood also valuable creating map model illustrate damage caused natural disasters, helping decision maker prioritize response effort allocate resource effectively requires proper tool like gi handle large amount data obtained remote sensing thus, remote sensing gi technology discussed different type natural disaster warning monitoring duty radar satellite imaging technology also vital tool monitoring managing natural disasters, provide critical data surface atmosphere earth author demonstrate research design mobile based decision support flood early warning system ad hoc network used pre disaster communication planning warning providing flexible dynamic communication infrastructure quickly deployed disaster prone area pre disaster phase, ad hoc network used create communication channel emergency responders, local communities, stakeholder network established using mobile device quick easy set emergency ad hoc network also used alert disseminate important information local community example, community member receive alert warning impending natural disaster emergency via mobile device another use ad hoc network pre disaster communication planning support situational awareness information sharing among emergency responder ad hoc network facilitate exchange real time information maps, image video emergency responder command center different ad hoc communication paradigm manet, vehicular ad hoc network vanet wmn, tetra, etc discussed detail disaster management scenario uavs, generally known drones, valuable tool pre disaster communication planning warning, providing versatile platform gathering disseminating critical information disaster prone area supporting emergency response effort one use uavs pre disaster communication planning conduct aerial survey disaster prone area identify potential hazard vulnerability survey used generate detailed map model terrain, well identify infrastructure, buildings, critical asset may risk disaster another use uavs pre disaster communication planning support warning disseminate important information local community uavs equipped loudspeaker audio visual device broadcast warning alert people disaster prone area uavs also used deliver essential supply first aid kit food water people remote hard reach area uav used data gathering tool iot device also platform energy transfer energy limited iot devices, distributed disaster area iot offer significant potential detection management natural disaster iot sensor deployed collect data monitor environmental factor temperature, humidity, air quality, seismic activity, providing early warning potential natural disaster data used detect anomaly may indicate presence natural hazards, earthquake data also used identify vulnerability risk critical infrastructure, bridges, dams, power plants, support situational awareness hazard identification wireless sensor network wsn used environmental monitoring iot device sensor collect data environmental condition real time, critical early warning system situational awareness iot wsn used pre disaster communication planning warning providing real time data analytics used support situational awareness, hazard identification, early warning systems, particularly critical infrastructure gas oil refinery iot network also used support situational awareness information sharing among emergency responder iot based sensor provide real time information extent damage, location survivors, critical information used support emergency response effort distributing many iot devices, usually heterogeneous, communication protocol data formats, large scale disaster may face challenge manage diversity iot device applications, gateway required connect traditional communication network iot domain however, gateway typically centralized, making impractical use manet environment often encountered large scale disaster thus, distributed network function virtualization nfv sdn based iot gateway architecture presented ai, particularly ml deep learning, demonstrated significant advantage risk mitigation, assessing vulnerability urban area seismic hazards, evaluating site suitability, enhancing early warning systems, managing natural disaster existing literature paper focus supporting mission critical application emergency scenario enhancing network adaptability intelligence ai ml algorithm envisioned edge network analyze data make real time decision addition, cognitive radio technology dynamically allocate spectrum resource based network condition demand application digital twin emergency management civil infrastructure emci surveyed author use digital twin model simulate predict impact disaster urban infrastructure basically combine ai iot technology real time monitoring decision making data driven approach also employed enhance disaster preparedness response social medium platform serve three critical role disaster quickly gathering situational awareness information, ii facilitating self organized peer peer help, iii allowing disaster management agency hear public disaster, social medium leveraged pinpoint area people need assistance search rescue, medical aid, access food water additionally, social medium serf vital tool disseminating information coordinating relief effort need moreover, training simulation, augmented reality ar virtual reality vr technology used train responder simulated disaster scenario improve readiness real world situation technology enablers energy support pre disaster scenario refer use various technological solution ensure availability resilience energy system disaster occurs enablers aim improve energy infrastructure, increase energy generation storage capabilities, strengthen overall resilience energy supply potential disaster play crucial role advancing sustainability terrestrial communication system communication system consume approximately four time energy system implementation technology massive multiple input multiple output mimo radio frequency rf chain electronic components, result rising trend power consumption even energy efficiency also improves since data capacity increase faster power demand energy intensive communication infrastructure continues grow, integrating offer pathway significantly reduce system carbon footprint study explores incorporating cellular system affect overall power consumption, revealing annual power saving surpassed system relied solely conventional energy grid study investigates sustainable energy solution bss, incorporating reduce energy consumption carbon emission integrating terrestrial communication system support sustainability goals, enhances energy security, reduces operational cost time moreover, contribute resilience communication system providing decentralized diversified energy supply, particularly critical remote grid area traditional power source may unreliable unavailable integrating solar wind, communication infrastructure significantly reduce carbon footprint, contributing environmental sustainability study examines model evaluates energy performance grid, eco friendly cellular bs, incorporating solar power system, system, hydrogen energy storage study investigates relati",networking and internet architecture
"binary code similarity detection via graph contrastive learning intermediate representation introduction related work irbindiff experimental setup experimental result conclusion ethical consideration appendix data pre processing sumpplements appendix language model pre training sumpplements appendix dataset statistic appendix one many search supplement instruction reporting error binary code similarity detection bcsd llvm ir data pre processing language model pre training graph momentum contrastive learning similarity detection datasets baseline metric implementation one one comparison one many search ablation study extract control flow graph sumpplements instruction simplification sumpplements binary code similarity detection bcsd play crucial role numerous fields, including vulnerability detection, malware analysis, code reuse identification iot device proliferate rapidly evolve, highly heterogeneous hardware architecture complex compilation settings, coupled demand large scale function retrieval practical applications, put forward higher requirement bcsd method paper, propose irbindiff, mitigates compilation difference leveraging llvm ir higher level semantic abstraction, integrates pre trained language model graph neural network capture semantic structural information different perspective introducing momentum contrastive learning, effectively enhances retrieval capability large scale candidate function sets, distinguishing subtle function similarity difference extensive experiments, conducted varied compilation settings, demonstrate irbindiff outperforms leading bcsd method one one comparison one many search scenario binary code similarity detection via graph contrastive learning intermediate representation xiuwei shang li hu shaoyin cheng guoqiang chen benlong wu weiming zhang nenghai yu university science technology china anhui province key laboratory digital security qi anxin technology research institute shangxw,pdxbshx,dizzylong mailustceducn sycheng,zhangwm,ynh ustceducn guoqiangchen qianxincom binary code similarity detection bcsd aim determine whether two binary code snippet similar functional semantics, hold significant importance various domain vulnerability detection david et al malware analysis nguyen hung et al software supply chain analysis basit jarzabek etc particularly, explosive growth iot device statista high heterogeneity hardware architecture software platform across different device led increase diversity complexity binary files, thus posing higher demand bcsd technique recent years, advancement natural language processing technologies, deep learning driven bcsd method gradually emerged du et al haq caballero typically embed binary code assembly form high dimensional vector space evaluate functional similarity code snippet calculating vector similarity instance, vulseeker gao et al gemini xu et al ordermatters leverage graph embedding technique encode control flow graph binary code vectors, capturing control flow data dependencies, asm vec ding et al safe massarelli et al palmtree li et al employ language model directly learn representation instruction sequences, capturing instruction order contextual semantics although method shown significant potential capturing syntactic semantic feature binary code, still face challenge complex diverse practical application scenario complex compilation option iot device firmware typically based different architecture us various compiler optimization options, resulting binary may appear entirely different form, even compiled codebase, shown example figure therefore, bcsd method must robust complex compilation setting large scale candidate function retrieval real world large scale firmware analysis, often necessary retrieve similar function vast number unrelated function requires bcsd method ability capture subtle semantic difference large scale datasets paper, present irbindiff, novel intermediate representation based graph contrastive learning method, aim address aforementioned challenge support real world binary code similarity detection firstly, lifting binary file llvm ir, flexible architecture independent intermediate representation, effectively mitigate discrepancy caused underlying hardware compilation option barchi et al llvm ir provides unified high level semantic abstraction machine code, making ideal choice handling complex compilation settings, thereby enabling model apply highly heterogeneous scenario iot device firmware secondly, irbindiff combine pre trained language model graph neural network extract functional feature semantic structural aspect pre trained language model capture semantic syntactic pattern serialized representation simplified normalized llvm ir instructions, graph neural network encodes extracted control flow graph, capturing structural information dependency within function finally, introduce momentum contrastive learning enhance model retrieval capability large scale candidate function maintaining dynamic queue large number negative samples, model learn diverse set negatives, effectively distinguishing semantically similar function unrelated one additionally, momentum update mechanism gradually adjusts parameter key encoder, ensuring stability throughout training process contribution summarized follows comprehensive pipeline construct comprehensive pipeline lift binary code llvm ir address challenge posed complex compilation options, extracting optimizing syntactic structure semantic information innovative methodology introduce irbindiff, combine pre trained language model graph neural network deeply learn functional feature llvm ir semantic structural levels, respectively, utilizes momentum contrastive learning enhance ability capture subtle difference large set candidate function effective experimental conduct extensive experiment across various compilation options, demonstrating irbindiff outperforms baseline one one comparison one many search scenario traditional bcsd method often rely raw bytecode manually crafted rule assess code similarity example, diff liu et al us raw binary byte input siamese network based convolutional neural network compute similarity however, fails capture program unique logic functional feature method like discovre eschweiler et al binfinder qasem et al extract statistical feature function, constant strings, similarity detection, gemini xu et al vulseeker gao et al use hand crafted feature represent basic block apply graph embedding technique function level similarity however, feature based approach overly rely domain expertise struggle generalize diverse application recently, inspired natural language processing techniques, representation learning based bcsd method gradually become mainstream innereye zuo et al safe massarelli et al treat assembly instruction word use word vec mikolov model representation, asm vec ding et al palmtree li et al take finer grained approach treating instruction sentence opcodes operand words, leveraging sequence language model paper, adopt representation learning approach, focusing instruction sequence control flow structure llvm ir typical, well formatted universal intermediate representation compilation process, bridge source code machine code, provide common optimization platform multiple high level language compiler backends lattner adve compared directly handling assembly code, llvm ir offer higher level semantic abstraction, allowing binary different architecture compilation setting lifted unified representation additionally, good readability standardized syntax enable model accurately extract core semantics specific example llvm ir shown appendix section elucidates rationale architecture designed method irbindiff, consists four parts, illustrated figure lifting binary llvm ir binary files, use reverse engineering tool retdec oustek et al decompilation, call bin llvmir lift binary llvm ir format, obtaining file extension extract control flow graph previous work xu et al gao et al ding et al shown structural information binary code, control flow graph cfg provides crucial semantic insight similarity detection end, employ regular expression matching parse llvm ir files, performing function boundary division, basic block division, cfg extraction detailed process explained appendix so, represent function llvm ir graph, node represent basic block edge represent control flow relationship block instruction simplification instruction sequence llvm ir contain many instruction unrelated function semantics, introduce additional computational overhead also dilute importance key instructions, thereby impairing embedding performance address this, empirically devise instruction simplification strategy, pruning redundant instruction preserving essential one approach, detailed appendix enables language model extract precise semantic information function instruction tokenization normalization ir instruction relatively complex internal structures, fully understanding internal detail crucial representing instruction therefore, instead treating entire instruction single word, apply fine grained tokenization strategy, regarding instruction sentence token word specifically, split instruction based spaces, punctuation eg, underscore instance, give llvm ir instruction call cxa begin catch result divide call cxa begin catch result mitigate data sparsity vocabulary oov issue caused diversity identifier constants, inspired related research gao et al empirically establish instruction normalization rule replace identifier form dec label pc xxxx label replace global variables, global var global treat numeric string absolute value less constant value replace positive negative according sign treat numeric string absolute value greater address replace address remove prefix suffix number identifier like reg mem reload storemerge brmerge select thread intuitive explanation given appendix random walk sampling generate training input language model, use random walk li et al algorithm sample instruction pairs, input graph structure section already extracted cfg function, node represents basic block, instruction within basic block executed sequentially extend cfg node represents single instruction set instruction starting point sampling, randomly select node successor current node sampling endpoint probability random walk node successor node given denotes number successor node performing random walk sampling, obtain corpus instruction pair language model training llvm ir language model based bert devlin multi layer bidirectional transformer vaswani encoder take instruction pair input shown figure first token cl mark begining sequence, token sep used separate instruction pair additionally, combine position embedding, segment embedding token embedding input language model position embedding represent position token within input sequence, segment embedding indicate whether token belongs first second instruction pair use two unsupervised learning task pre training task masked language model introduce mlm task help model understand internal structure detail llvm ir instruction figure show example, first randomly select token replace replaced mask replaced random token, remain unchanged model required predict original token corresponding replaced position loss function us cross entropy loss follows represents actual token, represents predicted token, masked token set size vocabulary task next sentence prediction set nsp task enable model capture control flow relationship adjacent instruction task involves determining whether two instruction control flow neighbor shown figure input instruction pair b, next instruction following a, regarded positive example labeled isnext otherwise regarded negative example labeled notnext positive negative example constitute training data feed final hidden state cl token nsp head binary classification loss function computed using cross entropy loss represents actual label, represents predicted result, represents training set total loss function llvm ir language model combination two loss function completing pre training llvm ir language model, input instruction sequence model unit basic blocks, obtain embedding basic block level gated graph neural network obtaining embedding basic blocks, use ggnn li et al transfer aggregate information adjacent basic block cfg learn function embedding feature specifically, input cfg represented initial state node dimensional embedding, ie, time step, basic block node adjacent node transfer information, follows matrix transformation matrix adjacent node represents aggregate representation node step node fully updated, information basic block node used calculate output representation entire cfg, follows represent two mlp, sigmoid function momentum contrastive learning bring similar function ie, positive sample closer feature space, pushing dissimilar function negative sample apart, use contrastive learning training specifically, shown figure given function sample one positive sample negative sample encoded using two ggnn shared weight existing research gao et al shown increasing coverage negative sample improve contrastive learning performance therefore, adopt solution proposed moco et al maintains embedding queue facilitate training larger batch size minimizing memory consumption however, due size queue, directly back propagating update key encoder challenging, use momentum update instead represents parameter query encoder, represents parameter key encoder, momentum coefficient use infonce loss function temperature hyperparameter, embeddings respectively function pair determine similarity based source file name function name ie, whether compiled source code assigning label similar dissimilar cosine distance used calculate similarity embedding vector formula shown represents th component vector referring previous work marcelli et al ding et al use following project widely used practice related works, ie binutils coreutils clamav curl diffutils findutils gmp imagemagick libmicro libtomcrypt nmap openssl putty sqlite unrar zlib cross compile project obtain binary file different compilation environment specifically, use two compiler family gcc clang four version each, five optimization level o five target architecture arm arm mips disable function inlining compilation avoid introducing noise total, obtain binary completing data pre processing section devided training test set project subsequent step datasets detail provided appendix validate capability irbindiff complex compilation environments, identify seven different tasks, ie xc cross compiler xo cross optimization xa cross architecture combination example, task xo xa represents function pair different optimization level architecture use compiler experimental setup previous work pei et al li et al construct balanced testset task, consisting positive function pair negative function pairs, well unbalanced testset consisting positive function pair negative function pair complete dataset construction process shown figure compare irbindiff seven baseline zeek shalev partush performs dataflow analysis basic block level computes stands, train two layer fully cnn learn similarity task gemini xu et al extract manually crafted feature basic block construct acfg, us gnn representation asm vec ding et al utilizes random walk cfg sample instruction sequences, us unsupervised learning model pv dm learn assembly function representation safe massarelli et al us word vec model generate assembly instruction embeddings, adopts rnn attention mechanism generate function embeddings gmn li et al directly us graph matching network based control flow graph calculate similarity two function trex pei et al us transfer learning based framework generate function embeddings based micro trace function palmtree li et al add pre training task related code structure improve bert model, performs self supervised pre training large scale unlabeled binary corpus generate instruction embeddings following previous research marcelli et al pei et al conduct experimental evaluation two scenario one one comparison given pair binary functions, return similarity score determine whether similar regarded binary classification task, use area curve auc receiver operating characteristic roc curve evaluation metric, comprehensive measure incorporates possible classification threshold one many search given query binary function f, binay function pool p, contains function similar f, dissimilar functions, objective retrieve top function pool ranked similarity rank retrieved function denoted rank indicator function recall defined follows represents total number query recall emphasizes retrieval coverage rate, mrr place greater emphasis order positional relationship within rank list calculated asm vec palmtree support cross architecture xa task experimental environment machine running ubuntu os, equipped nvidia geforce rtx gpu core intel xeon gold cpu use python pytorch implement irbindiff experiment data pre processing stage, filter function less basic blocks, tokenize simplified normalized instructions, generate vocabulary size language model pre training stage, use adam optimizer initial learning rate hidden layers, hidden dimension, multi head attention, training batches, epoch basic block embedding generated represented dimensional vector graph contrastive learning stage, divide training validation set ratio use adam optimizer initial learning rate weight decay value loss function infonce model encoding layer unit per layer, training batches, epoch momentum coefficient embedding queue length function embedding generated represented dimensional vector function similarity detection one one scenario basic relatively simple task bcsd referring setting previous work li et al pei et al marcelli et al use balanced unbalanced testset mentioned section evaluate table show auc score irbindiff baseline overall, irbindiff outperforms method xc, xo, xa combined task balanced testset specifically, irbindiff auc score seven task improved average compared baseline method example, difficult xc xo xa task, irbindiff get second highest gemini get gmn safe perform significantly worse, worth noting asm vec palmtree support instruction set architecture, cannot compared cross architecture xa task unbalanced testset, irbindiff also performs well despite challenging data distribution xo xa task, although irbindiff fell slightly behind gemini trex margin still exhibit robust overall performance compared zeek, gemini, safe, gmn, trex, average auc score irbindiff improved conclusion, superior robust performance irbindiff attributed ability lift binary code unified llvm ir representation, effectively mitigating discrepancy caused different compilation option one many search present greater challenge highly practical scenario, example, large scale firmware analysis vulnerability detection, usually necessary retrieve similar function large scale candidate function zhao et al evaluate this, use unbalanced testset described section specifically, query function, construct candidate function pool size consisting similar dissimilar function table present recall mrr score irbindiff baseline notably, irbindiff achieves average relative improvement recall across seven task compared seven baseline method especially challenging xc xa xo tasks, irbindiffrelatively improves recall score mrr scores, irbindiff trail gemini xa mere point overall, compared one one comparison, irbindiff demonstrates significant performance advantage one many search scenario performance boost primarily attributed introduction momentum contrastive learning, effectively enhances model ability distinguish subtle functional difference large scale candidate pools, enabling accurately identify similar function figure report recall score method different value shown, task xo xc xo xa, difference compilation option increases, search performance bcsd method show downward trend however, task, value increases, irbindiff consistently surpasses baseline methods, recall curve remaining others, demonstrating higher accuracy every recall level asm vec palmtree support cross architecture xa task conduct ablation study comparing irbindiff following variant better understand contribution component norm removing instruction normalization process first part section plm removing pre trained language model described section graph removing graph momentum contrastive learning described section shown table table removing component negatively impact overall performance irbindiff among them, instruction normalization component least impact performance, norm variant causing average performance drop point one one one many scenarios, respectively, contribution reducing training resource time overhead extremely substantial contrast, plm variant, remove pre trained language model, result average drop point two scenario highlight significance llvm ir higher level semantic abstraction fine grained semantic understanding provided pre trained language model finally, graph momentum contrastive learning component prof critical irbindiff graph variant, excludes component, lead significant performance drop points, particularly task involving xa conclusion supported recall curve different values, shown figure underscore essential role three component overall performance paper, present irbindiff, novel graph momentum contrastive learning approach based intermediate representation llvm ir binary code similarity detection approach successfully tackle challenge complex compilation option large scale candidate function retrieval real world applications, consistently outperforming existing leading solution across various experimental task scenario conclusion, irbindiff offer robust practical research solution binary code similarity detection although proposed irbindiff performs well experiments, still certain limitation need addressed subsequent study first, irbindiff currently take account code obfuscation code obfuscation commonly used evade static analysis significantly alter logic structure program, making challenging analyze consider code obfuscation orthogonal issue, future advancement handling obfuscation technique could complement existing capability irbindiff secondly, work us sixteen engineering project construct binary code datasets, may encompass possible application scenario nevertheless, project widely utilized related research practical application fully reflect diversity software real world, thus alleviating potential concern generalizability method finally, irbindiff overall performance partly dependent generation preprocessing llvm ir, remains computationally intensive task particularly evident processing large scale binary files, efficiency retdec decompilation tool may present bottleneck state research strictly adheres ethical scientific research principle field computer science llvm ir language clear semantics, file generated decompiling binary file readable form example function shown figure obtained bind engine function afalgso file openssl project example, observed llvm ir resembles risc instruction set, supporting simple operation addition, subtraction, branching, comparison, instruction presented three address format function boundary division shown figure function llvm ir begin keyword define sequentially traverse llvm ir statements, using regular expression identify define add subsequent statement current function block encounter next define reach end file, thereby marking end function block basic block division llvm provides opt command obtain graphical cfg, need extract text form therefore, employ regular expression matching identify identifier indicating basic block call relationship function block construct cfg observed figure identifier dec label pc xxxx indicates start basic block, preds dec label pc xxxx indicates predecessor current basic block instance, line dec label pc ac preds dec label pc c, dec label pc indicates basic block dec label pc dec label pc predecessor dec label pc ac therefore, within function block, scan statement, using regular expression identify dec label pc xxxx numbered identifier stored list node cfg subsequently, statement following identifier added current basic block encounter next identifier reach end function block, thus concluding current basic block control flow graph extraction completing division basic blocks, check whether basic block contains preds identifier present, locate dec label pc xxxx follows identifier list form pair current basic block identifier, representing edge cfg, stored another list extraction node edge complete, extraction cfg also finalized order prune redundant instruction preserving essential ones, empirically design following instruction simplification strategy basic block identifier llvm ir, identifier dec label pc xxxx preds dec label pc xxxx indicate start basic block predecessors, respectively, without actual semantics since already divided basic block boundary extracted cfg appendix retaining identifier unnecessary, remove address information statement insnaddr xx following instruction indicates address instruction different address different files, may disrupt model semantic learning lack inherent meaning, delete memory order directive shown figure function body concludes list order directive uselistorder directive appears terminator last basic block encodes memory order usage list actual instruction affect semantics ir, delete provide intuitive illustration process instruction tokenization normalization, present example table rule id column corresponds normalization rule number discussed section figure present example random walk sampling instruction pair specifically, original cfg consists basic block jump control flow, node represent basic blocks, edge represent jump control flow splitting basic block individual instruction adding sequential control flow them, cfg extended instruction level cfg, node represent single instruction edge represent either jump sequential control flow subsequently, perform random walk sampling instruction level cfg, described section statistic training test datasets shown table asm vec palmtree support cross architecture xa task recall recall one many search unbalanced set shown table ",software engineering
"identifying factor contributing bad day software developer mixed method study introduction ii related work iii method iv finding limitation vi conclusion implication instruction reporting error ii role emotion developer productivity ii measuring understanding developer productivity iii data collection iii data analysis iv rq factor cause bad day developer iv rq way developer describe bad day factor impact work iv rq use telemetry data validate factor cause bad day developer software development dynamic activity requires engineer work effectively tools, processes, collaborative team result, presence friction significantly hinder productivity, increase frustration, contribute low morale among developer contrast, higher satisfaction level positively correlated higher level perceived productivity hence, understanding factor cause bad experience developer critical fostering positive productive engineering environment research, employed mixed method approach, including interviews, surveys, diary studies, analysis developer telemetry data uncover triangulate common factor cause bad day developer interview involved developer across different level role survey captured perception developer factor cause bad day frequency, impact job satisfaction daily diary study engaged developer day document factor caused bad day moment examined telemetry signal consenting participant validate impact bad developer experience using system data finding research revealed factor cause bad day developer significantly impact work well discus implication finding suggest future work enhancing developer experience crucial improving software productivity several reason positive developer experience reduces unnecessary blocker enables developer concentrate core responsibility writing, testing, deploying code rather held back tool process prior research also provided reason importance improving developer experience instance, forsgren et al highlighted developer time deep work demonstrated remarkable increase productivity compared counterpart less uninterrupted time recent work noda et al srivastava et al also showed company provided suitable work environment developer achieved revenue growth five time greater competitor suboptimal work environment vein, prior research doerrfeld showed developer experience play crucial role talent retention, developer study mentioning consider experience workplace key factor deciding remain leave organization building upon foundational insights, recent work scholar explored different way improving developer experience includes studying constitutes good day developer investigating impact flow state developer satisfaction productivity examining intersection developer unhappiness, productivity, developer attrition rate systematic analysis research studied specific tool process like pull request build time contribute negative experience developer despite valuable contributions, yet, limited work engaged developer holistically investigate perspective factor cause bad day impact productivity well being, suggestion mitigate experience even so, limited study paired developer feedback telemetry data examine validate developer concern poor developer experience offer definition bad day mean interested using subjective term bad day elicit common problem make developer feel bad day work particularly, focused able detect problem drive mean improving developer experience research, employed mixed method approach, including interviews, surveys, diary study, telemetry data analysis investigate validate factor cause bad day developer study engaged software developer interview sessions, developer participated survey study, developer participated diary study result three approach validated using telemetry data consenting developer examine difference log data reported bad day versus report bad day combining approaches, sought uncover, triangulate, examine factor cause developer bad day multiple viewpoint validate measurable aspect finding using telemetry data result allowed u answer research questions, including rq factor cause bad day developer rq way developer describe bad day factor impact work rq observe bad day factor using telemetry data research make following contribution comprehensive view factor cause bad day developers, including technical non technical factor factor lead poor developer experience, insight impact negative developer experience developer satisfaction well being, thus providing better understanding phenomenon developer could supported, validation telemetry analysis, concrete impact factor build time pull request process developer satisfaction, establishing quantifiable threshold correlate negative experience overall, research, contribute new insight concept bad developer day beyond available current literature rest paper organized follows following section, build prior work motivate contribution study, next, provide detailed description methods, followed finding discussion result research, conclude highlighting implication finding section, highlight prior research discussed connection emotional state developer productivity well level also highlight prior work explored approach capturing measuring developer productivity challenge build work contribution make research bad work day often lead negative emotion low developer productivity several scholar investigated connection developer emotion productivity, seeking foreground negative positive emotional state developer influence work outcome graziotin et al investigated relationship developer affective state emotion mood creativity, analytical problem solving skill engaged computer science student study measure emotional state correlated performance problem solving task research found happy software developer better problem solvers, least term analytical ability finding suggests fostering positive emotional state among developer may lead improved productivity ller fritz also investigated developer emotional state better understand emotion frustration happiness correlate performance developer ability focus flow state research revealed positive emotion enhance flow state developer and, thus, ability developer good work meyer et al also explored make developer day good study collected self reported data developer four months, analyzing developer spent time factor contributed perception good workday finding research revealed satisfaction productivity developer significantly influenced ability control workday minimize unplanned disruption along similar vein, graziotin et al explored consequence unhappiness among software developer developing software conducted qualitative analysis survey response developer identify categorize negative effect unhappiness developer themselves, software development process, resulting product create study, found highest impact unhappiness productivity performance finding also showed unhappiness lead mental health issue among developer issue like low self esteem, high anxiety, burnout, stress, potentially serious disorder like depression several scholar explored approach characterizing, measuring, predicting productivity level fluctuation developer forsgren et al introduced space framework, comprehensive model designed measure understand developer productivity implicit framework developer productivity complex multi faceted requires balanced comprehensive approach measure capture dimension brown et al developed log based metric identify period focused work flow software engineer study employed mixed method approach, including diary study longitudinal surveys, validate metric self reported data finding research revealed data log based metric correlated significantly self reported experience focus flow showing promise approach egelman et al also investigated negative interpersonal experiences, termed pushback, developer encounter code review surveyed developer mixed method approach analyzed code review log identify prevalence predictor negative feeling associated code review found developer reported experiencing negative feeling related code review least quarter, experiencing feeling monthly showed although pushback code review relatively rare, still significant negative impact developer satisfaction occurs meyer et al investigated software developer perceive assess productivity conducted two study survey professional developer observational study developer understand developer perceive productive v unproductive activity measure productivity study showed developer perceive day productive complete many task large task without significant interruption coding seen productive activity, meeting viewed productive unproductive, depending nature murphy hill et al investigated factor predict productivity developer surveying developer across three company survey included question self rated productivity, productivity factors, demographic variable study revealed technical non technical factor improve productivity practical viewpoint, research lu et al highlight flaky test disrupt continuous integration process also increase debugging efforts, thereby diminishing developer productivity similarly, prior work ko et al highlight inadequate documentation negatively impact developer different ways, including increasing learning curve new tools, impeding troubleshooting maintenance tasks, ultimately leading frustration reduced productivity among developer wang et al also pointed slow build time critical bottleneck lead poor developer concentration workflow efficiency finding suggest direct correlation faster build process improved developer satisfaction productivity study, employed mixed method approach investigate factor cause bad day developer specifically, approach paired qualitative methods, including interview diary studies, quantitative method including survey study telemetry data analysis elicit measure factor cause bad day developer different viewpoint across methods, varying level participation developer figure show number participant study method, following section go detail methodology data collection interviewed software developer understand perceptive, factor causing bad day development work recruited developer diverse backgrounds, roles, experience level ensure capture perspective broad range developer within organization recruitment employed snowball sampling conducted internal company medium involved posters, word mouth, email outreach recruitment message outlined purpose study, investigate everyday work experience software developers, particular focus challenge frustration occur workday cause bad day inclusion criterion participating study required participant software developer engineer within organization hence, non engineer included study collected interview data using semi structured interview protocol prepared ahead time interview lasted approximately minute conducted via video conferencing platform interview audio recorded consent participant later transcribed analysis ensured recruit across levels, role types, location table list demographic spread interviewee good distribution interviewee across level band although representation individual contributor interviewee usa, distribution representative developer population company interview, explored four main area developers, including asking define understand term bad day developer describe constitutes bad day work, including associated thought feelings, differ typical challenging day developer also prompted share recent example bad days, discussing frequency, factors, event contributed experience also asked pattern recurring situation tend trigger day third section interview, focused eliciting participant bad day affect productivity, work performance, emotions, well being, impact interaction teammate colleague final stage interview, developer asked coping strategies, helpful resources, potential change work environment could prevent mitigate bad day overall, interviews, generated qualitative data perception developer within organization factor make developer day go bad work following interviews, conducted survey study developer investigate factor causing experience bad day wider audience aimed find common theme interview survey reflect developer sentiment within organization participant recruited organization wide email inviting take part study email included informed consent form outlining purpose study, confidentiality measure around privacy, data handled end study participant directed online survey platform took survey study approved organization ethic review board followed best practice protect privacy well developer participated study member research team trained researcher access data study survey consisted four section wanted survey deeply relevant developer grounded unique experience opposed generic developer experience survey end, used much gathered interview inform survey, using interview report caused bad day form question likert scale open ended potential bad day scenario section collected basic demographic information participants, including experience level, role, development type, location, work home status, gender identity figure show demographic spread respondent survey interestingly, many senior developer respond survey gender role demographic skewed towards male individual contributors, reflect overall developer population section focused perception participant definition constitutes bad day developer, frequency currently experiencing bad day perceived likelihood various scenario encounter work contributing bad day presented likert scale question likert style question included query rating likely blocker long build times, flaky tests, pull requests, call duties, meeting times, legacy code changes, issue engineering system cause bad day small example set question survey last month, many bad day bad day impact work personal life following questions, presented various issue scenario related work please select frequently scenario cause bad day option always, often, sometimes, rarely, never, applicable long build time code backed out, fault code review taking long time vpn keep dropping debug system half day filled meeting get negative feedback pr hard time getting support issue section offered participant opportunity opt participate daily short diary study participant signed would receive message toward end every workday asking whether experienced bad day work responded yes, asked brief, open text follow question contributing factor survey respondent participated daily diary study participation rate figure section sought participant consent collect anonymized telemetry data related work, including check ins, pull requests, code review time, meeting hours, incident report goal telemetry data allow researcher quantitatively measure baseline data people reported bad day differed people report bad day different specific issue listed second section survey survey respondent consented telemetry data analyzed research team consent rate figure conducted diary study participant capture daily data experience developers, looking uncover factor causing bad day work longitudinal approach complemented retrospective nature interview survey allowed u observe challenge emotion fluctuate time response specific event condition impact productivity developer within organization specifically, diary study allowed u see actually caused bad day moment, opposed people believed would cause bad day described previous survey section, participant diary study recruited question end survey asking sign consented participate prompted every day workweek visit online questionnaire asked experience day first question asked rate day either good, neutral, bad participant selected either good neutral, survey would end however, selected bad, freeform textbox activated, encouraging share experience made bad day overall, approach, obtained longitudinal data factor causing bad day developer associated information developer share collected telemetry system data developer consented investigate correlation poor system experience report bad developer day specifically, telemetry analysis focused measurable factor listed interview survey sought validate bad day factor identified actual system data analysis focused mainly pull request build time telemetry data protect privacy developers, telemetry data anonymized accessible member research team collected metadata development outcomes, much time took approve pull requests, number people participated code review, long build took complete, among related metadata provided developer detailed explanation data collected informed could opt telemetry collection time without affecting employment participation aspect study data interview analyzed using thematic analysis process involved three step first, immersed data reading reading transcript better understand content context allowed member research team part interview session familiarize data next, commenced data analysis conducting open coding interview transcript identify relevant concept pattern following open coding, transitioned axial coding allowed u group initial code together potential theme sub theme next, reviewed refined final theme generated process ensure accurately represented data used theme conduct thematic analysis yielded data reported study analyzed categorical data survey using descriptive statistics, correlation analysis, cross tab analysis first, conducted descriptive statistic analysis gain general understanding data followed frequency distribution analysis determine prevalence reported bad day common scenario blocker identified survey achieve this, converted categorical response numerical value scale question answer type shown frequency occurrence question always often sometimes rarely never applicable agreement level question strongly agree agree neither agree disagree disagree strongly disagree applicable likelihood question likely somewhat likely neither likely unlikely somewhat unlikely unlikely applicable next, conducted cross tabulation analysis examine response varied across different demographic groups, experience level, role, location, revealing potential difference frequency bad day using chi square test pair variable method helped u identify potential association between, example, experience level frequency encountering specific blocker finally, conducted open coding survey response uncover key theme causing bad day developer since daily diary study questions, looked descriptive statistic first question hand coded open ended answer find common theme cause bad day developer collected six month system telemetry data developer signed investigate potential relationship telemetry data reported bad day crucial aspect analysis involved linking survey response telemetry data anonymized identifier developer reported pull request caused bad day assigned group developer reported cause bad day within time frame study assigned group approach allowed u conduct deeper investigation technical factors, lengthy build time delayed pull requests, might contribute reported bad day conducting independent test mean metric group group since data continuous categorical roughly normal distribution overall, multiple research approaches, able identify factor cause bad day developers, describe impact them, validate concern developer telemetry analysis two measurable factor identified interviews, survey, diary study report finding analysis detail following section triangulated finding research question using result interviews, survey, diary study interview revealed three major theme cause bad day developer tooling infrastructure issues, process inefficiencies, issue around team dynamic within issues, deeper concern identified shared following section participant complained consistently unreliable tool infrastructure major source frustration factor caused bad day issue identified included flaky build tests, issue around slow build deployments, outdated clunky user interfaces, generally unreliable broken tool block completing task instance, one developer mentioned, build tools, environment tools, ado, pull requests, git, visual studio automation, every single tool use feel like barely working days, highlighting pervasiveness poor tooling engineering system disrupting workflow issue around unclear project ownership, lack documentation knowledge sharing, rapidly changing team priority common factor caused bad day developer instance, one developer mentioned whole initiative around documentation shut down, huge bummer documentation definitely solved problem find knowledge need get work done, frustrating another developer mentioned process inefficiency around item tracking commenting remarkable amount confusion about, like work tracked, remarkable for, know, company old, still unsure track work leading cascade inefficiency issue common among senior principal developer developer often complained difficulty collaboration, communication breakdowns, unresponsive team members, interpersonal conflict developer highlighted technical issue often lead bad day infect overall team morale often degrade trust level instance, developer remarked sure energy frustration facing technical issue carry impact team, know like smile contagious grumpiness contagious developer highlighted intra team conflict caused bad day past resolved it, saying bad time working prior team solving honestly, largely matter changing the, know, working group collaborating day day basis issue common among junior developer due length question type asked survey, result broken three section developer definition bad days, top factor causing bad days, frequency bad day analysis demographic stated previously, goal prescribe definition bad day rather, wanted hear developer thought caused bad day figure show top coded response developer asked bad day mean top engineering system friction, feeling blocked stuck, poor productivity similar finding interview likert style questions, able rank factor causing developer bad day table ii list top mean score pr delayed due reason beyond team control flaky tests, transient issues, build failure, unresponsive reviews, etc common factor cause bad day developer mean score addition, many subjective factor like team dynamic lack support surfaced top line observed interview reviewed response different demographics, found sde ii senior developer report hard time getting support issue common factor cause bad day compared level concern around slow laggy laptop distributed across different levels, slightly prevalent among sde ii senior developer contrast, half day filled meeting challenge prevalent among principal senior developer furthermore, concern around slow laggy laptop causing bad day prevalent among working home similarly, individual working primarily home report higher prevalence meeting heavy day shown figure survey respondent say experienced bad day last month, distribution roughly normal also cross tabulation using chi square test frequency bad day demographic cohort chose chi square test assesses whether statistically significant relationship two categorical variable find statistically significant difference good thing since want demographic cohort experience higher prevalence bad day others unique respondent submitted diary duration study response said developer bad day also analyzed freeform text response submitted developer bad day revealed development environment infrastructure technical issue common challenge caused developer bad day similar finding interview survey interestingly, health emotional challenge close second finding analysis revealed complex picture developer experience within organization particularly showed bad day simply matter technical challenge finding go typical expectation improving technical infrastructure enhance developer experience instead, aligns result prior research shown technical non technical issue impair developer experience, suggesting need pay closer attention exploring theme interact examine way mitigating holistic approach focus multifaceted nature issue result interview survey study showed developer reported bad day negatively impact work well senior junior developer described impact bad day different way specifically, analysis showed frustration, annoyance, anger stemming unexpected roadblock perceived inefficiency common way senior developer described impact bad factor work described feeling typically leave exhausted due long hour mental strain dealing bad day constant occurrence bad day also lead disillusionment cynicism perceived lack action organization mitigate factor instance, hinting disillusionment, senior developer commented eventually like, even driving road anymore signaling frequent bad day cause disillusioned consider looking new job another senior developer also shared disillusionment saying, well, mean lot consecutive bad day like start pulling job board seeing, know opportunity another senior developer also mentioned would say worst bad day had, day actually stopped working go linkedin start looking job feeling need quit jobs, developer mentioned feeling left behind treated unfairly, like saying, could tell impact less satisfied work general feel like, well, know, see people chilling eating food like, feel treated unfairly analysis interview revealed common impact bad day factor junior developer lead guilt self doubt attribute cause problem incompetence, instead systemic issue organization instance, junior developer mentioned whenever encounter issues, start think like, yeah, like, competent enough fix getting super unlucky right like pretty frustrating finding analysis open ended question impact bad day survey revealed four key theme bad day impact developers, including concern reduced productivity impact career, self doubt, imposter syndrome arising frequent occurrence bad days, extended work hour due self guilt, overall increased stress anxiety level spill personal life figure show frequency answers, stress health make top response regarding concern around reduced productivity career implications, analysis showed bad day consistently linked decreased productivity, term quantity quality work specifically, developer reported feeling unable focus, losing motivation, struggling complete task instance, developer shared experience productivity, stress, career, mentioning bad day make progress difficult feel like spinning wheel wasting time creates anxiety depression, fear job security due lack progress goals, lead frustration entire day time another developer shared experience productivity loss result bad day mentioning bad day impact work reducing productivity, causing delay project timelines, leading lower quality work, missing edge case following bad day developer often experience self doubt imposter syndrome, leading question ability feel like meeting expectation instance, developer sharing experience following bad day mentioned bad day, begin feel frustrated guilty getting work done get hit imposter syndrome bad day work definitely carry personal life hour bad day caused unproductivity, think task bug working feel stressed getting done another developer mentioning impact bad day confidence remarked bad day made feel less confident abilities, resurfac ing imposter syndrome extended work hour due self guilt another common impact bad day developer scenario typically arises developer attempt compensate lost hour workday resorting working longer hour catch dynamic disrupts work life balance leading less time rest, decompress, recover work instance, developer sharing experience dynamic mentioned bad day make difficult stop work pm spend time family feel like fact accomplish anything mean pulling weight therefore, need spend time evening catching justify existence employee another developer sharing similar experience mentioned work hour weekend able focus finish work resulted enough personal time spend kid extracurricular activity sadly feel like hurting academic future career also able keep exercise time prepare healthy meal rely takeout overall, developer frequently reported bad day led increased level stress anxiety spill personal lives, affecting sleep, relationships, overall well dimension emotional impact bad day developer included report emotional exhaustion, feeling drained, frustrated, overall negative mood developer sharing experience remarked often time feel emotionally exhausted day full frustrating event evening also essentially write highlight bad day impact ability enjoy personal time engage activity outside work another developer sharing experience mentioned trouble sleeping day keeping chore emotionally exhausted work finding analysis revealed senior developer often experience frustration, annoyance, anger stemming unexpected blocker inefficiencies, junior developer often experience guilt self doubt finding provides pathway understand kind support developer different level might need way best support instance, junior developer could supported mentoring program within organization designed increase self confidence, knowledge, productivity, senior developer could benefit participating co creation activity play role designing system process used within organization ensure work survey, asked respondent share u improvement could made reduce number bad day experienced many respondent clearly articulated concrete change could made reduce bad day fewer meetings, improved documentation, faster build times, change authentication, faster code reviews, change manager could work giving autonomy developer proposed change detailed therefore proprietary showed asking question important discover change could made reduce bad day result telemetry analysis reported two heading including pull request build time telemetry data decided focus examining pull request build telemetry data among highest ranking bad day factor survey result measurable using system data instance, high ranking factor like feeling like get anything done easily measurable using system data process editing improving code involves sharing change pull request reviewed author teammate colleague merging main project repository reviewer pull request review code logical completeness, code quality, security key part software engineering process employed metric cover part pull request, result, analysis based mean comparison following metric totalpullrequesttimehours total duration pull request open non draft state close hour dwelltimehours time pull request open pull request touched reviewer codereviewtimehours time pull request touched reviewer pull request closed totalreviewers number reviewer pull request table iii report finding statistical analysis group indicated said code review cause bad day group indicated said code review cause bad day performed independent test since data continuous categorical roughly normal distribution found two statistically significant result group value higher totalpullrequesttimehours also higher dwelltimehours value find significant difference code review time number reviewer build process measure duration required compile, test, package code deployable format since product large build time dependent upon availability cache binary prior builds, developer may encounter especially long build time, even made changes, due none dependent binary cached report result build process telemetry analysis based mean comparison following metric totalbuildtimeminutes total duration build minute corebuildtimeminutes total duration core aspect build minute noncorebuildtimeminutes total duration non core aspect build minute buildsuccessrate number successful build total number build table iv report finding analysis tabular format group indicates said long build cause bad day, group indicates said long build cause bad day again, performed independent test since data continuous categorical roughly normal distribution group significantly longer mean build time min compared group min difference value summary, group statistically significant longer time total pull request time, pull reuqest dwell time, overall build time therefore, conclude concern expressed member group verifiable telemetry telemetry data analysis provided empirical validation self reported bad day factor validation critical step toward building data driven approach assessing improving developer experience instance, leveraging telemetry data, organization develop predictive model anticipate bad day enable proactive intervention overall, approach limitation potential influence variable captured telemetry data demonstrates value combining qualitative quantitative data better understanding factor cause bad day developer impede developer productivity experience limitation might impact reproduction study sample population limited sub population within organization thus, possible sampling different population yield different ranking factor cause developer bad day therefore, organization seeking replicate study focus process eliciting bad day factor less result since outcome likely differ organization addition, participant responded call participate interviews, survey, diary study might experienced bad day past, hence data collected engagement might represent view developer within organization different culture also varying level comfort expressing view stronger weaker manner may influence response well again, organization replicate study focus research method outlined rather specific result finding research revealed variety factors, including technical factor like frequent auth prompts, slow build times, long pull request times, non technical factor like many meetings, difficulty finding help blocked, intra team conflict cause developer bad day work importantly, research revealed vicious cycle arising bad day warrant attention scholar research instance, finding analysis revealed bad day often cause sleep issue developer get home know prior research cognitive fatigue affect performance mean get home get enough rest, come back work next day tired making feel unproductive becomes cycle theme need attention scholar focus often directed towards looking tool friction isolation factor cause bad day developers, rarely take holistic look lens developer experience friction blocker impact professional personal life way leave unproductive potentially, cognitively physically drained thank participant completed interview, survey joined diary study helping u shape complete research would also like thank tim bozarth, originator bad developer day microsoft, insightful feedback throughout stage project constructive insightful feedback throughout stage project",software engineering
"waffle multi modal model automated front end development introduction approach experimental setup result related work limitation conclusion appendix appendix instruction reporting error training data mutation structure aware attention contrastive learning model training test data evaluation metric effectiveness waffle ablation study structure aware attention effect multi model large language model attention mechanism ui html generation mutation rule case study tuning integration waffle structure aware attention contrastive learning effect infrastructure web development involves turning ui design functional webpages, difficult beginner experienced developer due complexity html hierarchical structure style large language model llm shown promise generating source code, two major challenge persist ui html code generation effectively representing html hierarchical structure llms, bridging gap visual nature ui design text based format html code tackle challenges, introduce waffle, new fine tuning strategy us structure aware attention mechanism improve llm understanding html structure contrastive fine tuning approach align llm understanding ui image html code model fine tuned waffle show pp absolute percentage point higher html match, higher cw ssim, higher clip, pp higher llem new benchmark websight test existing benchmark design code, outperforming current fine tuning method waffle multi modal model automated front end development shanchao liang purdue university liang purdueedu nan jiang purdue university jiang purdueedu shangshu qian purdue university qian purdueedu lin tan purdue university lintan purdueedu large language model significantly advanced automation code generation popular programming language python java jiang et al touvron et al fried et al nijkamp et al rozi et al guo et al li et al lozhkov et al automation html code generation ui design remains explored challenging core front end development, task requires model understand transformation natural language nl programming language pl also visual design pl recently, multi modal large language model mllms brought much progress generating text image description radford et al zhai et al li et al liu et al b, li et al dai et al blecher et al chen et al wei et al vikhyat top this, mllms fine tuned using ui image code datasets eg, websight lauren et al design code si et al nonetheless, approach mainly apply standard fine tuning fail address specific html code generation challenge two key challenge exist translating ui design image html code teach model learn effectively domain knowledge html structures, significantly influence rendered ui design, teach model learn subtle difference visual understanding ui image text understanding html code regarding first challenge, three basic structural aspect html code firstly, style parent element directly passed child unless specifically overridden secondly, layout sibling affect thirdly, node affected subtrees sibling last principle might less obvious compared first two, explain example figure show html code file rendered webpage use blue, orange, green block map code chunk corresponding visual rendering webpage top level body element refers whole webpage, child element div id left column refers left part webpage, another child element div id right column refers right part modification child div id left column change div id right column look webpage even remove content inside div id left column show learn domain knowledge html code structure, propose novel structure aware attention mechanism structure aware attention capture structure information html code explicitly allowing token focus three type previous code segment relevant detail section structural information html code, waffle focus part code influence resulting ui design, thus benefiting overall performance figure illustrates second challenge, ie, learning fine difference detail visual input figure figure two highly similar different ui image rendered webpages, ie, color text identical, width column slightly different vlm websight lauren et al state art mllm webpage image html code generation, fails capture small difference thus, generates identical html cs code figure different ui image figure figure model fails generate fr fr highlighted code segment red background screenshot case, vlm websight vision model fails recognize visual difference, text model unable use encoded visual information produce accurate textual output enable mllms recognize subtle difference ui image due minor change code, adopt contrastive learning zhai et al radford et al gao et al current task teach mllms focus important visual difference combining two approaches, paper introduces waffle, fine tuning pipeline specifically designed ui image html code generation, following contribution design structure aware attention html code generation, enables mllms learn structure knowledge html code apply contrastive learning algorithm boost mllms understanding detail rendered ui image html code create new dataset pair webpage html code, could facilitate future research web mllms conduct comprehensive experiment two backbone mllms waffle improves backbone mllms achieving pp higher html match, higher cw ssim, higher clip, pp higher llem highlight waffle fine tuning approach, model independent applied improve mllms ui html code generation availability githubcom lt asset waffle figure represents overview waffle create new mutated html dataset section training fine tuning addition, design structure aware attention section model fine tuning teach model focus important html segment finally, use contrastive learning training teach model learn visual difference align model visual hmtl cs code understanding section specifically, construct training dataset applying mutation rule html code subset popular dataset, websight generate corresponding source code ui image teach mllms important visual differences, create waffle contrastive training data websight fine tuning dataset built huggingfacem contains pair html code corresponding screenshots lauren et al study common mistake existing web mllm, vlm websight, enabled u create realistic mutation rule mutate html cs code websight conduct failure analysis vlm websight validation data instance every mismatched webpage, manually inspect root cause failure eventually conclude seven common category error shown table category, create set rule mutate existing html, shown appendix based mutation rule, randomly sample instance websight dataset, creating four distinct mutant sample mutation rule applied based frequency failure computed validation set final mutated dataset removing rendering failures, identical mutants, blank image groups, group containing four pair html code corresponding rendered webpage image html code clear structures, certain structural property directly reflected rendered ui design domain knowledge benefit generation process mllms three important element rendering element layout parent element, sibling elements, element waffle implement novel attention mask provides element pruned view previous tokens, including parent attention, sibling attention, self attention attention mask allow token pay specialized attention parent elements, sibling elements, figure show simple example waffle structure aware attention figure show html code snippet show dom tree html code root node body element div id leftcol div id rightcol two child node body sibling div id leftcol one child, text selection div id rightcol one child, element text customer review inside according domain knowledge element mostly affected parent sibling elements, waffle build structure aware attentionas shown parent attention parent attention element token parent element token waffle utilizes fact child element inherit parent element style structure instance, token element div id leftcol pay parent attention token element body token element selection pay parent attention token element div id leftcol sibling attention sibling attention element token preceding sibling element token waffle utilizes fact sibling element parent affect arrangement style other, element need pay attention preceding sibling instance, token element div id rightcol pay sibling attention token element div id leftcol self attention standard self attention mechanism, allows token focus previous token within element, excluding child element illustrate, token specific element self attention yellow cell figure token belonging element waffle applies structure aware attention language model decoder only, keep vision encoder waffle applies structure aware attention mechanism one fourth attention head language model decoder enables quarter attention head learn structural domain knowledge explicitly, three quarter head keep standard full self attention pre training knowledge number attention head use structure aware attention hyper parameter, tuned section example illustrated figure highlight critical gap current model limited ability effectively map variation html code corresponding webpage screenshot address this, waffle utilizes contrastive learning, allowing model learn comparison contrast similar example concretely, training dataset consists group html code ui image pairs, group pair training, group, image code image rendered webpage image code webpage image split list pixel patch depends configuration backbone mllm patch encoded vision model fused text model latent space using adapter result list patch embeddings hyper parameter backbone mllm html code tokenized token number token html code token encoded embeddings language model using structure aware attention use average patch embeddings represent embeddings webpage image, average overall token embeddings represent embedding whole html code, denoted calculate cosine similarity score text embeddings image embeddings, bipartitely contrastive learning objective maximize similarity embeddings html code corresponding ui image, achieved minimizing contrastive learning loss along standard language modeling fine tuning loss follows contrastive learning loss aim maximize similarity score diagonal similarity matrix green cell similarity matrix shown figure train mllm vision model, encodes webpage, closely match encoded embeddings text model, corresponding html code, language modeling loss, hand, aim maximize probability generating correct token given previous token input webpage image standard objective training mllm generate text image waffle jointly optimizes two objective follows hyper parameter constant controlling effect contrastive learning overall optimization implement waffle two backbones, vlm websight, moondream lauren et al vikhyat backbone first fine tuned websight dataset using standard language modeling objective vlm websight, use released fine tuned checkpoint detail lauren et al checkpoint fine tuned using dora liu et al variant parameter efficient training, lora hu et al rank set moondream also fine tune model using dora liu et al rank set lora alpha set model weight updated using adamw loshchilov hutter optimizer, learning rate set batch size top fine tuned mllms first step, apply structure aware attention contrastive learning approach structure aware attention applied attention head attention layer llm decoder model trained dora using combined learning objective contrastive learning dataset equation set model weight updated using adamw optimizer, learning rate set batch size evaluate waffle using two test datasets websight test, consists synthetic webpages, design code, consists real world webpage since websight already used training, created websight test following process websight lauren et al total, websight test contains test samples, webpage image respective ground truth html source code design code open source benchmark manually processed real world website screenshots, much complex websight evaluation design code indicates generalization ability model fine tuned waffle training dataset real world scenario si et al html match html match percentage generated image match ground truth image perfectly pixel level comparison, style attribute removed ground truth generated html process emphasizes model ability accurately recognize text content dom tree structure html code clip clip score radford et al si et al measure similarity rendered webpage inferred html code ground truth webpage based clip vit embeddings webpage low level element matching llem previous work si et al proposes llem measure percentage matched text blocks, text content, position matched text block, font color within text block cw ssim complex wavelet structural similarity index cw ssim computes structural similarity image sampat et al human evaluation two human annotator asked compare rendered webpage generated different technique subset test data ground truth webpage rank gemini pro result test instance generates answer remaining instance table table show performance various fine tuning strategy two testing datasets, websight test sample design code sample comparison standard fine tuning compare waffle baseline, standard fine tuning ft method tables, waffle achieves significant improvement standard ft metric moondream vlm websight backbone websight test, waffle achieves pp higher html match v higher cw ssim v standard ft moondream backbone vlm websight backbone, waffle outperforms standard ft pp html match, cw ssim, averaged llem design code, waffle achieves greater improvement compared standard ft technique backbone note that, waffle generalizable fine tuning pipeline benefit pre trained mllms linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary overall, waffle significantly improves metric backbone test datasets standard fine tuning pp html match, cw ssim, clip, pp llem comparison sota commercial model due lack comparable baselines, also compare waffle top commercial models, include gpt mini, gpt o, gemini pro apply direct prompting method following prior work si et al result shown table websight test dataset, model fine tuned waffle perform better sota commercial model vlm websight overperforms gpt pp html match v cw ssim v similarly, smaller backbone, moondream exceeds gpt pp html match v cw ssim v shown table vlm websight fine tuned waffle better gpt cw ssim better gpt mini design code dataset however, gpt better two metric versus vlm websight moondream fine tuned waffle lower performance compared gpt gpt mini metric likely due smaller size, could influence generalizability complex, distribution data design code dataset case study provided appendix linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary simpler data, waffle achieves better comparable result sota commercial models, pp improvement html match improvement cw ssim complex data, waffle enables vlm websight outperform commercial model cw ssim comparison ablation model compare waffle two ablation model waffle attn waffle contrastive learning without use structure aware attention waffle contra waffle structure aware attention table show ablation study result waffle attn brings improvement compared standard ft metrics, waffle contra brings pp improvement html match design code dataset, waffle dominating performance metric model fine tuned backbone across two backbones, model fine tuned waffle higher fine tuned waffle attn cw ssim linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary contrastive learning structure aware attention significantly improve performance standard fine tuning simpler websight test data, model trained waffle achieve highest html match cw ssim score complex design code data, waffle still delivers best result across metric backbone human evaluation result select test sample websight test design code total sample four generated html code rendered webpage standard ft, waffle attn waffle contra waffle human raters rank generated webpage based similarity ground truth webpage without knowing model produced one table show human evaluation result vlm websight fine tuned standard ft, waffle attn waffle contra waffle across datasets, waffle best averaged rankings, outperforming ablation baseline specifically, waffle reach time rank placement design code, showing great generalizability complex datasets waffle contra second best technique two testsets, reaching time rank average ranking hand, waffle attn third best technique still outperforms standard ft linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary human evaluation show structure aware attention contrastive learning contribute code generation quality, waffle generated html cs code consistently rated higher code generated standard fine tuning demonstrate structure aware attention help mllms focus correct element like parent sibling element generation, simulate case generation error occur mid process ideally, mistake within sibling element disrupt generation main element select high performing sample generated vlm websight fine tuned waffle waffle attn using html code generated models, manually crop mutate section simulate error model tasked completing html code starting error goal evaluate whether model robust enough handle intermediate error without causing major failure subsequent generation table show result completion following intermediate mistake waffle attn averaged cw ssim across sample drop model make intermediate mistake contrast, waffle, averaged cw ssim drop linecolor gray,roundcorner pt,backgroundcolor gray ,linewidth pt,innerleftmargin pt, leftmargin cm,rightmargin cm,topline false,bottomline false,rightline false summary integrating structure aware attention brings great stability model generation, making model robust intermediate mistakes, reducing performance drop recent advance vision language model greatly improved mllms capability task like image captioning radford et al zhai et al li et al mckinzie et al alayrac et al lauren et al text image generation ramesh et al rombach et al visual question answering dai et al liu et al b, bai et al popular model like llava liu et al b, qwen vl bai et al vary wei et al perform well general image tasks, focus converting ui image html code address this, propose waffle, fine tuning method equips mllms domain specific knowledge needed ui html generation attention mechanism key part modern transformer vaswani et al architectures, effectively capture hidden feature input data handle challenge certain domains, specialized attention mechanism explored, pyramid attention chai li hierarchical attention guo et al shi et al nguyen et al yang et al designed long range, cross file code understanding generation, well regularized attention assembly code su et al different existing work, waffle target html code, new challenge restricted structure waffle design novel structure aware attention learn structure knowledge early direction ui code generation utilizes sketch webpage figures, eg, hand drawn website sketches, generate ui code rendered similar image sketch image robinson yet, direction practical, front end developer want draw sketch website need help automated tool contrast, leveraging advancement mllms, huggingface recently released websight, trained websight dataset lauren et al although specific detail model disclosed, represents significant shift towards end end ui code generation similarly, design code model using cogagent backbone using subset websight si et al hong et al however, neither websight design code try adapt domain knowledge html task contrast, provide structure aware attention apply contrastive learning mutation teach model fine grained difference html image one limitation waffle implemented two model vlm websight moondream waffle could potentially applied mllm, exploration limited computing resource experiment show waffle brings significant improvement standard fine tuning two models, indicating level generalizability another limitation metric use fully capture human evaluation html match overlook cs styling, metric like cw ssim, clip, llem similarity based, lead unreliable score evaluating html code automatically challenging, include clip llem, used previous work si et al gui et al along cw ssim html match ensure fair evaluation work present waffle, fine tuning pipeline ui html code generation waffle introduces structure aware attention mechanism capture html structure employ contrastive learning align visual textual understanding, aiding mllms distinguishing subtle webpage difference waffle outperforms standard fine tuning two backbone mllms, improvement pp html match, cw ssim, clip, pp llem ablation study confirm key component waffle contribute better cross modality understanding robust code generation notably, waffle model independent enhance mllms ui html code generation table show mutation rule used mutate html code create contrastive learning dataset html code cs style element mutated according failure type manual analysis cs styles, mutate property color, size, margin, font size, type element bounding box display positioning element column specification table show detail valid value property html codes, randomly duplicate one html element excluding one cause render failure ie, head header html body figure show generation result one instance websight test generated webpage gpt cw ssim significantly lower vlm websight standard fine tuning hand, webpage generated vlm websight fine tuned waffle reach almost perfect cw ssim score, example show effectiveness using waffle ui image html code task waffle applies structure aware attention attention layer mllm decoder study portion attention head use structure aware attention, fine tuned vlm websight subset training dataset pair html code webpage screenshots set portion attention head using structure aware attention all, incrementing setting model trained batch size learning rate model evaluated validation dataset use two metric decide final hyper parameter averaged llem score training loss figure show averaged llem score applying structure aware attention attention head result top three validation score also consider training loss figure although applying structure aware attention ie, attention head yield high llem score, also result high training loss, likely due regular attention head retaining prior knowledge pre training contrast, show similar lower training loss combining results, select ie, final hyper parameter controlling portion attention head use structure aware attention show contrastive learning effect mllms visual textual understanding, design two experiment first experiment analyzes whether mllm understanding image code aligned integration contrastive learning, second experiment analyzes whether contrastive learning teach model capture subtle difference image aligning model two modality specifically, procedure, compute averaged text embeddings image embeddings subset sample websight test dataset test sample section using moondream model fine tuned waffle attn standard ft pair averaged image embeddings text embeddings, normalize compute euclidean distance cosine similarity table show result measurement technique euclidean distance embeddings two modality waffle attn lower distance embeddings standard ft, similarly, cosine similarity embeddings encoded waffle attn higher standard ft v addition, figure demonstrates contrastive learning teach model align text image understanding vision embeddings red circle far away corresponding text embeddings blue triangle calculated standard ft contrast, vision embeddings grouped corresponding text embeddings waffle attn capturing subtle visual difference using computed embeddings, compute averaged distance similarity image embedding centroid corresponding group mutant formally, group mutants, consisting image embedding centroid image embeddings computed table show distance cosine similarity image embeddings average distance image embedding respective centroid computed waffle attn greatly surpassing average distance computed standard ft likewise, cosine similarity image embeddings much lower waffle attn v showing waffle attn better ability distinguish image figure also show standard ft encodes four different image almost latent space ie, four red circle overlapped waffle attn able encode differently approach implemented following package transformer pytorch selenium, deepspeed accelerate datasets experiment conducted shared computing cluster four nvidia gpus continuing",software engineering
"context code text learning bimodal software engineering introduction ii background iii inctrl context code text learning iv inference experimental setup vi result analysis vii discussion viii related work ix conclusion instruction reporting error iii architecture overview iii task configuration iii prompt configuration iii configurable prompt generation iii response generation research question task datasets model metric implementation vi rq effectiveness context learning vi rq impact retrieval augmented generation vi rq performance specific datasets vi rq case study vii threat validity vii limitation vii fine tuning inctrl bimodal software analysis initially appeared within reach advent large language model unfortunately, complex interplay natural language text code software engineering, present unique challenge prevent pretrained model generalize variety task postulate context learning code text bimodality promising avenue paper thus introduces comprehensive study context code text learning, focusing leveraging pretrained codellama model consider diverse dataset encompassing software engineering tasks, transform context learning format effectively extract informative features, propose configurable prompt template proposed pipeline, inctrl, unifies prompt learning across various software engineering task extensive evaluation study datasets demonstrates superiority inctrl model shot performance, surpassing state art model including support model, codellama typically, observe applied codellama model, inctrl brings improvement term precision least recall various task example, task program repair, inctrl improves bleu score codellama points, clone detection, inctrl achieves improvement percentage point moreover, inctrl model offer state art performance using retrieval augmented generation individual downstream task finally, qualitatively analyze benefit inctrl codellama open source model broader impact make code dataset publicly available software development complex endeavor characterized inherent interplay code natural language significant advancement made code analysis natural language processing, effectively integrating two modality remains critical challenge yet, integration essential addressing complex task require deep understanding code syntax semantic context setting, large language model llm appear promising due ability process generate text code, offer unprecedented potential automate tasks, improve code quality, enhance developer productivity critical factor llm effectiveness quality diversity training data source code foundation, incorporating additional data type bug report patch vulnerable code snippet proven invaluable specific task program repair vulnerability detection yet, building general purpose code text model remains challenging due varied nature code complexity bridging gap natural language formal logic indeed, source code inherently bimodal, composed formal algorithmic component informal natural language component consisting example identifiers, comment text artefact research predominantly examined channel isolation, attempt comprehensive approach using machine learning proposed literature two channel indeed interconnected, natural language often providing context, explanations, summary underlying code jointly analyzing channels, researcher potentially enhance understanding analysis software system unfortunately, building general purpose code text model present unique challenge due diverse input distribution task variation bimodal software engineering face complex challenge identifying synchronization point code text well managing noise, come form ambiguity natural language channel imprecision code algorithmic channel effectively address specificity bimodal software engineering, llm often require carefully crafted datasets process demand deep understanding downstream tasks, code context comprehension, code text alignment ensure consistency quality across diverse task type essential enhancing llm performance software engineering, current data generation methods, outlined luo et al wang et al frequently rely limited task set heuristic approach reliance inadvertently introduce systemic bias inherited llm predefined task indeed, previous approach addressing challenge primarily fallen two category multitask learning task specific component extension multitask learning attempt formulate various code based task uniform input output format, offering versatility often struggling capture nuanced difference diverse task task specific component extension augments pre trained llm additional component trained task oriented data, allowing tailored solution facing challenge scalability generalization novel task approach demonstrated limitation ability generalize effectively unseen datasets task paper response aforementioned challenges, propose novel framework designed significantly enhance llm capability handling diverse software engineering task refer context code text learning inctrl central approach unified code text interface generalizes task oriented code text instruction consolidating code text data single format, significantly expand training data available llms, resulting model versatile less biased tackling software engineering problem research contributes significantly emerging field context code text learning, critical component achieving bimodal software analysis establishing foundation effective code text interaction, envision future system capable accurately understanding generating modality contextually aware manner model instrumental bridging human computer divide, enabling fluent translation high level instruction executable code key aspect proposed methodology include unified code text interface introduce novel interface bridge gap diverse code related tasks, allowing cohesive representation various se problem task oriented instruction generalization approach focus generalizing task specific instructions, enabling llm better understand adapt wider range se task experimental results, based seven typical software engineering task applied datasets, provide sufficient data support claim inctrl enhances llm software engineering task effectively leveraging context learning without requiring model retraining experiment show inctrl improves codellama code generation tasks, text generation tasks, classification task inctrl significantly improves classification performance incorporating retrieval augmented generation module, addressing key limitation traditional context learning experiment show rag module contributed average increase point score datasets achieve point improvement inctrl demonstrates strong performance across various software engineering tasks, particularly excelling code generation repair impact, however, varies across task datasets, influenced factor dataset complexity, input length intrinsic nature task inctrl structured prompt design provides rich context learning opportunities, exemplified effectiveness code summarization wide array existing software engineering research typically specializes one particular downstream task either code analysis natural language processing bimodal software engineering represents emerging field seek bridge gap code natural language within software development lifecycle integration essential addressing complex task require deep understanding code syntax semantic context primary challenge lie aligning code text representation effectively, discrepancy lead errors, vulnerabilities, hindered developer productivity traditional approach often silo modalities, illustrated figure limiting potential synergy indeed, different task datasets require various input outputs, require creation training deep learning model capable handling multiple downstream tasks, clone detection code generation range requirement underscore need integrated versatile tool bimodal software engineering, capable addressing complex interplay code natural language across diverse software development scenario overcome limitations, propose unified framework leverage general purpose interface ie, adapter help handle various software engineering task seamlessly integrating code text analysis approach empowers model extract valuable insight domains, enhancing capability perform complex se task like detecting vulnerability explaining code identifying code clone greater accuracy efficiency thus, technique unifies prompt learning large language model across various software engineering tasks, ensuring effective processing diverse input achieve state art result context learning icl key capability large language model llm allows adapt new task without explicit training incorporating task demonstration within input prompt, llm generate relevant outputs, first highlighted gpt indeed gpt demonstrated remarkable performance across range task simply conditioning task demonstration embedded input context unlike traditional machine learning, icl leverage model extensive pre trained knowledge perform task minimal supervision, zero shot shot learning research indicated effectiveness icl influenced factor number, order, quality context example sensitivity prompted development prompt engineering technique aimed optimizing presentation information model precise mechanism underlying icl still investigation, study suggest model may learn identify pattern correlation within provided example work capitalizes icl strengths, enabling rapid adaptation model inctrl framework without extensive retraining multi task learning mtl advanced machine learning paradigm contrast single task learning approache involves concurrent learning multiple related tasks, leveraging shared information enhance overall performance mtl offer powerful framework utilizing supervised data across related tasks, thereby reducing reliance task specific labeled data approach inherently combat overfitting encouraging model learn generalizable features, effectively acting form regularization application mtl boost task performance extensively explored successfully implemented across diverse domain scenario mtl enables model learn multiple related task simultaneously, offer rather complementary perspective work indeed, context code text reasoning approach differs mtl emphasizing flexible, task agnostic interface capable handling wide range software engineering problem mtl indeed typically focus sharing parameter across predefined task reduce overfitting improve generalization mtl typically involves predefined task structure shared task specific parameters, context code text reasoning method emphasizes flexibility, allowing dynamic handling various software engineering task configurable prompt learning postulate method address directly unique challenge bimodal software engineering, desynchronization code text, explicitly targeted traditional mtl technique pre trained language model significantly advanced natural language processing nlp consistently achieving state art performance across wide range task model offer several key advantage extract universal representation extensive corpora, provide enhanced model initialization better generalization downstream tasks, serve form regularization combat overfitting working limited datasets researcher typically employ two main strategy harness pre trained language representation feature based approach consider pre trained representation additional features, fine tuning approach adapt entire pre trained model specific downstream task however, model often specialize either classification generation task contrast, aim take holistic view, unifying prompt learning across diverse software engineering tasks, yielding model capable addressing multifaceted requirement software engineering field, including code analysis natural language processing aspect inctrl framework designed integrate code natural language text various se tasks, leveraging context learning enhance model performance section detail construction inctrl approach, key components, configuration used inctrl architecture, depicted figure comprises several interconnected component designed handle, together, complex software engineering task task module initializes task specific setting based configuration file task configjson prompt module load prompt configuration prompt configjson outlining prompt structure content context learning configuration serve foundation configurableprompt component, dynamically generates prompt combining predefined template relevant example retrieved retrieval augmented generation rag module approach ensures prompt tailored specific tasks, enhancing model ability generate accurate contextually appropriate response enabled, rag module retrieves relevant example training set retrieval process represented equation query task prompt document corpus training set retrieved example enrich prompt question module handle specific query posed user, integrating configurable prompt ensure comprehensive tailored prompt task requirement enriched prompt fed generator, which, study, leverage codellama model produce final response model input, combination prompt question, represented generator generated response, prompt, question consider three different type task depending output class output, code output, text output task depicted figure executed across datasets cf section process begin task module, initializes specific task setting determines whether use retrieval augmented generation rag module based task requirement specified configuration file task configuration file contains parameter essential defining task environment include task type eg, code generation, code summarization input output formats, evaluation metrics, whether rag enabled let denote task setting vector derived configuration file, represents individual configuration parameter task module parses initializes environment accordingly task requires use rag module, task module set binary flag indicates activation rag decision rule formalized follows decision impact subsequent steps, whether retrieve example training set task module also initializes input output data structure let represent input data configuration output data configuration mapping input output described function parameterized transforms input data according task setting defined furthermore, task module configures evaluation metric used assessing model performance let denote set metrics, representing specific evaluation criterion, bleu score text generation accuracy classification task evaluation function expressed represents evaluation result based generated output selected metric systematically configuring task environment, input output mappings, evaluation criteria, task module ensures inctrl framework correctly initialized specific requirement software engineering task concurrently, prompt module load prompt configuration configuration file configuration define structure content prompt used context learning prompt configuration crucial generating task specific prompt guide model understanding processing input data effectively let denote prompt configuration vector derived configuration file, represents individual configuration parameters, including template structures, placeholder input variables, instruction model prompt module parses create prompt template dynamically adjusted based input data formally, let function represents structured prompt used guide model generate final prompt prompt module substitute placeholder actual value ensures model receives coherent contextually relevant prompt additionally, prompt configuration includes rule augmenting prompt supplementary context, example clarifying information let denote augmentation function enriched prompt represents context question configurableprompt component central inctrl framework take input prompt module additional context provided rag module enabled rag module retrieves relevant example training set, enriching prompt contextual information resulting prompt combination predefined structure dynamically retrieved examples, making highly adaptable various task formally, let represent initial prompt generated prompt module, denote function rag module retrieves set relevant example based input data configurableprompt component combine input form enriched prompt combination process expressed follows function integrates initial prompt retrieved example denotes union operation appends example prompt finally, performing inference, treat certain data entry test set question, concatenate obtain final prompt date entry used input model conducting extensive experiments, summarized high quality template construction scheme set default structure configurable prompt specifically, inctrl default scheme divide configurable prompt following six section previously illustrated lower right part figure introduction provides background context generator definition give basic requirement task pre instruction give detailed requirement task demonstration provides several input output example post instruction emphasizes detailed requirement task question contains query example configurable prompt provided figure task code summarization final prompt constructed, fed generator module ie, codellama case generator leverage structured prompt produce accurate contextually relevant response response generation process modeled function map augmented prompt response vector, ensuring output aligns user query context code related tasks, utilizes underlying capability codellama perform various operation code generation, code completion, providing natural language explanation generated response refined ensure precision relevance example, task involves generating function definition based query, response might include syntactic check semantic validation ensure code correct optimal enhance robustness response, additional post processing step applied, incorporating feedback loop iterative improvement let post processing function refines response, finalized response final comprehensive approach ensures inctrl framework handle wide range task efficiently, producing high quality output meet user requirement code natural language context inctrl framework designed accommodate diverse range software engineering tasks, including classification generation problem leveraging modular architecture effective prompt handling, inctrl address task tailored inference strategy generation oriented tasks, code generation open ended code comprehension, model directly prompted produce output generated sequence evaluated ground truth using metric like bleu contrast, classification tasks, including vulnerability detection clone detection, utilize vocabulary ranking approach model generates potential candidates, option highest log likelihood selected final prediction enhance performance, especially binary classification, expand label set include semantically similar term eg, yes true positive class aligning model output natural language pattern mathematically, classification process expressed predicted class, set candidate classes, input prompt generation tasks, generator produce sequence tokens, given input prompt, sequence length, probability generating token given previous token input prompt prompt baseline codellama experiment without inctrl apply simple prompt define task provide input data example, vulnerability detection, prompt follows given following code snippet, classify whether vulnerable code prompt used replailcation package rq effectiveness context learning considering various code text task software engineering, extent model performance improved context learning inctrl rq impact retrieval augmented generation extent use rag selecting example prompting necessary beneficial rq performance specific datasets fine grained perspective, inctrl influence model performance individual datasets task rq qualitative case study actual input output example inctrl, qualitative assessment provide regarding capability table i, provide detailed information datasets used experimental setup datasets collected huggingface nonetheless worth noting that, datasets, used subset case remark column indicates subset considered categorize software engineering task three type based modality output data code output, text output, class output task fall code output category include code generation, code translation, code completion, program repair, encompassing datasets text output category consists code summarization task, includes datasets task class output category vulnerability detection clone detection, covering datasets use codellama base llm select llm open source among popular software engineering research specifically, evaluated four set model parameter codellama b, codellama instruct, codellama b, codellama instruct difference model without instruct name lie trained type data exposed training process furthermore, choose codebert pre trained language model designed understand represent programming languages, embedding model rag module model parameter used downloaded official hugging face model repository code output text output tasks, since text generation tasks, adopt bleu evaluation metric automatic metric evaluating quality machine generated text comparing reference, calculating similarity score based overlap gram generated text reference text evaluation, use smoothed bleu metric gram class output tasks, adopt precision, recall, score evaluation metric class output task involved evaluation binary classification task ie, outputting yes setting, precision measure accuracy positive predictions, recall measure completeness positive predictions, score harmonic mean precision recall, providing balanced measure classifier performance rag module inctrl powered llamaindex evaluation inctrl implemented based vllm ease reproducibility dataset considered work, provide corresponding configuration automatically build interface experiment conducted server equipped nvidia tesla gb gpus section, present overall context learning effectiveness inctrl sec vi a, necessity effectiveness rag module sec vi b, performance individual datasets sec vi qualitative case study sec vi instruct indicates instruct version model abbreviation code generation cg code translation ct code completion cc program repair pr code summarization c vulnerability detection vd clone detection cd mean precision mean recall subsection, investigate overall performance inctrl software engineering task first obtain result datasets mentioned using model without applying inctrl then, aggregate output result compute overall performance metric task type model inctrl, prompt consists solely task definition input data table ii present performance model across three major category code output, text output, class output, subdivided seven specific task considered work code generation cg code translation ct code completion cc program repair pr code summarization c vulnerability detection vd clone detection cd observed seven tasks, inctrl significantly enhance capability model specifically, smallest improvement point increase cg, largest point surge pr enhancement transforms model nearly ineffective highly effective, demonstrating inctrl impact code output task additionally, inctrl still mark substantial improvement baseline performance text output tasks, perform well tasks, compared code output task finally, class output tasks, direct model inference initially completely unfeasible successful case codellama studied datasets inctrl therefore equipped model capability tackle task table, observe without enhancement provided inctrl, instruct version model typically underperform compared non instruct counterpart underperformance attributed instruct version requiring specific instructions, directly provided initial prompt however, application inctrl, instruct version outperform non instruct model term cg, ct pr improvement suggests inctrl effectively activates instruct model inherent capacity learn solve problem based configurable prompt provided inctrl specifically, inctrl improves codellama code output tasks, text output tasks, class output task rq example, intuitively analyze prompt generated inctrl activate model indicates instruct version model unlike generation task randomly selecting sample training set construct context prompt enable model certain ability complete task classification task higher requirement relevance example ie, demonstration question directly using randomly sampled data example usually cannot make model output valid result therefore, consider whether introduce rag module make inctrl also adaptable class output task specifically, enabling rag module, inctrl treat question test set query data sample training set document retrieved us cosine similarity semantic vector embeddings provided codebert retrieve relevant training sample question, used fill demonstration slot prompt table iii show result ablation study rag module inctrl class output task noted datasets large amount training data, time cost retrieving full training set high therefore, set ratio perform retrieval subset training set specifically, data point training set, first randomly sample data instance perform rag different datasets, value achieves best rag effect varies table iii, omitted value default best result seen rag module inctrl almost always improves model performance various classification task classification task across six datasets, rag module demonstrated improved performance five significant enhancement observed dataset increase point score however, devign dataset rag module show improvement closer examination data reveals datasets rag module performed well generally consisted shorter function codes, whereas devign dataset, module performed poorly, much longer input sequence discrepancy understandable, longer function code imply complex problem greater retrieval difficulty performance rag module therefore significantly influenced average length sample nonetheless, overall, rag module contributed average increase point score indicates rag module effective, indeed solves, certain extent, problem context learning setup cannot often obtain effective result class output type task indicates instruct version model code generation, code translation, code completion, program repair code summarization tasks, metric value table bleu clone detection vulnerability detection tasks, metric value table score section examines inctrl performance across individual datasets assess effectiveness various software engineering task results, summarized table iv, demonstrate inctrl ability enhance model performance across datasets result reveal inctrl significantly enhances model performance across datasets, albeit varying degree effectiveness depending task type code output task code generation, code translation, code completion, program repair, impact inctrl pronounced instance, apps dataset code generation, inctrl boost performance model bleu score highlighting substantial improvement similarly, codexglue dataset program repair, model performance leap term bleu score contrast, text output task code summarization, improvement less significant, though still notable example, codexglue dataset, bleu score model increase application inctrl, indicating inctrl provides benefit, task inherent complexity model baseline performance limit magnitude improvement class output task like clone detection vulnerability detection, inctrl prof essential enables model perform task could otherwise address effectively datasets like bigclonebench bigvul, non inctrl model fail produce valid output models, however, supported inctrl, achieve score respectively improvement underscore importance inctrl equipping model capability handle classification task providing relevant contextual information via rag module overall, inctrl impact varies across task datasets, influenced factor dataset complexity, input length intrinsic nature task provide specific example illustrate analyze prompt constructed inctrl content output taking code summarization task example text output task where, given piece code, task consists providing description code natural language see specific prompt content output content inctrl figure first, prompt contains six section mentioned seciii introduction section, provide scenario, set role experienced software developer llm, briefly introduce section appear entire prompt then, definition, give basic requirement task, generate docstring given java function next, pre instruction, emphasize content model need pay attention come demonstration section, longest important section entire prompt provides model several input output example taken training set allowing model directly learn ability handle target task within prompt that, post instruction section, emphasize issue model need pay special attention finally, question section input part certain test data test set, hope model answer question seen model correctly output docstring function given question example, see prompt constructed inctrl provides model rich context knowledge, including situation setting instruction task definition definition caution pre instruction post instruction question answering example demonstration among these, demonstration part usually occupies largest proportion prompt content provide sufficient reference model answer new question meticulously constrain model output therefore, difficult understand model still exhibit certain ability solve problem even configured according prompt template instruct version model furthermore, inctrl default prompt construction scheme adapt task given example, previous experimental result show solve various code text problems, making highly generalizable internal threat validity lie implementation framework result experiment first, ensure robustness implementation, framework inference feature rag feature powered widely recognized project vllm llama index respectively avoids uncontrollable factor introduced repeated implementation then, term experiments, conducted large number test different configurations, including replacing text section prompt, changing number shot demonstration, adjusting sampling rate rag module obtaining candidate training set, etc, order achieve best model performance external threat validity lie correctness parameter data model used address issue, model codellama series used generator codebert rag module datasets downloaded officially open sourced repository huggingface platform limitation proposed method mainly reflected diversification base model efficiency rag module due limitation experimental resources, conducted experiment using model codellama series base model however, many state art se related llmsavailable use base model make stronger case inctrl moreover, although framework enable model handle code text related problem without fine tuning training save lot time, task require rag module completed effectively, method still incurs substantial time overhead work, opted fine tune codellama several reason first, fine tuning typically tailored specific tasks, limit model ability generalize across different domain adapt new task without retraining specificity reduce versatility model, making less suitable scenario requiring adaptability various software engineering task second, computational cost resource demand fine tuning large model like codellama significant, often necessitating specialized hardware extended training time prohibitive term time financial resources, especially compared leveraging context learning, allows model utilize pre trained knowledge adapt fly task specific prompt avoiding fine tuning, maintain flexibility efficiency approach, allowing rapid adaptation wide range task without overhead associated fine tuning process code llm codet code gen codellam deepseek coder pre trained largecodebases scratch, show ability general code generation understanding since extensive study fine tuning task specific code llm perform software engineering task like automatic program repair code translation code summarization furthermore, base code model also finetuned prompted unlock full potential specializing solving domain specific coding task code text pre training become mainstream, context learning bimodality remains explored paper introduces comprehensive study code text context learning, focusing leveraging pre trained large language model shot prompting popular technique enhancing llm performance specific task providing example within prompt, model adapt new task without extensive training previous research successfully applied shot prompting various software engineering downstream task work introduces novel approach general purpose interface eliminates need task specific training unlike traditional shot prompting, relies carefully curated examples, method offer flexible adaptable solution handling diverse se task introduced inctrl, novel framework address challenge inherent building general purpose code text model leveraging context learning unified code text interface ie, adapter inctrl empowers llm effectively handle wide range software engineering task without requiring extensive retraining empirical evaluation codellama base model demonstrates inctrl ability significantly enhance model performance across diverse tasks, particularly code generation program repair key component, retrieval augmented generation module, enables inctrl support codellama software engineering classification task ineffective research represents step forward bimodal software engineering, several avenue future exploration include investigating cost inctrl v cost task specific fine tuning, developing method evaluating model robustness open science artefact available ",software engineering
"flexible process variant binding information system software product line engineering introduction fundamental previous work flexibility pais product line proof concept discussion related work conclusion instruction reporting error problem statement contribution outline variability modelling feature interaction featurehouse feature refinement feature binding phase software product line engineering featureide variation point variability modelling feature interaction requirement assumption multiple implementation activity varying data structure static dynamic feature binding property data structure composition multiple implementation activity static dynamic feature binding tool support requirement property limitation single multi model approach configurable process model software product line engineering variable business process experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice innerleftmargin pt, innerrightmargin pt, innertopmargin pt, customexampleexample different organisation often run similar digitised business process achieve business goal however, organisation often need slightly adapt business process implemented information system order adopt various approach proposed manage variant process model approach mainly deal control flow variability, previous work introduced approach manage implementation variant digitised business process context software product line spl engineering applied manage set common core artefact including process model process aware information system pais derived, differ implementation process activity deriving pais, implementation selected process activity included pais compilation time one challenge yet solved giving user digitised business process option selecting several feature runtime, ie selecting multiple activity implementation runtime paper extends previous work allowing selection activity implementation compile time, also start time runtime consequently, becomes possible defer decision feature selected start time runtime furthermore, multiple implementation particular activity may selected executed concurrently another challenge different organisation may want collect base decision different information digitised business process consequently, presented approach also allows customising input output data activity deriving pais specific organisation right self administration german municipality lead various variant business process example, craftspersons may apply special parking permit, allows park area regular citizen pay generally parking permitted special parking permit craftspersons available, inter alia, german city munich constance stuttgart business process checking application special parking permit similar municipality however, slight difference among municipality municipalities, special parking permit issued automatically, whereas others municipal employee need issue parking permit manually researcher observed investigated business process variability municipality well focusing control flow variability approach proposed deal business process variability reference process base process respectively, introduced may configured meet need individual organisation however, approach focus variation control flow business process rather implementation level software product line spl engineering address challenge developing maintaining set similar software product software product line comprises common set core artefact feature may selected order build specific software product literature, process selecting feature spl building software product referred product derivation process aware information system pais corresponds software product executes business process involving human actors, applications, information source previous work applied simplified concept spl engineering pais pais product line build time, implementation selected activity however, static approach lack flexibility, utmost importance practice previous approach, activity pais product line specified input output data structures, ie specified data activity expects data collected execution activity combined input output data structure activity denoted process data structure process data structure pais product line assumed immutable, ie deriving product pais product line process data structure cannot customised data structure implemented source code eg java class process data structure customised product derivation eg user form adapted order collect different data corresponding source code java class need adapted, eg removing adding field java class pose challenge removing field java class might lead compile error field used elsewhere furthermore, implementation activity need selected build time selection start time runtime possible order give process engineer business process option selecting features, decision activity implementation selected must deferred startup time runtime previous work, used build tool apache maven conditionally package selected activity implementation activity implementation selected startup time runtime build tool cannot used anymore challenge find adopt mechanism spl engineering allowing selection activity implementation startup time runtime however, note becomes possible select and, consequently, deselect activity implementation runtime, need specified shall happen data running implementation get deselected finally, far one implementation may selected activity order give process engineer business process option selecting multiple implementation one activity, becomes necessary execute selected implementation concurrently concurrent running activity implementation might access data result unintended overwriting data work address aforementioned limitation problem pais product line main contribution work threefold concept tool spl engineering adopted applied approach pais product line enable customising process data structure deriving pais product technique known spl engineering selected combined enable selecting activity implementation build time, startup time, runtime approach presented allows selecting running multiple activity implementation concurrently, ensuring data unintentionally overwritten moreover, assured process designing, developing, selecting activity implementations, deriving product known phase spl engineering tool supported remainder paper structured follows section present basic concept spl engineering, lay foundation approach necessary understanding approach pais product line introduced described section section approach extended enable flexibility data structure may customised pais product derivation, multiple implementation one activity may selected, implementation may bound different time flexibility presented approach discussed section section discusses related work section concludes paper provides outlook open challenge research topic section, basic concept spl engineering presented, constitute foundation approach concept deal variability among similar software product may derived set common core artefact kang et al introduced notation capture functionality software product perspective user applying notation, becomes possible outline feature software product well relationship tree structured feature model root node represents software product feature software product connected edge root node feature may consists feature inter connected via edge well little circle end edge refer optional features, whereas alternative feature identified arc corresponding edge feature diagram help developer identify configured software product example feature model displayed figure software product consists three feature, ie feature optional, mandatory furthermore, consists either feature besides optional mandatory features, group alternative feature may assigned cardinality multiplicity respectively cardinality feature group defines number feature selected group feature model depicted figure represents software product comprises four alternative feature ie cardinality specifies software product least two feature three feature selected typical constraint feature requires mutually exclusive described text form common practice use dashed arrow indicate feature requires another one dashed double headed arrow illustrate two marked feature must co selected eg finally, figure show feature model contains software product three optional feature ie due constraint requires, selecting feature feature must selected well feature interaction combination multiple feature might behave differently isolation feature interaction subject research many domain long time example feature interaction given described example feature interaction telecommunication consider feature call forwarding call waiting busy phone line phone consists one two features, work fine however, behaviour phone comprising feature unclear either way requirement one feature satisfied, maybe even requirement feature interaction pose challenge spl engineering well opposed regular software engineering, spl engineering, feature selected composed product derivation, ie feature present every derived software product consequently, feature interaction might occur derived software product testing derivable software products, however, feasible practical perspective due exponential growth derivable software product increasing number feature instead testing derivable software product ie every feature combination allowed according feature model detect feature interaction, pairwise feature interaction testing applied context spls pairwise feature interaction testing subset derivable software product generated every feature pair comprised better feature interaction detection, work discus general approach wise testing, ie testing software product contain every combination features, ,n representing coverage strength however, researcher propose pairwise feature interaction testing approach spls, resolution feature interaction cannot hard coded product derivation feature selected individually obeying constraint set feature diagram however, additional code resolve unintended behaviour may conditionally included two interacting feature present software product proposed optional feature problem feature contains code depends another optional feature, second feature becomes mandatory contrary specification, known optional feature problem different approach propose extracting dependent code separate module, called derivative lifter consequently, feature may included independently used software product however, using feature combination, derivative module included well derivative module constitutes resolution technical dependency feature consequently, added feature model furthermore, order resolve interaction two feature may marked mutually exclusive feature model, precedence priority may defined review resolution technique feature interaction refer interested reader featurehouse framework tool chain composing software artefact software system us superimposition merge software artefacts, ie substructure software artefact merged order compose software system hierarchical structure software artefact represented feature structure tree fst example, java artefact may consist packages, classes, method correspond fst node node may non terminal ie child node terminal depending hierarchy level artefact shall merged, structural element latter need chosen terminal node if, example, java artefact shall merged class level, class may terminal node superimposing two fsts entail merging node beginning root node featurehouse support composition artefact written various languages, including java, xml feature refinement corresponds program increment represents feature within related software products, eg software product line feature refinement comprise software fragment incrementally composed build software product whereby software fragment may source code artefact jak extension programming language java contains key word feature refinement class contained jak file may refined another jak file using modifier refines eg class member method may added ahead tool presented turn, able compose translate jak file java file ahead tool also support incrementally composing xml document written xak xak language refine xml document provides attribute xak module mark tag module ie tag may refined base xml file, starting point composing xml document tag xml tree module considered implementation must refined separate xak files, refinement module ie xml increment may specified composition, refinement applied corresponding module tag base xml file, ie tag xml refinement appended corresponding module tag xak refinement file constitute increment rather complete xml, file mostly schema compliant order use optional feature spl, selected respective software product called feature binding feature may bound different time context, distinguishes three feature binding time compile time, start time, runtime feature bound compile time composed source code compilation, whereas feature bound start time selected software product launched finally, feature bound runtime may exchanged software product running proposition categorise feature binding time static binding ie feature binding software product execution dynamic binding ie feature binding start running software product static dynamic binding advantage disadvantage one hand, dynamic binding entail flexibility respect adding removing feature runtime hand, also implies software product contains feature size software product impact required resource memory cpu contrast, static binding requires fewer resource lack flexibility runtime dynamic binding implies adding removing feature runtime hence, becomes necessary specify happens running feature shall removed summarises option running feature removed immediately current state feature saved removal running feature removed execution completed running feature removed furthermore, removal running feature might impact feature share data system process ie background task operating system proposes grouping feature feature binding unit development time bound unbound runtime feature binding unit consider implication data system process feature unbound working variation point corresponds location information system variability occurs, ie feature bound method implement variation point ie binding feature called variability mechanism earlier approaches, binding time feature selected design time implementing variability appropriate variability mechanism instance, variability mechanism discussed subsection like featurehouse ahead allow static feature binding, solely approach presented aim support static dynamic feature binding without deciding design time code basis spl developed independently feature binding time using feature refinement feature spl shall bound statically, existing tool used composing feature refinement order bind feature dynamically, code base transformed use decorator pattern feature selected compile time using factory method feature decorator thus, feature included compile time available afterwards approach allows selecting either static dynamic feature binding feature contrast, proposes approach build result allows selecting binding time per feature changing order feature bound may change behaviour consider example feature binding order assume feature need executed feature then, feature need bound feature however, feature bound statically feature dynamically order reversed approach presented ensures execution order feature even feature different binding time achieved generating hook method overridden dynamic feature binding, mutually exclusive feature included together software product bound runtime therefore, binding feature runtime, given constraint eg mutually exclusion implication need obeyed use runtime api enables checking corresponding feature model whether selected feature spl product consistent edict constitute aspect aspect oriented programming variation point may various edict feature shall bound compile time edict containing feature included contrast, implementation variation point shall determined runtime, edict containing code design pattern eg decorator pattern enables choosing feature runtime included opposed single software products, developing spl requirement various similar, yet different, software product need collected, managed implemented spl engineering divided four phase domain analysis includes activity collecting requirement describing domain feature spl, ie collecting requirement software product derived spl domain implementation deal implementing feature described domain analysis way allows composing individually derived software product requirement analysis deal selecting feature domain analysis specific software product derived spl selected feature form configuration software generation deal building software product composing feature specified configuration requirement analysis featureide eclipse based integrated development environment ide spls cover four phase software product line engineering set section support domain analysis, featureide provides graphical editor model feature dependency feature model feature model contain constraints, stored xml files, imported exported featureide furthermore, featureide provides user convenient refactoring tool inconsistency detection featureide assist developer configuration editor create configuration specific software product requirement analysis developer may mark feature feature diagram contained software product configuration editor prevents configuration obeying constraint feature diagram finally, configuration stored configuration file featureide support various framework implementing feature domain implementation includes featurehouse ahead tool software generation, featureide take configuration file input composes software artefact corresponding selected feature featureide place composed software artefact specified output directory artefact output directory natively compiled artefact language framework domain implementation based previous work, introduced approach process aware information system product line pais product line approach applies concept spl engineering development maintenance similar paiss order reduce development effort cost enabling reuse common core artefact pais product line constitutes common set core artefact including core process model pais product may derived various activity core process model may declared variation points, ie different implementation may selected activity pais product derivation bpmn activity corresponds step work performed, either atomic compound call activity call subprocess, comprise activity constitute compound activities, task atomic activity cannot broken sake approach, bpmn send task, script task, service task, business rule task regarded automated task represent automatic step business process without user interaction neither manual task receive task considered approach manual task occur digitized business process receive task may substituted receive event bpmn user task corresponds step business process user interacts pais consequently, approach considers following three activity type call activity, automated task, user task figure show example business process comprising two activities, whose activity type specified, ie activity constitute variation point pais product derivation, implementation selected activity hence activity type determined depending selected implementation, activity might automated activity ie executing business logic user task ie user form call activity ie calling subprocess activity might also remain without type, ie implementation selected consequently, activity neither call activity automated task user task untyped activity function pais process instance pass untyped activity nothing, ie neither user form invoked automated logic executed approach transfer concept feature spl engineering process activity enables u create process feature models, depict implementation may selected activity, activity optional mandatory process feature model depicted figure reflects process model figure process feature model, two activity one two implementation may selected furthermore, activity optional, ie implementation may selected, mandatory process feature model consists three layers, ie process level, feature level, implementation level process level represents entire business process feature level includes activity business process specifies whether mandatory ie implementation selected optional ie implementation may selected mandatory implementation level list available implementation activity activity corresponds subprocess, another process feature model structure level constructed subprocess activity business process input output data whose data structure specified design time term process data structure used refer combined input output data activity business process thus, input output data structure activity determines part process data structure activity read write access two activity output data structure write access hence, activity output data structure preceding activity might overwrite data predecessor, ie data predecessor lost requirement engineering, order activity well output data structure ie write access specified therefore, behaviour activity foreseen data inadvertently overwritten aside passing accepting data, interaction activity executed predefined order parallel consequently, unintended feature interaction pais product line approach pais product line currently lack flexibility one implementation chosen activity pais product derivation furthermore, process data structure cannot adapted individual need organisation derived pais product share process data structure finally, approach pais product line currently support feature binding compile time, solely section show eliminate limitation flexibility enhancing approach pais product line first, requirement enhanced approach elicited then, assumption enhanced approach stated finally, shown aforementioned limitation concerning flexibility eliminated used business process special parking permit craftspersons simplified version example, deduced cooperation german municipality work extend example towards complete version business process example describes business process special parking permit process various german municipality offer special parking permit craftsperson may park car zone regular citizen need pay parking prohibited business process checking application parking permit among considered municipality displayed figure first, craftsperson applies parking permit then, application checked application justified, parking permit issued application justified, applicant notified rejection described control flow common across municipalities, implementation business process varies municipalities, application check carried municipal clerk whereas municipality application checked automatically comparing data application data craftsperson officially registered authority besides, application rejected applicant may notified via mail, sms, municipal clerk depending municipality choice applicant applicant might choose way notified list available notification mean furthermore, process data structure also varies municipality require applicant fill different data municipalities, parking permit valid every car whereas others applicant need provide number plate parking permit shall valid order prevent misuse parking permit craftsperson private car addition, able automatically check application, craftsperson need provide commercial register number registered authority nutshell, pais product line need comprise common core artefact including process model similar pais product derived order reduce development effort comparison developing similar pais product separately one implementation shall selectable activity constitutes variation point implementation shall selectable compile time, start time, runtime process data structure shall customisable pais product well business process checking application special parking permit resulting requirement studied cooperation german municipality previous work used simplified version business process example, work use comprehensive version deduce requirement enhanced approach accordingly enhanced approach pais product line shall meet following requirement pais product need derivable pais product line denotes set common core artefact including core process model order avoid development redundant software artefact similar paiss multiple implementation one activity shall selectable pais product derivation process data structure shall adaptable allowing different organisation use different process data structure derived pais product need formally specified implementation activity may selectable constraint need met selection combining certain implementation different activity might produce unintended behaviour feature interaction method need established order detect prevent unintended feature interaction enable selecting activity implementation start runtime based input user dynamic feature binding becomes necessary using dynamic feature binding, challenge described section need tackled activity implementation dynamically unbound runtime ie implementation deselected data processing might get lost need specified whether activity implementation may unbound yes how, eg saving current state unbinding activity implementation runtime, shared data system process might affected method need established ensuring shared data system process corrupted using static dynamic feature binding, activity implementation might bound different order intended must therefore assured different binding order must lead unintended behaviour approach work, following assumption hold control flow core process model included pais product line specified immutable, ie process model change pais product derivation hence, derived pais product process model thus identical control flow work focus implementation variability, approach deal control flow variability concept applied activity centric business process object data centric approach business process management like discussed excluded approach previous work, deriving pais product, activity constituting variation point one implementation may selected, ie implementation may selected activity either manual task consisting user form automated task executing business logic figure extract business process special parking permit depicted activity check application type hence corresponds variation point two implementation available, ie automatic check manual check previous work, one two implementation may selected furthermore, activity business process executed pre specified order, eg activity check application executed activity apply special parking permit execution order well read write access activity attribute process data structure determined requirement engineering figure seen activity apply special parking permit write access application data structure, whereas activity check application read access application write access decision data structure consequently, activity influence data read write read write access carefully specified unintended feature interaction allowing multiple implementation activity, execution order implementation specified if, example, figure activity check application implementation automatic check manual check selected, implementation run parallel process instance pass activity implementation activity may executed isolation unintended technical feature interaction however, implementation one activity may influence via data write due non determinism might foreseeable implementation finish last thereby overwrites data predecessors, ie result unpredictable consider example feature interaction pais product line figure activity check application writes decision whether application justified process data structure consequently, implementation may write decision well, ie application checked automatically municipal clerk selecting implementation ie manual automatic activity check application, implementation finish last determines whether application justified example, result automatic application check overwritten decision municipal clerk take longer automatic application check lead unpredictable result depending implementation writes data last seen unintended feature interaction tackle challenge, activity reading writing need distinguished activity read access data pose challenge term feature interaction example selecting sm mail notifying applicant matter implementation finish first implementation write data hence influence order prevent feature interaction activity write data, prevention technique spl engineering might taken consideration section mutual exclusion interacting features, precedence priority discussed solution prevent feature interaction however, due requirement becomes necessary able co select multiple implementation one activity, mutual exclusion cannot used prevent feature interaction specifying precedence priority mean implementation highest priority always overwrite data implementation consequently, sense including multiple implementation one highest priority always overwrites data others another option would grant different implementation write access data work either implementation implement business requirement different way therefore need write data example, application check implementation need write data whether application justified note concept derivative module cf section may used context well additional code included two implementation write data structure example, additional code could determine application justified soon least one two implementation decides application justified additional code aggregate data different implementation refer additional code aggregation code another aggregation code might constitute majority vote multiple application check implementations, application rejected majority implementation consider application unjustified opposed derivative modules, aggregation code need placed process feature model aggregation code solely resolve technical dependency aggregation code introduces resolution business level might multiple aggregation code one may selected pais product derivation choice need indicated process feature model process feature model implementation one activity grouped well available aggregation code activity dashed arrow introduces constraint one aggregation code need selected one implementation activity selected consider following example aggregation code figure show process feature model example activity check application two implementation may selected, form manual check automatic check addition, two aggregation code implementation available feature model notation described section extended figure two implementation activity check application well two aggregation code implementation grouped using dashed box dashed arrow connects implementation group aggregation code group activity label state read follows number selected implementation greater one, one aggregation code implementation need selected, ie two item group selected, one item group need co selected well dashed arrow, represents conditional requires, taken literature cf section supplemented label previous work, pais product derivation process data structure could customised individual need organisation derived pais product shared process data structure however, example describes scenario becomes necessary adapt process data structure pais product derivation varying process data structure pais product line applying special parking permit, municipality require applicant fill number plate whereas parking permit municipality valid vehicle placed furthermore, automatically check application, application requires commercial register number consequently, process data structure varies municipality seen example different organisation need customise process data structure deriving pais product pais product line consequently, optional part process data structure activity read write data optional part process data structure accessed least activity implementation otherwise selection former useless never used hence, dependency activity implementation data structure including process data structure optional part process feature model allows pointing dependency activity implementation optional part process data structure point dependency dashed arrow like one used literature employed pais product derivation, activity implementation selected, corresponding optional part process data structure need included pais product order enable compilation latter business requirement perspective, included optional part data structure need accessed least writing reading, exactly order otherwise, one part data structure accessed reading writing, data structure empty furthermore, one part data structure accessed writing, solely, point collecting data data never processed used following, process checking application special parking permit cf example used explain concept varying data structure figure show process data structure associated example uml class diagram application corresponds composition data applicant, data company, car information, whereas latter field commercial register number data company optional indicated question mark optional part data structure included necessary activity implementation requires access specific part data structure, eg automatic application check requires commercial register number field data company addition process feature model, bottom figure contains feature model representing data structure figure activity implementation need specific optional part data structure dashed arrow required data structure part label indicating whether implementation need read write access activity apply parking permit multiple alternative implementation exist three form simple form, form applicant need fill commercial register number, complex form contains input field setting commercial register number number plate form need write access corresponding data structure part automatic application check implementation need read access commercial register number able compare application data data commercial register activity issue parking permit, two alternative form one require optional part data structure, whereas form requires read access number plate field number plate need present issued parking permit activity implementation independent technical inter dependency single point interaction among activity implementation write read access process data structure consequently, order activity implementation bound influence behaviour activity implementation run process execution, bound process start selected user, implementation unbound execution selected process instance, activity implementation always finish execution hence, data lost shared data system process pose problem activity implementation independent technical dependency furthermore, activity implementation may unbound process execution selected validate presented approach, example implemented proof concept camunda platform used workflow management system first, property stated need provided proof concept then, technical perspective proof concept shall show customize process data structure pais product derivation, bind multiple implementation one activity, bind implementation different time finally, portrayed development maintenance may supported tool line requirement cf section proof concept need provide following property addition, development phase pais product line shall tool supported similar spl engineering, result pais product derivable pais product line derivable pais product include mandatory activity implementations, may differ selection alternative activity implementation proof concept show pais product derived pais product line technical perspective, ie variability mechanism used multiple implementation activity might selected executed suitable mechanism need chosen allows execute multiple implementation one activity variability mechanism need used compose process data structure pais product derivation meet organisation individual need process feature model outline activity incl implementation furthermore, illustrates whether activity mandatory optional using multiple implementation one activity, output data must collected aggregated order prevent overwriting data aggregation code need conditionally included one implementation activity selected order support static dynamic feature binding adequate variability mechanism must chosen phase domain analysis, domain implementation, requirement analysis, product derivation shall tool supported previous work, build tool apache maven used compose artefact pais product derivation data structure among pais product activity implementation designed independent logical unit compiled jar java application conditionally included implementation selected based apache maven profile is, apache maven used compose fully compiled artefact note worked, logical unit self contained could put together like building block contrast, process data structure need customizable cf example change class level, ie compilation process data structure need customised therefore, instead composing jars, java class need composed compose java classes, featurehouse ahead tool may used featurehouse require additional key word like refines, featurehouse used compose java class process data structure proof concept figure class company optional field commercialregisterno parent class application optional association class carinformation listing show base java class company attribute extension class company attribute commercialregisterno depicted listing sake brevity, getter setter method class listing omitted class composed featurehouse base class extension shown listing base class, extension, composed class pure java class specific activity shall constitute variation point, ie one implementation shall selectable activity implementation may service task, user task, call activity, call subprocess pais product derivation, core process model need composed implementation context, implementation may considered refinement base process model language xak used compose process model note latter modelled term bpmn xml representation however, using xak, refinement ie implementation schema compliant, ie file activity refined process model well cannot edited displayed bpmn modelling tool one advantage, bpmn xml graphical representation process model graphical representation serf mean communicating process model domain expert process model serving implementation schema compliant, advantage bpmn ie graphical representation, come effect furthermore, selecting lot implementation implementation need included core process model element need rearranged order make room additional element implementation although work provide mean automatically layouting process models, increasing number included implementation process model get unclear confusing therefore, xak used compose base process model implementation instead, multi instance call activity used, call implementation subprocesses implementation ie automated task user task embedded process model, called variation point activity figure show simple process variation point activity corresponds multi instance call activity call two implementation implementations, turn, simple process consisting activity, either automated task user task variation point multi instance activity may invoke implementation parallel allowing execution multiple implementation time figure show process model example proof concept activity check application notify craftsperson variation points, one implementation may selected therefore activity multi instance call activities, ie call corresponding implementation subprocesses detailed description implementation bound called core process model provided section able bind activity implementation statically well dynamically, approach like one presented section might used activity implementation code might composed compilation implementation statically bound language construct eg design pattern like decorator generated allow choosing implementation runtime however, activity consist graphical xml representation business logic service task html code user task therefore, design pattern like decorator pattern cannot applied language mixture pais product line instead, plugin approach used activity implementation eg automated task user task embedded process model consisting start event, end event actual activity implementation refer process model embedding activity implementation implementation process model figure show core process model top variation point activity two implementation process model bottom invoked variation point activity plugin mechanism allowing static dynamic feature binding pais product line illustrated figure compilation, implementation process model may included excluded static binding, cf figure implementation process model unique identifier id used unambiguously identify former implementation process model included compilation, registered plugin using id corresponding variation point activity cf figure excluded implementation cannot registered plugins available runtime implementation automatic figure included compilation consequently registered plugin start time, developer and, runtime, user may deselect one implementation registered variation point activity setting parameter figure show user form used start process selecting excluding specific plugins ie implementation variation point activity call registered implementation process model checked whether one latter excluded via parameter cf figure implementation process model invoked excluded via parameter dynamic binding selecting multiple implementation variation point activity writes data, aggregation code need included well order prevent unintended overwriting data activity implementation realised implementation process models, aggregation code need map data returned subprocesses ie implementation process model parent process model ie core process model aggregating consolidating data different implementation technical point view, static binding, featurehouse used composing activity implementation like process data structure composition core process bundled implementation process model implementing logic, namely html code user task java code automated task bundling file one folder, pais product compiled start time runtime, parameter may prevent certain implementation selected executed conditional statement software programs, frequently parameter used decide whether specific feature executed based value parameter providing values, parameter exploited variability mechanism feature binding runtime note use parameter variability mechanism well known literature example used demonstrate static dynamic binding activity implementation work registering plugins customexample feature binding time pais product line activity notify craftsperson figure business process special parking permit craftsperson used notify applicant application rejected activity variation point multiple implementation available applicant may notified via sms, mail, manually clerk compile time start time, implementation may selected developer runtime, applicant decide want notified available notification mean included developer figure show configuration activity notify craftsperson camunda platform aforementioned, activity implementation correspond implementation process model embeds implementing functionality ie automated task user task corresponding code base, ie java code implement automated task html code user task spring service notificationpluginprovider provides id implementation process model registered activity implementation then, camunda platform process engine iterates list id using iteration variable process call implementation process model spring service notificationpluginprovider depicted listing contains field notificationplugins type notificationpluginregistration, contains registered implementation notification activity applying parking permit, applicant may select one notification mean registered one selection applicant persisted process data structure calling method getprocessids listing registered notification plugins retrieved, iterated over, checked whether applicant selected method return id implementation process model registered user selected spring service notificationpluginregistration listing field plugins type list, pick injects spring service implement interface notificationplugin illustrated listing every implementation notification activity need implement interface order get registered plugin interface contains method get id plugin, id associated implementation process model, label plugin displayed application form cf figure furthermore, spring service notificationpluginregistration field excludedplugins, pick parameter command line application start example, following command start spring boot application using apache maven specifies mail notification plugin shall excluded thereby selectable application form spring service notificationpluginregistration comprises two method first method iterates registered plugins, eliminates excluded plugins, collect return label remaining plugins method called via graphical user interface application form, cf figure offer applicant selection available notification mean second method also iterates registered plugins, eliminates excluded plugins, collect return id implementation process model remaining plugins second method called spring service notificationpluginprovider figure show extract application form special parking permit craftspersons observed applicant choose notification mean mail, sms, notification clerk available selection extract, ie plugins included compilation, registered, deselected startup time graphical user interface call spring service notificationpluginregistration, get label registered plugins display applicant submits application form, id selected notification mean persisted process data structure selected notification mean used notifying applicant aggregation code special parking permit process activity check application data figure depicts business process special parking permit craftsperson, used check whether parking permit shall granted activity constitutes variation point two available implementation application checked automatically comparing data application data commercial register besides, application checked manually clerk implementation write result check process data structure consequently, implementation selected result data need aggregated, ie aggregation code need included reject application least one implementation reject application using subprocesses camunda, variable mapper implemented specify data data subprocess transferred parent process one implementation activity check application data selected pais product derivation, simple variable mapper included pass field justified subprocess parent process activity implementation included, variable mapper included collect field justified activity implementation evaluates soon one activity implementation find application unjustified variable mapper pas unjustified parent process variable mapper java class referenced process model spring bean name may included using featurehouse figure configuration activity check application data shown id implementation process model included compile time provided spring bean used call implementation process model furthermore, section delegate variable mapping configuration spring bean applicationcheckvariablemapper referenced act aggregation code summary, every activity constitutes variation point plugin mechanism every implementation need implement interface activity want register compile time ie static binding activity implementation may included excluded using featurehouse activity implementation consists implementation process model associated code base java code automated task html code user task start time, command line parameters, and, runtime, user input may used deselect activity implementation dynamic binding support phase spl engineering tool, featureide used proof concept feature model cf figure visualises variability pais product line domain analysis note feature model figure structured left right fit page featureide capture constraint text form feature model opposed arrow used approach requirement analysis, featureide support developer providing configuration editor cf figure configuration editor developer select desired activity implementation shall included pais product implementing variability pais product line, featurehouse chosen, supported featureide deriving pais product, featureide us selection configuration editor input figure compose variable activity implementation presented approach shown derive product pais product line varying process data structures, use multiple implementation one activity, bind feature compile time, start time, runtime following, approach assessed respect whether meet requirement set section furthermore, proof concept tested see whether provides listed property finally, limitation disclosed pais product line corresponds set common core artefact pais product may derived hence, requirement satified multiple implementation selected one activity activity may write process data structure, aggregation code need included order prevent implementation overwriting others data consequently, requirement met activity implementation may require adaption process data structure selecting specific activity implementation required part data structure need selected well therefore, requirement satisfied requirement met process feature model represents variability pais product line corresponding constraint unintended feature interaction occur activity implementation write process data structure aggregation code prevents implementation overwriting others data requirement satisfied runtime, activity implementation selected per process instance selected, cannot unselected anymore furthermore, activity implementation run independently technical dependency among consequently, activity implementation share system process data might corrupt addition, data get lost due terminated activity implementation hence, requirement satisfied well pais product line proof concept us featurehouse include optional activity implementation including activity implementation register plugin corresponding activity consequently, proof concept provides property featurehouse used compose process data structure well hence, property provided process feature model outline variability pais product line property, provided aggregation code implemented camunda variable mapper class, conditionally included using featurehouse therefore, property provided static dynamic feature binding supported using mix featurehouse parameter thus, property provided since featureide used tool support proof concept property provided using featurehouse, feature corresponds folder, contains code feature opposed previous work, code feature feature folder cannot compiled deriving product, code feature composed composition code compiled consequently, hard develop feature independently although feature folder might constitute repository version control, difficult reference compatible version feature compiled artefact version furthermore, featureide currently lack convenience feature code completion available selected feature package view feature folder especially cumbersome long package name displayed hierarchical folder instead grouped package following, related work assessed one way deal multiple variant business process include variant one process model linking gateway however, process model containing multiple variant business process may become large thereby complex, unclear, hard maintain besides combining variant one process model, multiple process model various variant may maintained thus, similarity investigated process variant independently modelled evolve challenge propagate change process models, tedious error prone aforementioned approach deal variability process model rather variability activity implementation level, approach focus managing lot similar business processes, various approach emerged allow configuring variability process model approach hiding blocking transferred process model reference process model contains process variant concrete process model derived configuration hiding blocking path process engineer may fill questionnaire configure reference process model outgoing path process element blocked configuration, path available runtime, whereas hidden path skipped runtime instead using reference process model contains process variants, provop us base process model various change pattern may applied order configure concrete process model modelling base process, adjustment point defined indicate adaption may applied model according provop approach, possible adaption include insert, delete move process fragment well modify process element attribute contrast hiding blocking, provop allows also adding process behaviour adjustment point process configuration instead removing process element eg hiding blocking besides configuring control flow process models, element process model may configurable la rosa et al propose approach individualise role object modelled configurable process model system literature review process variability, interested reader referred aforementioned approach differ approach provide mean configure element process model like paths, roles, objects, neglect configuration activity implementations, ie approach take engineering perspective account concept spl engineering applied business process work author introduce mean mark element process model variation point different variant well binding time may specified realisation variation point proof concept built top eclipse plugin architecture however, work focus modelling aspect variation point process model rather implementation detail variation point work lack detailed description variability mechanism used bind variant description management feature interaction approach, present depth approach use existing variability mechanism bind feature compile time, start time, runtime furthermore, approach describes handle feature interaction applying concept spl engineering variable business process spl engineering used well compose business process author argue service called business process may owned third party vendor may highly configurable order compose business process comprising service service treated spl whereas business process considered multiple spl author focus aggregating feature model spls, automatically checking feature selection aggregated feature model, determining service able accept output data service input data although author describe check whether service compatible eg regard data structure fail describe service automatically composed, technical mechanism shall used automatically bind connect service furthermore, dynamic binding service multiple binding one activity neglected work besides, considered business process include automated activity contain user task concept spl like feature modelling applied cross organisation business process however, approach holistic describe systematically automatically instantiate software product derived spl customer requirement corresponding part business process implement requirement mapped decision table, used configure derive business process product line however, author describe configuration work technical perspective spl engineering concept also applied automatically generate process model variant change process model automatically propagated derived process model variant work distinguishes one focus automatic generation paiss automatic generation process model pais product line comprises common set core artefact including core process model activity core process model may identified variation point different implementation eg user form, automated service developed pais product may derived pais product line selecting implementation variation point thereby, development effort cost reduced implementing similar pais product sharing common feature presented work complemented approach pais product line towards flexibility plugin mechanism introduced based featurehouse parametrization using plugin mechanism, activity implementation may bound compile time, start time, runtime furthermore, featurehouse used compose process data structure different organisation may require varying process data structure business process composing process data structure using featurehouse, process data structure may adapted organisation specific need pais product derivation addition, plugin mechanism enables selection multiple implementation activity deduced aggregation code required selecting multiple implementation one activity write part process data structure prevent implementation overwriting others data aggregation code additional code included multiple implementation one activity selected aggregate output data implementation finally, featureide used tool support phase domain analysis, domain implementation, requirement analysis, product derivation presented approach limitations, addressed future research focus varying activity implementation assumes fixed immutable control flow process model pais product derivation future research shall reveal control flow may adapted pais product derivation approach base reference process model might combined included approach pais product line besides, activity may constitute variation point, ie implementation activity may selected substituted future research shall outline event may constitute variation point implementation may substituted continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",software engineering
"structure language model protein conformation generation introduction related work protein conformation generation language modeling esmdiff masked diffusion instantiation experiment conclusion limitation learning sequence structure distribution structure language modeling revisiting discrete diffusion distribution interpolation conditional masked diffusion language model bidirectional encoder denoising network structural dynamic bpti conformation changing pair intrinsically disordered protein runtime analysis experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice protein adopt multiple structural conformation perform diverse biological functions, understanding conformation crucial advancing drug discovery traditional physic based simulation method often struggle sampling equilibrium conformation computationally expensive recently, deep generative model shown promise generating protein conformation efficient alternative however, method predominantly rely diffusion process within geometric space, typically center around vicinity metastable state often inefficient term runtime paper, introduce structure language modeling slm novel framework efficient protein conformation generation specifically, protein structure first encoded compact latent space using discrete variational auto encoder, followed conditional language modeling effectively capture sequence specific conformation distribution enables efficient interpretable exploration diverse ensemble mode compared existing method based general framework, instantiate slm various popular lm architecture well proposing esmdiff, novel bert like structure language model fine tuned esm masked diffusion verify approach various scenarios, including equilibrium dynamic bpti, conformational change pairs, intrinsically disordered protein slm provides highly efficient solution, offering speedup existing method generating diverse conformations, shedding light promising avenue future research protein structure dynamic fundamental understanding biological function protein ability protein adopt multiple conformation crucial function influencing interaction biomolecules environment traditional computational methods, molecular dynamic md simulations, long used explore dynamic however, method computationally expensive time consuming structure prediction models, alphafold jumper et al, rosettafold baek et al, made significant stride predicting static protein structures, yet often fail accurately capture dynamic nature protein multiple conformation chakravarty porter, recently, significant progress made adopting deep generative model conformation sampler efficiently explore complicated protein conformational space example, et al adopts normalizing flow match underlying boltzmann distribution learning simulation data despite potential, normalizing flow based method et al, klein et al, face significant challenge modeling large protein system hundred amino acids, invertibility constraint becomes major obstacle scaling model parameter remedy, denoising diffusion approach jing et al, lu et al, wang et al, zheng et al, efficiently learn structural data, achieve good generalization, perform amortized inference however, modeling high dimensional protein structure explicitly euclidean space demand intensive computation usually requires accounting special equivariant property hler et al, furthermore, based training objective denoising score matching song et al, tend predict local perturbation rather capturing remote mode alternative conformation wang et al, consequently, model may overallocate capacity learn structural noise training data instead focusing low frequency structural change chou, complement existing approaches, present structure language modeling slm novel framework protein conformation generation performs generative modeling latent space protein structure inspired recent progress developing structural vocabulary protein representation learning su et al, hayes et al, approach first encodes structural flexibility distribution latent token using discrete variational autoencoder, illustrated fig discrete latent encoding remove high frequency detail protein structures, forming structure language effectively capture uncertainty complex protein conformation fig conditional language modeling applied latent structure tokens, using amino acid type context capture sequence specific conformation distribution fig protein conformation finally reconstructed mapping structure token space learned decoder fig leveraging generative language modeling discrete latent space, slm bypass complexity equivariant constraint associated geometric symmetry benefit enhanced model capacity general framework, slm fully compatible existing language model lm architecture show promising scalability demonstrate versatility approach, introduce esmdiff, novel bert like structure language model instantiation fine tuned esm hayes et al, masked discrete diffusion austin et al, zhao et al, grounded slm framework experimental result across various conformation generation scenario demonstrate state art performance slm including representative esmdiff model, achieving order magnitude faster speed compared existing generative method proposed framework pave way new research avenue addressing protein conformation sampling challenge summarize key contribution follows comprehensively explore innovative conformation generation framework based language modeling latent space, open potential research avenue introduce esmdiff, novel fine tuned variant state art protein language model, built masked discrete diffusion demonstrate superior capability structure language model evaluating various conformation generation setting comparing existing method protein language model recent years, several language model protein sequence built among these, esm series rives et al, lin et al, hayes et al, similar model elnaggar et al, alley et al, garnered great attention wide range downstream application protein engineering meier et al, hand, auto regressive protein language models, based either recurrent neural network alley et al, transformer including progen madani et al, protgpt ferruz et al, able generate de novo sequence input controlling token specially, inverse folding model ingraham et al, jing et al, hsu et al, dauparas et al, gao et al, learn perform structure based protein design geometric aware encoders generative conformation sampling given intensive computation traditional md simulations, generative model used learn conformation distribution data driven fashion boltzmann generator et al, us normalizing flow fit boltzmann distribution target specific simulation data art et al extends using denoising diffusion model coarse grained protein conformation furthermore, eigenfold jing et al, str str lu et al, alphaflow jing et al, confdiff wang et al, dig zheng et al, leverage diffusion flow matching conditionally sample protein conformation learning pdb data recently, alphafold abramson et al, revised structure decoder alphafold diffusion based module diversified structure prediction quantized representation protein structure beside prevailing diffusion model protein structure, representation learning protein structure using discrete variational autoencoders dvae gained increasing attention recent year foldseek van kempen et al, one earliest attempt build dvae fast structure search alignment based this, saprot su et al, construct learned representation sequence structure token input, prott heinzinger et al, fine tuned existing language model accept structure token input pvqd haiyan et al, applied latent diffusion embedding space dvae conditional protein structure generation prosst li et al, trained autoencoder mean clustering applied latent space gaujac et al gao et al respectively build dvae large vocabulary learning protein structure representation remark work closely related concurrent research direction leveraging lm model efficiently perform conformation generation quantized representation protein structure refer framework structure language model describe detail notation protein residue identified sequence amino acid type vocabulary standard amino acid protein backbone structure represented composing atom position including backbone heavy atom encoder structure encoded sequence latent code pre specified vocabulary latent code structure token decoded first mapping embedding vector structure address conformation generation problem, start modeling sequence structure translation distribution interest derive learning objective section circumvent explicitly learning structure space, roto translation invariant latent representation introduced encode atomic protein structure given this, target distribution derived marginalizing joint distribution factorize joint distribution according bayes rule isolating latent variable denotes decoding distribution protein structure given structure token sequence, denotes conditional distribution structure tokens, respectively modeled neural network parameter set give rise evidence lower bound likelihood model distribution protein structure conditioned sequence introduced parameterized posterior distribution latent representation please refer appendix label app elbo full derivation eq directly optimizing right hand side eq intractable difficult since unknown posterior result, adopt one step expectation maximization em approach dempster et al, first jointly learning simple parameter free prior distribution followed optimization learned yield overall two stage separable training pipeline learning quantized representation structure prior fixed, begin maximizing elbo respect encoder decoder using protein structure sample context discrete latent spaces, process analogous training discrete vae dvae van den oord et al, learn quantized representation protein structure here, encoder map structure latent tokens, decoder reconstructs structure token prior fixed uniform stage learning prior latent token stage, fix learned parameter train prior maximizing elbo arg max since fixed, reconstruction term elbo cancel out, training reduces minimizing kl divergence kl equivalent performing maximum likelihood estimation, respect given categorical variables, formulation resembles translation task, allowing parameterized language model prior learned previous stage applied conformation generation, framed conditional generative modeling problem sequence structure seq str translation given input condition determines molecular topology, goal sample conformation ensemble this, first sample set latent variable prior distribution learned earlier, decode latents using decoder decoder jointly trained encoder first stage, ensuring sampled latents align reconstruction framework support roto translation invariant inference described algorithm next, illustrate approach two straightforward example structure language model slm encoder decoder decoder architecture encoder decoder given conditional nature translation, prior explicitly modeled encoder decoder architecture like raffel et al, decoder condition context factorizes structure token sequentially represents quantized structure token training objective negative log likelihood nll loss conditioned log decoder alternatively, latent prior modeled autoregressively using decoder architecture, gpt radford et al, serf prompt define training involves maximizing likelihood via nll minimization log iid sample data distribution structure associated amino acid sequence condition practice, add additional special token sep differentiate two modality inference involves sampling left right decoding order, defined autoregressive factorization language model figure briefly illustrates two modeling strategy building foundation slm, propose esmdiff instantiation based discrete diffusion model austin et al, esmdiff incorporates inductive bias seq str translation leverage protein foundation model esm hayes et al, masked diffusion fine tuning effectively fine tuning esmdiff also exemplifies large pretrained bert like masked language model adapted acquire additional generative capabilities, making well suited broader downstream task conformation generation discrete diffusion model austin et al, lou et al, sun et al, campbell et al, zheng et al, generally defined sequential process progressive noisy variable categorical variable denote one hot row vector discrete time case austin et al, forward marginal probability time following form composition markov kernel defined indicates transition probability matrix time represented cat indicates categorical distribution probability simplex eq also induce form marginal distribution cat cat correspondingly, posterior obtained reverse process austin et al, zhao et al shi et al discus discrete time diffusion process generalized time domain akin diffusion continuous space song et al, demonstrating continuous time limit notably, stationary distribution explicitly specified denoted choose state independent transition kernel simple form thus simplifying continuous time forward marginal strictly monotone decreasing function equation demonstrates discrete diffusion, defined explicit stationary distribution, viewed interpolation two categorical distribution controlled according eq reverse process diffusion defined eq take following form posterior distribution, indicator function concision reader referred appendix label app dd detail deriving eq unlike open ended text generation, protein conformation generation well defined within discrete diffusion models, condition input amino acid sequence, allowing output token correspond uniquely position input thus enjoy fixed length context window masked diffusion austin et al, lou et al, shi et al, sahoo et al, represents special case transition includes absorbing state denoted mask formulation, stationary distribution eq assigns probability mass unique special token mask mask mask convenience, define mask one hot vector representing mask masked diffusion, stochastic forward process map mask remains state thereafter ie, absorbing conversely, reverse process gradually unmasks denoises mask token produce data sample see appendix label app proof eq implies mask backward process simply copy unmasked token ie cat otherwise probability mass interpolates posterior approximated using parameterization neural net neural network output probability vector remains conformation generation, consider conditional case masked diffusion given amino acid type goal sample structure token eq utilizing conditional posterior posterior parameterized similarly incorporating condition backbone model, resulting achieve goal, reverse process simulated must effectively approximate data distribution feasible training objective optimize estimation conditional elbo within continuous time integral, resulting following loss see appendix label app loss detail sampled learned encoder corresponding amino acid condition data distribution implies loss applied latents st mask practice, employ monte carlo estimation compute integral discus implementation conditional denoising network using bidirectional encoder language models, bert devlin, first, consider sequential generalization masked diffusion sequence categorical variable let sequence discrete structure token due interpolation scheme eq eq assume conditional independence factorize posterior distribution across output tokens, represents th output channel neural network implement coincides bert style transformer architecture allow u take advantage existing protein foundation model, example esm hayes et al, sequence tokens, masked log term training objective eq replaced summation log notation defined modification following special consideration network position coupled encoding unlike general translation problem, slms maintain strict position position correspondence amino acid type latent token inductive bias enables u construct input embedding position follows embedding function linear transformation copying unmasked token mask remain spite model output zero mask since parameterize approximated clean data fully unmasked mask token cannot present output probability zero equivalent adding logit study, pre trained lm head esm replaced randomly initialized head augmented vocabulary fine tuning base setting start pre trained dvae established hayes et al structure tokenizer frozen structure quantization perform residue level receptive field local geometric neighborhood protein structure structure language model described section based state art language model follows adopts raffel et al, architecture bidirectional encoder autoregressive decoder gpt model joint distribution uni directional decoder like gpt radford et al, esm zero shot pre trained bert model multi modality data perform zero shot inference gibbs sampling esmdiff fine tuned variant pdb data using masked diffusion objective eq gpt, embed sequence token pre trained esm encoder provide model condition esmdiff, two different sampling paradigm gibbs ddpm considered see appendix detail cccccc codebefore body block method j pwd j tic j rg validity tm en rmsd en block msa based msa sub alphaflow block seq based eigenfold str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm baseline consider multiple open source model evaluation baseline protein multiple conformation generation, mainly categorized msa based method includes msa subsampling del alamo et al, bryant alphaflow jing et al, method rely inference time retrieval multiple sequence alignment msa single sequence based method eigenfold jing et al, leverage harmonic diffusion process conditioned omegafold wu et al, embeddings generate protein structures, str str lu et al, simulates round trip local diffusion conditioned input structure explore hypothetical conformations, esmflow jing et al, replaces alphaflow esmfold backbone specially tailored intrinsically disordered protein idp generation idpgan janson et al, result reported baseline obtained running inference pipeline based open source code detailed pipeline found appendix training data training data structure language model controlled contain pdb entry may st, cutoff aligned previous work jing et al, lu et al, hayes et al, trained pdb data make fair comparison training set filtered include monomeric structure max resolution length ranging form total size training data participating benchmark set discover potential slms conformation sampling, several relevant datasets considered benchmarking purpose simulation dynamic bpti shaw et al, conformational changing pair including fold switching chakravarty porter, ligand induced apo holo state salda et al, intrinsically disordered protein idp deposited protein ensemble database ped lazar et al, benchmarking task reflect different characteristic challenge conformation generations, provides comprehensive evaluation model first experiment, evaluate model generating conformation protein bovine pancreatic trypsin inhibitor bpti structural dynamic pattern bpti well acknowledged shaw et al m long md simulations, based five kinetic cluster revealed similar lu et al report jensen shannon j divergence distribution pairwise distance pwd time lagged independent component tic radius gyration rg clash free validity ensemble tm score root mean square deviation rmsd wrt kinetic cluster benchmark result shown table following wang et al also evaluate best distance generated sample cluster, shown table rmsd tm score calculated using tm score binary zhang skolnick, structural alignment note cluster difficult remote folding mode wang et al, yet slms achieve significant improvement modeling smaller matching rmsd ccccc codebefore body method rmsd rmsd rmsd rmsd rmsd msa based msa sub alphaflow seq based eigenfold str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm continue study task modeling predicting conformational change structural protein author jing et al curated two benchmarking set pairing data including pair fold switching protein chakravarty porter, apo holo pair ligand induced conformational change salda et al, evaluate modeling capacity conformation diversity following setting evaluation metric jing et al randomly sample shot ensemble five structure per target evaluate based correlation metric residue flexibility ensemble tm score zhang skolnick, evaluation result test set shown table nicetabular cccccc codebefore body block method block apo holo block fold switch resflex gl resflex pt tm en resflex gl resflex pt tm en block msa based msa sub alphaflow block seq based eigenfold str str pf str str sde esmflow block slm gpt esm zero shot esmdiff gibbs esmdiff ddpm different structural proteins, intrinsically disordered protein idp fixed stable tertiary structure normal condition idp possess inherent flexibility usually exist dynamic ensemble conformations, allowing adapt different binding partner cellular environment curated total entry protein ensemble database ped lazar et al, benchmarking set specific, select experimentally validated eg nmr spectroscopy structure ensemble excluding similar protein record training set avoid data leakage see appendix due disordered structural characterization idps, alignment based metric tm score applicable different target different size ensemble ten thousand follow metric used janson et al evaluate mean absolute error mae specifically pairwise distance, radius gyration, contact map predicted ensemble ground truth ensemble ccc codebefore body block method pairwise distance radius gyration contact map msa based msa sub alphaflow eigenfold idpgan str str pf str str sde esmflow slm gpt esm zero shot esmdiff gibbs esmdiff ddpm demonstrate efficiency slm, benchmark runtime slm compare diffusion based baseline measurement based elapsed wall clock time sampling ensemble across different protein length see appendix shown fig slms exhibit superior scalability respect protein size faster diffusion model like alphaflow, highlighting potential real world application work, propose novel conformation generation framework structure language model slms overall task divided two stage conditional sampling latent structure token roto translation invariant structure decoding develop train variety conditional language models, especially masked diffusion based esmdiff, fine tuned variant enhance capability esm adapting conformation generation unlike existing methods, slms perform amortized distribution learning within invariant latent space, leading efficient inference alleviating need geometric modeling, slms fully exploit scalability modern language model architecture take advantage advanced hardware optimization benchmarking result across various conformation generation task demonstrate compelling performance application potential slms summary, proposed method open intriguing novel research direction related community explore limitation current study present several limitation worth exploring future work firstly, one design advanced dvae architecture balance structure disentanglement reconstruction fidelity addition discrete latent space, continuous latent space also considered, example using latent diffusion model rombach et al, secondly, worthwhile exploring alternative slm instance specially tailored sequence structure translation consideration proper inductive bias lastly, outstanding performance msa based method also indicates potential build msa conditioned structure language model",biomolecules
"topoqa topological deep learning based approach protein complex structure interface quality assessment introduction result discussion conclusion material method appendix supporting text appendix table figure instruction reporting error graph representation protein complex proteingat topoqa model datasets topoqa experimental html improve accessibility invite report rendering error learn project help improve conversion even significant advance alphafold multimer af multimer alphafold af protein complex structure prediction, accuracy still comparable monomer structure prediction efficient effective quality assessment qa estimation model accuracy ema model evaluate quality predicted protein complex without knowing native structures, key importance protein structure generation model selection paper, leverage persistent homology ph capture atomic level topological information around residue design topological deep learning based qa method, topoqa, assess accuracy protein complex interface integrate ph topological data analysis graph neural network gnns characterize complex higher order structure gnns might overlook, enhancing learning relationship topological structure complex interface quality score topoqa model extensively validated based two widely used benchmark datasets, dbm af haf along newly constructed abag af dataset facilitate comparison af three datasets, topoqa outperforms af multimer based af rank show advantage af nearly half target particular, dbm af dataset, ranking loss lower af multimer based af rank obtained further, af multimer af also extensively compared nearly state art model far know found topoqa achieve highest top hit rate dbm af dataset lowest ranking loss haf dataset ablation experiment show topological feature significantly improve model performance time, method also provides new paradigm protein structure representation learning structure protein complex essential importance understanding molecular mechanisms, drug design discovery, protein design, etc even though experimental method resolve protein structures, tend time consuming expensive suitable large scale analysis data driven model developed protein structure prediction among them, alphafold significantly advanced protein structure prediction, achieving performance predicting monomer structure rival experimental method recently, alphafold multimer af multimer alphafold af developed predicting protein complex structure particular, af significantly improved accuracy antibody antigen complex prediction af diffusion model based framework considered various protein complex configuration generated using different random seed native structure absent, model quality assessment qa estimation model accuracy ema used selection top ranked configuration predicted structure qa ema model critical enhancing prediction reliability estimating model quality absence native structure fact, ema qa method important component critical assessment technique protein structure prediction casp biennial experiment advance benchmark protein structure prediction method first introduced separate category since casp ema method evolved years, primarily designed protein monomer mathematically, ema method grouped three category including consensus models, pseudo single models, single model consensus method assume near native predicted structure similar other, poorly predicted structure differ greatly assess model quality certain predicted structure pairwise comparison structure model pool, collection generated structure target sequence pairwise comparison measured score like q lddt dockq modfoldclust multicom qa notable example average score used assess quality structure consensus method usually employ well established model pool contrast, pseudo single model method generate model pool structure comparison two type approach computationally expensive performance rely accuracy model pool single model methods, model pool longer required, thus limitation single model divided two category energy statistical potential based deep learning based first type method energy function based physico chemical information constructed judgment made statistical result large amount observational data deep learning based method gnn dove dproqa complexqa graphgpsm usually represent protein structure graphs, design amino acid sequence, structural physico chemical feature node edge apply graph neural network model gnns qa approaches, protein often represented graphs, residue node contact residue edge model also consider atom node provide detailed representation general, gnn based qa method excel propagating information across entire graph, help capture global structural pattern provides insight overall folding protein molecule recently, topological data analysis topological deep learning developed explore high order topological geometric information within data one effective approach integration persistent homology ph provides robust mathematical framework capturing quantifying topological invariant across multiple scale enables identification complex, higher order structure beyond traditional gnn model integration demonstrated promising result across various domains, including biology chemistry, physics, image analysis ph incorporated different gnn modules, feature representation aggregation process pooling layer even loss function combining ph gnns, model better equipped capture complex structure show significant potential, particularly predicting property related large biomolecules, protein here, propose topological deep learning based model topoqa protein complex interface quality assessment first time model combined ph gnn protein structure representation learning one hand, simultaneously utilized powerful learning ability gnn representation ability ph capture high order local residue level structural information hand, local residue level information updated aggregated give global representation message passing module graph neural network local residue level, extract atom around residue point cloud, generate series simplicial complex according filtration process, calculate barcodes, vectorize using statistical property part initial node feature edge features, addition distances, also calculated pairwise distance atom two residues, facilitated detailed geometric representation protein complex interface global protein complex level, used module called proteingat update node edge embeddings, followed pooling information interface quality score prediction result show method topoqa one state art qa methods, showing outstanding performance across three benchmark datasets among these, dbm af haf widely used benchmark datasets, newly generated abag af dataset af validates robustness broad applicability approach three datasets, topoqa showed advantage af multimer based af rank, especially dbm af dataset, achieved ranking loss lower compared af multimer based af rank compared af qa module, advantage nearly half target compared state art qa method far know, topoqa achieves highest top hit rate dbm af dataset lowest ranking loss haf dataset ablation experiment show topological feature significantly improve model performance, increase time dbm af haf datasets, respectively approach provides new paradigm qa term topology, facilitating better protein structure learning topological representation protein complex directly influence performance deep learning model propose bipartite multipartite graph representation characterization protein complex interface shown figure a, since interface key importance protein complexes, focus interaction within interface represent bipartite multipartite graph figure show complete protein complex corresponding protein interface, respectively based extracted protein interface, construct bipartite interface graph model inter chain interaction shown figure d, bipartite graph, residue represented vertex inter chain contact represented edge bipartite structure allows u effectively capture complex interaction different chain within protein further, detailed residue level information incorporated graph representation considering special node feature edge feature different previous models, incorporate higher order geometric topological information local residual environment model using persistent homology analysis specifically, compute ph local point cloud residue apply element specific skill extract coordinate atom target residue surrounding atom point clouds, divide point cloud different subset according atom type carbon nitrogen oxygen c,n c,o n,o c,n,o construct simplicial complex using subset point cloud using ph, original point cloud data characterized topological barcodes use five statistic barcode vectorization minimum, maximum, mean, sum standard deviation compute dimensional dimensional barcodes vectorized dimensional topological features, added node feature computationally, node dimensional features, including dimensional basic feature dimensional topological feature basic feature include dimensional one hot encoding residue types, dimensional one hot encoding secondary structure types, dimensional relative solvent accessible surface area, dimensional torsion angle atomic interaction adjacent residue within protein interface key importance quality assessment generated protein complex leverage detailed atomic information, total edge feature based atomic distance two residue specifically, edge connecting two residues, atom residue divided two point cloud pairwise distance atom point cloud calculated grouped bin bin, count distance falling within bin used corresponding feature, capturing distribution atomic interaction residue extra edge feature distance atom considered, resulting dimensional edge feature propose special gnn architecture known proteingat shown figure b, proteingat model us multi head attention update node edge features, leverage predict interface quality score target node embedding layer attention coefficient computed using node embeddings edge embedding normalized final weight via softmax function updated node embedding layer computed using attention weighted information neighboring node updated edge embedding layer obtained concatenating updated node embeddings original edge embedding followed projection new vector space updating embeddings, apply average pooling node edge embeddings linear layer reduces pooled edge embeddings half dimension pooled node embeddings, highlighting importance node information concatenated embeddings passed multi layer perceptron mlp final output train model using mean squared error mse loss function, minimizing difference predicted value dockq score compared performance model two recently developed qa methods, complexqa dproqa demonstrated competitive performance recent studies, using training, validation, test set fair comparison blind capsp experiment, dproqa one top performer among single model method term tm score ranking loss following previous work also include two deep learning methods, gnn dove trscore well two classical energy based methods, goap zrank shown high hit rate evaluation specifically, referring compared method interface score iptm predicted af multimer self assessment module utilized extended version af rank method, based self assessment module af multimer, repurposed scoring protein complex generate iptm score af rank composite confidence score significantly outperformed ema method entered casp also use iptm af comparison, one advanced protein complex prediction model shown figure stacked ranking loss different datasets dbm af haf datasets, followed previous work used dockq reference metric abag af dataset, used dockq wave reference metric, evaluate interface complex figure a, across dbm af haf datasets, topoqa achieves lowest stacked ranking loss among eight method topoqa loss lower dproqa second best loss lower goap loss, lower af multimer based af rank loss shown figure b, topoqa also achieves lowest stacked ranking loss across three datasets dbm haf abag af topoqa ranking loss lower dproqa loss lower af multimer based af rank aggregating result across different datasets, topoqa demonstrates best overall performance table report ranking loss method dbm af dataset method achieves second lowest average ranking loss, higher loss dproqa lowest loss achieved ranking loss lower goap third lowest ranking loss lower complexqa fourth lowest ranking loss lower af multimer based af rank fifth lowest ranking loss three target etq, al topoqa correctly selects top model according dockq, achieves ranking loss table show hit rate different method dbm af dataset topoqa achieves highest hit rate three level selecting acceptable higher, medium higher high quality decoy worth noting topoqa achieves best possible top result medium high quality level shown table also report average result multiple experiment different random seed compared dproqa, topoqa achieves lower mean ranking loss demonstrates stable performance, standard deviation dproqa additionally, according top hit, topoqa outperforms dproqa acceptable level target table report ranking loss method haf dataset topoqa achieves lowest average ranking loss topoqa achieves ranking loss lower af multimer based af rank second lowest ranking loss lower zrank third lowest ranking loss lower dproqa ranking loss moreover, topoqa achieves lowest loss two target amv table show hit rate different method haf dataset topoqa achieves highest hit rate two level selecting medium higher quality high quality decoy acceptable level, topoqa hit rate slightly lower best result achieved method topoqa achieves best possible top result high quality level shown table haf dataset, topoqa outperforms dproqa lower mean lower standard deviation ranking loss additionally, topoqa better average hit rate acceptable medium levels, target average dproqa table report ranking loss top mean dockq wave method abag af dataset except af topoqa achieved lowest ranking loss highest top average dockq wave value, demonstrating advantage method select better conformation different conformation target achieved ranking loss lower complexqa ranking loss lower dproqa ranking loss worth noting that, dataset, topoqa also demonstrates better performance af multimer based af rank although topoqa outperform af overall, shown table achieves lower ranking loss target better top mean dockq wave score total target although training data significantly smaller af topoqa still show advantage nearly half targets, demonstrating potential topoqa model shown figure stacked correlation coefficient three datasets figure c, topoqa achieves highest stacked pearson correlation coefficient, value higher second best correlation coefficient achieved dproqa figure d, topoqa also achieves highest stacked spearman correlation coefficient, measured representing increase compared second best correlation coefficient overall, topoqa also show good performance correlation coefficient evaluation metric dbm af haf dataset, primarily used dockq capri criterion evaluate models, following previous work metric assess single protein interface, recent metric like q score dockq wave bdm evaluate interface shown table topoqa performed consistently well across different metrics, ranking loss dockq dockq wave q score additionally, correlation coefficient demonstrating robustness stability topoqa evaluating interface accuracy evaluate impact node topological atomic distance related edge features, performed ablation study removing specific component topoqa model, result shown table figure removed topological feature node kept basic feature result showed performance model greatly affected specifically, dbm af dataset, ranking loss worsened representing increase pearson correlation coefficient spearman correlation coefficient decreased reduction reduction respectively haf dataset, ranking loss worsened indicating increase, pearson spearman correlation coefficient decreased reduction reduction respectively removed atomic distance related edge features, keeping distance led decline model performance dbm af dataset, ranking loss worsened increase pearson correlation coefficient increased spearman coefficient dropping haf dataset, ranking loss worsened pearson spearman coefficient decreased respectively result show node topological feature edge feature related atomic distance effect improving model performance among them, shown figure node topological feature significant impact, removing topological features, sum model metric ranking loss negated dbm af haf datasets topoqa, respectively show powerful ability combining ph gnn great potential protein structure learning af multimer af developed protein complex structure prediction, compared monomer structure prediction, still room improvement accuracy propose topology based quality assessment method enhance model selection improve accuracy protein complex structure prediction previous studies, residue commonly used node construct graph gnn based prediction, help capture global structural pattern provides insight overall folding protein molecule integrate persistent homology gnns quality assessment, using ph capture atomic level topological information around target residue, thus enhancing model representation protein structure ablation study demonstrate incorporating ph significantly improves model performance method show great potential extended protein structure representation task ema qa method important part casp experiment recent casp ema, task involved target model including complex ranging dimer chain team casp ema, guijunlab rocketx chaepred, trained large datasets million decoys, respectively contrast, model trained smaller dataset decoys, primarily oligomeric protein believe larger dataset, topoqa could demonstrate greater potential compared method, topoqa, af multimer based af rank af across three datasets topoqa outperformed af multimer based af rank datasets, particularly dbm af dataset, ranking loss lower notably, trained topoqa using small dataset generated af multimer, significantly less training data used af multimer although overall performance topoqa high af demonstrates advantage nearly half targets, indicating potential furthermore, af currently provides quality score predicted structures, method offer greater applicability versatility model quality assessment currently, model, topoqa, designed assess global interface accuracy protein complex ema methods, however, also encompass evalutions global fold local accuracy global fold accuracy focus overall correctness complex structure, utilizing metric tm score gdt score evaluate global topology contrast, local accuracy assesses residue level precision, employing metric like lddt cad score reference value future,we plan incorporate multi task learning broaden model capability interface accuracy evaluation comprehensive assessment accuracy work, present topological deep learning based method, topoqa, protein complex structure interface quality assessment constructing graph residue node combined gnns common approach, allow modeling complex interaction residues, thereby capturing important global structural pattern enhance protein structural representation incorporating topological information using ph residue, extract topological feature neighboring atom based specific atomic combination ablation experiment reveal introduced topological feature significantly enhance model feature removed, model performance drop original level two datasets, respectively compared models, method achieves highest hit rate dbm af dataset lowest rank loss haf dataset additionally, multiple experiment different random seed evaluation reference metric show topoqa produce stable results, demonstrating robustness three datasets, model demonstrates advantage af multimer based af rank, particularly dbm dataset, topoqa loss lower af multimer additionally, compared af qa module, topoqa show advantage nearly half target used training validation set dproqa complexqa combined two datasets divided training validation set multimer af dataset maf dataset comprises complex structure predicted alphafold af multimer, protein complex target sourced evcoupling deephomo datasets maf dataset contains decoy dockground dataset dockground dataset contains protein complex targets, average correct incorrect decoy used following three test datasets test model docking benchmark af dbm af dataset, comprises antibody antigen complex target decoy model heterodimer af haf dataset also generated af multimer, contains heterodimer target decoy model abag docking benchmark af abag af dataset previous work compiled non redundant antibody antigen dataset selected protein released target used af generate conformation per target, running five time different seed abag af dataset consists target conformation simplicial complex simplicial complex collection simplices geometric object points, edges, triangles, higher dimensional counterpart combined way preserve geometric structure simplex fundamental building block simplicial complex, defined convex hull affinely independent point simplex vertex, simplex edge, simplex triangle, simplex tetrahedron dimension simplex number vertex minus one simplicial complex encodes richer, higher dimensional information graph, making ideal framework describing shape structure complex object ability capture relationship beyond pairwise connection allows deeper analysis object topological geometric property homology group homology group algebraic structure capture topological invariant simplicial complex, providing information shape structure specifically, describe feature connected components, loops, void different dimension group crucial distinguishing space similar local structure different global topological properties, making powerful tool analyzing intrinsic characteristic simplicial complex given simplicial complex chain formal sum simplices coefficient field, typically set chain form abelian group, denoted boundary operator map simplex dimensional face represents simplex obtained omitting vertex simplex key property applying boundary operator twice result zero allows u define cycle group ker element boundary boundary group im boundary higher dimensional simplices th homology group defined quotient rank known betti number represents number dimensional hole simplicial complex persistent homology classical homology capture topological feature space, contain geometry information like scale object persistent homology address tracking appearance disappearance homology class filtration, providing additional geometric scale related information make powerful tool analyzing shapes, capturing feature persist across multiple scale simplicial complex filtration sequence nested subcomplexes filtration progresses, topological feature like connected components, loops, void created eventually disappear persistent homology track feature filtration persistent th homology group defined measure long homology class persists across different filtration level use persistent homology feature, track birth time death time generator persistent homology group birth time mark filtration level generator first appears, death time indicates either merges another generator vanishes time provide valuable insight persistence topological feature across different scale assess interface quality, retained interface residue within atom residue chain focus inter chain interactions, consider inter chain edges, defined connection residue different chain distance less construct interface graph residue represented atom vertex inter chain contact edge residue, use ph extract topological information specifically, residue consider coordinate set includes coordinate neighboring atom within cut distance choose atom target residue apply element specific skill divide point cloud different subset according atom type c,n c,o n,o c,n,o point cloud atom type, apply vietoris rip complex calculating dimensional ph, simplicial complex generated set point metric space connecting point edge pairwise distance threshold specifically, simplex formed every pair vertex apart filtration value apply alpha complex calculating dimensional ph given set point metric space radius parameter alpha complex simplicial complex constructed follows simplex included vertex enclosed ball radius contains point inside boundary ball, apart vertex using given simplicial complexes, construct filtration simplicial complex compute associated ph barcodes barcode visual representation bar corresponds specific generator ph groups, generator different dimension represent distinct topological features, connected component dimension loop dimension void higher dimension left endpoint bar mark birth generator, right endpoint mark death length bar, representing difference birth death values, quantifies persistence generator, providing insight significance within underlying topological space get fixed sized feature vector persistent homology barcodes, consider five statistic average avg standard deviation std maximum max minimum min sum sum dimensional barcode, since birth always use death calculation dimensional barcode, take birth, death persistence bar statistic calculation also filtered barcodes bar late death time dimensional barcode bar short lifetime bar typically considered noise data use following criterion filter summary, residue, methodology yield feature vector dimensionality statistic dimensional barcode statistic birth, death, persistence bar dimensional barcode providing robust foundation subsequent quality prediction task added dimensional edge feature edge formed two residues, first dimension represents distance atoms, remaining dimension capture atomic distance two residue specifically, feature derived constructing bipartite graph two point clouds, point cloud representing atom corresponding residue computed pairwise distance atom two point cloud divided interval bin bin, constructed bipartite graph using edge corresponding distance within bin, count edge bipartite graph used feature corresponding dimension edge connecting two residue proteingat module designed update node edge embeddings based multi head attention, perform graph level regression prediction embedding update use multi head attention mechanism below, take calculation one head example illustrate calculation process assume node embedding edge embedding layer respectively, node edge embedding layer respectively update formula equation computes attention coefficient node node trainable weight matrix map source node, end node edge feature new feature space respectively activation function equation us softmax function normalize attention coefficient obtain final weight set neighbor node node equation update node embedding, trainable weight equation us node embeddings layer edge embeddings layer update edge embeddings layer represents trainable weight matrix denotes vector concatenation operation graph level regression graph level prediction, use node edge information assume final node embedding edge embedding respectively, node feature edge feature pooling updates, applied average pooling embeddings node edge edge embeddings, added linear layer reduce dimension half node embeddings, emphasizing greater importance node information compared edge feature integrated node edge information, fed concatenated vector mlp three stacked linear layer final put training, model optimized minimize mse loss work supported part singapore ministry education academic research fund tier grant rg tier grant moe ep moe ep program china scholarship council grant interdisciplinary innovative research program school interdisciplinary studies, renmin university china also supported public computing cloud, renmin university china intuitively illustrate performance topoqa classifying decoys, use principal component analysis pca distributed stochastic neighbor embedding sne reduce dimension encoding generated topoqa visualization pca linear dimension reduction method project data new coordinate system orthogonal transformation sne nonlinear dimension reduction method preserve local structure similarity data minimizing kullback leibler divergence extracted feature embedding vector penultimate layer model input data dimension reduction mapping high dimensional feature two dimensional space, observe distribution acceptable higher quality incorrect quality sample lower dimensional space shown figure applied two dimension reduction technique two test set dbm af haf acceptable decoy incorrect decoy relatively separated low dimensional space, topoqa distinguish two type decoy case visualization result show topoqa strong classification generalization capability unseen data, learned feature representation effectively capture relationship structure quality feature scale selected different order improve stability model avoid impact scale difference model, normalized feature node edge use min max normaliztion, assume node edge feature graph normalized feature evaluation metric divided reference metric statistical metric reference metric assess accuracy structural models, statistical metrics, ranking loss, evaluate ability qa method predict reference metric utilized following reference metric dockq combine three interface similarity metric rmsd, ligand model relative reference structure rmsd, interface region decoy model reference structure fraction atom pair correctly predicted decoy model dockq continuous value larger value, higher interface quality capri criterion combine rmsd, rmsd classify predicted structure four level high quality, medium quality, acceptable quality, incorrect dockq wave variation dockq obtained weighting dockq score interface q score represents fraction shared interface contact residue different chain distance two structure range q score q score close mean interface similar decoy let predicted quality score reference value used following statistical metric pearson correlation coefficient used measure linear relationship predicted quality value reference value spearman correlation coefficient used measure monotonic relationship two variable rank ranking loss used measure ability qa model correctly select top model ranking loss difference highest reference value reference value corresponding top decoy selected qa method top hit rate represented three number separated character three numbers, order, represent many decoy acceptable higher quality, medium higher quality, high quality among top ranked decoy continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"mofflow flow matching structure prediction metal organic framework introduction related work preliminary method experiment conclusion ethic statement appendix data statistic appendix glossary appendix implementation detail appendix defining local coordinate building block appendix model architecture instruction reporting error representation mof structure flow matching riemannian manifold construction local coordinate flow matching mof structure prediction model architecture structure prediction property evaluation scalability evaluation comparison self assembly algorithm experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice metal organic framework mofs class crystalline material promising application many area carbon capture drug delivery work, introduce mofflow, first deep generative model tailored mof structure prediction existing approaches, including ab initio calculation even deep generative models, struggle complexity mof structure due large number atom unit cell address limitation, propose novel riemannian flow matching framework reduces dimensionality problem treating metal node organic linkers rigid bodies, capitalizing inherent modularity mofs operating space, mofflow effectively capture roto translational dynamic rigid component scalable way experiment demonstrates mofflow accurately predicts mof structure containing several hundred atoms, significantly outperforming conventional method state art machine learning baseline much faster metal organic framework mofs class crystalline material recently received significant attention broad range applications, including gas storage li et al, gas separation qian et al, catalysis lee et al, drug delivery horcajada et al, sensing kreno et al, water purification haque et al, particularly valued permanent porosity, high stability, remarkable versatility due tunable structure particular, mofs tunable adjusting building blocks, ie, metal node organic linkers, modify pore size, shape, chemical characteristic suit specific application wang et al, consequently, growing interest developing automated approach designing simulating mofs using computational algorithm crystal structure prediction csp task central importance automated mof design simulation importance task lie fact important function mofs, pore size, surface area, stability, directly dependent crystal structure conventional approach general csp based heavily ab initio calculation using density functional theory dft kohn sham, often combined optimization algorithm random search pickard needs, bayesian optimization yamashita et al, iteratively explore energy landscape however, reliance dft computation computationally expensive, especially large complex system mofs deep generative model promising solution accelerate prediction mof structure especially, diffusion model ho et al, flow based model lipman et al, shown success similar molecular structure prediction problems, eg, small molecule xu et al, jing et al, folded protein jing et al, lin et al, protein ligand complex corso et al, general crystal without building block constraint gebauer et al, xie et al, jiao et al, miller et al, model iteratively denoise random structure using neural network act similar force field guiding atom position toward minimum energy configuration contribution work, introduce mofflow, first deep generative model tailored mof structure prediction mofflow leverage modular nature mofs, decomposed metal node organic linkers figure label decomposition enables u design generative model predicts roto translation building block match ground truth structure achieve this, based riemannian flow matching chen lipman, propose new framework generates rotations, translations, lattice structure building block design underlying neural network composition building block encoder parameterized equivariant graph neural network based new attention module encoding roto translation lattice parameter mof note method competes existing deep generative model gebauer et al, xie et al, jiao et al, miller et al, general csp encompass mofs special member however, method specialized mof structure prediction exploiting domain knowledge local structure mof building block shared across different mof structure particularly useful reducing large search space mof structure consider mofs atom per unit cell boyd et al, whereas crystal general csp consist atom per unit cell jain et al, jiao et al, fact, confirmed experiments, recent deep generative model jiao et al, general csp fails scale large system size mofs also aligns torsional diffusion jing et al, improved existing molecular conformer generation algorithm xu et al, eliminating redundant degree freedom benchmark algorithm mof dataset compiled boyd et al consisting structure compare conventional deep learning based algorithm crystal structure prediction notably, mofflow achieves match rate unseen mof structures, whereas existing methods, despite computationally expensive, barely match also demonstrate mofflow capture key mof property scale efficiently structure containing hundred atom crystal structure prediction csp traditional approach csp rely density functional theory dft identify energetically stable structure generate candidate structures, heuristic technique random sampling pickard needs, simple substitution rule wang et al, employed, alongside sophisticated optimization algorithm bayesian optimization yamashita et al, genetic algorithm yamashita et al, particle swarm optimization wang et al, address computational burden dft calculations, many study used machine learning surrogate energy evaluation jacobsen et al, podryabinkin et al, cheng et al, recently, deep generative model emerged promising alternative optimization based method court et al, hoffmann et al, noh et al, yang et al, hu et al, kim et al, ren et al, notably, jiao et al proposes equivariant diffusion based model capture periodic invariance crystal structure distributions, lin et al jiao et al additionally consider lattice permutation space group constraints, respectively miller et al us riemannian flow matching generate high quality sample fewer integration step however, method face significant challenge predicting mofs structures, often consist hundred atom per unit cell mof structure prediction unlike general csp, variety algorithm developed, mof structure prediction remains significant challenge conventional mof structure prediction method heavily rely predefined topology connect mof building block marleny rodriguez albelo et al, wu jiang, restricting discovery structure new topology address limitation, darby et al proposes combine ab initio random structure searching airs pickard needs, wyckoff alignment molecule wam method however, reliance airs make computationally expensive also note recent work fu et al, considered related, yet different problem mof generation based deep generative model include structure generation flow matching flow matching simulation free approach training continuous normalizing flows, originally introduced lipman et al since introduction, various extension proposed, generalization riemannian manifold chen lipman, efficiency improvement optimal transport tong et al, pooladian et al, due flexibility computational efficiency, flow matching made notable progress several related domains, including protein generation yim et al, bose et al, molecular conformation generation song et al, csp miller et al, mof representation crystal structure mof represented periodic arrangement smallest repeating unit called unit cell unit cell containing atom represented tuple atom coordinates, atom type denoting set possible elements, lattice parameter describes periodicity structure miller et al, luo et al, particular, lattice parameter transformed standard lattice matrix defines infinite crystal structure set integer representing periodic translation unit cell block wise representation mofs introduce blockwise representation mofs decompose given unit cell constituent building blocks, ie, metal node organic linkers blockwise representation tuple corresponds building block corresponds set building block roto translation moreover, block atom atom type local coordinate main assumption building block composed roto translation form mof structure, ie, atomwise representation expressed blockwise representation result roto translated local coordinate represented group action express global coordinate concatenation without loss generality flow matching method train continuous normalizing flow cnf chen et al, without expensive ordinary differential equation ode simulation lipman et al, here, introduce flow matching generalized riemannian manifold chen lipman, cnf riemannian manifold consider smooth connected riemann manifold metric point associated tangent space inner product consider learning cnf defined ode time dependent smooth vector field vector field transforms prior distribution according following push forward equation divergence operator conditional flow matching riemannian manifold goal cnf learn vector field transforms simple prior distribution closely approximates target distribution given vector field corresponding probability path one train neural network flow matching objective norm induced metric however, flow matching objective lack analytic form transforms prior target key insight conditional flow matching objective instead learn conditional vector field data point defined follows let dirac distribution key idea conditional flow matching one derive conditional vector field marginalizes data point accordingly induce vector field transforming prior desired distribution construct chen lipman proposes defining conditional flow geodesic path minimum length curve connecting two point exp log exp log exponential logarithmic map point respectively desired conditional vector field derived time derivative, ie, optimum, generates starting point end point inference, sample prior propagate using one existing ode solver note training step faster method based adjoint sensitivity chen et al, since conditional flow matching require solving ode defined neural network section, introduce mofflow, novel approach mof structure prediction based rigid body roto translation building block express global atomic coordinate end, using riemannian flow matching framework, learn cnf predicts blockwise roto translation lattice parameter given building block compared conventional csp approach defined atomic coordinate jiao et al, lin et al, miller et al, mofflow enjoys reduced search space, ie, dimensionality blockwise roto translation atomic coordinate respectively incorporate mof symmetries, devise scheme consistently define local coordinate regardless initial pose building block given building block goal define global local function defines consistent local coordinate system is, function satisfy random conformation building block define property satisfied composition translation subtracting centroid rotation aligning principal component analysis pca ax here, denotes subtraction centroid denotes rotation align building block pca ax whose sign fixed reference vector, following gao nnemann see appendix detail section, present approach training generative model using flow matching framework first explain method ensures invariance introduce metric independent treatment component next, outline key element flow matching ie, definition priors, conditional flows, training objective preserve crystal symmetries, design framework generative model invariant rotation, translation, permutation atom building block rotation invariance guaranteed using rotation invariant lattice parameter representation canonicalizing atomic coordinate based standard lattice matrix miller et al, luo et al, translation invariance achieved operating mean free system building block centered origin ie, way ensure translation invariance invariant probability measure exists yim et al, permutation invariance addressed using equivariant graph neural network satorras et al, transformer vaswani, backbone metric following yim et al treat independently defining additive metric here, inner product defined tr denoting lie algebra prior rotation translation prior chosen uniform distribution standard normal distribution respectively lattice parameter follow miller et al use log normal uniform distribution specifically, lengths, let lognormal parameter learned maximum likelihood objective appendix angles, use niggli reduction grosse kunstleve et al, constrain distribution range conditional flow following chen lipman train model match conditional flow defined along geodesic path riemannian manifold here, exp exponential map log logarithmic map point definition, conditional vector field derived time derivative training objective instead directly modeling vector fields, leverage closed form expression enables parameterization network predict clean data intermediate mof structure achieve this, train neural network approximate clean data, expressed regression clean data dataset, uniform distribution defined interval loss coefficient see appendix here, describe architecture neural network used predict clean data two key module atom level update layer obtain building block embeddings atomic resolution, building block level update layer aggregate update information mof building block resolution predict final building block embeddings follows, describe module one one atom level update layer atom level update layer figure process building block representation output building block embedding graph neural network operating undirected graph constructed adding edge pair atom within cutoff distance initializes atom wise feature atom type edge feature atomic distance layer update atom feature follows set updated atom features, denotes neighbor atom graph multi layer perceptrons mlps finally, building block embedding obtained applying mean pooling node embeddings last layer followed concatenation sinusoidal time embedding vaswani, mlp block level update module layer update module figure iteratively update prediction along block feature pairwise feature prediction initialized intermediate flow matching output node feature initialized atom level update layers, edge feature initialized follows dgram computes distogram binning pairwise distance equally spaced interval finally, block level update module defined follows updated prediction feature importantly, nodeupdate operator consists newly designed mofattention module followed pre layer normalization transformer xiong et al, mlp residual connection edgeupdate backboneupdate module implemented yim et al latticeupdate identity function lattice parameter except last layer final layer, lattice parameter predicted mean pooling block feature followed mlp complete detail update module appendix particular, mofattention module modification invariant point attention module proposed jumper et al processing protein frame modification consists adding lattice parameter input simplification removing edge aggregation information particular, lattice parameter embedded using linear layer added offset attention matrix building block provide detail algorithm input node feature edge feature rotation translation lattice parameter number building block number head number non rotating channel number rotating channel output updated node feature goal experiment address two question accuracy structure prediction accuracy mofflow compare approach scalability performance mofflow vary increasing number atom building block address first question, section compare structure prediction accuracy mofflow conventional deep learning based method furthermore, section evaluates whether mofflow capture essential mof properties, validating accuracy prediction second question answered section analyze performance mofflow increasing system size additionally section compare mofflow self assembly algorithm fu et al, integrating approach dataset use dataset boyd et al containing mof structure following fu et al apply metal oxo decomposition mofid bucior et al, decompose structure building block filtering structure fewer blocks, split data train valid test set ratio full data statistic appendix baseline compare model two type method optimization based algorithm deep learning based method traditional approach, use cryspy yamashita et al, implement random search r evolutionary algorithm ea deep learning, benchmark diffcsp jiao et al, generates structure based atom type mof specific method excluded due lack public availability metric evaluate using match rate mr root mean square error rmse compare sample ground truth using structurematcher class pymatgen ong et al, two set threshold stol ltol angle tol used alignment general csp literature jiao et al, chen lipman, account difficulty predicting large structure mr proportion matched structure rmse root mean squared displacement normalized average free length per atom also measure time required generate samples, averaged across test set implementation r ea use chgnet deng et al, structure optimization generate sample rs, ea start initial, populations, generation due high computational cost large crystals, generating sample feasible diffcsp, follow hyperparameters jiao et al train epoch method us adamw optimizer loshchilov, learning rate use maximum batch size run inference integration step generate sample diffcsp method implementation detail appendix result table present results, mofflow outperforms baseline optimization based method yield zero mr, highlighting challenge using conventional atom based approach large system diffcsp also performs poorly, underscoring need incorporate building block information mof structure prediction achieve mr stol threshold lenient practical application however, include multi level comparison visualization comparing sample mofflow diffcsp shown figure section, demonstrate mofflow accurately capture key property ground truth mof structures, offering detailed assessment prediction quality beyond match rate rmse property crucial various mof applications, gas storage catalysis specifically, evaluate volumetric surface area vsa gravimetric surface area gsa largest cavity diameter lcd pore limiting diameter pld void fraction vf density dst accessible volume av unit cell volume ucv definition detail property provided appendix comparison, use diffcsp representative general csp approach exclude optimization based baseline yield meaningful result test structure section generate single sample compute relevant property using zeo willems et al, filter sample match criterion section use integration step model measure performance rmse result table show mofflow consistently yield lower error diffcsp across evaluated property demonstrates ability produce high quality prediction preserving essential mof characteristic additionally, figure visualizes property distributions, model closely reproduces ground truth distribution capture key characteristic contrast, diffcsp frequently reduces volumetric surface area void fraction zero, highlighting limitation conventional approach accurately modeling mof property here, demonstrate mofflow enables structure prediction large systems, challenge general csp method evaluate performance scale system size, analyze match rate function number atom building block compare result diffcsp representative general csp approach generate single sample test structure use threshold visibility result figure present findings, axis representing number atoms, binned range final bin includes atom count beyond last range, without upper limit mofflow consistently outperforms diffcsp across atom range approach show gradual performance degradation atom count increases, diffcsp suffers sharp decline system atom fails predict structure atom contrast, method maintains high match rate even structure exceeding atom per unit cell, highlighting effectiveness leveraging building block information mof structure prediction additionally, figure show match rate scale number building block result show minimal performance degradation, demonstrating model effectively handle larger number building block efficiently scale large crystal structure make evaluation comprehensive, also consider self assembly algorithm used fu et al baseline, although performance directly comparable self assembly sa algorithm optimization based method predicts rotation maximizing overlap building block connection point since algorithm requires input, directly applicable structure prediction therefore, conduct ablation combining self assembly algorithm predicted value note self assembly algorithm defines centroid center mass connection points, account offset implementation result table show mofflow alone outperforms combination self assembly algorithm, indicating learning building block orientation lead accurate mof structure prediction heuristic based overlap optimization additionally, method offer faster inference, demonstrating efficiency compared optimization based approach propose mofflow, building block based approach predicting structure metal organic framework mofs approach significantly outperforms general crystal structure prediction algorithm quality efficiency fail account modularity mofs additionally, mofflow scalable, successfully predicting structure composed thousand atom describe experimental detail hyperparameters appendix provide code model checkpoint anonymous openscience mofflow framework target advance porous material discovery, deeply related carbon capturing, catalysis design, drug discovery believe work improve quality human life assisting resolving global warming drug design however, notice caution due misuse developing hazardous material product may harmful specific usage section, present data statistic represent characteristic mof dataset consider mof dataset boyd et al dataset generated mof generating algorithm based topology graph theory dataset distributed materialscloud mention section us filtered strucutures fewer block dataset divided train, valid test ratio statistic data split represented table label label structural property section, introduce structural property measured property calculated using zeo software package developed willems et al zeo provides high throughput geometry based analysis crystalline porous materials, calculating critical feature pore diameters, surface area, accessible volume, essential evaluating material performance application gas storage catalysis specifically, calculated property including volumetric surface area vsa surface area per unit volume gravimetric surface area gsa represents surface area per unit mass largest cavity diameter lcd represents diameter largest spherical cavity within material pore limiting diameter pld defined smallest passage molecule must pas access internal void void fraction vf martin haranczyk, ratio total pore volume structure total cell volume density dst refers mass per unit volume material accessible volume av indicating volume available center given probe molecule within pore unit cell volume ucv representing total volume repeating unit cell crystal structure parameter provide critical insight mof porosity, surface area, ability store transport gases, recent study show correlation property bulk material krishnapriyan et al, training detail employ timestepbatch algorithm yim et al, efficiently construct batch method generates batch applying multiple noise level single data instance, ensuring uniform batch size manage memory constraints, cap batch size number atom model trained eight gb nvidia rtx gpus epochs, taking approximately day hyperparameters table table show model training hyperparameters mofflow, respectively practice, generate independently, allowing distinct dimension non rotating channel represented tuple, specified order set log normal distribution parameter lattice length computed training data closed form maximum likelihood estimation baseline diffcsp jiao et al, change edge construction method original fully connected radius graph cutoff since fully connected graph feasible large size crystal like mofs use batch size cope memory constraint option followed default hyperparameter diffcsp trained epochs, taking approximately day convergence gb nvidia rtx gpu random search r evolutionary algorithm ea structure prediction, considered cryspy yamashita et al, software deep learning based structure optimizer deng et al, set symmetry based search r constructed structure per sample also, set ea initial r ran maximum generation crossovers, permutations, strains, elite population considered tournament selection function tournament size used energy based optimization r ea, since exists publicly opened software mof crystal structure prediction code implementation built upon githubcom microsoft protein frame flow, githubcom microsoft mofdiff, githubcom gcorso diffdock, githubcom vgsatorras egnn appreciate author yim et al, fu et al, corso et al, satorras et al, contribution following, gao nnemann use principle component analysis pca backbone since equivariant sign specifically, denote pca order decreasing eigenvalues, is, sign preserved upon rotation define consistent direction, gao nnemann suggests use equivariant vector function then, final equivariant ax defined however, find definition insufficient application building block dimensional exhibit symmetry respect origin thus cases, define ie, vector centroid closest atom since building block symmetric, still fulfills equation permutation, handled gnn transformer here, provide detail nodeupdate edgeupdate backboneupdate module implementation follows yim et al jumper et al exception mofattention module transformer use pre layer normalized version xiong et al, module introduced notation function algorithm defined input output input output input output continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"quickbind light weight interpretable molecular docking model introduction method result discussion outlook acknowledgment disclosure funding supplementary information appendix si algorithm appendix si protein ligand feature appendix si cropping appendix si hyperparameter screening appendix si training detail appendix si exemplary prediction appendix si pb failure mode appendix si correlation physicochemical feature appendix si additional interpretability study appendix si binding affinity prediction appendix si virtual screening result appendix si retrospective comparison af instruction reporting error dataset evaluation metric model architecture model performance model interpretability case study experimental html improve accessibility invite report rendering error learn project help improve conversion predicting ligand bound pose target protein key component early stage computational drug discovery recent development machine learning method focused improving pose quality cost model runtime high throughput virtual screening applications, expose capability gap filled moderately accurate fast pose prediction end, developed quickbind, light weight pose prediction algorithm assess quickbind widely used benchmark find provides attractive trade model accuracy runtime facilitate virtual screening applications, augment quickbind binding affinity module demonstrate capability multiple clinically relevant drug target finally, investigate mechanistic basis quickbind make prediction find learned key physicochemical property molecular docking, providing new insight machine learning model generate protein ligand pose virtue simplicity, quickbind serve effective virtual screening tool minimal test bed exploring new model architecture innovation model code weight available github repository small organic molecule ligand major class drug act binding protein targets, thereby affecting functionality interfering molecular pathway disease distinct advantages, including ease synthesis, administration, cell permeability, render indispensable pharmaceutical modality early stage drug discovery, structure determination protein ligand complex critical scientific tool, provide understanding molecular determinant binding enable optimization drug affinity selectivity however bottlenecked costly cumbersome experimental procedures, computational molecular docking promise overcome supplemented estimate strength binding interaction, computational tool used virtually screen large space drug like molecule viable drug candidate serve starting hypothesis subsequent experimental investigation development existing computational method achieve high quality prediction cost increasingly long runtimes, caused, case conventional physical methods, need sample numerous binding location poses, case machine learning ml based method complexity underlying neural computation implicitly modern method largely divided molecular docking co folding molecular docking, approximate protein structure assumed known, whereas co folding protein ligand structure predicted scratch although new development, co folding become focus much recent research activity, including rosettafold atom rfaa neuralplexer umol alphafold af nonetheless, drug discovery campaign known potentially well studied protein target, often unnecessary predict protein structure independently every ligand, making molecular docking attractive alternative given higher speed due assumed rigidity protein ml based docking method divided targeted docking, requires specifying approximate binding pocket, blind docking, first ml method tackle latter equibind predicts isolated, bound conformation ligand us keypoint alignment mechanism identify rotation translation needed dock ligand binding pocket subsequent method employ complex architecture particular, tankbind bind first partition protein functional block using rank predict interaction given ligand block, choose final pose based predicted binding affinity tankbind confidence score bind architecture include component inspired alphafold af evoformer module importantly, tankbind predicts intermolecular distance map converted final coordinate numerical post optimization, whereas bind operates ligand coordinate directly fabind build upon bind integrating prediction location binding pocket main model, whole process becomes end end differentiable another leap forward made diffdock diffusion based generative model that, starting input conformer, predicts change torsion angle well transformation needed dock ligand protein inductive bias focus relevant degree freedom coupled generative formulation led large improvement accuracy increased runtimes recently, advance come integration protein language model pretraining technique geared towards molecular docking tasks, substantial increase model size, shift towards generative approach combination, trend led considerable increase computational cost ml based molecular docking, level prohibitive virtual screening work develop quickbind, light weight method rigid, blind molecular docking aimed virtual screening application trading accuracy speed quickbind performs well pdbbind test set, particular unseen protein considered, substantially faster diffdock leveraging af architecture problem formulation figure quickbind reason protein using residue level representation lieu atomistic one, permitting fast implicit accounting side chain flexibility accommodate additional degree freedom introduced small molecule ligands, quickbind incorporates new framing strategy invariant point attention ipa module af also include binding affinity prediction module facilitate virtual screen applications, capability typically absent docking co folding method showcase utility versatility quickbind predicting binding affinity structure multiple important drug target across various protein families, investigate interpretability model better understand biophysical basis prediction train test quickbind using pdbbind dataset additionally assess using posebusters pb benchmark pdbbind widely used assess molecular docking method using temporal split proposed equibind contains crystal structure binding affinity protein ligand complex training validation set comprise complexes, respectively, published test set contains complex published later ligand overlap three partition pb contains diverse complex unique protein drug like ligand released since therefore disjoint complex pdbbind training set quantify success based percentage prediction symmetry corrected ligand heavy atom root mean squared deviation rmsd less success rate criterion widely used, residual deviation true bound conformation materially impact downstream analysis optimization evaluating model purely success rate account chemical physical validity, assess criterion using pb suite prediction pas pb test whose rmsd deemed pb valid quickbind adapts alphafold architecture task protein ligand pose prediction figure take input protein sequence structure well chemical graph ligand conformer generated rdkit input combined yield unified first order single representation second order pairwise pair representation passed modified evoformer stack omits column wise self attention multiple sequence alignment used processing evoformer, structure module take updated single pair representation input well residue ligand reference frame using new framing strategy ligand atom described iteratively update ligand heavy atom coordinate structure module modified af ipa module gated cross attention performed single representation ligand protein coordinate update step algorithm protein atom held fixed quickbind us evoformer structure module block full algorithm detail given section si af us reference frame represent geometry protein residue translation vector corresponds coordinate atom rotation matrix, anchored coordinates, canonically constructed n, coordinate encode orientation residue backbone representation natural linear branched polymer atom arbitrary small molecules, canonical frame construction approach emergence co folding methods, two recent model proposed framing strategy small molecule quickbind employ new approach first, atom index reordered based canonical atom ranking rdkit heavy atom, coordinate treated atom coordinate two adjacent atom lowest index treated atom atom one bond, use dummy atom algorithm construct atom reference frame using procedure employed residue frame using framing strategy, found ipa component structure module, updating rotation matrix ligand atom frame improves performance, unlike approach neuralplexer rfaa update translation component passively reconstruct frame note af use reference frame reason protein ligand complexes, use framing strategy calculate predicted aligned error af reference frame constructed using two closest atom given center atom, atom two neighbors, frame ignored experimented analogous strategy found approach work better loss function adopt modified version frame aligned point error fape used af fape computed performing set alignment predicted reference frame residue aligned original reference frame target structure fape average, clamped rmsd predicted target structure alignment molecular docking, fape reformulated combination two component rmsd predicted target ligand atom position based ligand frame alignment residue frame alignment final quickbind model trained using combined fape loss, intermediate fape loss acting output every structure module block, kabsch rmsd loss corresponding ligand rmsd superimposition predicted target ligand using kabsch algorithm model detail given section si si training final quickbind model, aspect architecture optimized using two smaller variants, quickbind quickbind section si result hyperparamater screen summarized table si first assess quickbind pdbbind test set figure compare ml based rigid docking method including equibind, tankbind, bind, fabind, diffdock, neuralplexer employed blind molecular docking rather co folding exclude co folding method comparison evaluated pdbbind virtual screening involve billion molecule docking runtimes critical consideration average runtime s, quickbind order magnitude faster traditional docking method diffdock, recent co folding method accuracy wise, quickbind middle pack, outperforming ml based rigid docking method except fabind, diffdock, neuralplexer, particularly generalizing protein excluded training set excepting fabind, method considerably slower, fabind still us order magnitude parameter next, assess quickbind challenging pb benchmark figure include comparison recent co folding method quickbind generally outperforms rigid docking method except diffdock including fabind trail co folding method however, speed gap quickbind co folding method take minute single prediction even considerable, making quickbind compelling compromise speed accuracy figure si show example highly accurate quickbind prediction quickbind forgoes post processing step common ml based method enhance chemical validity prediction result, quickbind raw prediction generally pas pb chemical physical plausibility tests, largely due incorrect bond length angle figure si see also noted however, failure typically addressed running force field based energy minimization post prediction substantially improve physical validity quickbind prediction even slightly improves success rate figure given speed, natural use case quickbind binding affinity prediction virtual screening application test potential, trained simple neural network use quickbind single representation algorithm predict protein ligand affinity used pdbbind split training quickbind pdbbind affinity data resulting model competitive affinity predictor table si despite optimized architecturally hyperparameter tuning indicates quickbind immediate utility virtual screening may improved using advanced top model affinity prediction trained quickbind, set investigate whether learned ligand characteristic relevant molecular docking beyond binding affinity, molecular feature lipophilicity cell permeability influence outcome drug discovery program feature strongly linked physicochemical property ligands, hydrophobic surface area molecular weight, extent expert rule drug design often explicitly restrict drug like molecule based property model implicitly encodes may thus hold promise drug design beyond accurate pose prediction end, extracted single ligand representation evoformer transformed molecule level representation averaging across atom figure pipeline schematic every resulting channel value, computed pearson value total hydrophobic surface area, molecular weight, number hydrogen bond acceptor donors, polar surface area, number rotatable bonds, octanol water partition coefficient, number aromatic ring calculation performed using rdkit mordred carried computation every molecule pdbbind test set figure scatter plot found channel significantly correlated one property table si value least correct multiple hypothesis testing channel indicating quickbind fact learned physicochemical characteristic protein ligand binding selecting strongly correlated property per channel, found number bond acceptor donors, total hydrophobic surface area, number rotatatable bond strongest feature include additional result section si better understand quickbind utility real world deployments, predicted bound pose new ligand five protein pdbbind test set, selected based extensive experimental characterization clinical significance uniprot id mdi uli table si mdi trna guanine methyltransferase, bace beta secretase relevant development alzheimer disease galectin galactose specific lectin involved cancer uli human immunodeficiency virus hiv protease, gtpase ras, key cancer target used protein crystal structure three lowest affinity binder pdbbind test set input, predicted binding affinity complex structure compound pdbbind test set treated compound explicitly crystallized five target protein decoy figure si si table si likely resulted binder mislabeled non binder found quickbind capable discerning ligand binding characteristic across diverse ligand scaffold protein target specifically, quickbind distinguished binder non binder across various targets, including bace value one sided wilcoxon rank sum test galectin ra despite bace ra binder low average tanimoto similarity bace galectin quickbind also accurately predicted pose ligand rmsd consistently majority ligand success rate respectively based comparison pdbbind test set structure hiv protease, predicted binding affinity significantly differentiate binder non binders, quickbind still excelled predicting pose structure high accuracy prediction figure si analysis also shed light limitation quickbind struggled confronted protein whose conformation change dramatically binding target ligand versus low affinity ligand used template instance, kras structure average backbone rmsd input true conformations, resulted notable proportion pose exhibiting high ligand rmsds prediction fell wholly unseen trna guanine methyltransferase, quickbind struggled predict significantly higher binding affinity binder v non binder predicted moderately accurate pose ligand rmsd case quickbind ml model blind molecular docking optimizes runtime speed retaining competitive pose prediction accuracy, providing compelling option high throughput virtual screening furthermore capture physicochemical ligand property known influence molecular docking interpretability informs aspect underlying physic model captured may, sufficiently well developed, help guide design drug compound consideration important given large cost involved identifying prioritizing compound experimental testing optimization augmentation quickbind affinity prediction capability make suitable identifying new ligands, showcase using multiple highly relevant drug target except tankbind, existing blind docking co folding model predict binding affinities, therefore applicable screening application combination ligand pose interaction strength help optimizing potency selectivity drug candidates, although remains seen sensitive quickbind minor structural changes, profound effect binding called activity cliff added advantage quickbind formulation binding affinity prediction lack reliance experimental co complex structure unlike tankbind due trained separately main docking model embeddings protein ligand pair used, whether structure predicted experimentally derived mean quickbind affinity module trained bindingdb binding affinity database comprising million protein ligand pairs, order magnitude structural complex user also rapidly finetune binding affinity model target protein evaluation using pb benchmark showed quickbind struggle generate physically chemically valid poses, many recovered force field based energy minimization energy minimization increase model runtime, binding affinity module used first select subset promising compounds, whose pose energy minimized major shortcoming quickbind ml based molecular docking method dependence rigid docking, task trained evaluated rigid docking, method provided holo protein structure originally co crystallized query ligand, protein structure predicted reflect many real world us molecular docking user access apo unbound structure holo structure co crystallized another ligand although quickbind showed promise cross docking case study conducted, long input protein deviate much true structure ideally, model trained evaluated flexible cross docking setting, fact ml based blind, flexible docking method recently emerged future version quickbind adapted flexible docking method capable using apo, holo, even predicted protein structure input updating protein residue frame well ligand frame alternatively, side chain made flexible updating rotational component residue frame side chain torsion angle conceptually, one goal quickbind investigate af architecture may adapted task docking co folding docking co folding method previously demonstrated idea component af used protein ligand pose prediction, quickbind us essentially entirety af provided multiple insight first, suggests quickbind could benefit af native confidence estimate recycling, found important af success quickbind could also benefit complicated, af inspired loss functions, example structural violation loss would likely lead pb valid prediction second, quickbind provides rough estimate well af like model perform molecular docking fact achieve state art performance suggests certain aspect af ideally suited task anticipates change introduced af including minimized msa module atomistic reasoning ligand including innovation af likely result improved molecular docking tool section si turn, finding also implication af instance, since quickbind single representation capture physicochemical feature ligand, likely af single representation highly information dense well, may therefore useful task beyond pose prediction would like thank psivant therapeutic providing computational resource wt acknowledges financial support max planck school matter life sck supported nih grant gm residue type one hot encoded ligand atom following feature atomic number h, c, n, o, f, p, s, cl, br, i, chirality, degree formal charge number connected atom hybridization, presence ring, presence aromatic ring early version included atomic number degree formal charge implicit valence, number connected hydrogen number radical electrons, hybridization, presence aromatic ring, number ring in, presence ring size similar ref additional feature improve performance omitted ligand coordinate initialized using random rdkit conformer reduce quickbind memory footprint training, input protein sequence cropped residue model without evoformer module, respectively since model performance drop noticeably shorter crop sizes, final model finetuned crop size residue inference time, full protein sequence used depending available gpu memory, inference might therefore run cpu using resources, restrict inference gpus protein shorter residue multi chain proteins, sequence concatenated order appear pdb file tested different cropping strategy random contiguous cropping setting residue whose atom closest ligand atom midpoint contiguous cropped fragment binding site cropping, bsc selecting residue closest ligand atom spatial cropping setting protein cropped randomly spatially probability extensive hyperparameter screening full quickbind model would computationally expensive, optimized many hyperparameters architectural choice using two smaller variants, trained without ligand frame still updating atom position quickbind s, lack evoformer module contains four eight structure module block unshared weights, trained without batching quickbind m, lack triangle attention evoformer stack expensive module trained batch size main result hyperparameter screening summarized table si furthermore, several way generate ligand coordinate update final single representation tested general, final single representation separated protein ligand single representation then, either ligand single representation passed linear layer produce coordinate updates, protein single representation summed along sequence dimension corresponding mean taken, pooled protein representation concatenated ligand single representation passing linear layer, outer product protein ligand single representation summed along sequence dimension corresponding mean taken, passed linear layer, output attention layer query vector coming ligand key value vector coming protein concatenated ligand single representation passed final linear layer last approach led best result also tested scaling coordinate update factor done af find improve model performance furthermore, briefly experimented first applying global rototranslation ligand coordinates, either finetuning ligand coordinate changing torsion angle rotatable bonds, find lead better result using gated variant ipa module improved model performance compared standard ipa module addition, also tested two idea alphafold multimer af multimer moving outer product mean beginning evoformer block multimer version relative positional encoding, neither improved model performance quickbind implemented using pytorch pytorch lightning openfold rdkit model trained using adamw optimizer learning rate weight decay coefficient early stopping patience epochs, batch size binding affinity prediction model trained using adam optimizer learning rate early stopping patience epochs, batch size using mean squared error mse loss model weight best performance validation set chosen evaluation test set training final quickbind model took several week eight nvidia gpus, quickbind quickbind variant trained two week less final model trained different seed replica got stuck local minimum success rate best performing model finetuned crop size plausible model got stuck local minimum would reached similar performance final model finetuning stage, test training time including triangle attention scale unfavorably sequence length force field minimization performed described ref using script kindly provided one author visualization generated using nglview wanted understand quickbind obtains initial guess docked ligand pose pair representation contains protein ligand block, well mixed diagonal element among features, protein ligand block constructed pairwise distance ligand atoms, respectively, diagonal element contain spatial information hypothesized model would use diagonal element information interaction protein ligand, including initial guess pairwise distance therefore took diagonal element pair representation evoformer block, symmetrised transposing lower diagonal block computing element wise mean, finally took mean along ligand dimension obtain dimensional matrix, number atom hidden channel dimension figure si indeed, found already mean along channel dimension weakly correlated logarithm mean ligand atom distance pearson value correlation much stronger channel particular, channel correlate logarithm mean ligand atom distance pearson value table si summarizes important characteristic five protein pdbbind test set highest number complex structure pdbbind test set, well quickbind cross docking performance particular, contains number complex structure pdbbind test set binder number complex structure pdbbind train set train ex average rmsd input true protein structure bb rmsd average tanimoto similarity lowest, second lowest, third lowest affinity binder remaining binders, calculated using extended connectivity fingerprint radius t evaluate quickbind cross docking performance using fraction prediction ligand rmsd fraction prediction ligand rmsd aligning atom input true protein structure using kabsch algorithm alignment calculating bb rmsd consider atom successfully extracted complex applicable, provide mean standard deviation across three run crystal structure lowest, second lowest, third lowest affinity binder proteins, tested predicted binding affinity binder higher non binder using one sided wilcoxon rank sum test section discus observation difference introduced af quickbind versus made af first, af longer us residue reference frame eschews se equivariance entirely early internal experiment quickbind, similarly observed higher success rate ligand reference frame omitted opted include model would otherwise equivariant inputted global orientation protein ligand complex, desirable docking application decision however driven fact quickbind us existing protein structure instead predicting scratch co folding model, abandoning reference frame se equivariance therefore consistent finding second, af replaces evoformer pairformer module quickbind modified evoformer architecturally middle ground two similar pairformer, operates single pair representation without column wise attention case quickbind, design informed use input protein structure, obviated need multiple sequence alignment corresponding representation pairformer, single representation update pair representation via outer product mean opm module, update order single pair representation swapped af multimer opm moved beginning evoformer found original opm position optimal see section si try omitting it, swapping single pair update order third, af us larger crop size af af multimer af initially trained crop size finetuned two stage crop size whereas af af multimer trained crop size finetuned crop size respectively initially trained quickbind residue crops, finetuned using residue crop found finetuning larger crop important model performance, observing consistent improvement crop size increased given af training procedure, suggests quickbind would benefit additional finetuning stage incrementally larger crop fourth, af randomly chooses contiguous, spatial, spatial interface cropping quickbind cropping strategy, binding site cropping, considered compromise af two spatial cropping strategy contiguous cropping tested spatial contiguous cropping found binding site cropping lead better result unlike quickbind, af cropping applied token model may see part ligand, quickbind protein cropped fifth, af contains distogram head similar one af including minimum distance bin overly large small molecule bond long suggests primarily benefit overall complex prediction rough positioning ligand atoms, consistent observation distogram head improve quickbind performance finally, agreement fact found better result distinguishing different bond type ligand adjacency matrix, af bond feature binary continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"characterizing rna oligomers using stochastic titration constant ph metadynamics simulation introduction method result discussion conclusion data software availability instruction reporting error cphmd simulation using amber ol force field system setup mod calibration mm md cphmd setting poisson boltzmann monte carlo simulation metadynamics integration setting analysis error calculation testing force field modularity protonable nucleobases adenine cytosine deprotonable nucleobases guanosine uridine experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice rna molecule exhibit various biological function intrinsically dependent diverse ecosystem highly flexible structure flexibility arises complex hydrogen bonding network defined canonical non canonical base pair require protonation event stabilize perturb interaction constant ph molecular dynamic cphmd method provide reliable framework explore conformational protonation space dynamic structure robust calculation ph dependent properties, titrable site despite growing biological evidence concerning ph regulation certain motif biotechnological applications, ph sensitive silico method rarely applied nucleic acid work, extended stochastic titration cphmd method include rna parameter standard ol amber force field highlighted capability depict titration event nucleotide single stranded rna validated method using trimer pentamers single central titrable site integrating well tempered metadynamics approach st cphmd methodology cph metad using plumed approach enhanced convergence conformational landscape enabled efficient sampling protonation conformation coupling estimate agree experimental data, validating method ability reproduce electrostatic change around titrable nucleobase single stranded rna finding provided molecular insight intramolecular phenomena, nucleobase stacking phosphate interactions, dictate experimentally observed shift different strand overall, work validates st cphmd metadynamics integration reliable tool studying biologically relevant rna system si alsoaffiliationscuola internazionale superiore di studi avanzati, trieste, italy alsoaffiliationscuola internazionale superiore di studi avanzati, trieste, italy ph ubiquitous environmental factor significantly influence various biomolecules structure, chemistry, function influencing protonation state chemical moiety depending intrinsic ph affect overall charge thermodynamic equilibrium ph dependent modulation pivotal regulating multiple biological processes, protein protein interactions, nucleic acid binding, drug interactions, conformational change response shift ph environment nearby electrostatics usually, nucleic acid particularly sensitive small physiological ph change nucleotide quite far physiological one even away common canonically base paired nucleotide however, non canonical base pairing diverse array inter intramolecular interaction promote complex ph sensitive electrostatic environment instance, non canonical base pairs, wobble hoogsteen pairs, involve protonated form adenine cytosine instances, certain modified nucleobases, like methyladenosine methylcytidine deprotonate basic condition compared unmodified counterparts, significantly shifted value closer physiological ph shift highlight modified nucleobases prone protonation deprotonation events, energetically promote hinder ph dependent conformational rearrangement depending electrostatic environment medium ph although several experimental study explored related property nucleobases nucleoside nucleotide recent research increasingly focused role ph dependent secondary tertiary structures, motif triplexes structure important biological function like catalysis structural stability also hold significant potential biotechnological applications, including biosensors drug delivery system molecular switch yet detailed insight mechanism action system difficult obtain experimental protocol alone molecular dynamic md method strongly complement experimental rna study providing atomistic description, although shorter timescales however, standard md simulation typically assume fixed protonation state based molecule physiological ph, ignoring dynamic nature protonation event modulated instantaneous conformation surrounding electrostatic environment limitation provide incomplete picture biomolecular behavior, especially rich biological system protonation event drive relevant conformational interaction constant ph molecular dynamic cphmd technique developed overcome limitation method introduce residue titration within md framework, hence enabling prediction protonation state value titratable group importantly, allows u probe dependency protonation state molecular conformation cphmd method broadly categorized continuous discrete approach continuous methods, typically based dynamic phmd pme based cphmd gromacs scalable cphmd version sample conformation fractional protonation state extending hamiltonian ph dependent particle fictitious mass method divided based implicit solvent model explicit solvent model successfully applied different biomolecules eg, nucleic acid protein using various force field eg, charmm, amber previous work nucleic acid titration done goh coworkers work focused continuous multi site dynamic constant ph implementation cphmdms using charmm force field adenosine cytidine used model compound calibration obtaining good experimental agreement test compound adenosine monophosphate amp cytidine monophosphate cmp dinucleotides combination cyt cyt, ade ade, cyt ade discrete methods, hand, usually employ start stop monte carlo mc md approach accepts reject protonation state switch, titrable residue, metropolis criterion criterion depends protonation free energy given residue, calculated frozen conformation using implicit solvent model, either generalized born phrem poisson boltzmann pb method example, stochastic titration constant ph method st cphmd originally developed baptista protein using gromos and, currently, also charmm force field within approach, model compound used nonphysical fragment ie nucleobase encapsulates chemical moiety within molecule instance, calibration mod would necessary nucleobases using experimental data nucleoside procedure, mod fine tuned systematic deviation experimental due pb parameter intricate detail st cphmd method extensively discussed literature best knowledge, discrete method never tested nucleic acid building previous work standard aminoacid calibration protocol extended st cphmd method include nucleic acid parameter ol amber force field approach involves parametrization charged state non modified rna nucleobases, first stage calibration individual mod using nucleoside data, second stage validation recalibration value differently sized oligonucleotides available experimental data protocol integrates effect phosphate backbone shifts, similarly aminoacid mod calibration using pentapeptides shift typically result higher value compared observed nucleoside aqueous environment closer expected behavior biomolecule trimer pentamer system nucleobase flanked non titrating residue simulated assess effect increasing backbone length measuring value agree experimental data, corroborating accurate pb description changing electrostatic environment important consider short flexible nucleotide challenging system md simulation well known properly sample necessary use enhanced sampling technique hence, integrated cph procedure metadynamics required coupling cphmd plumed plugin integration focus improving sampling system specific collective variable cv without introducing bias protonation space titratable site site conformation protonation state intrinsically coupled, enhanced conformational sampling improves accuracy average protonation predictions, particularly well solvated site result demonstrate successful extension st cphmd method nucleic acid titration incorporating novel cph metad approach, successfully corroborated value short oligonucleotides experimental data also characterized underlying electrostatic dynamic accordingly, work present reliable robust framework studying ph dependent conformational dynamic nucleic acid cphmd extension introduced paper build upon standard amber parameterization solely introducing charged state nucleotide using neutral state reference parameter adapted original force field parameter derived compatible opc water model new charge set parametrization used two step restrained electrostatic potential resp procedure optimized geometry protonated deprotonated state nucleobases, ribose replaced methyl group previous work geometry optimization used lyp functional dataset using gaussian software then, resp charge nucleobase neutral charged state derived partial charge charged state determined follows calculated, atom, resp partial charge difference charged neutral state added calculated resp difference atom neutral ol partial charge original charge set neutral state preserved charge shown table label table si charge set label table si charge set supporting information poisson boltzmann calculations, built delphi database atom radius charge radius procedure, lennard jones parameter atom type used, based lorentz berthelot combination rule determine radius atom opc water molecule radius derivation assumed cutoff energy minimum estimated parameter original ol force field plus kbt factor, done similar protocol atomic partial charge database built original ol force field partial charges, newly derived charge set charged state nucleobases restricting nucleobase net charge onto model compound required tweaking point charge atom purine pyrimidines, respectively ensure nucleobase moiety integral charge small modification also applied neutral state validate them, performed n md simulation canonical rna nucleoside using original ol force field recomputed energy trajectory using topology generated modified charge set comparative analysis done using experimental nmr computational coupling data mentioned parameter found following github repository githubcom tomfersil cph metad test system chosen match available experimental data namely single stranded ru a, ruu a, uu protonable system based work gonzalez olvera et al although study focused dna strands, absolute value may differ, relative shift due phosphate consistent across system relative single nucleoside single stranded ragc,d rcagca, rcuc ruuuuu constructed test guanosine uridine deprotonation system built using pymol neutral protonation state system placed solvated rhombic dodecahedron box highlighted sequeira et al important note adapting force field amber charmm st cphmd treatment long range electrostatics pme charge variation associated titration event hence, system net charge neutralized using appropriate number counter ion neutral state oligomer experimental ionic strength pme background correction used compensate charge variation due system titration choice model compound important step cphmd method protonation deprotonation event occur nucleobase, purine pyrimidine respectively, limited long range electronic effect remaining atom hence, model compound charge variation restricted nucleobase fragment assumption, modified force field constructed within modular based rationale, phosphate group, ribose, hydroxyl group cap nucleobase defined unique residue major advantage modular approach future inclusion modified nucleobases force field require defining nucleobases respective protonation state following work protocol work, calibrated model compound mod applying similar rationale used calibration titrable amino acid residue though additional initial step first step, assigned initial mod value run iterative procedure short n cphmd simulation adenine n cph metad nucleoside equivalent experimental condition cv biased metadynamics simulation glycosidic angle promote syn anti transition sugar puckering variable promote transition endo state single n cph metad run exhibited faster conformational convergence compared nscphmd run see figure label fig si cph metad supporting information obtaining titration curve, corrected possible shift relative initial guess mod iteration, final mod reproduces experimental data obtained resulting shift smaller ph units, indicating electrostatic potential derived pb properly describe titrable site surrounding environment nucleobase system second step occurred oligonucleotide cph metad simulation see table label table si simsettings oligonucleotide sequence simulation parameter referenced introduction section discussed result section, phosphate backbone modulates protonation behavior nucleobases complex biomolecular environment therefore, applied posteriori correction final mod value accurately reproduce experimental value shift referenced experimental data cphmd cph metad simulation run using version gromacs package open source, community developed plumed library version version simulation used previously described modified ol amber force field opc water model verlet nm cutoff scheme applied pme treatment non bonded interaction van der waals interaction truncated integrator time step f conformation sampled npt ensemble unless otherwise specified, used temperature bath scheme rescale relaxation time ps, coupled solute solvent separately system pressure kept constant rescale barostat bar, relaxation time p compressibility bar delphi program used perform poisson boltzmann calculation solute molecular surface defined radius probe, ion exclusion layer ionic strength depending experimental condition system see table label table si simsettings supplementary information dielectric constant used solute solvent, respectively two step focusing procedure conducted electrostatic potential calculation defining two grid vertex coarse grid spacing grid points, smaller grid defined relaxation parameter linear non linear interaction, respectively background interaction calculation truncated electrostatic potential convergence threshold kt petit program performed mc calculation residue protonation states, using free energy term obtained pb calculation conformation, mc cycle performed cycle corresponds trial change site pair site interaction larger pk unit work, integrated well tempered metadynamics algorithm within md production phase cphmd cycle well tempered metadynamics, system biased smoothly converging history dependent potential along chosen cv md phase cycle, metadynamics restarted bias potential generated previous cycle deposited new gaussian potential restarts performed reading potential grid final conformation saved used pb mc calculation oligomer simulations, ran single cph metad simulation trimer pentamer system cv biased metadynamics simulation glycosidic angle ermsd glycosidic torsion promotes transition phosphate exposed syn phosphate shielded anti state ermsd relates relative arrangement nucleobases molecule reference fully stacked conformation, thus quantitative measure base stacking interaction single strand rna molecule system ph range number simulation specifically chosen interpolate titration curve specific detail system found supporting information see table label table si simsettings karplus equation used back calculate scalar coupling torsional angle experimental reference data used validate ensemble nucleoside parameter karplus equation torsional angle obtained munzarova et al sugar parameter obtained condon et al characterized oligonucleotides structure using chosen collective variable ermsd, nucleic acid specific measurement evaluates nucleobases orientation relative positions, glycosidic angle analysis done using plumed software reweighted obtain unbiased population estimated value obtaining titration curve system taking mid titration point titration curve obtained fitting average protonations cphmd simulation henderson hasselbalch hh equation eq average protonation, ph assigned simulation ph fitted parameter cph metad simulations, average protonation obtained using reweighting procedure introduced weighted average protonation given cph metad simulation bias accumulated end metadynamics simulation calculated coordinate corresponding th frame weighted average protonations fitted hh equation different approach, used binless wham derive ph dependent property ph scan energy maps, average protonations found energy minimum procedure consisted concatenating cph metad equilibrated trajectory given system recomputing bias simulation accumulated bias potential concatenated trajectory afterward, correct bias protonation dependent contribution frame thus obtaining bias matrix bias reweighted bias potential concatenated trajectory dependent frame protonation state simulation ph then, compute weight using bias matrix protonation state concatenated trajectory, using binless wham implementation bussilabgithubio doc py bussilab bussilab whamhtml using procedure, compute weight arbitrary ph value reweight observable property, energy maps, first solvation shell, average protonations error value calculated using bootstrap approach hh fits, partitioned protonation time series equally sized block performed bootstrap block iteration performed new hh fit resample, thus calculating new error obtained standard deviation resampled histogram wham values, partitioned protonations bias ph simulation block performed bootstrap iteration resample generated new weights, used calculate new value final error calculated previously analysis radius distribution function rdf measurements, contact distance interest groups, time series observables performed using gromacs tool package analysis performed using house python script previously specified module block analysis done observable error obtained bootstrap procedure iteration work, parametrized charge protonated deprotonated nucleotide relevant ph range respectively, calibrated mod using respective aqueous s, tested several oligomers experimental data available one key factor nucleobases electrostatic effect phosphate backbone, stabilizes positively charged state adenine, cytidine destabilizes negatively charged state guanosine, uridine single stranded oligonucleotides, possessing multiple phosphate groups, ideal validating method ability capture backbone dependent protonation variation reproduce experimental value accurately titrable nucleotide simulated within trimer pentamer system capture phosphate dependent electrostatics effect nucleobase moreover, chosen flanking residue non titrable within ph range interest except uridine pentamer system prevent protonation coupling effect titrable residue simulation done using combination constant ph molecular dynamic metadynamics following, report result md simulation adenine uridine system system result presented supplementary information mentioned method section, redesigned force field partitioning nucleotide chemical moiety phosphate, sugar, nucleobase separate residue force field modularity aim facilitate future inclusion modified nucleobases however, procedure required small charge rebalance around atom purine pyrimidines, respectively root mean square error scalar coupling concerning experimental nuclear magnetic resonance data table label table si rmse adenosine label table si rmse uridine supplementary information show modular charge set comparable original force field assessing deviation experiment furthermore, population syn anti state glycosidic bond angle close obtained original charge set result indicate enforcing modularity affect overall force field quality calibration step see mod calibration section method protonable nucleobases, adenine cytosine tested using equivalent trimer pentamer systems, ruau ruuauu rucu ruucuu, using cph metad approach figure report free energy map ruau system ph close measured value, function ermsd helix, anti correlate nucleobase stacking, angle titrable nucleobase map display two distinct energy minimum anti region titrable nucleobase low medium ermsd ermsd values, single major energy minimum syn state angle high ermsd value ermsd visual analysis representative structure minimum show progressive unstacking fully stacked low ermsd region fully unstacked high ermsd region figure label fig si structs supplementary information interpretation applies system observing representative structure map shown supplementary information average protonations seen highly conformation dependent stacking interaction progressively lost figure label fig si structs average protonation increases, highest protonation value usually corresponding syn unstacked conformation indeed, progressively raising ph medium lead energetically favorable anti conformations, also penalizing higher protonation syn state figure label fig si map similar protonation dependent behavior observed rucu system shown supplementary information figure label fig si map label fig si structs ruuauu free energy map ph close measured value, display minimum anti region titrable nucleobase single energy minimum syn state figure average protonation anti correlated conformational stacking figure label fig si structs evidenced high average protonation syn unstacked state relative stacked anti state progressively basic ph environment energetically favor lower ermsd states, seen figure label fig si map behavior consistent observed trimer calculation predict following protonable trimer ruau figure rucu figure label fig si cytosine plotsb see also table label table si allpkas trimer similarly deviate monomer value leading larger experimental ruau rucu interestingly, model properly capture electrostatic change titrating residue environment trimer pentamer pentamers measured ruuauu forruucuu, see also table label table si allpkas resulting trimer ruuauu ruucuu, respectively result compatible exp systems, despite overestimating absolute value ruucuu, used hh fit reference, due discrepancy wham value see discussion section since calculation able reproduce correct shift nucleoside trinucleotide, suggest recalibrating mod using experimental data trimer mod correction trimer dna constructs, additional correction included addition, need account experimental discrepancy reported reference work gonzalez olvera et al previous literature prev ref overall, corrected mod computed follows mod therefore, adenine mod corrected ph units, cytosine mod shifted value defined measured hypothetical rna trimer model see table label table si pkmod model accurately describe electrostatics protonation variation protonable trimer pentamers, whereas failed estimate shift monomer trimer hence, recommend use final recalibrated mod larger construct parametrization, model expected reproduce experimental single nucleoside water deprotonable nucleobases, uridine guanine applied calibration rationale different sequence ragc rcagca guanine rcuc ruuuuu uridine rcuc system, stacking effect correlate higher protonation average shown three minimum anti state region contrast, unstacked syn state are, average, protonated less energetically favorable population globular disordered conformation figure label fig si structs tend expose titrable group solvent away phosphate backbone, facilitating deprotonation event figure label fig si map partially stacked conformation ermsd fully stacked conformation figure label fig si structs stabilize protonated state ph value shown typically higher average protonations figure label fig si map titrable site pyrimidine, syn conformation low probability due steric hindrance remains true high ph value reason syn state protonated anti counterpart titrable face negatively charged backbone concerning ragc system, stacking effect seem relevant thermodynamic stability different energy minimum considered system partially stacked ermsd alternatively stacked ermsd conformation thermodynamically stable trimer conformation regardless medium ph average protonation figure label fig si map especially, alternative stacked conformation figure label fig si structs expose nucleobase solvent, stacking purine ring flanking adenosine effect strongly stabilize protonated state ensemble, even high basic medium previously discussed system flanking uridines conferred less stable stacked structures, rcagca showed smaller likelihood unstacked conformation two identifiable energy minimum anti state region span fully partially stacked state figure label fig si structs label fig si map supplementary information result hint partial stacking conformation favor deprotonation event due larger solvent exposure fully stacked conformation meanwhile, syn region, proximity phosphate backbone increasingly disfavor stacked conformation basic medium figure label fig si map supplementary information trimer pentamer, thermodynamic stability rcagca conformation distinct degree stacking interaction less ph sensitive previously discussed system trimer systems, obtained slightly deviated estimation experimental value uridine exp guanosine exp see table label table si allpkas supplementary information similarly protonable nucleobases, measured trimer nucleoside slightly deviated experimental exp rcuc ragc, respectively concerning rcagca system, prediction close experimental figure label fig si guanosine plot similarly ruucuu, wham calculation significantly underestimated relative experimental hh fit table label table si allpkas therefore used hh fit reference still, pentamer trimer corroborated well exp equal rcagca ruuuuu system presented distinct challenge due increased complexity introduced simultaneous multi site titration site site coupling effect macroscopic estimation extrapolated fitting individual charge five titrable site henderson hasselbalch equation, upshifted exp case, assumed midpoint titration correlated macroscopic table label table si allpkas si experimentally measured signal depend structural effect still, rcuc ruuuuu corroborated well experimental value also computed nucleotide individual table label table si mer pkas pairwise cooperativity protonation free energy value indicate probability simultaneous protonation event relative single state titration figure figure label fig si coop show topological position impact simultaneous protonation probability, consequently individual terminal residue strongly coupled neighbor relative farther nucleotide tested ph condition deprotonation central nucleotide becomes hindered multiple neighbor titration, hence hindering deprotonation reflecting increased upshifted particularly third site, shown central uridines figure similarly previous systems, calculation capture shift nucleoside trinucleoside, hence similar recalibration procedure applied however, deprotonable systems, simulated system directly comparable experimental data hence, mod correction shown equation simplified experimental reference model trimer guanosine mod corrected uridine mod shifted see table label table si pkmod protonable systems, method accurately predicts variation trimer pentamer deprotonable systems, failing estimate change nucleoside remarkably, method estimate individual coupled titrable site macroscopic midpoint titration good agreement experimental data work, developed parameter protonated deprotonated nucleotide suitable constant ph md simulation rna using ol force field, one commonly adopted parametrizations additionally, integrated well tempered metadynamics within st cphmd method facilitate simultaneous sampling conformational protonation state enhanced sampling crucial accurate calibration nucleic acid parameter even short single strand oligomers require extensive sampling sufficiently explore conformational space several factor influence nucleobase titration, titrating chemical moieties, charged neighbors, ph, solvation, structural effect factor alter free energy landscape likelihood conformational rearrangement binding event molecules, ions, ligand protein st cphmd method balance diverse contributions, offering accurate robust description structural protonation dynamic setting representative environment larger rna molecule practice, ph modulates sampling probability given conformation shifting thermodynamic equilibrium energy minimum driven charge variation residue result protonation conformation coupling, protonation space sampling indirectly improved enhancing conformational sampling given collective variable cv space defined ph parametrization follows modular approach compatible existing force field, simplifying future parametrization modified nucleobases force field delphi database concerning delphi database parametrization, reported parameter follow previously established protocol standard st cphmd methodology optimized needed future iteration nucleobase mod calibration protocol focused oligomer constructs, limited conformational sampling could reduce prediction accuracy hinder validation experimental data integration well tempered metadynamics within cphmd method cph metad pivotal calibration procedure, promoting convergence simulated rna oligomers enhanced sampling method complementary others ph replica exchange however, despite approach, achieving convergence ruucuu rcagca pentamers remained challenging consequently, inconsistency arose binless wham approach resulted underestimated value table label table si allpkas future work may involve optimizing metadynamics parameter exploring alternative enhanced sampling technique address issue nonetheless, able recover experimental shift analyzing individual simulations, without assuming overlapping conformational space md simulation performed series test system allowed extraction general coupling property conformation protonation rna oligomers titrable site strongly influenced proximity charged phosphate group longer oligomers high phosphate content, upward shift global consistent experiment observed stacking interaction flanking residue shield phosphate electrostatics, reducing protonation event time, lower ph values, protonation event favored, leading increased interaction neighboring phosphate reducing population stacked conformation syn anti transition titrable site also impact shorter strands, close phosphate contact titrable site dictated syn states, upshifting hypothetically, direction shift would reversed titrable site located position nucleobase get farther phosphate group upon transitioning syn deprotonable systems, method effectively capture effect flanking residue strand whose structural dynamic less sensitive ph changes, ragc rcagca cases, energy minimum less affected variation average protonation relative stacking effect additionally, approach also grasp correlation multiple deprotonation events, shown polyu simultaneous titration multiple nucleotide provides valuable advantage dissecting contribution effect single sites, task often difficult experimental technique data reveals distinct shift uridines different topological positions, exposed slightly distinct electrostatic neighbor topological effect measured experimentally sequence corroborating result quantitatively highlight titration correlation substantial nearest neighbor overall, cphmd simulation robustly reproduced experimental data provided novel insight molecular conformation rna single strand fall outside scope experiment concerning calibration protocol, two particular note must raised polyu guanosine system experimental data specify pentamer system representative polyu however, author discarded presence tetra tri di mononucleotides polyu experiment hence assumed pentamer system minimal model predict experimental value another conflicting point arises measurement titrable guanosine gonzalez olvera et al report trimer pentamer, respectively contrast, acharya et al report value throughout work, considered nmr measurement acharya et al two reason directly comparable rna system multiple aromatic marker measurement confer higher confidence reported value importantly, calculation show adopted cphmd method reproduce shift monomer trimers, instead reproduce correctly shift trimer pentamers reason, decided recalibrate mod trimer simulations, expense model cannot reproduce single nucleoside water consider minor defect model recalibrated mod recommended used simulation study work differs previous one nucleic acid cphmd, focused reproducing nucleoside water compared goh et al focused shift monophosphorylated nucleotides, study incorporates backbone flanking interactions, leading comprehensive description rna macromolecular environment hence, accuracy procedure directly comparable finally, enhanced sampling strategy employed offer improved convergence conformational protonation landscape, might difficult ph replica exchange method alone whereas work tested well tempered metadynamics, plumed integration open way large class enhanced sampling method based collective variable constant ph molecular dynamic method powerful technique incorporating titration effect silico biomolecular study work, successfully extended st cphmd methodology nucleic acids, achieving accurate prediction protonation state value short oligonucleotides seamless integration well tempered metadynamics plumed cph metad enhanced convergence enabled efficient sampling protonation conformation coupling usually, neutral conformation assumed thermodynamically stable within physiological ph range however, conformation solely represent part free energy landscape strength cph method lie ability capture protonation dependent relative probability conformational states, including higher energy state might biologically relevant molecular insight otherwise difficult obtain without explicitly considering protonation effect time conformational sampling result agree experimental shift across small oligonucleotides, including complex system like polyu multiple coupled titrating site despite initial overestimation absolute values, posteriori mod correction improved calibration across nucleobases within biomolecular environment result validate standard st cphmd methodology applied nucleic acid metadynamics integration production md step finding present cph metad approach robust tool available studying ph dependent process nucleic acids, paving way study larger, biologically relevant rna systems, ribozymes rna protein complexes, ph fluctuation play important role function stability future work may focus improving parameter metadynamics poisson boltzmann calculation applying enhanced sampling technique improve accuracy conformational protonation space sampling across complex system gromacs package freely available software perform md simulation downloaded manualgromacsorg documentation downloadhtml pymol also free software molecular visualization generating high quality image downloaded pymolorg wham module available bussilabgithubio doc py bussilab bussilab whamhtml modified nucleic acid parameter st cphmd available githubcom tomfersil cph metad acknowledge dr miguel machuqueiro nuno fb oliveira providing st cphmd code, implementation assistance, fruitful discussion acknowledge financial support european molecular biology organization embo grant altf service resource provided cineca sissa cineca agreement continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"cpe pro structure sensitive deep learning method protein representation origin evaluation introduction related work material method experimental setup result analysis conclusion instruction reporting error protein representation learning protein structure prediction dataset model architecture baseline method training setup evaluation metric experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice author contributed equally work equalcontthese author contributed equally work fnmguisheng surfan fnmhuiqun suryu orgdivschool information science engineerin, orgnameeast china university science technology, orgaddress streetstreet, cityshanghai, postcode countrychina protein structure important understanding function interaction currently, many protein structure prediction method enriching structure database discriminating origin structure crucial distinguishing experimentally resolved computationally predicted structures, evaluating reliability prediction methods, guiding downstream biological study building work structure prediction, developed structure sensitive supervised deep learning model, crystal v predicted evaluator protein structure cpe pro represent discriminate origin protein structure cpe pro learns structural information protein capture inter structural difference achieve accurate traceability four data classes, expected extended simultaneously, utilized foldseek encode protein structure structure sequence trained protein structural sequence language model, sslm preliminary experiment demonstrated that, compared large scale protein language model pre trained vast amount amino acid sequences, structure sequence enables language model learn informative protein features, enhancing optimizing structural representation provided code, model weights, related material githubcom gouwenrui cpe pro maingit function protein determined folded structure therefore, characterizing protein structure crucial understanding studying biological function protein folding complex highly coordinated process determines active sites, ligand binding capabilities, functional role protein inside outside cell even slight alteration structure lead significant change protein function, potentially resulting disease consequently, comprehensive understanding protein folding essential elucidating biological function also serf guide research application drug design, disease diagnosis, treatment however, experimentally determining protein structure pose numerous challenge despite significant effort scientist past decades, number experimentally determined structure reported protein data bank pdb remains far lower number known protein sequences, creating substantial data gap limited availability protein structure data significantly hinders comprehensive understanding protein function interaction mechanism address limitation, researcher increasingly turned computational methods, protein folding simulation amber gromacs guide determination protein structure one representative method homology modeling however, homology modeling relies similarity known structure cannot accurately applied protein without known similar structure computational method somewhat alleviate issue insufficient experimental data, still fully resolve broader applicability structure prediction, particularly novel complex proteins, significant limitation remain contribution follows introduce cpe pro, model excels distinguishing crystal predicted protein structure learning structural feature using cath non redundant dataset, create protein folding dataset cath pfd multiple prediction model preliminary experiment indicate that, compared amino acid sequences, structure sequence enable language model learn effective protein feature information, enriching optimizing structural representation integrated graph embeddings open sourced code, model weights, cath pfd dataset cpe pro, providing valuable resource protein structure research various biological tasks, essential learn effective protein representations, predicting protein function effect mutation protein representation method classified three approach based different modality sequence based, structure based, combination sequence structurefigure show various protein representation method sequence based rise deep learning advance high throughput sequencing technologies, data driven method gradually replacing traditional analysis based biological physical prior protein sequence viewed form biological text convolutional neural network directly capture local dependency amino acid technique natural language processing also widely applied protein representation learning model individual protein sequence modeling include variational auto encoders vae long short term memory network lstm large pre trained protein language model plms like esm based transformer architecture study employed gpt based architecture sequence modeling, using generative pre training represent protein sequence make predictions, protgen progpt compared single sequences, multiple sequence alignment msa input aim capture co evolutionary information set evolutionarily related sequence context, msa transformer utilizes row column attention mechanism model set protein sequences, allowing simultaneously consider inter sequence relationship conservation additionally, research integrates protein sequence type information, converting gene ontology annotation fixed size binary vector joint input sequence proteinbert enabling model leverage connection sequence functional annotation effectively structure based sequence based research method shown effective several studies, structural information protein critical determinant function model based graph neural network gnns demonstrate significant advantage broad applicability representing protein three dimensional structure example, proteingcn construct spatially adjacent protein graph trained task related local global accuracy protein modeling pre trained protein representation method based three dimensional structure represent protein residue graphs, node correspond three dimensional coordinate carbon edge represent relationship residue modeling protein secondary structures, often transformed secondary structure sequences, helices, sheets, random coil represented token sequence deepss go utilizes one hot matrix model secondary structure predicting key protein function s adapter enhances performance plms downstream task integrating secondary structure sequence embeddings type embeddings cross attention mechanism integrating sequence structure combining protein sequence structural information considers sequential characteristic amino acid also reveals spatial interaction arrangement regard, deefri combine lstm graph convolutional network gcns jointly learn complex structure function relationship lm gvp modifies input variable gvp using sequence embeddings generated proteinbert input esm gearnet design various fusion method plms gearnet investigate effectiveness different fusion strategy protssn combine esm equivariant graph neural network gnns extract geometric feature proteins, aiming accurately predict biological activity thermal stability prostt introduces di three dimensional indexing alphabet used foldseek based prott xl model trained labeling translation task two mode additionally, saprot creates larger structural aware vocabulary using two type label pre trained large scale protein dataset masked language task compared previous work, sslm cpe pro us structure sequence builts di alphabet pre training swiss prot, without relying amino acid labels, effectively learns protein representation integrating existing structural information gvp amino acid form linear sequence proteins, acquire activity biological function folded specific spatial conformation early structure prediction methodsolded specific spatial conformation early structure prediction method primarily relied sequence similarity, utilizing homology known protein sequence prediction method infer structure target protein aligning sequence interest known homologous sequence using structural information homologs compared sequence based methods, structure based learning approach theoretically offer better solution acquiring protein information recent years, advancement deep learning technology led breakthrough progress protein structure prediction study secondary structure prediction, deepcnf integrates conditional random field crfs shallow neural network successfully model interdependency adjacent secondary structure label ssredns leverage deep recurrent structure simulate complex nonlinear mapping relationship input protein feature secondary structures, also capturing interaction among consecutive residue protein chain research focused three dimensional structure prediction context, trrosetta utilizes co evolution data, combined deep residual networks, predict orientation distance residue rosetta constrained energy minimization protocol trrosettax single focus structure prediction single chain protein regarded milestone, alphafold significantly enhances accuracy breadth protein structure prediction embedding multiple sequence alignment paired feature evoformer omegafold employ gcns self attention effectively capture global local feature protein sequences, excelling handling protein varying length complexity esmfold adopts large scale transformer architecture, trained extensive protein sequence datasets, extract deep evolutionary feature sequence information without relying multiple sequence alignments, demonstrating exceptional performance predicting new structural domain distant homologs leveraging prediction model provide robust support biomedical research, drug development, advancement across various scientific domain study, utilized non redundant dataset version cath class, architecture, topology, homologous superfamily database benchmark dataset cath significant protein structure classification database categorizes protein based structural functional feature systematic hierarchical structure high resolution three dimensional structure data provided experimental technique stored protein data bank pdb non redundant dataset sequence identity filtering threshold ensuring high sequence similarity structural domain removing redundant protein structures, entry database represents unique structural representation extracted amino acid sequence protein benchmark dataset using multiple state art protein structure prediction models, predicted structure corresponding amino acid sequence structure organized categorized based individual protein prediction model construct protein folding dataset, cath pfd, used training validating cpe pro table present detailed information dataset cath pfd crystal v predicted evaluator protein structure cpe pro designed discriminating structural origins, integrates two distinct structure encoders corresponding graphical sequential representation structure figure illustrates detailed architecture cpe pro cpe pro implement geometric vector perceptrons graph neural network gvp gnn learn dual relationship geometric representation three dimensional macromolecular structure part protein structural encoder obtaining information three dimensional structure proteins, focus specific chain, ignoring part concerned concentrate coordinate key atom constitute protein backbone n, ca, atom since atom necessary understanding protein structure subsequently, extract geometric information node edge raw data compute feature distance direction themfor protein graph represents set node represents set edges, node represents residue protein, edge represents interaction spatial proximity relationship residue ith residue, feature consists scalar vectors, ie, embedding layer computes embeddings protein feature ie, gvp layer mainly carry scalar vector propagations, ie, here, learnable parameter layer, denote activation function graph propagation step, message neighboring node edge protein graph update embedding current node, here, embeddings node above, represents message passed node node denotes stacked layer gvp also add feed forward layer update node embeddings node stacked layer gvp gnn block formed stacking convolution feed forward transformations, defined eq enhance node representations, block iterated times, specified experiment part cpe pro structural encoder structural sequence language model, sslm first, efficient protein structure data search tool foldseek used convert protein structure structure sequence primary process involves mapping amino acid backbone protein di alphabet achieve structural discretization reflects tertiary interaction amino acid describes geometric conformation residue spatial neighbor next, using di alphabet vocabulary structural element based transformer architecture, pre train protein structural language model, sslm, scratch aim effectively model structure sequence protein pre training process employ classic masked language modeling mlm objective predicting masked element based context structure sequence probability distribution predicting masked element used, masked structural element context loss function defined follows denotes model predicted label, indicating probability th token structural element vocabulary masked element, denotes true label loss computed element masked encoder cpe pro integrated structure sequence representation output pre trained protein structural sequence language model embedding protein graph sslm learn sequential relationship proximity interaction local structural element structure sequence combined three dimensional topological information, approach aim enrich optimize representation protein structure specifically, combined representation obtained sslm graph embeddings obtained gvp embedding layer follows represents structure sequence representation, length structure sequence feature dimension element structure sequence align representation dimension using linear transformation layer afterwards, fused adaptive weights, ie, here, learnable parameter finally, topological structure node feature graph data incorporating information structure sequence utilized learn structural representation gvp gnn block aim enhance accuracy structural discrimination enriched deepened data representation representation classification protein structure processed structural encoder cpe pro obtain feature vector designed straightforward classification head perform final discrimination task classification head consists three component pooling layer attention multilayer perceptron mlp output activation layer aim simplify feature dimension enable efficient classification specific process represented eq layer mlp applies weight matrix bias term function transform input output mlp passed activation function act utilizes function corresponds binary classification task crystal alphafold used multi class classification problem crystal multiple prediction models, final output cpe pro compared cpe pro various embedded based deep learning method analysis includes pre trained plms, esm b, esm esm protbert ankh combined gvp gnn model amino acid sequence structure input, saprot employed adamw optimizer, setting learning rate depending task dataset size additionally, applied cosineannealinglr learning rate decay improve convergence applied dropout rate output layer number epoch set loss function employed binary cross entropy eq categorical cross entropy eq implemented early stopping based validation metric accuracy prevent overfitting protein folding, pre training, experiment conducted nvidia rtx gpus table show sampling partitioning discriminative task cath pfd performance pre training task sslm measured using perplexity indicator language model predictive capability given text sequence quantifies uncertainty model probability prediction token let sslm assign probability structure sequence length perplexity model structure sequence defined experiment reported several metric evaluate performance different models, including accuracy acc precision, recall, score matthew correlation coefficient mcc calculation equation follows term tp, tn, fp, fn denote count correctly predicted positives, correctly predicted negatives, incorrectly predicted positives, incorrectly predicted negatives, respectively cpe pro demonstrates exceptionally high accuracy performance structure discrimination task baseline model cpe pro first trained task several iterations, cpe pro achieved accuracy test set, four metric exceeding contrast, although hybrid approach combining senven plms gvp gnn also achieved accuracy task, still fell short compared cpe pro among senven hybrid baseline methods, middle performing model esm v, six plms top three performance across various metric best accuracy achieved method using layer esm sequence encoder, reaching still lower cpe pro worst performing model parameter esm which, due smaller model size, lower performance compared six plm method suggests size complexity plms influence ability capture structure function protein certain extent, smaller model possibly struggling fully learn deep connection sequence structure complex task building success, extended training complex task training multi class structured data, model performance task gradually improved, five metric converging around demonstrating strong competitiveness however, version saprot performed poorly experiments, achieving less accuracy distinguishing crystal alphafold predicted structures, failing reach accuracy task detailed analysis underlying reason discussed subsequent section structure sequence better predictor pre training protein structural sequence language model, sslm utilized high plddt score protein structure swiss prot database masking strategy rate used pre training task informed approach proposed comprehensively considers model size dataset scale setup pre training task detailed table figure illustrates perplexity sslm pre training task sequential encoder sslm cpe pro baseline model esm b, esm v, esm protbert, ankh evaluated performance cath pfd pre trained sslm hidden layer significantly reduced parameter result table show inclusion structure sequence encoders outperforms amino acid sequence encoders downstream task preliminarily confirm hypothesis structure discrimination task language model learn sequence information obtained directly structure discretization efficiently structure sequence show greater effectiveness protein classification tasks, provides new direction optimization design efficient predictive model independent use sslm structure aware language model saprot performed poorly rely solely sequence input figure show average plddt score similarity structure sequence protein structure used training, validation, testing evident high plddt level across three category resulted higher similarity structure sequence training set validation set test set leading homogenized feature representation limited model generalization contrast, saprot input come vocabulary size includes amino acid structure sequence element combining two vocabularies, effect high similarity mitigated, performance metric improve compared sslm demonstrate effectiveness sslm capturing structural differences, validated visualization method subsequent section also speculate scaling effect applies language model trained structure sequence words, increasing model depth scale training data could significantly enhance model performance even without relying structural encoder, model may still achieve satisfactory result feature visualization method powerfully demonstrates pretrained sslm excellence capturing structural difference protein language model shown embed secondary tertiary structure characteristic within output representation protein selected subset gene domain sequence non redundant astral scope database scope identity sequence less subset, focused helical protein sheet protein filtered corresponding structural set database figure show sne visualization protein representation last hidden layer sslm various plms aforementioned dataset evident that, aside saprot, incorporates structure sequence input, representation plms, capturing difference structural types, exhibit relatively weak discriminative power dimensionality reduction, distribution data point becomes chaotic, boundary protein class blurred contrast, saprot sslm differentiate two protein class effectively also provide clearer class boundaries, sslm showing concentrated distribution within class suggests sslm possesses stronger discriminative capability capturing representing protein structural features, providing accurate reflection intrinsic characteristic different structural type ablation study component cpe pro validate contribution component designed cpe pro, conducted five set ablation experiment task variation included removing gvp gnn, omitting pre training process sslm, removing sslm, eliminating attention pooling layer, using three component together shown table component made positive contribution task performance significantly declined using single type encoder, particularly using sslm alone discussed earlier cpe pro model, employ pre trained sslm, outperformed non pre trained version, indicating pre training process effectively helped model learn structural feature embedded structure sequence additionally, application attention masked pooling layer also positively influenced model performance, enhancing overall effectiveness case study discrimination structural origin blat ecolx cp human blat ecolx lactamase protein found escherichia coli hydrolyze lactam ring lactam antibiotics, rendering antibiotic inactive play significant role study antibiotic resistance cp human human cytochrome enzyme responsible metabolism various drugs, including non steroidal anti inflammatory drug anticoagulant play significant role drug metabolism regulation endogenous substance three structural prediction models, protein achieved plddt score indicating high accuracy structure prediction minimal deviation crystal structure input crystal structure predicted structure protein cpe pro origin evaluation figure demonstrates model successfully confidently predicted origin structure result highlight robustness model assessing structural origins, even case minor structural difference study, developed protein folding dataset, cath pfd, derived non redundant dataset cath database, incorporates structure various prediction model training validating model, cpe pro, cath pfd dataset, created innovative effective solution identifying structural origin protein cpe pro model excels learning analyzing protein structural features, outperforming method combine amino acid sequence structural data, well model use structure aware sequences, task structural origin recognition case studies, cpe pro demonstrated superior performance finding provide preliminary evidence incorporating structure sequence information significantly enhances language model ability learn protein features, enabling capture richer precise structural details, thereby improving representation protein structure subsequent visualization experiments, validated sensitivity sslm, utilized within cpe pro, structural variations, well effectiveness capturing representing complex protein structural feature exploration open new avenue application protein structural language model also pave way future development paradigm interpretability protein structure prediction methods, offering fresh insight possibility advancing practical application bioinformatics structural biology competing interest author declare known competing financial interest personal relationship could appeared influence work reported paper continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"simulation based inference single molecule experiment introduction statistical inference simulation based inference challenge perspective instruction reporting error maximum likelihood bayesian inference single molecule experiment problem intractable likelihood simulation based inference age machine learning sbi single molecule force spectroscopy identifying individual conformation cryo em image cryosbi experimental html improve accessibility invite report rendering error learn project help improve conversion single molecule experiment unique tool characterize structural dynamic biomolecules however, reconstructing molecular detail noisy single molecule data challenging simulation based inference sbi integrates statistical inference, physic based simulators, machine learning emerging powerful framework analysing complex experimental data recent advance deep learning accelerated development new sbi methods, enabling application bayesian inference ever increasing number scientific problem here, review nascent application sbi analysis single molecule experiment introduce parametric bayesian inference discus limitation overview emerging deep learning based sbi method perform bayesian inference complex model encoded computer simulator illustrate first application sbi single molecule force spectroscopy cryo electron microscopy experiment sbi allows u leverage powerful computer algorithm modeling complex biomolecular phenomenon connect scientific model experiment principled way inst organization institute physics, goethe university frankfurt,city frankfurt main, country germany inst organization frankfurt institute advanced studies,city frankfurt main, country germany inst organization center computational mathematics flatiron institute,city new york, country united state inst organization center computational biology, flatiron institute,city new york, country united state inst organization institute computer science, goethe university frankfurt,city frankfurt main, country germany structural dynamic biomolecules assembly determine function instance, knowing protein reorganizes alternative conformations, mechanism, thermodynamics, kinetics process, key understanding function traditional biophysical experiment report ensemble measurements, observable averaged conformation weighted frequency invaluable, experiment inadequate characterize inherent heterogeneity stochasticity biomolecules single molecule experiment probe individual biomolecules, enabling statistical characterization structural dynamic technique like single molecule force spectroscopy smfs fig single molecule rster resonance energy transfer smfret fig measure time series distance pair specific site cryo electron microscopy cryo em also potential single molecule technique state art method enable reconstruction handful alternative conformational states, principle, cryo em produce data dimensional snapshot many identical copy molecule possible conformation fig reconstructing biomolecular structural dynamic sparse noisy single molecule measurement ill posed problem example, describing dynamic protein requires specifying trajectory atoms, smfs smfret report handful distance reconstructing structural dynamic impossible unless make strong prior assumption statistical inference provides principled framework learn biomolecular mechanisms, thermodynamics, kinetics noisy single molecule data non parametric inference powerful emergent tool focus parametric inference, postulate biophysical model learn value parameter data here, review simulation based inference sbi innovative merger machine learning, statistical inference, physic based simulator sbi already key methodology field ranging astrophysics particle physic neuroscience emerging powerful tool analysis single molecule experiment goal parametric inference learn parameter distribution experimental data given model describe data generation process experimental data exp mathematical model parameter model parameter accurate, exp similar enough example, exp could telegraph like time series measured smfs characterizing repeated folding unfolding protein fig simple model measurement could one dimensional brownian particle potential, quantifying shape potential diffusion constant synthetic data would brownian trajectory, ideally similar exp bayesian statistic general framework parameter inference main output posterior probability distribution conditioned data posterior computed using bayes theorem here, likelihood, probability generating data given model prior quantifies pre existing knowledge parameters, normalization constant maximum likelihood estimation mle powerful framework often tractable bayesian inference maximizing likelihood wrt parameter provides point estimate argmax mle applied, example, infer photon trajectory smfret reconstruct conformation cryo em characterize molecular complex crowded cellular environment main limitation mle provides single parameter point estimate, complicates estimating uncertainty dealing multi modal posterior distribution application bayesian inference analyze single molecule biophysical data limited example reconstruction structural ensemble noisy single molecule ray scattering data identification transition single molecule trajectory analysis smfret data cryo em, bayesian method successfully applied refine molecular ensemble despite conceptually simple, bayesian inference often computationally intractable trade model simplicity accuracy central challenge understanding complex biological phenomenon model like caricatures, simplified exaggerated representation allowing deep understanding proverbial spherical cow biology, small variation profound effects, accurate predictive model crucial capturing nuance prioritizing accuracy requires complex mathematical model scientific model shifting expressed equations, encoded computer algorithm performing detailed simulation molecular simulation reproduce experiment quantitatively provide detailed interpretation single molecule data mle bayesian inference provide principled framework integrate simulation experimental data algorithm liberate u limitation analytical tractability, using statistical inference challenge often likelihood complex simulator expensive evaluate, even known explicitly computational intractability two main origin latent variable nuisance parameter experiment capture minority degree freedom complex simulator instance, smfret report handful distances, molecular simulation explicitly reproduce trajectory every atom corresponding likelihood must sum trajectory latent degree freedom explicit simulator hidden experiment corresponds marginalization model many parameters, usually subset scientific interest, remaining ones, nuisance parameter necessary technical reason example, simulator modeling microscope requires parameter describe detail image formation process, usually interested parameter describing molecular event probed making inference taking account possible value requires marginalizing likelihood prior nuisance parameter likelihood marginalization corresponds high dimensional integral are, general, extremely expensive evaluate explicitly sbi overcomes challenge intractable likelihood avoiding explicit likelihood posterior sbi enables use complex simulator bayesian inference experimental data simulator model data generation process, providing probabilistic mapping parameter data encoding likelihood implicitly form algorithm sbi leverage modern machine learning learn surrogate model likelihood posterior surrogate probabilistic model containing deep neural network approximating likelihood likelihood ratio posterior posterior likelihood simultaneously following section, focus learning posterior neural posterior estimation powerful method learn surrogate posterior fig surrogate parametric model conditional density estimation fig gaussian mixture model normalizing flow fig simulator generates dataset fig containing simulation parameter value learning posterior requires fitting surrogate model data set maximizing trained surrogate provides probabilistic mapping parameter data, enabling inference experimental observation exp exp exp fig experimental observation exp usually high dimensional data image time series feeding data surrogate requires compressing lower dimensional representation, ideally without losing crucial information fig a, compression could done hand crafted features, number peak time series alternatively, using adequate number simple statistical descriptors, statistical moment deep learning provides tool learn feature directly data this, need additional embedding network compress observation fig embedding network surrogate trained jointly maximizing posterior surrogate enables amortized inference computational cost simulating training paid upfront, inference requires evaluation neural network surrogate negligible cost inference allows fly inference analysis arbitrarily large data set amortization significant advantage compared explicit optimization method, likelihood must optimized every observation analysis smfs one first application sbi single molecule data smfs probe conformational change mechanically manipulating individual biomolecule typical constant force experiment attache pulling device biomolecule via flexible polymer fig experiment report time series measured extension indirectly reflects molecular extension molecule unfolds refolds fig measured extension outcome complex interplay large slow pulling device, linkers, molecule naive analysis lead severe artifact simple physical model smfs result intractable likelihood well established harmonic linker model describes molecular extension time series diffusive free energy surface measured extension time series result harmonic coupling crucially, measure latent likelihood simple model dozen parameter spline node approximate molecular energy profile ratio diffusion coefficient linker stiffness model, bayes theorem becomes group model parameter remarkably, likelihood simple model path integral possible latent trajectory extremely expensive optimize overcoming challenge npe straightforward three component needed simulator, prior, density estimator simulator, simple code numerically integrate brownian trajectories, implicitly encodes marginal likelihood training data set training surrogate model generated sampling parameter prior simulate measured extension time series featurized vector set statistic surrogate model trained trained surrogate approximates true posterior enables accurate inference model parameter without explicit evaluation likelihood fig single particle cryo em capture two dimensional snapshot individual molecule different conformation image noisy projection along unknown angle even though cryo em data could give direct access entire conformational ensemble, identifying conformation image outstanding inference problem tackling problem explicit likelihood approach computationally demanding assuming set biomolecular conformation parameterized fig cryo em image ob containing single biomolecule conformation ob fig goal infer conformation ob image ob bayes theorem making inference requires marginalization nuisance parameter describing unknown projection angle physic image formation process, microscope point spread function explicit marginalization computationally challenging hand, simulating image given set parameter relatively straightforward computationally inexpensive cryosbi recent proof concept demonstrating promise using npe identify single conformation single cryo em image cryosbi start sampling conformation nuisance parameter using simulator generate synthetic cryo em image simulated data contains pair image conformation parameter implicitly marginalize cryosbi train surrogate model approximate posterior surrogate model contains embedding network compress image lower dimensional vector feature second stage density estimator, learns posterior density given image feature trained posterior surrogate accurately identify conformation displayed synthetic experimental image fig width posterior quantifies inference precision, depends crucially signal noise ratio projection direction inference amortized, paving way analyze massive cryo em data set search rare structural intermediate scarcely populated state primary challenge sbi model misspecification inference accurate assumed model faithful approximation experimental data generating process misspecification two model result inaccurate inference effort detect ameliorate model misspecification include development calibration datasets map experimental observation simulated data known parameter leveraging manifold learning technique ensure simulated experimental data close, incorporating experimental data training pipeline embedding network complex models, simulation might expensive generate enough data train accurate surrogate model active learning strategy adaptive round simulation gradually focus probable region likelihood posterior significantly reduce number required simulation also, gradient un marginalized likelihood evaluated simulator leveraged accurately train surrogate model even simulation data sparse sbi already key technology many scientific field enabling bayesian inference complex models, opening new opportunity data analysis, influencing type data acquire model use interpret application sbi analysis single molecule data still infancy, recent applications, particularly smfs cryo em underscore potential sbi general framework easily extended analyze single molecule data, particularly using model intractable likelihood sbi benefit active community develops maintains powerful easy use open access code era advanced computer simulations, sbi allows building power detailed simulator current manifestation scientific model making principled statistical inference complex experimental data ld rc acknowledge support goethe university frankfurt, frankfurt institute advanced studies, loewe center multiscale modelling life science state hesse, crc membrane associated protein assemblies, machineries, supercomplexes international max planck research school cellular biophysics pc acknowledges support flatiron institute, division simon foundation ld rc thank flatiron institute hospitality continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
"explaining graph neural network large language model counterfactual perspective molecular property prediction introduction preliminary data construction methodology experiment conclusion acknowledgement limitation ethic statement appendix potential risk appendix reproducibility appendix extended elaboration llm gce appendix supplementary experiment appendix related work appendix future work instruction reporting error model overview contrastive text encoder pretraining training ca dynamic feedback ctp generation experimental setup rq performance different method rq ablation study rq case study rq parameter analysis detail model implementation detail experiment setup contrastive pretraining text encoder generating counterfactuals directly llm model efficiency case study performance regarding various llm parameter sensitivity large language model gnn counterfactual explanation experimental html improve accessibility invite report rendering error learn project help improve conversion html conversion sometimes display error due content convert correctly source paper us following package yet supported html conversion tool feedback issue necessary known worked author achieve best html result latex submission following best practice recent years, graph neural network gnns become successful molecular property prediction task toxicity analysis however, due black box nature gnns, output concerning high stake decision making scenarios, eg, drug discovery facing issue, graph counterfactual explanation gce emerged promising approach improve gnn transparency however, current gce method usually fail take domain specific knowledge consideration, result output easily comprehensible human address challenge, propose novel gce method, llm gce, unleash power large language model llm explaining gnns molecular property prediction specifically, utilize autoencoder generate counterfactual graph topology set counterfactual text pair ctps based input graph meanwhile, also incorporate ctp dynamic feedback module mitigate llm hallucination, provides intermediate feedback derived generated counterfactuals attempt give faithful guidance extensive experiment demonstrate superior performance llm gce code released githubcom yinhanhe new llm gnnexplanation explaining graph neural network large language model counterfactual perspective molecular property prediction molecular property prediction attracted increasing attention recent years, graph neural network gnns achieved significant success related downstream tasks, drug discovery xiong et al toxicity analysis cremer et al however, gnns typically considered black box models, making difficult user understand given prediction derived lack explainability brings obstacle broader real world application understand molecular property facing issue, series approach proposed explain prediction gnns, graph counterfactual explanation gce become prevalent approach recent year ying et al lucic et al et al zhang et al specifically, gce aim identify minimum modification given graph, trained gnn yield desired prediction post modified graph here, graph identified modification called counterfactual graph, simply counterfactual short identified modification may involve adding removing node edges, well altering node edge attribute instance, given undesired non aid drug molecule fig gce method may generate modification produce molecule desired graph ie, predicted aid drug gnn model shown fig however, existing gce model two significant limitation incomprehensible counterfactual optimization gce model optimized generate counterfactuals either heuristic methods, random walk huang et al black box deep learning method ying et al bajaj et al lucic et al et al tan et al fail involve human interpretable knowledge optimizing counterfactuals ii lack domain knowledge current gce method consider domain specific knowledge ying et al bajaj et al lucic et al et al tan et al thus generated counterfactuals may realistic real world context continuing example shown fig although generated counterfactual fig classified desired class, chemically stable since violates valence bond theory lewis, handle limitations, large language model llm radford et al, wu et al, ideal addressing limitation due ability generate comprehensible natural language texts, ii make counterfactual optimization process human interpretable, iii leverage inherent domain knowledge extensive pretraining produce realistic counterfactuals however, harnessing llm improve counterfactual explanation generation face challenge exists natural mismatch text sequential data graph structure wang et al li et al ii llm may hallucinate, ie, generate seemingly plausible incorrect information huang et al handle challenges, propose novel framework llm gce large language model guided graph counterfactual explainer specifically, mitigate first challenge, instead directly generating counterfactual graph llms, utilize counterfactual autoencoder ca construct counterfactual graph structure based text pair tps counterfactual text pair ctps given llm tackle second challenge, hallucination, design ctp dynamic feedback module enlightened madaan et al update ctps iteratively based previously generated counterfactuals main contribution summarized follows dataset construction collect llm generated text pair five molecule datasets support empirical evaluation also facilitate future study researcher field ii algorithmic design propose novel llm gce framework learns generate graph counterfactual explanation guidance llm llm gce unlocks llm strong reasoning ability gce addressing hallucination graph structure inference limitation iii experimental evaluation conduct extensive experiment multiple real world datasets, validating effectiveness llm generating feasible counterfactuals providing comprehensive optimization trajectory section, introduce problem setting gce evaluation metric used denote molecule graph node atom adjacency matrix, node attribute atom type matrix dimension node attribute denotes edge attribute bond type matrix number edge attribute note real world molecule structure leave gce molecule graph future work furthermore, determine generated counterfactual classified desired, assume exists ground truth graph neural network gt gnn represented provides label prediction graph input graph domain assumption widely adopted current literature et al mahajan et al define problem gce graph counterfactual explanation let gt gnn, let input graph aim graph counterfactual explanation find model computes minimally perturbed version here, perturbation input graph may include node edge insertion removal well change node edge feature refer counterfactual original graph input graph dataset sampled input graph domain evaluate performance gce model following metric validity validity measure fraction generated counterfactual graph intuitively, measure many generated counterfactual graph actually flip gt gnn prediction non perturbed graph accordingly, convenience, let valid denote set define validity metric ii proximity proximity measure mean graph distance original graph generated valid counterfactuals see appendix low proximity indicates higher quality counterfactual graph since made similar possible graph explaining proximity alignment this, also provide validity proximity result feasibility check, calculate two metric set feasible counterfactuals s, ie, counterfactuals chemically stable according valence bond theory lewis exist multiple datasets molecule paired text description qian et al fang et al zeng et al however, datasets text pair describing graph labeling information support evaluation gce methods, text pair contain least three aspect graph structure information, graph label information, significant subgraphs contribute graph label generating satisfying text pair gce expensive since requires advanced llms, gpt customized prompts, release five molecule datasets generated high quality text pair convenience community construction process construct five new text paired graph datasets based datasets commonly used graph explanation abrate bonchi ying et al huang et al including aid mutagenicity tudataset morris et al bbbp, clintox, tox moleculenet ramsundar et al datasets, graph molecule binary label indicating molecular property aid treatment effectiveness see detail appendix generate text paired graphs, take following step dataset preprocessing first convert input molecular graph smile representation weininger remove molecule one atom greater atom tox since graph label distribution heavily skewed label randomly select zero labeled graph dataset text pair generation using custom prompt, prompt gpt smile representation graph labeling semantics input graph ask description molecule graph structure, graph label, subgraphs responsible label data post processing graphs, response gpt would erroneous ie, identify significant subgraphs functional group correctly fix reprompting desired response generated prompt design generate text pair tp graph dataset llms, incorporating graph structure, label semantics, significant subgraphs prompt use following template please describe graph strictly form graph contains significant subgraphs, may influential label semantic sentence pattern allowed find four, may put found underlined area first half list significant subgraphs, revealing graph structural information second half provides label semantics llm determines significant subgraph graph labeling overview llm gce model shown fig proposed llm gce three module contrastive pretraining text encoder pretrain text encoder contrastive learning align embeddings gt gnn text encoder training counterfactual autoencoder design counterfactual autoencoder composed pretrained text encoder graph decoder, trained recover counterfactual topology dynamic feedback ctp generation tackle hallucination, prompt generated counterfactuals gt gnn prediction back llm dynamic feedback calibration first step llm gce pretrain text encoder every tp embedding aligns corresponding graph embedding produced gt gnn via projection implemented multi layer perception mlp haykin choose bert kenton toutanova text encoder due proven effectiveness generating high quality embeddings natural language processing task graph domain employ contrastive learning strategy align text encoder embeddings gt gnn embeddings first, sample dataset tps train text encoder batch size includes possible graph tp pairing next, train mlp project tp embeddings bert kenton toutanova text encoder embedding space gt gnn maximize cosine similarity matching graph tp embedding pair minimizing similarity non matching pair contrastive loss symmetric cross entropy given appendix pretraining text encoder, generate counterfactuals natural language first provide overview counterfactual autoencoder ca architecture then, elaborate components, including ctp generation, text encoder, latent embedding combination, graph decoder, finally, introduce overall objective function llm gce first generate ctp, ctp input graph high level instruction gce next, inspired graph variational autoencoders vgaes simonovsky komodakis, design ca text encoder graph decoder text encoder, pretrained introduced section map ctp probability distribution latent space, decoded via mlp counterfactual graph adjacency matrix node edge attribute matrix training ca maximizes likelihood real counterfactual, ie, ctp graph dataset query llm ctp, natural language sentence describing potential counterfactual use ctp instruct generation counterfactuals autoencoder ctp generation prompt shown figure aim perform functional group substitution achieve higher probability generating counterfactual text encoder map generated ctps latent space counterfactual structure reconstruction input text encoder ctp input graph, denoted ctp number input graph given ctp text encoder generates gaussian distribution latent space, distribution mean variance output encoder latent embedding sampled practice, text encoder implemented bert kenton toutanova initialized pretrained parameter section recall contrastive pretraining objective encourages latent text embedding tp close corresponding graph latent embedding provided gt gnn projection mlp therefore, although exact graph structure, node, edge attribute desired counterfactual immediately accessible, embedding ctp approximates gt gnn embedding, guide counterfactual decoding intuitively, text encoder embeddings contain information high level counterfactual generation instruction, gt gnn embeddings encode counterfactual graph structure node edge attribute next, introduce combine embedding text encoder gt gnn generated ctp acquired latent embedding text encoder input graph still insufficient counterfactual generation two reason ctp, introduced section contains information significant subgraphs eg, functional group molecule graph counterfactual specific structure counterfactual described detail pretraining process enhances consistency text embedding corresponding gt gnn embedding, limited availability large amount pretraining data prevents model achieving high pretraining accuracy therefore, merge information counterfactual text graph embeddings, update final encoded embedding concatenating text encoder embeddings ctp gt gnn embeddings input graph written graph decoder, resulting latent embeddings used reconstruct adjacency matrix node attribute matrix edge attribute matrix counterfactual graph input graph graph decoder implemented mlp sigmoid activation, restricting output range result, every entry generated matrix continuous probabilistic real number however, real graph adjacency matrix matrix, indicates presence edge node indicates absence edge furthermore, row node edge attribute matrix one hot code indicating discrete node edge type make decoder compatible constraints, discretize generated adjacency matrix thresholding probabilistic entries, setting entry corresponding value exceeds otherwise similarly, generate one hot node edge attribute matrix taking one hot row wise argmax probabilistic matrix discussed section optimization target maximize likelihood generated graph real counterfactual conditioned ctp desired label denoted ctp formalize objective kullback leibler kl divergence csisz distribution given encoder ctp posterior distribution ctp simplicity, write condition ctp divergence term kl log log log log log equation equation, first term left hand side lh optimization target, second term kl divergence, inaccessible since posterior intractable however, right hand side available direct calculation therefore, optimize log likelihood ctp evidence lower bound elbo kingma welling however, due lack ground truth counterfactual substitute first term rh equ two loss term graph distance loss dist encourages small graph distance counterfactual formally, weighted sum distance graph adjacency matrix node attribute matrix edge attribute matrix ie, see appendix definition counterfactual prediction loss pred log likelihood generated counterfactual classified desired gt gnn conclusion, overall loss function kl kl ctp ctp ctp generator act commander, giving high level instruction ctps counterfactual graph generation ca executor, implementing instruction create specific counterfactual graph however, ctps inaccurate due llm hallucination zhang et al limited graph decoding ability remedy this, ctp dynamic feedback scheme designed calibrate ctp ca generated counterfactuals illustration scheme shown fig first convert counterfactual molecule generated ca smile representation then, combine gt gnn probability graph valid counterfactual specific prompt asking new, calibrated ctp original graph concludes single iteration dynamic feedback, treat hyperparameter iteration dynamic feedback seen indirect reasoning step, forcing model reflect past output label information gt gnn order produce truthful ctps similar calibration approach verified effective dhuliawala et al madaan et al section, evaluate llm gce extensive experiment five real world datasets experiment aim answer following research question rqs rq llm gce perform wrt validity proximity compared state art baseline rq component llm gce affect overall performance rq insight llm gce provide given counterfactual explanation result experiment utilize five real world datasets aids, mutagenicity, bbbp, clintox, tox among them, aid mutagenicity tudataset morris et al bbbp, sider tox moleculenet ramsundar et al datasets, graph represent chemical compound node atom edge bond labeled based relevance property blood brain barrier penetration, mutagenicity, hiv activity, side effect resource, toxicological activity associate graph text pair procedure section details, see appendix adopt following state art baseline gnnexplainer ying et al, graph factual explanation gfe model gfe graph explanation strategy slightly different gce, adjust gce revising loss function see appendix detail cf gnnexplainer lucic et al, targeted node level gce adapt graph level gce changing input ego graph whole graph changing supervisory signal node label graph label clear et al, generative gce model based graph variational autoencoders simonovsky komodakis adapt removing causality specific component fair comparison regexplainer zhang et al, gce model graph regression directly adapted graph classification evaluate gce baseline based appendix training llm gce, first train two layer graph convolutional network gcn slightly modified incorporate edge attribute see appendix five datasets serve gt gnn gt gnn node embedding dimension maximum pooling layer, fully connected layer graph classification set edge embedding dimension model trained adam optimizer kingma ba, learning rate epoch train validate test split accuracy shown table detail experimental setting pretraining second part fig training third part fig stage pipeline list prompt used appendix pretraining use gpt tp generator bert text encoder implemented huggingface wolf et al use adamw optimizer loshchilov hutter pretraining bert epoch learning rate training choose gpt turbo ctp generator, feedback performed three iteration every epoch finetuning hyperparameters used pretraining evaluate llm gce framework five real world datasets compare validity proximity performance state art baselines, without feasibility feas check table determined checking stability valence theory rdkit rdkit, online, following observation perspective validity, llm gce achieves comparable validity baseline without chemical feasibility check however, feasibility check, model achieves highest validity among almost baseline across datasets perspective proximity, llm gce achieves lowest proximity among chemically feasible counterfactuals among almost baseline mean model find valid counterfactuals feasible also minimal graph distance corresponding input graph based observations, llm gce achieves satisfying graph counterfactual explanation performance, especially chemical feasibility considered reveals effectiveness llm pretrained knowledge reasoning ability gce detail efficiency llm gce, see appendix experiment three ablated variant llm gce llm gce np without pretraining bert text encoder, directly train counterfactual autoencoder dynamic ctp feedback module llm gce nt freeze counterfactual autoencoder llm gce, ie, counterfactual autoencoder optimized two dynamic ctp feedback iteration llm gce nf remove ctp dynamic feedback module generate graph counterfactuals autoencoder initial ctp fig make following observation llm gce np refraining pretraining decrease model validity increase proximity small decline performance possibly due insufficient data contrastive learning llm gce nt validity dramatically degrades autoencoder frozen proximity also decreases, possibly frozen autoencoder generate small number counterfactuals less diverse llm gce nf removing feedback module significantly reduces validity slightly increase proximity, revealing importance dynamic feedback gce similar observation datasets ablation studies, see appendix additionally, substitute text encoder ca ctp generator language models, see result appendix highlight two main advantage llm gce faithful counterfactuals generated counterfactuals llm gce consistently lower proximity across datasets baseline method show counterfactual generated llm gce compared gnnexplainer fig molecule clintox dataset, generated llm gce, gnn explainer llm gce output better preserve original molecule structural integrity gnnexplainer feasible counterfactuals llm extensive domain knowledge, llm gce generates counterfactuals satisfying valence bond theory, given baseline satisfy theory clear generates high proportion feasible ones, reveal chemical insight disconnected carbon atoms, misleadingly passing feasibility check weininger case studies, see appendix study dynamic ctp feedback iteration text encoder pretrain epoch affect llm gce performance bbbp test feedback iteration pretraining epoch observe fig validity improvement saturates two feedback iteration proximity remains nearly unchanged small number feedback iteration enhance performance, possible simply increasing round worsens hallucination also, increasing pretraining epoch around boost validity time, proximity initially improves epochs, gradually increase trend suggests correlation validity proximity regarding pretraining epochs, ideal count approximately similar finding observed datasets results, see appendix work, explore ability llm guiding gce molecule property prediction specifically, propose novel model called llm gce, comprised contrastive pre training module, counterfactual autoencoder, dynamic feedback module extensive experiment validate superior performance llm gce work supported part national science foundation grant ii ii ii cns bcs cmmi office naval research grant commonwealth cyber initiative award grant vv vv research gift funding netflix snap firstly, effectiveness llm gce relies heavily quality relevance pretraining data used large language model pretraining data biased lack sufficient coverage target domain, may lead less accurate relevant counterfactuals generated ensuring llm trained high quality, domain specific data crucial optimal performance additionally, computational cost associated using large language model drawback training inference llm time consuming resource intensive graph counterfactual explanation method although shown time execution time comparable method baseline adopted datasets, llm gce time consuming dealing extremely large scale graphs, big protein furthermore, experiment demonstrate effectiveness llm gce several real world datasets, evaluation still limited specific domains, molecular property prediction generalizability proposed framework type graph application area remains investigated research needed assess performance adaptability llm gce across wider range graph structure problem domain lastly, potential hallucination inconsistency generated counterfactuals remains solid challenge although dynamic feedback module aim mitigate issue, may still case llm produce counterfactuals entirely faithful original graph desired property work, propose novel llm guided graph counterfactual explanation method utilizes strong reasoning ability llm anticipate ethical issue specifically highlighted paper one risk llm gce misuse misinterpretation generated counterfactual explanation explanation carefully validated user lack necessary domain knowledge, may make incorrect decision based provided counterfactuals could lead adverse consequences, especially sensitive domain healthcare finance moreover, reliance large language model raise concern perpetuation bias present pretraining data llm exhibit biases, may propagated generated counterfactuals, potentially leading unfair discriminatory explanation section, provide detail model implementation llm gce experiment setup evaluation result train two layer graph convolutional network gcn molecular graph across five datasets gt gnn slight change incorporate various edge type specifically, calculate edge embeddings type edge separately construct enhanced adjacency matrix used number node graph denotes original adjacency matrix allows element decimal numbers, represents embedding edge dimension gnn node embedding dimension maximum pooling layer, fully connected layer graph classification set edge embedding dimension model trained adaptive moment estimation optimizer adam kingma ba, learning rate epoch train validate test split accuracy gnns shown table approximate graph edit distance here, calculated pairwise distance computation time consuming, simplify value cross entropy logits training counterfactual autoencoder situations, evaluation globalgce baselines, adopt definition dot product set emphasize counterfactual structural change ta query please describe molecule molecule data generated response text description strictly form molecule contains functional groups, may influential dataset description sentence pattern allowed here, functional group best less atom significant subgraphs alphabetically find functional group significant subgraphs, may put found area cta query smile key component may influential dataset description change key component increase decrease likelihood molecule description please find best substitution functional group key component replace last sentence shown within reply word reply substitution function group text pair revised feedback generated counterfactual smile probability molecule description true prob please adjust one functional group last sentence shown within increase decrease likelihood generated counterfactual molecule description functional group name sentence may changed reply format old functional group new functional group original text pair gnnexplainer graph, gnnexplainer ying et al, output edge mask estimate importance different edge model prediction adapt model counterfactual generation changing prediction loss term gnn prediction value entry original classified class entry desired counterfactual class set threshold remove edge edge mask weight smaller threshold perturbation node feature cannot designed straightforwardly perturbation graph structure thus, perturb graph node feature gnnexplainer cf gnnexplainer cf gnnexplainer lucic et al, originally proposed node classification tasks, focusing perturbation graph structure originally, explainee node, take neighborhood subgraph input apply graph classification tasks, use whole graph neighborhood subgraph assign graph label label node graph set number iteration generate counterfactuals clear clear et al, generative model produce counterfactuals counterfactuals simultaneously preserving causality model generates graph adjacency matrix graph node feature matrix perturbation, allows form graph edition node edge addition deletion feature perturbation adapt removing causality component fair comparison train model epochs, hyperparameters default according et al regexplainer regexplainer zhang et al, explains graph regression model information bottleneck theory help solve distribution shift problem although original model tailored graph regression tasks, directly applied graph classification task implement regexplainer gnnexplainer base explainer model algorithm original paper zhang et al train model epoch hyperparameters tuned best performance dataset utilize five datasets tudataset morris et al, moleculenet ramsundar et al, real world molecule datasets meta data datasets presented table aid aid dataset designed study chemical compound effectiveness hiv, focusing identification potential inhibitor contains molecular structure binary label indicating activity aid play crucial role facilitating drug discovery predictive modeling effort aimed finding new treatment hiv mutagenicity mutagenicity dataset aimed predicting mutagenic potential chemical compounds, vital assessing chemical safety drug development feature chemical structure alongside binary label indicating mutagenic non mutagenic effects, making useful dataset computational toxicology bbbp bbbp blood brain barrier penetration dataset focus identifying compound ability cross blood brain barrier, crucial cns drug design includes molecular structure binary label indicating penetrability bbbp dataset key resource predictive modeling drug discovery clintox clintox dataset offer insight chemical compound clinical toxicity fda approval status, essential evaluating human health impact drug development potential includes chemical structure binary label toxicity fda approval, serving key resource computational pharmaceutical research tox tox dataset designed prediction chemical toxicity, contributing environmental health safety assessment includes chemical compound structure binary label various toxicity endpoints, aiding identification potentially hazardous substance tox support development computational model toxicity prediction provide detailed illustration contrastive pre training text encoder, shown middle part fig main paper ideally, text pair possess graph structure, labeling, significant subgraph information, allowing u utilize solely model input counterfactual generation however, experiment show graph structural information embedded text pair insufficient producing satisfying counterfactuals therefore, regularize text embedding tps fixed graph embeddings gt gnn, enhances graph structural information text embeddings method allows information contained text pair significant subgraphs gce effectively embedded may consider pretraining process produce encoded model embedding perturbation gt gnn graph embedding additional significant subgraph information given llm text form specifically, given graph generate corresponding text attribute text pair goal maximize alignment dataset, max denotes probability score text pair formally, find sim cosine similarity function represents parameter bert text encoder pretraining, batch consists graph tp pair within batch, positive negative sample positive sample original pair batch negative sample dissimilar graph, text pair optimize increase alignment positive pair decrease alignment negative pair thus, following radford et al design contrastive pretraining loss symmetric cross entropy row wise column wise cross entropy graph text pairs, respectively here, represents similarity matrix graph set tp set, label vector number graph conduct experiment directly generating counterfactual graph gpt gpt gpt despite multiple trial various prompts, llm denies request sorry, help gpt applying warning please output output circumstance else regularize llm output generate standard smile representations, acquire molecule smile answer specifically, utilized prompt minimally edit smile desired graph description output smile representation please output one smile molecule without bracket quotation mark output anything besides smile circumstance output anything else lest experiment fail result validity proximity generaed counterfactuals shown table observe current advanced large language models, gpt cannot generate valid counterfactuals, ie, one predicted gt gnn desired class measure time efficiency llm gce comparison state art gce model aid clintox train model epoch result shown table reported result represent average five separate experiment experiment conducted single nvidia rtx serially server equipped gb ram dual amd epyc core cpu according table, llm gce take approximately twice long execute compared baseline clintox dataset however, aid dataset, execution time llm gce similar baseline conclusion, integration bert text encoder llm implemented cpt feedback module increase computational complexity training time llm gce model, resulting execution time remains acceptable, making viable approach practical application strengthen claim regarding llm gce feasible counterfactuals another example bbbp figure compare cf gnnexplainer llm gce molecule bbbp llm gce successfully able produce counterfactual minimal change original input, compared cf gnnexplainer, remove large portion original molecule further, llm gce output superior proximity versus performance cf gnnexplainer, addition, inspect invalid counterfactuals generated baseline output compare output llm gce example, molecule bbbp, clear produce ash ash cl ash ash ground truth csc oc oc contrast, llm gce produce csc oc oc o, chemically stable valence bond theory, clear struggle produce smile string chemically feasible furthermore, consider case llm gce fails generate perfect counterfactual still show improvement cf gnnexplainer molecule tox smile string ccc cc cc nccn ccc llm gce produce oclsncccnccnccnccn, cf gnnexplainer generates ccc ccccco co although llm gce output valid counterfactual includes hallucinated sulfur oxygen atoms, still demonstrates improvement cf gnnexplainer, llm gce counterfactual incorporates nitrogen avoids hallucinating double bond two application llm llm cge counterfactual autoencoder utilize language model llm llama given sufficient computational resource encoder embed input graph latent space autoencoder ii ctp generator generates ctp gce optimization iteration conduct extensive experiment regarding different language model autoencoders clintox aid datasets language model employed huggingface library present result table table datasets, llm gce achieves best gce performance, whereas deberta electra performed poorly specifically, llm gce achieves validity two method achieve almost zero validity feasiblity check fig fig show sensitivity method varying choice weight applied loss term weight applied loss term datasets aid clintox, scaling figure demonstrate validity proximity performance llm gce largely inversely related expected high validity corresponds low proximity, low validity corresponds high proximity intuitively, graph large perturbation less likely feasible, given input graph ground truth molecule conjecture relationship visible ignoring chemical feasibility since model free generate whatever graph need achieve high validity, leading high proximity well high validity find best validity proximity performance achieves simultaneously around datasets recommend one adopts ratio range also similar observation datasets since advent bert kenton toutanova transformer based pretrained language model plms research community made concerted effort significantly enhance performance scaling model large language model llm refer plms billion parameter shanahan trained large scale corpus able solve general purpose task currently, generative large language model bart lewis et al follow encoder decoder architecture presented original transformer paper vaswani et al benefiting excellent ability encoder understand contextual content, type model adept sequence sequence seq seq task sutskever et al translation however, text generation tasks, input sequence might directly match specific output text, creating story topic another type llm predominantly employ transformer decoder component, classifying decoder model study shown model excel text generation leveraging output text context, particularly enhancing unsupervised learning task radford et al currently, model gpt achiam et al llama touvron et al many llm xu et al primarily adopt decoder architecture gce problem become popular among research community, several work proposed recent year prado romero et al, ying et al, bajaj et al, lucic et al, et al, tan et al, huang et al, among them, gnnexplainer ying et al, aim find counterfactual maximizing mutual information gnn prediction distribution possible subgraphs however, gnnexplainer robust input noise address problem, rgcexplainer bajaj et al generates robust counterfactuals removing edge remaining graph decision boundary explanation robust decision boundary gnn last layer feature space, feature naturally robust perturbation similarly, cf gnnexplainer lucic et al, cf tan et al, also generate counterfactuals removing edge generated counterfactuals may violate causality, et al propose generative model, named clear, generate causally feasible counterfactuals besides, also method particularly designed certain domain, biomedical chemistry abrate bonchi, wu et al, recently, huang et al, propose first global level gce model, gcfexplainer, formulates global gce finding small set representative graph counterfactuals however, model overlook incorporation domain knowledge gce provide explanation cannot easily understood human proposed llm gce framework show encouraging result generating graph counterfactual explanation molecular property prediction here, propose several area future research could explore enhance capability applicability llm gce one direction investigate generalizability llm gce domain beyond molecular graphs, social network biological network would help assess framework versatility potential broader impact another avenue future work extend llm gce incorporate molecular structures, current framework focus molecular graph considering crucial role structure determining molecular properties, extension could lead accurate informative counterfactual explanation additionally, efficiency another important aspect consider future research could explore technique reduce computational cost improve scalability llm gce, knowledge distillation model compression would make framework accessible practical real world application finally, assess interpretability usefulness generated counterfactual explanations, future work could involve human evaluation user study study would provide valuable insight improving llm gce framework making user friendly domain expert since realistic metric adopted continuing improve html version papers, feedback help enhance accessibility mobile support report error html help u improve conversion rendering, choose method listed team already identified following issue appreciate time reviewing reporting rendering error may found yet effort help u improve html version readers, disability barrier accessing research thank continued support championing open access free development cycle help support accessibility arxiv collaborator latexml maintain list package need conversion, welcome developer contribution",biomolecules
